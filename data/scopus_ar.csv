Authors,Title,Year,Source title,Cited by,DOI,Link,Abstract,Author Keywords,Index Keywords,Document Type,Source
"Stoehr F., Kämpgen B., Müller L., Zufiría L.O., Junquero V., Merino C., Mildenberger P., Kloeckner R.","Natural language processing for automatic evaluation of free-text answers — a feasibility study based on the European Diploma in Radiology examination",2023,"Insights into Imaging",,"10.1186/s13244-023-01507-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171855477&doi=10.1186%2fs13244-023-01507-5&partnerID=40&md5=d98dcf8f7c4aded708481f58760f9ddd","Background: Written medical examinations consist of multiple-choice questions and/or free-text answers. The latter require manual evaluation and rating, which is time-consuming and potentially error-prone. We tested whether natural language processing (NLP) can be used to automatically analyze free-text answers to support the review process. Methods: The European Board of Radiology of the European Society of Radiology provided representative datasets comprising sample questions, answer keys, participant answers, and reviewer markings from European Diploma in Radiology examinations. Three free-text questions with the highest number of corresponding answers were selected: Questions 1 and 2 were “unstructured” and required a typical free-text answer whereas question 3 was “structured” and offered a selection of predefined wordings/phrases for participants to use in their free-text answer. The NLP engine was designed using word lists, rule-based synonyms, and decision tree learning based on the answer keys and its performance tested against the gold standard of reviewer markings. Results: After implementing the NLP approach in Python, F1 scores were calculated as a measure of NLP performance: 0.26 (unstructured question 1, n = 96), 0.33 (unstructured question 2, n = 327), and 0.5 (more structured question, n = 111). The respective precision/recall values were 0.26/0.27, 0.4/0.32, and 0.62/0.55. Conclusion: This study showed the successful design of an NLP-based approach for automatic evaluation of free-text answers in the EDiR examination. Thus, as a future field of application, NLP could work as a decision-support system for reviewers and support the design of examinations being adjusted to the requirements of an automated, NLP-based review process. Clinical relevance statement: Natural language processing can be successfully used to automatically evaluate free-text answers, performing better with more structured question-answer formats. Furthermore, this study provides a baseline for further work applying, e.g., more elaborated NLP approaches/large language models. Key points: • Free-text answers require manual evaluation, which is time-consuming and potentially error-prone. • We developed a simple NLP-based approach — requiring only minimal effort/modeling — to automatically analyze and mark free-text answers. • Our NLP engine has the potential to support the manual evaluation process. • NLP performance is better on a more structured question-answer format. Graphical Abstract: [Figure not available: see fulltext.] © 2023, European Society of Radiology (ESR).","Automatization; Education; Free-text answers; Natural language processing; Radiological","adult; article; automation; clinical significance; decision support system; decision tree; education; feasibility study; female; gold standard; human; human experiment; large language model; learning; major clinical study; male; natural language processing; radiology; recall",Article,Scopus
"Zhang X., Wu C., Zhang Y., Xie W., Wang Y.","Knowledge-enhanced visual-language pre-training on chest radiology images",2023,"Nature Communications",2,"10.1038/s41467-023-40260-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165742663&doi=10.1038%2fs41467-023-40260-7&partnerID=40&md5=701a13818ef55d7060290cacdddc580d","While multi-modal foundation models pre-trained on large-scale data have been successful in natural language understanding and vision recognition, their use in medical domains is still limited due to the fine-grained nature of medical tasks and the high demand for domain knowledge. To address this challenge, we propose an approach called Knowledge-enhanced Auto Diagnosis (KAD) which leverages existing medical domain knowledge to guide vision-language pre-training using paired chest X-rays and radiology reports. We evaluate KAD on four external X-ray datasets and demonstrate that its zero-shot performance is not only comparable to that of fully supervised models but also superior to the average of three expert radiologists for three (out of five) pathologies with statistical significance. Moreover, when few-shot annotation is available, KAD outperforms all existing approaches in fine-tuning settings, demonstrating its potential for application in different clinical scenarios. © 2023, The Author(s).",,"detection method; knowledge; language; vision; article; controlled study; diagnosis; human; human experiment; language; radiologist; statistical significance; thorax radiography; vision; X ray; knowledge; language; radiography; radiology; Humans; Knowledge; Language; Radiography; Radiologists; Radiology",Article,Scopus
"Lyu Q., Tan J., Zapadka M.E., Ponnatapura J., Niu C., Myers K.J., Wang G., Whitlow C.T.","Translating radiology reports into plain language using ChatGPT and GPT-4 with prompt learning: results, limitations, and potential",2023,"Visual Computing for Industry, Biomedicine, and Art",18,"10.1186/s42492-023-00136-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159966033&doi=10.1186%2fs42492-023-00136-5&partnerID=40&md5=2aa47089067bc0c04bae7a3f56e640da","The large language model called ChatGPT has drawn extensively attention because of its human-like expression and reasoning abilities. In this study, we investigate the feasibility of using ChatGPT in experiments on translating radiology reports into plain language for patients and healthcare providers so that they are educated for improved healthcare. Radiology reports from 62 low-dose chest computed tomography lung cancer screening scans and 76 brain magnetic resonance imaging metastases screening scans were collected in the first half of February for this study. According to the evaluation by radiologists, ChatGPT can successfully translate radiology reports into plain language with an average score of 4.27 in the five-point system with 0.08 places of information missing and 0.07 places of misinformation. In terms of the suggestions provided by ChatGPT, they are generally relevant such as keeping following-up with doctors and closely monitoring any symptoms, and for about 37% of 138 cases in total ChatGPT offers specific suggestions based on findings in the report. ChatGPT also presents some randomness in its responses with occasionally over-simplified or neglected information, which can be mitigated using a more detailed prompt. Furthermore, ChatGPT results are compared with a newly released large model GPT-4, showing that GPT-4 can significantly improve the quality of translated reports. Our results show that it is feasible to utilize large language models in clinical education, and further efforts are needed to address limitations and maximize their potential. © 2023, The Author(s).","Artificial intelligence; ChatGPT; Large language model; Patient education; Radiology report","Computational linguistics; Diagnosis; Health care; Magnetic resonance imaging; Radiology; Translation (languages); ChatGPT; Health care providers; Human like; Language model; Large language model; Low dose; Lung cancer screening; Patient education; Radiology reports; Reasoning ability; Computerized tomography",Article,Scopus
"Jorg T., Kämpgen B., Feiler D., Müller L., Düber C., Mildenberger P., Jungmann F.","Efficient structured reporting in radiology using an intelligent dialogue system based on speech recognition and natural language processing",2023,"Insights into Imaging",2,"10.1186/s13244-023-01392-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150858072&doi=10.1186%2fs13244-023-01392-y&partnerID=40&md5=d67cb63f691fb76729dd7f49b5c19cf8","Background: Structured reporting (SR) is recommended in radiology, due to its advantages over free-text reporting (FTR). However, SR use is hindered by insufficient integration of speech recognition, which is well accepted among radiologists and commonly used for unstructured FTR. SR templates must be laboriously completed using a mouse and keyboard, which may explain why SR use remains limited in clinical routine, despite its advantages. Artificial intelligence and related fields, like natural language processing (NLP), offer enormous possibilities to facilitate the imaging workflow. Here, we aimed to use the potential of NLP to combine the advantages of SR and speech recognition. Results: We developed a reporting tool that uses NLP to automatically convert dictated free text into a structured report. The tool comprises a task-oriented dialogue system, which assists the radiologist by sending visual feedback if relevant findings are missed. The system was developed on top of several NLP components and speech recognition. It extracts structured content from dictated free text and uses it to complete an SR template in RadLex terms, which is displayed in its user interface. The tool was evaluated for reporting of urolithiasis CTs, as a use case. It was tested using fictitious text samples about urolithiasis, and 50 original reports of CTs from patients with urolithiasis. The NLP recognition worked well for both, with an F1 score of 0.98 (precision: 0.99; recall: 0.96) for the test with fictitious samples and an F1 score of 0.90 (precision: 0.96; recall: 0.83) for the test with original reports. Conclusion: Due to its unique ability to integrate speech into SR, this novel tool could represent a major contribution to the future of reporting. © 2023, The Author(s).","Dialogue system; Natural language processing; Speech recognition; Structured reporting","Article; artificial intelligence; computer assisted tomography; human; intelligent dialogue system; machine learning; natural language processing; obstructive uropathy; procedures; radiologist; radiology; reporting and data system; speech discrimination; urolithiasis; visual feedback; workflow",Article,Scopus
"Silva W., Gonçalves T., Härmä K., Schröder E., Obmann V.C., Barroso M.C., Poellinger A., Reyes M., Cardoso J.S.","Author Correction: Computer-aided diagnosis through medical image retrieval in radiology (Scientific Reports, (2022), 12, 1, (20732), 10.1038/s41598-022-25027-2)",2023,"Scientific Reports",1,"10.1038/s41598-023-28523-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146783859&doi=10.1038%2fs41598-023-28523-1&partnerID=40&md5=6e02ebc96d16b633ba1ecfc6122d9f7a","The original version of this Article contained an error in the Acknowledgements section. “This work was partially funded by the Project TAMI—Transparent Artificial Medical Intelligence (NORTE- 01-0247-FEDER-045905) financed by ERDF—European Regional Fund through the North Portugal Regional Operational Program—NORTE 2020 and by the Portuguese Foundation for Science and Technology—FCT under the CMU—Portugal International Partnership, and also by the Portuguese Foundation for Science and Technology—FCT within PhD grants SFRH/BD/139468/2018 and 2020.06434.BD. The authors thank the Swiss National Science Foundation grant number 198388, as well as the Lindenhof foundation for their grant support.” now reads: “This work was supported by National Funds through the Portuguese Funding Agency, FCT–Foundation for Science and Technology Portugal, under Project LA/P/0063/2020, and also by the Portuguese Foundation for Science and Technology - FCT within PhD grants SFRH/BD/139468/2018 and 2020.06434.BD. The authors thank the Swiss National Science Foundation grant number 198388, as well as the Lindenhof foundation for their grant support.” The original Article has been corrected. © The Author(s) 2023.",,"erratum",Erratum,Scopus
"Zhang S., Zhou C., Chen L., Li Z., Gao Y., Chen Y.","Visual prior-based cross-modal alignment network for radiology report generation",2023,"Computers in Biology and Medicine",,"10.1016/j.compbiomed.2023.107522","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173624711&doi=10.1016%2fj.compbiomed.2023.107522&partnerID=40&md5=5f4071f9241d799dd27cf2445c03899e","Automated radiology report generation is gaining popularity as a means to alleviate the workload of radiologists and prevent misdiagnosis and missed diagnoses. By imitating the working patterns of radiologists, previous report generation approaches have achieved remarkable performance. However, these approaches suffer from two significant problems: (1) lack of visual prior: medical observations in radiology images are interdependent and exhibit certain patterns, and lack of such visual prior can result in reduced accuracy in identifying abnormal regions; (2) lack of alignment between images and texts: the absence of annotations and alignments for regions of interest in the radiology images and reports can lead to inconsistent visual and textual features of the abnormal regions generated by the model. To address these issues, we propose a Visual Prior-based Cross-modal Alignment Network for radiology report generation. First, we propose a novel Contrastive Attention that compares input image with normal images to extract difference information, namely visual prior, which helps to identify abnormalities quickly. Then, to facilitate the alignment of images and texts, we propose a Cross-modal Alignment Network that leverages the cross-modal matrix initialized by the features generated by pre-trained models, to compute cross-modal responses for visual and textual features. Finally, a Visual Prior-guided Multi-Head Attention is proposed to incorporate the visual prior into the generation process. The extensive experimental results on two benchmark datasets, IU-Xray and MIMIC-CXR, illustrate that our proposed model outperforms the state-of-the-art models over almost all metrics, achieving BLEU-4 scores of 0.188 and 0.116 and CIDEr scores of 0.409 and 0.240, respectively. © 2023 Elsevier Ltd","Contrastive attention; Cross-modal alignment; Multi-head attention; Radiology report generation; Visual prior","Diagnosis; Medical imaging; Medical problems; Radiology; Contrastive attention; Cross-modal; Cross-modal alignment; Multi-head attention; Radiology report generation; Radiology reports; Report generation; Textual features; Visual feature; Visual prior; Alignment",Article,Scopus
"Fink M.A.","From data to insights: how natural language processing and structured reporting advance data-driven radiology",2023,"European Radiology",,"10.1007/s00330-023-10242-w","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173098192&doi=10.1007%2fs00330-023-10242-w&partnerID=40&md5=40fd07faced813939eccdc6843cee816",[No abstract available],,,Note,Scopus
"Kim M., Ong K.T.-I., Choi S., Yeo J., Kim S., Han K., Park J.E., Kim H.S., Choi Y.S., Ahn S.S., Kim J., Lee S.-K., Sohn B.","Natural language processing to predict isocitrate dehydrogenase genotype in diffuse glioma using MR radiology reports",2023,"European Radiology",1,"10.1007/s00330-023-10061-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167840385&doi=10.1007%2fs00330-023-10061-z&partnerID=40&md5=71ae7ac172070fab5644096191099ab3","Objectives: To evaluate the performance of natural language processing (NLP) models to predict isocitrate dehydrogenase (IDH) mutation status in diffuse glioma using routine MR radiology reports. Materials and methods: This retrospective, multi-center study included consecutive patients with diffuse glioma with known IDH mutation status from May 2009 to November 2021 whose initial MR radiology report was available prior to pathologic diagnosis. Five NLP models (long short-term memory [LSTM], bidirectional LSTM, bidirectional encoder representations from transformers [BERT], BERT graph convolutional network [GCN], BioBERT) were trained, and area under the receiver operating characteristic curve (AUC) was assessed to validate prediction of IDH mutation status in the internal and external validation sets. The performance of the best performing NLP model was compared with that of the human readers. Results: A total of 1427 patients (mean age ± standard deviation, 54 ± 15; 779 men, 54.6%) with 720 patients in the training set, 180 patients in the internal validation set, and 527 patients in the external validation set were included. In the external validation set, BERT GCN showed the highest performance (AUC 0.85, 95% CI 0.81−0.89) in predicting IDH mutation status, which was higher than LSTM (AUC 0.77, 95% CI 0.72−0.81; p =.003) and BioBERT (AUC 0.81, 95% CI 0.76−0.85; p =.03). This was higher than that of a neuroradiologist (AUC 0.80, 95% CI 0.76−0.84; p =.005) and a neurosurgeon (AUC 0.79, 95% CI 0.76−0.84; p =.04). Conclusion: BERT GCN was externally validated to predict IDH mutation status in patients with diffuse glioma using routine MR radiology reports with superior or at least comparable performance to human reader. Clinical relevance statement: Natural language processing may be used to extract relevant information from routine radiology reports to predict cancer genotype and provide prognostic information that may aid in guiding treatment strategy and enabling personalized medicine. Key Points: • A transformer-based natural language processing (NLP) model predicted isocitrate dehydrogenase mutation status in diffuse glioma with an AUC of 0.85 in the external validation set. • The best NLP models were superior or at least comparable to human readers in both internal and external validation sets. • Transformer-based models showed higher performance than conventional NLP model such as long short-term memory. © 2023, The Author(s), under exclusive licence to European Society of Radiology.","Glioma; Isocitrate dehydrogenase; Natural language processing","isocitrate dehydrogenase; nicotinamide adenine dinucleotide; nicotinamide adenine dinucleotide phosphate; adult; area under the curve; Article; cancer model; cancer patient; cancer prognosis; clinical significance; controlled study; electronic health record; female; gene mutation; genotype; glioma; human; immunohistochemistry; language processing; long short term memory network; major clinical study; male; middle aged; mutation; natural language processing; neuroimaging; neuroradiologist; neurosurgeon; nuclear magnetic resonance; nuclear magnetic resonance imaging; oligodendroglioma; performance; personalized medicine; polymerase chain reaction; prediction; radiology; receiver operating characteristic; retrospective study; short term memory; tertiary care center",Article,Scopus
"Vosshenrich J., Nesic I., Boll D.T., Heye T.","Investigating the impact of structured reporting on the linguistic standardization of radiology reports through natural language processing over a 10-year period",2023,"European Radiology",1,"10.1007/s00330-023-10050-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166957610&doi=10.1007%2fs00330-023-10050-2&partnerID=40&md5=5c266a4b19e7561aa9f2ad73ebf4c9bd","Objectives: To investigate how a transition from free text to structured reporting affects reporting language with regard to standardization and distinguishability. Methods: A total of 747,393 radiology reports dictated between January 2011 and June 2020 were retrospectively analyzed. The body and cardiothoracic imaging divisions introduced a reporting concept using standardized language and structured reporting templates in January 2016. Reports were segmented by a natural language processing algorithm and converted into a 20-dimension document vector. For analysis, dimensionality was reduced to a 2D visualization with t-distributed stochastic neighbor embedding and matched with metadata. Linguistic standardization was assessed by comparing distinct report types’ vector spreads (e.g., run-off MR angiography) between reporting standards. Changes in report type distinguishability (e.g., CT abdomen/pelvis vs. MR abdomen) were measured by comparing the distance between their centroids. Results: Structured reports showed lower document vector spread (thus higher linguistic similarity) compared with free-text reports overall (21.9 [free-text] vs. 15.9 [structured]; − 27.4%; p < 0.001) and for most report types, e.g., run-off MR angiography (15.2 vs. 1.8; − 88.2%; p < 0.001) or double-rule-out CT (26.8 vs. 10.0; − 62.7%; p < 0.001). No changes were observed for reports continued to be written in free text, e.g., CT head reports (33.2 vs. 33.1; − 0.3%; p = 1). Distances between the report types’ centroids increased with structured reporting (thus better linguistic distinguishability) overall (27.3 vs. 54.4; + 99.3 ± 98.4%) and for specific report types, e.g., CT abdomen/pelvis vs. MR abdomen (13.7 vs. 37.2; + 171.5%). Conclusion: Structured reporting and the use of factual language yield more homogenous and standardized radiology reports on a linguistic level, tailored to specific reporting scenarios and imaging studies. Clinical relevance: Information transmission to referring physicians, as well as automated report assessment and content extraction in big data analyses, may benefit from standardized reporting, due to consistent report organization and terminology used for pathologies and normal findings. Key Points: • Natural language processing and t-distributed stochastic neighbor embedding can transform radiology reports into numeric vectors, allowing the quantification of their linguistic standardization. • Structured reporting substantially increases reports’ linguistic standardization (mean: − 27.4% in vector spread) and distinguishability (mean: + 99.3 ± 98.4% increase in vector distance) compared with free-text reports. • Higher standardization and homogeneity outline potential benefits of structured reporting for information transmission and big data analyses. © 2023, The Author(s).","Language; Linguistics; Radiology; Report; Standardization","abdomen; algorithm; article; big data; clinical significance; controlled study; embedding; extraction; human; human experiment; linguistics; magnetic resonance angiography; metadata; natural language processing; nomenclature; pelvis; physician; radiology; retrospective study; standardization; stochastic model",Article,Scopus
"Liu Y., Liu W., Chen H., Xie S., Wang C., Liang T., Yu Y., Liu X.","Artificial intelligence versus radiologist in the accuracy of fracture detection based on computed tomography images: a multidimensional, multi-region analysis",2023,"Quantitative Imaging in Medicine and Surgery",,"10.21037/qims-23-428","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173848811&doi=10.21037%2fqims-23-428&partnerID=40&md5=8f1c9f76b13191af9fc1b6c81b38d21d","Background: Extremities fractures are a leading cause of death and disability, especially in the elderly. Avulsion fracture are also the most commonly missed diagnosis, and delayed diagnosis leads to higher litigation rates. Therefore, this study evaluates the diagnostic efficiency of the artificial intelligence (AI) model before and after optimization based on computed tomography (CT) images and then compares it with that of radiologists, especially for avulsion fractures. Methods: The digital X-ray photography [digital radiography (DR)] and CT images of adult limb trauma in our hospital from 2017 to 2020 were retrospectively collected, with or without 1 or more fractures of the shoulder, elbow, wrist, hand, hip, knee, ankle, and foot. Labeling of the fracture referred to the visualization of the fracture on the corresponding CT images. After training the pre-optimized AI model, the diagnostic performance of the pre-optimized AI, optimized AI model, and the initial radiological reports were evaluated. For the lesion level, the detection rate of avulsion and non-avulsion fractures was analyzed, whereas for the case level, the accuracy, sensitivity, and specificity were compared among them. Results: The total datasets (1,035 cases) were divided into a training set (n=675), a validation set (n=169), and a test set (n=191) in a balanced joint distribution. At the lesion level, the detection rates of avulsion fracture (57.89% vs. 35.09%, P=0.004) and non-avulsion fracture (85.64% vs. 71.29%, P<0.001) by the optimized AI were significantly higher than that by pre-optimized AI. The average precision (AP) of the optimized AI model for all lesions was higher than that of pre-optimized AI model (0.582 vs. 0.425). The detection rate of avulsion fracture by the optimized AI model was significantly higher than that by radiologists (57.89% vs. 29.82%, P=0.002). For the non-avulsion fracture, there was no significant difference of detection rate between the optimized AI model and radiologists (P=0.853). At the case level, the accuracy (86.40% vs. 71.93%, P<0.001) and sensitivity (87.29% vs. 73.48%, P<0.001) of the optimized AI were significantly higher than those of the pre-optimized AI model. There was no statistical difference in accuracy, sensitivity, and specificity between the optimized AI model and the radiologists (P>0.05). Conclusions: The optimized AI model improves the diagnostic efficacy in detecting extremity fractures on radiographs, and the optimized AI model is significantly better than radiologists in detecting avulsion fractures, which may be helpful in the clinical practice of orthopedic emergency. © 2023 AME Publishing Company. All rights reserved.","Artificial intelligence (AI); deep learning; diagnostic efficiency; fracture","adult; aged; algorithm; Article; artificial intelligence; avulsion fracture; computer assisted tomography; controlled study; detection algorithm; diagnostic test accuracy study; digital imaging and communications in medicine; digital radiography; female; human; major clinical study; male; radiodiagnosis; radiologist; retrospective study; sensitivity and specificity; ulna fracture",Article,Scopus
"Mukherjee P., Hou B., Lanfredi R.B., Summers R.M.","Feasibility of Using the Privacy-preserving Large Language Model Vicuna for Labeling Radiology Reports",2023,"Radiology",1,"10.1148/radiol.231147","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173334559&doi=10.1148%2fradiol.231147&partnerID=40&md5=d63b279816b7f8242e4f02f5fbdb19cd","Background: Large language models (LLMs) such as ChatGPT, though proficient in many text-based tasks, are not suitable for use with radiology reports due to patient privacy constraints. Purpose: To test the feasibility of using an alternative LLM (Vicuna-13B) that can be run locally for labeling radiography reports. Materials and Methods: Chest radiography reports from the MIMIC-CXR and National Institutes of Health (NIH) data sets were included in this retrospective study. Reports were examined for 13 findings. Outputs reporting the presence or absence of the 13 findings were generated by Vicuna by using a single-step or multistep prompting strategy (prompts 1 and 2, respectively). Agreements between Vicuna outputs and CheXpert and CheXbert labelers were assessed using Fleiss κ. Agreement between Vicuna outputs from three runs under a hyperparameter setting that introduced some randomness (temperature, 0.7) was also assessed. The performance of Vicuna and the labelers was assessed in a subset of 100 NIH reports annotated by a radiologist with use of area under the receiver operating characteristic curve (AUC). Results: A total of 3269 reports from the MIMIC-CXR data set (median patient age, 68 years [IQR, 59-79 years]; 161 male patients) and 25 596 reports from the NIH data set (median patient age, 47 years [IQR, 32-58 years]; 1557 male patients) were included. Vicuna outputs with prompt 2 showed, on average, moderate to substantial agreement with the labelers on the MIMIC-CXR (κ median, 0.57 [IQR, 0.45-0.66] with CheXpert and 0.64 [IQR, 0.45-0.68] with CheXbert) and NIH (κ median, 0.52 [IQR, 0.41-0.65] with CheXpert and 0.55 [IQR, 0.41-0.74] with CheXbert) data sets, respectively. Vicuna with prompt 2 performed at par (median AUC, 0.84 [IQR, 0.74-0.93]) with both labelers on nine of 11 findings. Conclusion: In this proof-of-concept study, outputs of the LLM Vicuna reporting the presence or absence of 13 findings on chest radiography reports showed moderate to substantial agreement with existing labelers. © 2023 Radiological Society of North America Inc.. All rights reserved.",,"adult; article; feasibility study; human; large language model; major clinical study; male; national health organization; nonhuman; privacy; proof of concept; radiologist; receiver operating characteristic; retrospective study; thorax radiography; vicuna; aged; animal; feasibility study; language; middle aged; New World camelid; privacy; radiology; United States; Aged; Animals; Camelids, New World; Feasibility Studies; Humans; Language; Male; Middle Aged; Privacy; Radiology; Retrospective Studies; United States",Article,Scopus
"Cai W.","Feasibility and Prospect of Privacy-preserving Large Language Models in Radiology",2023,"Radiology",,"10.1148/radiol.232335","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173297410&doi=10.1148%2fradiol.232335&partnerID=40&md5=ee11ac3085d7bd9a7d05bd47f35bd804",[No abstract available],,"feasibility study; human; privacy; radiography; radiology; Feasibility Studies; Humans; Privacy; Radiography; Radiology",Editorial,Scopus
"Hou X., Liu Z., Li X., Li X., Sang S., Zhang Y.","MKCL: Medical Knowledge with Contrastive Learning model for radiology report generation",2023,"Journal of Biomedical Informatics",,"10.1016/j.jbi.2023.104496","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172987099&doi=10.1016%2fj.jbi.2023.104496&partnerID=40&md5=d42e5d977bc750713688e3768193d45c","Automatic radiology report generation has the potential to alert inexperienced radiologists to misdiagnoses or missed diagnoses and improve healthcare delivery efficiency by reducing the documentation workload of radiologists. Motivated by the continuous development of automatic image captioning, more and more deep learning methods have been proposed for automatic radiology report generation. However, the visual and textual data bias problem still face many challenges in the medical domain. Additionally, do not integrate medical knowledge, ignoring the mutual influences between medical findings, and abundant unlabeled medical images influence the accuracy of generating report. In this paper, we propose a Medical Knowledge with Contrastive Learning model (MKCL) to enhance radiology report generation. The proposed model MKCL uses IU Medical Knowledge Graph (IU-MKG) to mine the relationship among medical findings and improve the accuracy of identifying positive diseases findings from radiologic medical images. In particular, we design Knowledge Enhanced Attention (KEA), which integrates the IU-MKG and the extracted chest radiological visual features to alleviate textual data bias. Meanwhile, this paper leverages supervised contrastive learning to relieve radiographic medical images which have not been labeled, and identify abnormalities from images. Experimental results on the public dataset IU X-ray show that our proposed model MKCL outperforms other state-of-the-art report generation methods. Ablation studies also demonstrate that IU medical knowledge graph module and supervised contrastive learning module enhance the ability of the model to detect the abnormal parts and accurately describe the abnormal findings. The source code is available at: https://github.com/Eleanorhxd/MKCL. © 2023 Elsevier Inc.","Medical knowledge graph; Radiology report generation; Supervised contrastive learning","Diagnosis; Image enhancement; Knowledge graph; Learning systems; Medical imaging; Radiology; Healthcare delivery; Knowledge graphs; Learning models; Medical knowledge; Medical knowledge graph; Radiology report generation; Radiology reports; Report generation; Supervised contrastive learning; Textual data; Deep learning; accuracy; Article; automation; computer model; health care delivery; human; image analysis; knowledge; learning; Medical Knowledge with Contrastive Learning model; radiodiagnosis; radiology; reporting and data system; documentation; knowledge; radiography; radiologist; Documentation; Humans; Knowledge; Radiography; Radiologists; Radiology",Article,Scopus
"Tzanis E., Damilakis J.","A neural network-enhanced methodology for the rapid establishment of local DRLs in interventional radiology: EVAR as a case example",2023,"Physica Medica",,"10.1016/j.ejmp.2023.103140","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171993271&doi=10.1016%2fj.ejmp.2023.103140&partnerID=40&md5=c66d962ba33302514a2d9f50cd67c2ae","Purpose: To develop a neural network-enhanced workflow for the automatic and rapid establishment/update of local diagnostic reference levels (DRLs) in interventional radiology (IR) using endovascular aneurysm repair (EVAR) procedures as a case example. Methods: Radiation dose reports were collected retrospectively for 46 consecutive EVAR procedures. These reports served as demonstrative data for the development of the proposed methodology. An algorithm was developed to receive multiple dose reports, automatically extract the kerma area product (KAP), air kerma (Ka,r), number of exposure images, and fluoroscopy time (FT) from each report and calculate the first, second, third quartiles as well as the maximum and minimum values of the extracted parameters. To extract the values of interest from the dose reports, Tesseract, an open-source optical character recognition (OCR) engine was employed. Furthermore, the accuracy and time efficiency of the proposed methodology were assessed. Specifically, the values extracted from the algorithm were compared with the ground truth values and the algorithm's processing time was compared with the respective time needed to manually extract and process the values of interest. Results: The OCR-based algorithm managed to correctly recognize 182 from the 184 target values, resulting in an accuracy of 99%. Moreover, the proposed pipeline reduced the processing time for the establishment of DRLs by 98%. DRL value for EVAR procedures, set as the third quartile of KAP was found to be 551 Gy*cm2. Conclusion: An accurate and time-efficient workflow was developed for the establishment of local DRLs in interventional radiology. © 2023","Diagnostic reference levels; Endovascular aneurysm repair; Interventional radiology; Natural language processing; Radiation protection","algorithm; article; clinical article; controlled study; diagnosis; diagnostic reference level; endovascular aneurysm repair; fluoroscopy; human; interventional radiology; multiple drug dose; natural language processing; optical character recognition; pipeline; radiation dose; radiation protection; retrospective study; workflow",Article,Scopus
"Sebro R.A., Kahn C.E.","Automated detection of causal relationships among diseases and imaging findings in textual radiology reports",2023,"Journal of the American Medical Informatics Association : JAMIA",,"10.1093/jamia/ocad119","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172740038&doi=10.1093%2fjamia%2focad119&partnerID=40&md5=310a3b2ce3c00e52f0c89d799d2b8069","OBJECTIVE: Textual radiology reports contain a wealth of information that may help understand associations among diseases and imaging observations. This study evaluated the ability to detect causal associations among diseases and imaging findings from their co-occurrence in radiology reports. MATERIALS AND METHODS: This IRB-approved and HIPAA-compliant study analyzed 1 702 462 consecutive reports of 1 396 293 patients; patient consent was waived. Reports were analyzed for positive mention of 16 839 entities (disorders and imaging findings) of the Radiology Gamuts Ontology (RGO). Entities that occurred in fewer than 25 patients were excluded. A Bayesian network structure-learning algorithm was applied at P < 0.05 threshold: edges were evaluated as possible causal relationships. RGO and/or physician consensus served as ground truth. RESULTS: 2742 of 16 839 RGO entities were included, 53 849 patients (3.9%) had at least one included entity. The algorithm identified 725 pairs of entities as causally related; 634 were confirmed by reference to RGO or physician review (87% precision). As shown by its positive likelihood ratio, the algorithm increased detection of causally associated entities 6876-fold. DISCUSSION: Causal relationships among diseases and imaging findings can be detected with high precision from textual radiology reports. CONCLUSION: This approach finds causal relationships among diseases and imaging findings with high precision from textual radiology reports, despite the fact that causally related entities represent only 0.039% of all pairs of entities. Applying this approach to larger report text corpora may help detect unspecified or heretofore unrecognized associations. © The Author(s) 2023. Published by Oxford University Press on behalf of the American Medical Informatics Association. All rights reserved. For permissions, please email: journals.permissions@oup.com.","biomedical ontologies (D064229); correlation of data (D000078331); data mining (D057225); etiology (Q000209); machine learning (D000069550); natural language processing (D009323); radiology (D011871); radiology information systems (D011873)","graphene oxide; Bayes theorem; diagnostic imaging; human; natural language processing; radiography; radiology; Bayes Theorem; Diagnostic Imaging; Humans; Natural Language Processing; Radiography; Radiology; Radiology Information Systems",Article,Scopus
"Tan R.S.Y.C., Lin Q., Low G.H., Lin R., Goh T.C., Chang C.C.E., Lee F.F., Chan W.Y., Tan W.C., Tey H.J., Leong F.L., Tan H.Q., Nei W.L., Chay W.Y., Tai D.W.M., Lai G.G.Y., Cheng L.T.-E., Wong F.Y., Chua M.C.H., Chua M.L.K., Tan D.S.W., Thng C.H., Tan I.B.H., Ng H.T.","Inferring cancer disease response from radiology reports using large language models with data augmentation and prompting",2023,"Journal of the American Medical Informatics Association : JAMIA",,"10.1093/jamia/ocad133","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172739874&doi=10.1093%2fjamia%2focad133&partnerID=40&md5=8a443fa7b1d3ec03cfba1332d5116e0a","OBJECTIVE: To assess large language models on their ability to accurately infer cancer disease response from free-text radiology reports. MATERIALS AND METHODS: We assembled 10 602 computed tomography reports from cancer patients seen at a single institution. All reports were classified into: no evidence of disease, partial response, stable disease, or progressive disease. We applied transformer models, a bidirectional long short-term memory model, a convolutional neural network model, and conventional machine learning methods to this task. Data augmentation using sentence permutation with consistency loss as well as prompt-based fine-tuning were used on the best-performing models. Models were validated on a hold-out test set and an external validation set based on Response Evaluation Criteria in Solid Tumors (RECIST) classifications. RESULTS: The best-performing model was the GatorTron transformer which achieved an accuracy of 0.8916 on the test set and 0.8919 on the RECIST validation set. Data augmentation further improved the accuracy to 0.8976. Prompt-based fine-tuning did not further improve accuracy but was able to reduce the number of training reports to 500 while still achieving good performance. DISCUSSION: These models could be used by researchers to derive progression-free survival in large datasets. It may also serve as a decision support tool by providing clinicians an automated second opinion of disease response. CONCLUSIONS: Large clinical language models demonstrate potential to infer cancer disease response from radiology reports at scale. Data augmentation techniques are useful to further improve performance. Prompt-based fine-tuning can significantly reduce the size of the training dataset. © The Author(s) 2023. Published by Oxford University Press on behalf of the American Medical Informatics Association.","cancer; healthcare; large language models; natural language processing; radiology","artificial neural network; diagnostic imaging; human; machine learning; natural language processing; neoplasm; radiology; research; Humans; Machine Learning; Natural Language Processing; Neoplasms; Neural Networks, Computer; Radiology; Research Report",Article,Scopus
"Yu F., Endo M., Krishnan R., Pan I., Tsai A., Reis E.P., Fonseca E.K.U.N., Lee H.M.H., Abad Z.S.H., Ng A.Y., Langlotz C.P., Venugopal V.K., Rajpurkar P.","Evaluating progress in automatic chest X-ray radiology report generation",2023,"Patterns",1,"10.1016/j.patter.2023.100802","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169793819&doi=10.1016%2fj.patter.2023.100802&partnerID=40&md5=2c0a3dd1bdd9d37ced5ccc7b084b873e","Artificial intelligence (AI) models for automatic generation of narrative radiology reports from images have the potential to enhance efficiency and reduce the workload of radiologists. However, evaluating the correctness of these reports requires metrics that can capture clinically pertinent differences. In this study, we investigate the alignment between automated metrics and radiologists' scoring of errors in report generation. We address the limitations of existing metrics by proposing new metrics, RadGraph F1 and RadCliQ, which demonstrate stronger correlation with radiologists' evaluations. In addition, we analyze the failure modes of the metrics to understand their limitations and provide guidance for metric selection and interpretation. This study establishes RadGraph F1 and RadCliQ as meaningful metrics for guiding future research in radiology report generation. © 2023","alignment with radiologists; automatic metrics; chest X-ray radiology report generation; DSML 2: Proof-of-concept: Data science output has been formulated, implemented, and tested for one domain/problem","Radiology; Alignment with radiologist; Automatic metrics; Chest X-ray radiology report generation; Domain problems; DSML 2: proof-of-concept: data science output have been formulated, implemented, and tested for one domain/problem; Intelligence models; Proof of concept; Radiology reports; Report generation; X-ray radiology; Image enhancement",Article,Scopus
"Amin K., Khosla P., Doshi R., Chheang S., Forman H.P.","Artificial Intelligence to Improve Patient Understanding of Radiology Reports",2023,"Yale Journal of Biology and Medicine",,"10.59249/NKOY5498","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172993037&doi=10.59249%2fNKOY5498&partnerID=40&md5=4fdf68605e06bdc8db45ee9722d1e204","Diagnostic imaging reports are generally written with a target audience of other providers. As a result, the reports are written with medical jargon and technical detail to ensure accurate communication. With implementation of the 21st Century Cures Act, patients have greater and quicker access to their imaging reports, but these reports are still written above the comprehension level of the average patient. Consequently, many patients have requested reports to be conveyed in language accessible to them. Numerous studies have shown that improving patient understanding of their condition results in better outcomes, so driving comprehension of imaging reports is essential. Summary statements, second reports, and the inclusion of the radiologist’s phone number have been proposed, but these solutions have implications for radiologist workflow. Artificial intelligence (AI) has the potential to simplify imaging reports without significant disruptions. Many AI technologies have been applied to radiology reports in the past for various clinical and research purposes, but patient focused solutions have largely been ignored. New natural language processing technologies and large language models (LLMs) have the potential to improve patient understanding of their imaging reports. However, LLMs are a nascent technology and significant research is required before LLM-driven report simplification is used in patient care. © 2023,Yale Journal of Biology and Medicine Inc. All rights reserved.","21st Century Cures Act; Artificial Intelligence; Imaging Report; Large Language Model; NaturaLanguage Processing; Radiology Report","artificial intelligence; human; interpersonal communication; procedures; radiology; Artificial Intelligence; Communication; Humans; Radiology",Short Survey,Scopus
"Borondy Kitts A.","Patient Perspectives on Artificial Intelligence in Radiology",2023,"Journal of the American College of Radiology",1,"10.1016/j.jacr.2023.05.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168811974&doi=10.1016%2fj.jacr.2023.05.017&partnerID=40&md5=fb17170485d290f8b7d81c0cd5eedf6d","There are two major areas for patient engagement in radiology artificial intelligence (AI). One is in the sharing of data for AI development; the second is the use of AI in patient care. In general, individuals support sharing deidentified data if used for the common good, to help others with similar health conditions, or for research. However, there is concern with risk to privacy including reidentification and use for other than intended purposes. Lack of trust is mentioned as a barrier for data sharing. Individuals want to be involved in the data-sharing process. In the use of AI in medical care, patients generally support AI as an assist to the radiologist but lack trust in unsupervised AI. Patients worry about liability in case of bad outcomes. Patients are concerned about loss of the human connection and the loss of empathy during a vulnerable time in their lives. Patients expressed concern about risk of discrimination due to bias in AI algorithms. Building trust in AI requires transparency, explainability, security, and privacy protection. Radiologists can take action to prepare their patients to become more trusting of AI. Developing and implementing data-sharing agreements allows patients to voluntarily help in the algorithm development process. Developing AI disclosure guidelines and having AI use disclosure discussions with patients will help them understand the use of AI in their care. As the use of AI increases, there is an opportunity for radiologists to develop and maintain close relationships with their patients and to become more involved in their care. © 2023 American College of Radiology","AI in medical care; AI in radiology; data sharing; patient perspective on AI","adult; anonymised data; article; artificial intelligence; case report; clinical article; empathy; female; human; male; medical care; outcome assessment; patient care; patient engagement; patient worry; practice guideline; privacy; radiologist; radiology; risk assessment; security; trust; algorithm; Algorithms; Artificial Intelligence; Humans; Privacy; Radiologists; Radiology",Article,Scopus
"Abbasi N., Lacson R., Kapoor N., Licaros A., Guenette J.P., Burk K.S., Hammer M., Desai S., Eappen S., Saini S., Khorasani R.","Development and External Validation of an Artificial Intelligence Model for Identifying Radiology Reports Containing Recommendations for Additional Imaging",2023,"AJR. American journal of roentgenology",,"10.2214/AJR.23.29120","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168784450&doi=10.2214%2fAJR.23.29120&partnerID=40&md5=cc05a8f9fd1fc9f5af6f02999c68ddd9","BACKGROUND. Reported rates of recommendations for additional imaging (RAIs) in radiology reports are low. Bidirectional encoder representations from transformers (BERT), a deep learning model pretrained to understand language context and ambiguity, has potential for identifying RAIs and thereby assisting large-scale quality improvement efforts. OBJECTIVE. The purpose of this study was to develop and externally validate an artificial intelligence (AI)-based model for identifying radiology reports containing RAIs. METHODS. This retrospective study was performed at a multisite health center. A total of 6300 radiology reports generated at one site from January 1, 2015, to June 30, 2021, were randomly selected and split by 4:1 ratio to create training (n = 5040) and test (n = 1260) sets. A total of 1260 reports generated at the center's other sites (including academic and community hospitals) from April 1 to April 30, 2022, were randomly selected as an external validation group. Referring practitioners and radiologists of varying sub-specialties manually reviewed report impressions for presence of RAIs. A BERT-based technique for identifying RAIs was developed by use of the training set. Performance of the BERT-based model and a previously developed traditional machine learning (TML) model was assessed in the test set. Finally, performance was assessed in the external validation set. The code for the BERT-based RAI model is publicly available. RESULTS. Among a total of 7419 unique patients (4133 women, 3286 men; mean age, 58.8 years), 10.0% of 7560 reports contained RAI. In the test set, the BERT-based model had 94.4% precision, 98.5% recall, and an F1 score of 96.4%. In the test set, the TML model had 69.0% precision, 65.4% recall, and an F1 score of 67.2%. In the test set, accuracy was greater for the BERT-based than for the TML model (99.2% vs 93.1%, p < .001). In the external validation set, the BERT-based model had 99.2% precision, 91.6% recall, an F1 score of 95.2%, and 99.0% accuracy. CONCLUSION. The BERT-based AI model accurately identified reports with RAIs, outperforming the TML model. High performance in the external validation set suggests the potential for other health systems to adapt the model without requiring institution-specific training. CLINICAL IMPACT. The model could potentially be used for real-time EHR monitoring for RAIs and other improvement initiatives to help ensure timely performance of clinically necessary recommended follow-up.","artificial intelligence; external validation; natural language processing; quality and safety improvement; recommendations for additional imaging","artificial intelligence; diagnostic imaging; female; human; male; middle aged; natural language processing; radiography; radiology; retrospective study; Artificial Intelligence; Diagnostic Imaging; Female; Humans; Male; Middle Aged; Natural Language Processing; Radiography; Radiology; Retrospective Studies",Article,Scopus
"Meyer C.A., Klein J.S., Liubauskas R., Bhalla S., Eisenberg R.L.","Cardiothoracic Radiologist Workload, Work Capacity, and Burnout Post-COVID: Results of a Survey From the Society of Thoracic Radiology",2023,"Journal of Thoracic Imaging",,"10.1097/RTI.0000000000000710","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168427700&doi=10.1097%2fRTI.0000000000000710&partnerID=40&md5=319563ae21225c93ed952a8c72b2b18e","In this report and analysis of the results of a late 2021 post-COVID pandemic survey of members of the Society of Thoracic Radiology, we compared cardiothoracic radiologist workloads and burnout rates with those obtained from a prepandemic survey of society members. The more recent survey also asked respondents to provide a subjective assessment of their individual workload capacity should they be required to read cases at a section average daily case work volume, and this assessment was correlated with burnout rates. To measure nonrelative value unit workload, we requested data on non-case-related work responsibilities including teaching and multidisciplinary conferences that were not assessed in the first survey. In addition, we asked respondents to provide information on the availability of support services, personnel, and hardware and software tools that could improve work efficiency and reduce radiologist stress levels thereby mitigating burnout. We found that postpandemic case workload and cardiothoracic radiologists' burnout rates were similarly high compared with prepandemic levels with an overall burnout rate of 88% including a 100% burnout rate among women which had significantly increased. The range of radiologists' workload capacity is broad, although 80% of respondents reported that reading at an average sectional case volume was at or above their capacity, and the perceived capacity correlated with burnout measures. The presence of fellows and computer-aided diagnosis/artificial intelligence tools were each associated with significant decreases in burnout, providing 2 potential strategies that could be employed to address high cardiothoracic radiologist burnout rates. © 2023 Lippincott Williams and Wilkins. All rights reserved.","burnout; cardiothoracic radiology; computed tomography; workload","achievement; adult; Africa; Article; Asia; burnout; Canada; career; computer assisted tomography; controlled study; demographics; Europe; female; government; human; long COVID; lung biopsy; major clinical study; male; medical student; multidisciplinary team; nuclear magnetic resonance imaging; overall response rate; personnel; physician assistant; productivity; radiologist; radiologist assistant; resident; responsibility; society; South America; student; teaching; thoracocentesis; thorax radiography; time; training; United States; university; work capacity; workload; artificial intelligence; coronavirus disease 2019; education; professional burnout; questionnaire; radiologist; radiology; workload; Artificial Intelligence; Burnout, Professional; COVID-19; Female; Humans; Radiologists; Radiology; Surveys and Questionnaires; Workload",Article,Scopus
"Batra K., Xi Y., Bhagwat S., Espino A., Peshock R.M.","Radiologist Worklist Reprioritization Using Artificial Intelligence: Impact on Report Turnaround Times for CTPA Examinations Positive for Acute Pulmonary Embolism",2023,"AJR. American journal of roentgenology",1,"10.2214/AJR.22.28949","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166200996&doi=10.2214%2fAJR.22.28949&partnerID=40&md5=7c116562cea121be0e50fe4365f5d0ab","BACKGROUND. In patients with acute pulmonary embolism (PE), timely intervention (e.g., initiation of anticoagulation) is critical for optimizing clinical outcomes. OBJECTIVE. The purpose of this study was to evaluate the effect of artificial intelligence (AI)-based radiologist worklist reprioritization on report turnaround times for pulmonary CTA (CTPA) examinations positive for acute PE. METHODS. This retrospective single-center study included patients who underwent CTPA before (October 1, 2018-March 31, 2019 [pre-AI period]) and after (October 1, 2019-March 31, 2020 [post-AI period]) implementation of an AI tool that reprioritized CTPA examinations to the top of radiologists' reading worklists if acute PE was detected. EMR and dictation system timestamps were used to determine the wait time (time from examination completion to report initiation), read time (time from report initiation to report availability), and report turnaround time (sum of wait and read times) for the examinations. Times for reports positive for PE, with final radiology reports as reference, were compared between periods. RESULTS. The study included 2501 examinations of 2197 patients (1307 women, 890 men; mean age, 57.4 ± 17.0 [SD] years), including 1335 examinations from the pre-AI period and 1166 from the post-AI period. The frequency of acute PE, based on radiology reports, was 15.1% (201/1335) during the pre-AI period and 12.3% (144/1166) during the post-AI period. During the post-AI period, the AI tool reprioritized 12.7% (148/1166) of examinations. For PE-positive examinations, the post-AI period, compared with the pre-AI period, had significantly shorter mean report turnaround time (47.6 vs 59.9 minutes; mean difference, 12.3 minutes [95% CI, 0.6-26.0 minutes]) and mean wait time (21.4 vs 33.4 minutes; mean difference, 12.0 minutes [95% CI, 0.9-25.3 minutes]) but no significant difference in mean read time (26.3 vs 26.5 minutes; mean difference, 0.2 minutes [95% CI, -2.8 to 3.2 minutes]). During regular operational hours, wait time was significantly shorter in the post-AI than in the pre-AI period for routine-priority examinations (15.3 vs 43.7 minutes; mean difference, 28.4 minutes [95% CI, 2.2-64.7 minutes]) but not for stat- or urgent-priority examinations. CONCLUSION. AI-driven worklist reprioritization yielded reductions in report turnaround time and wait time for PE-positive CTPA examinations. CLINICAL IMPACT. By assisting radiologists in providing rapid diagnoses, the AI tool has potential for enabling earlier interventions for acute PE.","artificial intelligence; CT angiography; CTA; pulmonary embolism; reprioritization; turnaround time","acute disease; adult; aged; artificial intelligence; computed tomographic angiography; diagnostic imaging; female; human; lung embolism; male; middle aged; procedures; radiologist; retrospective study; Acute Disease; Adult; Aged; Artificial Intelligence; Computed Tomography Angiography; Female; Humans; Male; Middle Aged; Pulmonary Embolism; Radiologists; Retrospective Studies",Article,Scopus
"Li H., Moon J.T., Iyer D., Balthazar P., Krupinski E.A., Bercu Z.L., Newsome J.M., Banerjee I., Gichoya J.W., Trivedi H.M.","Decoding radiology reports: Potential application of OpenAI ChatGPT to enhance patient understanding of diagnostic reports",2023,"Clinical Imaging",4,"10.1016/j.clinimag.2023.06.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162156868&doi=10.1016%2fj.clinimag.2023.06.008&partnerID=40&md5=f0c826be01eb28718f3fd1300f72c4dd","Purpose: To evaluate the complexity of diagnostic radiology reports across major imaging modalities and the ability of ChatGPT (Early March 2023 Version, OpenAI, California, USA) to simplify these reports to the 8th grade reading level of the average U.S. adult. Methods: We randomly sampled 100 radiographs (XR), 100 ultrasound (US), 100 CT, and 100 MRI radiology reports from our institution's database dated between 2022 and 2023 (N = 400). These were processed by ChatGPT using the prompt “Explain this radiology report to a patient in layman's terms in second person: <Report Text>”. Mean report length, Flesch reading ease score (FRES), and Flesch-Kincaid reading level (FKRL) were calculated for each report and ChatGPT output. T-tests were used to determine significance. Results: Mean report length was 164 ± 117 words, FRES was 38.0 ± 11.8, and FKRL was 10.4 ± 1.9. FKRL was significantly higher for CT and MRI than for US and XR. Only 60/400 (15%) had a FKRL <8.5. The mean simplified ChatGPT output length was 103 ± 36 words, FRES was 83.5 ± 5.6, and FKRL was 5.8 ± 1.1. This reflects a mean decrease of 61 words (p < 0.01), increase in FRES of 45.5 (p < 0.01), and decrease in FKRL of 4.6 (p < 0.01). All simplified outputs had FKRL <8.5. Discussion: Our study demonstrates the effective use of ChatGPT when tasked with simplifying radiology reports to below the 8th grade reading level. We report significant improvements in FRES, FKRL, and word count, the last of which requires modality-specific context. © 2023 Elsevier Inc.","21st century cures act; Large language model; Natural language processing; Patient-centered reports","Computerized tomography; Radiology; 21st century cure act; Diagnostic Report; Language model; Language processing; Large language model; Natural language processing; Natural languages; Patient-centered report; Radiology reports; Reading level; Natural language processing systems; Article; computer assisted tomography; controlled study; data extraction; data processing; echography; human; nuclear magnetic resonance imaging; radiodiagnosis; radiography; reading; retrospective study; adult; comprehension; factual database; radiology; Adult; Comprehension; Databases, Factual; Humans; Magnetic Resonance Imaging; Radiography; Radiology",Article,Scopus
"Roth B., Kampalath R., Nakashima K., Shieh S., Bui T.-L., Houshyar R.","Revenue and Cost Analysis of a System Utilizing Natural Language Processing and a Nurse Coordinator for Radiology Follow-up Recommendations",2023,"Current Problems in Diagnostic Radiology",,"10.1067/j.cpradiol.2023.05.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160226599&doi=10.1067%2fj.cpradiol.2023.05.008&partnerID=40&md5=4a1994d6fb584bfa443363e150cfd968","Radiology reports often contain recommendations for follow-up imaging, Provider adherence to these radiology recommendations can be incomplete, which may result in patient harm, lost revenue, or litigation. This study sought to perform a revenue assessment of a hybrid natural language processing (NLP) and human follow-up system. Reports generated from January 2020 to April 2021 that were indexed as overdue from follow-up recommendations by mPower Follow-Up Recommendation Algorithm (Nuance Communications Inc., Burlington, MA), were assessed for follow up and revenue. Follow-up exams completed because of the hybrid system were tabulated and given revenue amounts based on Medicare national reimbursement rates. These rates were then summated. A total of n =3011 patients were flagged via the mPower algorithm as having not received a timely follow-up indicated for procedure. Of these, n = 427 required the quality nurse to contact their healthcare provider to place orders. The follow-up imaging of these patients accounted for $62,937.66 of revenue. This revenue was calculated as higher than personnel cost (based on national average quality and safety nurse salary and time allotted on follow-ups). Our results indicate that a hybrid human-artificial intelligence follow-up system can be profitable, while potentially adding to patient safety. Our revenue figure likely significantly underestimates the true revenue obtained at our institution. This was due to the use of Medicare national reimbursement rates to calculate revenue, for the purposes of generalizability. © 2023 Elsevier Inc.",,"adult; algorithm; article; artificial intelligence; cost benefit analysis; drug safety; female; follow up; health care personnel; human; major clinical study; male; medicare; natural language processing; nurse; patient safety; radiology; reimbursement; salary",Article,Scopus
"Elkassem A.A., Smith A.D.","Potential Use Cases for ChatGPT in Radiology Reporting",2023,"AJR. American journal of roentgenology",23,"10.2214/AJR.23.29198","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158982793&doi=10.2214%2fAJR.23.29198&partnerID=40&md5=3e955e880ac3c436ed2e5f681b57fc07","Large language models (LLMs) such as ChatGPT are advanced artificial intelligence models that are designed to process and understand human language. LLMs have the potential to improve radiology reporting and patient engagement by automating generation of the clinical history and impression of a radiology report, creating layperson reports, and providing patients with pertinent questions and answers about findings in radiology reports. However, LLMs are error prone, and human oversight is needed to reduce the risk of patient harm.","artificial intelligence; ChatGPT; health care; large language models; radiology reports","artificial intelligence; human; patient participation; radiology; Artificial Intelligence; Humans; Patient Participation; Radiology",Article,Scopus
"Shetty S., Ananthanarayana V.S., Mahale A.","Cross-modal Deep Learning-based Clinical Recommendation System for Radiology Report Generation from Chest X-rays",2023,"International Journal of Engineering, Transactions B: Applications",1,"10.5829/IJE.2023.36.08B.16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167870369&doi=10.5829%2fIJE.2023.36.08B.16&partnerID=40&md5=427b2fcc21c4cc0c9cd91daa0595269a","Radiology report generation is a critical task for radiologists, and automating the process can significantly simplify their workload. However, creating accurate and reliable radiology reports requires radiologists to have sufficient experience and time to review medical images. Unfortunately, many radiology reports end with ambiguous conclusions, resulting in additional testing and diagnostic procedures for patients. To address this, we proposed an encoder-decoder-based deep learning framework that utilizes chest X-ray images to produce diagnostic radiology reports. In our study, we have introduced a novel text modelling and visual feature extraction strategy as part of our proposed encoder-decoder-based deep learning framework. Our approach aims to extract essential visual and textual information from chest X-ray images to generate more accurate and reliable radiology reports. Additionally, we have developed a dynamic web portal that accepts chest X-rays as input and generates a radiology report as output. We conducted an extensive analysis of our model and compared its performance with other state-of-the-art deep learning approaches. Our findings indicate significant improvement achieved by our proposed model compared to existing models, as evidenced by the higher BLEU scores (BLEU1 = 0.588, BLEU2 = 0.4325, BLEU3 = 0.4017, BLEU4 = 0.3860) attained on the Indiana University Dataset. These results underscore the potential of our deep learning framework to enhance the accuracy and reliability of radiology reports, leading to more efficient and effective medical treatment. © 2023 Materials and Energy Research Center. All rights reserved.","Clinical Recommendation System; Decoder; Deep Learning; Encoder; Radiology Reports; Report Generation","Decoding; Diagnosis; Learning systems; Medical imaging; Radiology; Recommender systems; Signal encoding; Chest X-ray image; Clinical recommendation system; Cross-modal; Decoder; Deep learning; Encoder; Encoder-decoder; Learning frameworks; Radiology reports; Report generation; Deep learning",Article,Scopus
"DeSimone A.K., Kapoor N., Lacson R., Budiawan E., Hammer M.M., Desai S.P., Eappen S., Khorasani R.","Impact of an Automated Closed-Loop Communication and Tracking Tool on the Rate of Recommendations for Additional Imaging in Thoracic Radiology Reports",2023,"Journal of the American College of Radiology",,"10.1016/j.jacr.2023.05.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165662883&doi=10.1016%2fj.jacr.2023.05.004&partnerID=40&md5=162407cf59a3fbfee5728886ad3defe4","Objective: Assess the effects of feedback reports and implementing a closed-loop communication system on rates of recommendations for additional imaging (RAIs) in thoracic radiology reports. Methods: In this retrospective, institutional review board–approved study at an academic quaternary care hospital, we analyzed 176,498 thoracic radiology reports during a pre-intervention (baseline) period from April 1, 2018, to November 30, 2018; a feedback report only period from December 1, 2018, to September 30, 2019; and a closed-loop communication system plus feedback report (IT intervention) period from October 1, 2019, to December 31, 2020, promoting explicit documentation of rationale, time frame, and imaging modality for RAI, defined as complete RAI. A previously validated natural language processing tool was used to classify reports with an RAI. Primary outcome of rate of RAI was compared using a control chart. Multivariable logistic regression determined factors associated with likelihood of RAI. We also estimated the completeness of RAI in reports comparing IT intervention to baseline using χ2 statistic. Results: The natural language processing tool classified 3.2% (5,682 of 176,498) reports as having an RAI; 3.5% (1,783 of 51,323) during the pre-intervention period, 3.8% (2,147 of 56,722) during the feedback report only period (odds ratio: 1.1, P =.03), and 2.6% (1,752 of 68,453) during the IT intervention period (odds ratio: 0.60, P &lt;.001). In subanalysis, the proportion of incomplete RAI decreased from 84.0% (79 of 94) during the pre-intervention period to 48.5% (47 of 97) during the IT intervention period (P &lt;.001). Discussion: Feedback reports alone increased RAI rates, and an IT intervention promoting documentation of complete RAI in addition to feedback reports led to significant reductions in RAI rate, incomplete RAI, and improved overall completeness of the radiology recommendations. © 2023 American College of Radiology","Closed-loop communication; follow-up imaging recommendation; physician feedback; quality improvement","article; controlled study; documentation; follow up; human; institutional review; natural language processing; outcome assessment; physician; radiology; retrospective study; total quality management; interpersonal communication; radiography; thorax radiography; Communication; Radiography; Radiography, Thoracic; Radiology; Retrospective Studies; Teach-Back Communication",Article,Scopus
"Gundogdu B., Pamuksuz U., Chung J.H., Telleria J.M., Liu P., Khan F., Chang P.J.","Customized Impression Prediction From Radiology Reports Using BERT and LSTMs",2023,"IEEE Transactions on Artificial Intelligence",1,"10.1109/TAI.2021.3086435","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152865162&doi=10.1109%2fTAI.2021.3086435&partnerID=40&md5=f078e25757b7342c415981189f3380a9","Clinical language processing has become an attractive field with the improvements of deep learning applications and the abundance of large unstructured narratives in the healthcare records. The capability to extract unstructured information from raw text to provide actionable information for healthcare personnel plays a vital role in healthcare workflows. In this article, we introduce a deep learning approach to automate the generation of radiology impressions by analyzing radiology findings and patient background information of each examination. Since the impression section of a radiology report is an essential conclusion, any errors can prove to be detrimental. Thus, we developed a deep learning system to prevent important clinical findings from being overlooked by using almost 1 million de-identified radiology reports obtained from the University of Chicago Medicine over the last 12 years. We propose to automate the generation of radiology reports by incorporating sequence-to-sequence neural network models with the power of bidirectional encoder representations from transformers (BERT). We tested our model in a real-time experimental setup with radiologists in a top tier academic institution and statistically validated the performance by using ROUGE metrics. Clinical validations have shown that 76% of our predictions are at least as accurate as human-generated impressions by radiologists. Furthermore, statistical validation metrics demonstrated higher ROUGE scores compared to previously published studies over two different test sets. © 2020 IEEE.","Bidirectional encoder representations from transformers (BERT); clinical language processing; deep learning; impression; long short-term memory (LSTM); neural networks; radiology","Health care; Learning systems; Radiology; Signal encoding; Bidirectional encoder representation from transformer; Clinical language processing; Deep learning; Healthcare record; Healthcare workflow; Impression; Language processing; Long short-term memory; Neural-networks; Radiology reports; Long short-term memory",Article,Scopus
"Doi K., Takegawa H., Yui M., Anetai Y., Koike Y., Nakamura S., Tanigawa N., Koziumi M., Nishio T.","Deep learning-based detection of patients with bone metastasis from Japanese radiology reports",2023,"Japanese Journal of Radiology",1,"10.1007/s11604-023-01413-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151375402&doi=10.1007%2fs11604-023-01413-2&partnerID=40&md5=40e20af40a6f3d934f4dd273be94d4e5","Purpose: Deep learning (DL) is a state-of-the-art technique for developing artificial intelligence in various domains and it improves the performance of natural language processing (NLP). Therefore, we aimed to develop a DL-based NLP model that classifies the status of bone metastasis (BM) in radiology reports to detect patients with BM. Materials and Methods: The DL-based NLP model was developed by training long short-term memory using 1,749 free-text radiology reports written in Japanese. We adopted five-fold cross-validation and used 200 reports for testing the five models. The accuracy, sensitivity, specificity, precision, and area under the receiver operating characteristics curve (AUROC) were used for the model evaluation. Results: The developed model demonstrated classification performance with mean ± standard deviation of 0.912 ± 0.012, 0.924 ± 0.029, 0.901 ± 0.014, 0.898 ± 0.012, and 0.968 ± 0.004 for accuracy, sensitivity, specificity, precision, and AUROC, respectively. Conclusion: The proposed DL-based NLP model may help in the early and efficient detection of patients with BM. © 2023, The Author(s) under exclusive licence to Japan Radiological Society.","Bone metastasis; Deep learning; Long short-term memory; Natural language processing; Radiology report","Article; bone metastasis; cancer patient; controlled study; cross validation; deep learning; diagnostic accuracy; human; long short term memory network; natural language processing; radiology; sensitivity and specificity; artificial intelligence; East Asian; natural language processing; procedures; Artificial Intelligence; Deep Learning; East Asian People; Humans; Natural Language Processing; Radiology",Article,Scopus
"Wu X., Li J., Wang J., Qian Q.","Multimodal contrastive learning for radiology report generation",2023,"Journal of Ambient Intelligence and Humanized Computing",,"10.1007/s12652-022-04398-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137807778&doi=10.1007%2fs12652-022-04398-4&partnerID=40&md5=1f2ce155ce6f43094e3403b3fdc4428a","Automated radiology report generation can not only lighten the workload of clinicians but also improve the efficiency of disease diagnosis. However, it is a challenging task to generate semantically coherent radiology reports that are also highly consistent with medical images. To meet the challenge, we propose a Multimodal Recursive model with Contrastive Learning (MRCL). The proposed MRCL method incorporates both visual and semantic features to generate “Impression” and “Findings” of radiology reports through a recursive network, in which a contrastive pre-training method is proposed to improve the expressiveness of both visual and textual representations. Extensive experiments and analyses prove the efficacy of the proposed MRCL, which can not only generate semantically coherent radiology reports but also outperform state-of-the-art methods. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","Contrastive learning; Multimodal recursive model; Radiology report generation; Semantic representation; Visual representation","Diagnosis; Learning systems; Medical imaging; Radiation; Radiology; Contrastive learning; Disease diagnosis; Multi-modal; Multimodal recursive model; Radiology report generation; Radiology reports; Recursive modeling; Report generation; Semantic representation; Visual representations; Semantics",Article,Scopus
"Tan W.M., Ng W.L., Ganggayah M.D., Hoe V.C.W., Rahmat K., Zaini H.S., Mohd Taib N.A., Dhillon S.K.","Natural language processing in narrative breast radiology reporting in University Malaya Medical Centre",2023,"Health Informatics Journal",,"10.1177/14604582231203763","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172018335&doi=10.1177%2f14604582231203763&partnerID=40&md5=080f08b2430b1acc7b738edc82939357","Radiology reporting is narrative, and its content depends on the clinician’s ability to interpret the images accurately. A tertiary hospital, such as anonymous institute, focuses on writing reports narratively as part of training for medical personnel. Nevertheless, free-text reports make it inconvenient to extract information for clinical audits and data mining. Therefore, we aim to convert unstructured breast radiology reports into structured formats using natural language processing (NLP) algorithm. This study used 327 de-identified breast radiology reports from the anonymous institute. The radiologist identified the significant data elements to be extracted. Our NLP algorithm achieved 97% and 94.9% accuracy in training and testing data, respectively. Henceforth, the structured information was used to build the predictive model for predicting the value of the BIRADS category. The model based on random forest generated the highest accuracy of 92%. Our study not only fulfilled the demands of clinicians by enhancing communication between medical personnel, but it also demonstrated the usefulness of mineable structured data in yielding significant insights. © The Author(s) 2023.","information extraction; natural language processing; radiology reporting; rule-based; text mining","article; breast imaging reporting and data system; human; Malaysia; medical personnel; mining; narrative; natural language processing; predictive model; radiologist; radiology; random forest",Article,Scopus
"Datta S., Roberts K.","Weakly supervised spatial relation extraction from radiology reports",2023,"JAMIA Open",1,"10.1093/jamiaopen/ooad027","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161486999&doi=10.1093%2fjamiaopen%2fooad027&partnerID=40&md5=8d952f23945d536873201df0b9fed495","Objective: Weak supervision holds significant promise to improve clinical natural language processing by leveraging domain resources and expertise instead of large manually annotated datasets alone. Here, our objective is to evaluate a weak supervision approach to extract spatial information from radiology reports. Materials and Methods: Our weak supervision approach is based on data programming that uses rules (or labeling functions) relying on domain-specific dictionaries and radiology language characteristics to generate weak labels. The labels correspond to different spatial relations that are critical to understanding radiology reports. These weak labels are then used to fine-tune a pretrained Bidirectional Encoder Representations from Transformers (BERT) model. Results: Our weakly supervised BERT model provided satisfactory results in extracting spatial relations without manual annotations for training (spatial trigger F1: 72.89, relation F1: 52.47). When this model is further fine-tuned on manual annotations (relation F1: 68.76), performance surpasses the fully supervised state-of-the-art. Discussion: To our knowledge, this is the first work to automatically create detailed weak labels corresponding to radiological information of clinical significance. Our data programming approach is (1) adaptable as the labeling functions can be updated with relatively little manual effort to incorporate more variations in radiology language reporting formats and (2) generalizable as these functions can be applied across multiple radiology subdomains in most cases. Conclusions: We demonstrate a weakly supervision model performs sufficiently well in identifying a variety of relations from radiology text without manual annotations, while exceeding state-of-the-art results when annotated data are available. © The Author(s) 2023. Published by Oxford University Press on behalf of the American Medical Informatics Association.","data programming; information extraction; natural language processing; radiology report; relation extraction; weak supervision","article; clinical significance; extraction; human; human experiment; natural language processing; radiology",Article,Scopus
"Samuel N., Giuffrida M.A., Culp W.T.N., Palm C.A.","A 20-year scoping review of the veterinary interventional radiology and interventional endoscopy literature (2000-2019)",2023,"Journal of Veterinary Internal Medicine",,"10.1111/jvim.16748","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160648506&doi=10.1111%2fjvim.16748&partnerID=40&md5=fdbe1769fdd60ec67753e5f0b9a5cd96","Background: Interventional radiology (IR) and interventional endoscopy (IE) have broad potential for minimally invasive therapy in veterinary patients, but the scope of original peer-reviewed veterinary IR/IE research publications has not been described. Objectives: Catalogue published applications and indications for noncardiac therapeutic IR/IE in animals and describe type and quality of veterinary IR/IE research over 20 years. Methods: Highly-cited veterinary journals were searched to identify articles published 2000 to 2019 involving therapeutic IR/IE applications for clinical veterinary patients. Articles were assigned a level of evidence (LOE) according to published standards. Authorship, animal data, study design, and interventions were described. Change in publication rate, study size, and LOE of IR/IE articles over time was analyzed. Results: One hundred fifty-nine of 15 512 (1%) articles were eligible, including 2972 animals. All studies were low LOE and 43% were case reports with ≤5 animals. Number of IR/IE articles per year (P <.001), proportion of journals' articles pertaining to IR/IE (P =.02), and study size (P =.04) all increased over time, but LOE (P =.07) did not. Common target body systems were urinary (40%), digestive (23%) respiratory (20%), and vascular (13%). Common indications were nonvascular luminal obstructions (47%), object retrieval (14%), and congenital anomalies (13%). Most procedures involved indwelling medical devices or embolic agents, whereas tissue resection and other procedures were less common. Procedures utilized fluoroscopy (43%), endoscopy (33%), ultrasound (8%), digital radiography (1%), or fluoroscopy in combination with other modalities (16%). Conclusions: Treatments involving IR/IE have wide applicability in veterinary medicine but large, rigorous, and comparative studies describing these procedures are lacking. © 2023 The Authors. Journal of Veterinary Internal Medicine published by Wiley Periodicals LLC. on behalf of the American College of Veterinary Internal Medicine.","evidence-based medicine; minimally invasive; therapy; veterinary; veterinary","carboplatin; abscess drainage; arterial embolization; arteriovenous malformation; Article; balloon dilatation; cauterization; chemoembolization; cholecystostomy; chylothorax; comparative study; cystostomy; digital radiography; digital subtraction angiography; dog; endoscopic therapy; endoscopic ultrasonography; endoscopy; endotracheal intubation; esophagostomy; evidence based medicine; fluoroscopy; gastropexy; hematuria; hemiplegia; information retrieval; interventional radiology; laser lithotripsy; laser surgery; lithotripsy; minimally invasive procedure; nonhuman; portosystemic anastomosis; prospective study; publication; pyonephrosis; quality of life; recanalization; sclerotherapy; screening; soft tissue injury; ultrasound; ureterocele; veterinary medicine; writing",Article,Scopus
"Mallio C.A., Sertorio A.C., Bernetti C., Beomonte Zobel B.","Large language models for structured reporting in radiology: performance of GPT-4, ChatGPT-3.5, Perplexity and Bing",2023,"Radiologia Medica",11,"10.1007/s11547-023-01651-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160411585&doi=10.1007%2fs11547-023-01651-4&partnerID=40&md5=ed8a1d6294591e8fbe771019471e75c6","Structured reporting may improve the radiological workflow and communication among physicians. Artificial intelligence applications in medicine are growing fast. Large language models (LLMs) are recently gaining importance as valuable tools in radiology and are currently being tested for the critical task of structured reporting. We compared four LLMs models in terms of knowledge on structured reporting and templates proposal. LLMs hold a great potential for generating structured reports in radiology but additional formal validations are needed on this topic. © 2023, Italian Society of Medical Radiology.","Artificial intelligence (AI); Computed tomography (CT); Generative pre-trained transformer (GPT)-based models; GPT-4; Large language models (LLMs); Structured report","article; artificial intelligence; computer assisted tomography; human; human experiment; language; radiology; interpersonal communication; language; radiography; Artificial Intelligence; Communication; Humans; Language; Radiography; Radiology",Article,Scopus
"Zhao S., Li Q., Yang Y., Wen J., Luo W.","From Softmax to Nucleusmax: A Novel Sparse Language Model for Chinese Radiology Report Summarization",2023,"ACM Transactions on Asian and Low-Resource Language Information Processing",3,"10.1145/3596219","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164235257&doi=10.1145%2f3596219&partnerID=40&md5=1b2232b3a03135bf89ec7674adfd0468","The Chinese radiology report summarization is a crucial component in smart healthcare that employs language models to summarize key findings in radiology reports and communicate these findings to physicians. However, most language models for radiology report summarization utilize a softmax transformation in their output layer, leading to dense alignments and strictly positive output probabilities. This density is inefficient, reducing model interpretability and giving probability mass to many unrealistic outputs. To tackle this issue, we propose a novel approach named nucleusmax. Nucleusmax is able to mitigate dense outputs and improve model interpretability by truncating the unreliable tail of the probability distribution. In addition, we incorporate nucleusmax with a copy mechanism, a useful technique to avoid professional errors in the generated diagnostic opinions. To further promote the research of radiology report summarization, we also have created a Chinese radiology report summarization dataset, which is freely available. Experimental results showed via both automatic and human evaluation that the proposed approach substantially improves the sparsity and overall quality of outputs over competitive softmax models, producing radiology summaries that approach the quality of those authored by physicians. In general, our work demonstrates the feasibility and prospect of the language model to the domain of radiology and smart healthcare. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.","abstractive summarization; Additional Key Words and PhrasesChinese radiology report summarization; language model; softmax","Computational linguistics; Health care; Probability distributions; Abstractive summarization; Additional key word and phraseschinese radiology report summarization; Dense output; Interpretability; Key words; Language model; Output layer; Radiology reports; Softmax; Sparse languages; Radiology",Article,Scopus
"Remedios D., Remedios A.","Transformers, codes and labels: large language modelling for natural language processing in clinical radiology",2023,"European Radiology",,"10.1007/s00330-023-09566-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151728710&doi=10.1007%2fs00330-023-09566-4&partnerID=40&md5=f2e4007ba4220c218810ebd1b82b8ee4",[No abstract available],,"artificial intelligence; clinical decision making; diagnostic imaging; human; logical reasoning; natural language processing; Note; radiology; algorithm; language; research; Algorithms; Humans; Language; Natural Language Processing; Radiology; Research Report",Note,Scopus
"Agrawal A., Khatri G.D., Khurana B., Sodickson A.D., Liang Y., Dreizin D.","A survey of ASER members on artificial intelligence in emergency radiology: trends, perceptions, and expectations",2023,"Emergency Radiology",3,"10.1007/s10140-023-02121-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149984493&doi=10.1007%2fs10140-023-02121-0&partnerID=40&md5=510cf00162af3d3ea1db90dcf29f974d","Purpose: There is a growing body of diagnostic performance studies for emergency radiology-related artificial intelligence/machine learning (AI/ML) tools; however, little is known about user preferences, concerns, experiences, expectations, and the degree of penetration of AI tools in emergency radiology. Our aim is to conduct a survey of the current trends, perceptions, and expectations regarding AI among American Society of Emergency Radiology (ASER) members. Methods: An anonymous and voluntary online survey questionnaire was e-mailed to all ASER members, followed by two reminder e-mails. A descriptive analysis of the data was conducted, and results summarized. Results: A total of 113 members responded (response rate 12%). The majority were attending radiologists (90%) with greater than 10 years’ experience (80%) and from an academic practice (65%). Most (55%) reported use of commercial AI CAD tools in their practice. Workflow prioritization based on pathology detection, injury or disease severity grading and classification, quantitative visualization, and auto-population of structured reports were identified as high-value tasks. Respondents overwhelmingly indicated a need for explainable and verifiable tools (87%) and the need for transparency in the development process (80%). Most respondents did not feel that AI would reduce the need for emergency radiologists in the next two decades (72%) or diminish interest in fellowship programs (58%). Negative perceptions pertained to potential for automation bias (23%), over-diagnosis (16%), poor generalizability (15%), negative impact on training (11%), and impediments to workflow (10%). Conclusion: ASER member respondents are in general optimistic about the impact of AI in the practice of emergency radiology and its impact on the popularity of emergency radiology as a subspecialty. The majority expect to see transparent and explainable AI models with the radiologist as the decision-maker. © 2023, The Author(s), under exclusive licence to American Society of Emergency Radiology (ASER).","Artificial intelligence; Computer-aided detection; Emergency; Emergency radiology; Imaging; Machine learning; Radiology; Survey; Trauma","Article; artificial intelligence; cross-sectional study; emergency; expectation; health survey; human; job satisfaction; Likert scale; multiple choice test; needs assessment; perception; private practice; questionnaire; radiologist; teleradiology; education; motivation; radiologist; radiology; United States; Artificial Intelligence; Humans; Motivation; Radiologists; Radiology; Surveys and Questionnaires; United States",Article,Scopus
"Nowak S., Biesner D., Layer Y.C., Theis M., Schneider H., Block W., Wulff B., Attenberger U.I., Sifa R., Sprinkart A.M.","Transformer-based structuring of free-text radiology report databases",2023,"European Radiology",1,"10.1007/s00330-023-09526-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149793983&doi=10.1007%2fs00330-023-09526-y&partnerID=40&md5=0864d545648c0635260e285d043e03c7","Objectives: To provide insights for on-site development of transformer-based structuring of free-text report databases by investigating different labeling and pre-training strategies. Methods: A total of 93,368 German chest X-ray reports from 20,912 intensive care unit (ICU) patients were included. Two labeling strategies were investigated to tag six findings of the attending radiologist. First, a system based on human-defined rules was applied for annotation of all reports (termed “silver labels”). Second, 18,000 reports were manually annotated in 197 h (termed “gold labels”) of which 10% were used for testing. An on-site pre-trained model (Tmlm) using masked-language modeling (MLM) was compared to a public, medically pre-trained model (Tmed). Both models were fine-tuned on silver labels only, gold labels only, and first with silver and then gold labels (hybrid training) for text classification, using varying numbers (N: 500, 1000, 2000, 3500, 7000, 14,580) of gold labels. Macro-averaged F1-scores (MAF1) in percent were calculated with 95% confidence intervals (CI). Results: Tmlm,gold (95.5 [94.5–96.3]) showed significantly higher MAF1 than Tmed,silver (75.0 [73.4–76.5]) and Tmlm,silver (75.2 [73.6–76.7]), but not significantly higher MAF1 than Tmed,gold (94.7 [93.6–95.6]), Tmed,hybrid (94.9 [93.9–95.8]), and Tmlm,hybrid (95.2 [94.3–96.0]). When using 7000 or less gold-labeled reports, Tmlm,gold (N: 7000, 94.7 [93.5–95.7]) showed significantly higher MAF1 than Tmed,gold (N: 7000, 91.5 [90.0–92.8]). With at least 2000 gold-labeled reports, utilizing silver labels did not lead to significant improvement of Tmlm,hybrid (N: 2000, 91.8 [90.4–93.2]) over Tmlm,gold (N: 2000, 91.4 [89.9–92.8]). Conclusions: Custom pre-training of transformers and fine-tuning on manual annotations promises to be an efficient strategy to unlock report databases for data-driven medicine. Key Points: • On-site development of natural language processing methods that retrospectively unlock free-text databases of radiology clinics for data-driven medicine is of great interest. • For clinics seeking to develop methods on-site for retrospective structuring of a report database of a certain department, it remains unclear which of previously proposed strategies for labeling reports and pre-training models is the most appropriate in context of, e.g., available annotator time. • Using a custom pre-trained transformer model, along with a little annotation effort, promises to be an efficient way to retrospectively structure radiological databases, even if not millions of reports are available for pre-training. © 2023, The Author(s).","Deep learning; Intensive care units; Natural language processing; Radiology; Thorax","silver; silver; adult; Article; comparative study; controlled study; data base; deep learning; female; health data; human; information system; informed consent; institutional review; intensive care unit; major clinical study; male; medical research; multilabel classification; natural language processing; thorax radiography; factual database; natural language processing; procedures; radiology; retrospective study; Databases, Factual; Humans; Natural Language Processing; Radiology; Retrospective Studies; Silver",Article,Scopus
"Lecler A., Duron L., Soyer P.","Revolutionizing radiology with GPT-based models: Current applications, future possibilities and limitations of ChatGPT",2023,"Diagnostic and Interventional Imaging",50,"10.1016/j.diii.2023.02.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149756697&doi=10.1016%2fj.diii.2023.02.003&partnerID=40&md5=579953503b3c607121d4f8ba0069fe3e","Artificial intelligence has demonstrated utility and is increasingly being used in the field of radiology. The use of generative pre-trained transformer (GPT)-based models has the potential to revolutionize the field of radiology, offering new possibilities for improving accuracy, efficiency, and patient outcome. Current applications of GPT-based models in radiology include report generation, educational support, clinical decision support, patient communication, and data analysis. As these models continue to advance and improve, it is likely that more innovative uses for GPT-based models in the field of radiology at large will be developed, further enhancing the role of technology in the diagnostic process. ChatGPT is a variant of GPT that is specifically fine-tuned for conversational language understanding and generation. This article reports some answers provided by ChatGPT to various questions that radiologists may have regarding ChatGPT and identifies the potential benefits ChatGPT may offer in their daily practice but also current limitations. Similar to other applications of artificial intelligence in the field of imaging, further formal validation of ChatGPT is required. © 2023 Société française de radiologie","Artificial intelligence; ChatGPT; Generative pre-trained transformer (GPT); Radiology","adult; article; artificial intelligence; data analysis; decision support system; human; language; outcome assessment; radiologist; radiology; interpersonal communication; radiography; Artificial Intelligence; Communication; Humans; Radiography; Radiologists; Radiology",Article,Scopus
"Mithun S., Jha A.K., Sherkhane U.B., Jaiswar V., Purandare N.C., Dekker A., Puts S., Bermejo I., Rangarajan V., Zegers C.M.L., Wee L.","Clinical Concept-Based Radiology Reports Classification Pipeline for Lung Carcinoma",2023,"Journal of Digital Imaging",1,"10.1007/s10278-023-00787-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148025292&doi=10.1007%2fs10278-023-00787-z&partnerID=40&md5=85cd1b6ec93ed8585e427ed25916b5ef","Rising incidence and mortality of cancer have led to an incremental amount of research in the field. To learn from preexisting data, it has become important to capture maximum information related to disease type, stage, treatment, and outcomes. Medical imaging reports are rich in this kind of information but are only present as free text. The extraction of information from such unstructured text reports is labor-intensive. The use of Natural Language Processing (NLP) tools to extract information from radiology reports can make it less time-consuming as well as more effective. In this study, we have developed and compared different models for the classification of lung carcinoma reports using clinical concepts. This study was approved by the institutional ethics committee as a retrospective study with a waiver of informed consent. A clinical concept-based classification pipeline for lung carcinoma radiology reports was developed using rule-based as well as machine learning models and compared. The machine learning models used were XGBoost and two more deep learning model architectures with bidirectional long short-term neural networks. A corpus consisting of 1700 radiology reports including computed tomography (CT) and positron emission tomography/computed tomography (PET/CT) reports were used for development and testing. Five hundred one radiology reports from MIMIC-III Clinical Database version 1.4 was used for external validation. The pipeline achieved an overall F1 score of 0.94 on the internal set and 0.74 on external validation with the rule-based algorithm using expert input giving the best performance. Among the machine learning models, the Bi-LSTM_dropout model performed better than the ML model using XGBoost and the Bi-LSTM_simple model on internal set, whereas on external validation, the Bi-LSTM_simple model performed relatively better than other 2. This pipeline can be used for clinical concept-based classification of radiology reports related to lung carcinoma from a huge corpus and also for automated annotation of these reports. © 2023, The Author(s).","Artificial Intelligence; Big data analytics; Clinical concept extraction; Deep learning; Electronic medical records; Lung carcinoma; Named entity recognition; Natural Language Processing; Radiology reports","Big data; Biological organs; Computer aided instruction; Computerized tomography; Data Analytics; Data mining; Deep learning; Diseases; E-learning; Extraction; Learning systems; Natural language processing systems; Radiology; Big data analytic; Clinical concept extraction; Concept extraction; Data analytics; Deep learning; Electronic medical record; Language processing; Lung carcinoma; Medical record; Named entity recognition; Natural language processing; Natural languages; Radiology reports; Pipelines; carcinoma; human; lung; natural language processing; positron emission tomography-computed tomography; radiology; retrospective study; Carcinoma; Humans; Lung; Natural Language Processing; Positron Emission Tomography Computed Tomography; Radiology; Retrospective Studies",Article,Scopus
"Fu T., Berlin S., Gupta A., Plecha D., Sunshine J., Sommer J.","Implementing a Streamlined Radiology Workflow to Close the Loop on Incidental Imaging Findings in the Emergency Department",2023,"Journal of Digital Imaging",,"10.1007/s10278-022-00773-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146568150&doi=10.1007%2fs10278-022-00773-x&partnerID=40&md5=2eac2f88e0f52cd16bbc1bedc9b4860d","Actionable incidental findings (AIFs) are common imaging findings unrelated to the clinical indication for the imaging test for which follow-up is recommended. Increasing utilization of imaging in the emergency department (ED) in recent years has resulted in more patients with AIFs. When these findings are not properly communicated and followed up upon, there is harm to the patient’s health outcome as well as possible increased financial costs for the patient, the health system, and potential litigation. Tracking these findings can be difficult, especially so in a large health system. In this report, we detail our experience implementing a closed-loop AIF program within the ED of 11 satellite hospitals of a large academic health system. Our new workflow streamlined radiologist reporting of AIFs through system macros and by using a standardized form integrated into the dictation software. Upon completion of the form, an automatic email is sent to a dedicated nurse navigator who documented the findings and closed the loop by coordinating follow-up imaging or clinic visits with patients, primary care providers, and specialists. Through the new workflow, a total of 1207 incidental finding reports have been submitted from July 2021 to May 2022. The vast majority of AIFs were identified on CT, and the most common categories included lung nodules, pancreas lesions, liver lesions, and other potentially cancerous lesions. At least 10 new cancers have been detected. We hope this report can help guide other health systems in the design of a closed-loop incidental findings program. © 2023, The Author(s) under exclusive licence to Society for Imaging Informatics in Medicine.","Closed-loop communication; Incidental findings; Quality improvement; Radiology informatics; Radiology reporting; System workflow","Computerized tomography; Emergency rooms; Laws and legislation; Closed-loop; Closed-loop communication; Emergency departments; Health systems; Incidental findings; Quality improvement; Radiology informatics; Radiology reporting; System workflow; Work-flows; Radiology; diagnostic imaging; hospital emergency service; human; radiography; radiology; workflow; Diagnostic Imaging; Emergency Service, Hospital; Humans; Radiography; Radiology; Workflow",Article,Scopus
"Cohen M., Puntonet J., Sanchez J., Kierszbaum E., Crema M., Soyer P., Dion E.","Artificial intelligence vs. radiologist: accuracy of wrist fracture detection on radiographs",2023,"European Radiology",3,"10.1007/s00330-022-09349-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143807809&doi=10.1007%2fs00330-022-09349-3&partnerID=40&md5=cac159b99b63c14f5b53366eef37db85","Objective: To compare the performances of artificial intelligence (AI) to those of radiologists in wrist fracture detection on radiographs. Methods: This retrospective study included 637 patients (1917 radiographs) with wrist trauma between January 2017 and December 2019. The AI software used was a deep neuronal network algorithm. Ground truth was established by three senior musculoskeletal radiologists who compared the initial radiology reports (IRR) made by non-specialized radiologists, the results of AI, and the combination of AI and IRR (IR+AI) Results: A total of 318 fractures were reported by the senior radiologists in 247 patients. Sensitivity of AI (83%; 95% CI: 78–87%) was significantly greater than that of IRR (76%; 95% CI: 70–81%) (p < 0.001). Specificities were similar for AI (96%; 95% CI: 93–97%) and for IRR (96%; 95% CI: 94–98%) (p = 0.80). The combination of AI+IRR had a significantly greater sensitivity (88%; 95% CI: 84–92%) compared to AI and IRR (p < 0.001) and a lower specificity (92%; 95% CI: 89–95%) (p < 0.001). The sensitivity for scaphoid fracture detection was acceptable for AI (84%) and IRR (80%) but poor for the detection of other carpal bones fracture (41% for AI and 26% for IRR). Conclusions: Performance of AI in wrist fracture detection on radiographs is better than that of non-specialized radiologists. The combination of AI and radiologist’s analysis yields best performances. Key Points: • Artificial intelligence has better performances for wrist fracture detection compared to non-expert radiologists in daily practice. • Performance of artificial intelligence greatly differs depending on the anatomical area. • Sensitivity of artificial intelligence for the detection of carpal bones fractures is 56%. © 2022, The Author(s), under exclusive licence to European Society of Radiology.","Artificial intelligence; Bones; Fractures; Radiography; Wrist","adult; anonymization; Article; artificial intelligence; carpal bone; controlled study; convolutional neural network; digital imaging and communications in medicine; female; hospital admission; human; major clinical study; male; McNemar test; nuclear magnetic resonance imaging; predictive value; radiography; radiologist; retrospective study; scaphoid fracture; wrist fracture; wrist injury; artificial intelligence; diagnostic imaging; fracture; radiologist; scaphoid bone; wrist injury; Artificial Intelligence; Fractures, Bone; Humans; Radiologists; Retrospective Studies; Scaphoid Bone; Wrist Fractures; Wrist Injuries",Article,Scopus
"Adams L.C., Truhn D., Busch F., Kader A., Niehues S.M., Makowski M.R., Bressem K.K.","Leveraging GPT-4 for Post Hoc Transformation of Free-text Radiology Reports into Structured Reporting: A Multilingual Feasibility Study",2023,"Radiology",23,"10.1148/radiol.230725","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153096647&doi=10.1148%2fradiol.230725&partnerID=40&md5=a8884a6e400c6ea527b4890c6c34ae11",[No abstract available],,"Article; automation; clinical effectiveness; clinical evaluation; computer assisted tomography; feasibility study; Germany; hospital information system; lung congestion; lung disease; lung opacity; natural language processing; nuclear magnetic resonance imaging; pneumothorax; pre trained transformer 4; quality control; thorax radiography; human; radiography; radiology; Feasibility Studies; Humans; Radiography; Radiology; Radiology Information Systems",Article,Scopus
"Yang S., Wu X., Ge S., Zheng Z., Zhou S.K., Xiao L.","Radiology report generation with a learned knowledge base and multi-modal alignment",2023,"Medical Image Analysis",1,"10.1016/j.media.2023.102798","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151008526&doi=10.1016%2fj.media.2023.102798&partnerID=40&md5=d833d037e029fa7162e0a3e90afd6d19","In clinics, a radiology report is crucial for guiding a patient's treatment. However, writing radiology reports is a heavy burden for radiologists. To this end, we present an automatic, multi-modal approach for report generation from a chest x-ray. Our approach, motivated by the observation that the descriptions in radiology reports are highly correlated with specific information of the x-ray images, features two distinct modules: (i) Learned knowledge base: To absorb the knowledge embedded in the radiology reports, we build a knowledge base that can automatically distill and restore medical knowledge from textual embedding without manual labor; (ii) Multi-modal alignment: to promote the semantic alignment among reports, disease labels, and images, we explicitly utilize textual embedding to guide the learning of the visual feature space. We evaluate the performance of the proposed model using metrics from both natural language generation and clinic efficacy on the public IU-Xray and MIMIC-CXR datasets. Our ablation study shows that each module contributes to improving the quality of generated reports. Furthermore, the assistance of both modules, our approach outperforms state-of-the-art methods over almost all the metrics. Code is available at https://github.com/LX-doctorAI1/M2KT. © 2023 The Author(s)","Knowledge base; Multi-modal alignment; Radiology report generation","Alignment; Knowledge based systems; Medical imaging; Natural language processing systems; Patient treatment; Radiology; Semantics; Chest x-rays; Embeddings; Highly-correlated; Knowledge base; Multi-modal; Multi-modal alignment; Multi-modal approach; Radiology report generation; Radiology reports; Report generation; Embeddings; Article; embedding; human; human experiment; knowledge base; language; learning; manual labor; radiology; thorax radiography; X ray; benchmarking; knowledge base; radiography; Benchmarking; Humans; Knowledge Bases; Learning; Radiography; Radiology",Article,Scopus
"Nakaura T., Naganawa S.","Writing medical papers using large-scale language models: a perspective from the Japanese Journal of Radiology",2023,"Japanese Journal of Radiology",3,"10.1007/s11604-023-01408-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149787401&doi=10.1007%2fs11604-023-01408-z&partnerID=40&md5=293d3d4aa0ae643e2af13e25e28fce81",[No abstract available],,"Editorial; human; Japan; Japanese (people); language; medical literature; radiology; East Asian; language; radiography; writing; East Asian People; Humans; Language; Radiography; Radiology; Writing",Editorial,Scopus
"Mirniaharikandehei S., Abdihamzehkolaei A., Choquehuanca A., Aedo M., Pacheco W., Estacio L., Cahui V., Huallpa L., Quiñonez K., Calderón V., Gutierrez A.M., Vargas A., Gamero D., Castro-Gutierrez E., Qiu Y., Zheng B., Jo J.A.","Automated Quantification of Pneumonia Infected Volume in Lung CT Images: A Comparison with Subjective Assessment of Radiologists",2023,"Bioengineering",1,"10.3390/bioengineering10030321","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152694449&doi=10.3390%2fbioengineering10030321&partnerID=40&md5=1e2e84a2dd832d91d873323d7965ecc8","Objective: To help improve radiologists’ efficacy of disease diagnosis in reading computed tomography (CT) images, this study aims to investigate the feasibility of applying a modified deep learning (DL) method as a new strategy to automatically segment disease-infected regions and predict disease severity. Methods: We employed a public dataset acquired from 20 COVID-19 patients, which includes manually annotated lung and infections masks, to train a new ensembled DL model that combines five customized residual attention U-Net models to segment disease infected regions followed by a Feature Pyramid Network model to predict disease severity stage. To test the potential clinical utility of the new DL model, we conducted an observer comparison study. First, we collected another set of CT images acquired from 80 COVID-19 patients and process images using the new DL model. Second, we asked two chest radiologists to read images of each CT scan and report the estimated percentage of the disease-infected lung volume and disease severity level. Third, we also asked radiologists to rate acceptance of DL model-generated segmentation results using a 5-scale rating method. Results: Data analysis results show that agreement of disease severity classification between the DL model and radiologists is >90% in 45 testing cases. Furthermore, >73% of cases received a high rating score (≥4) from two radiologists. Conclusion: This study demonstrates the feasibility of developing a new DL model to automatically segment disease-infected regions and quantitatively predict disease severity, which may help avoid tedious effort and inter-reader variability in subjective assessment of disease severity in future clinical practice. © 2023 by the authors.","comparison between manual and automated image segmentation; COVID-19 detection; COVID-19 severity assessment; deep neural network; infected lung segmentation; quantification of lung disease severity",,Article,Scopus
"Park S.H.","Authorship Policy of the Korean Journal of Radiology Regarding Artificial Intelligence Large Language Models Such as ChatGTP",2023,"Korean Journal of Radiology",7,"10.3348/kjr.2023.0112","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148773074&doi=10.3348%2fkjr.2023.0112&partnerID=40&md5=a843289d9a0930be92a883f811c05585",[No abstract available],,"academic journal; artificial intelligence; ChatGTP; computer language; computer model; editorial; Editorial; education; human; large language model; nonhuman; organizational policy; publication; publishing; radiology; scientific literature; writing; artificial intelligence; language; radiology; South Korea; Artificial Intelligence; Authorship; Humans; Language; Radiology; Republic of Korea",Editorial,Scopus
[No author name available],"Erratum regarding missing patient consent statements in previously published articles (Radiology Case Reports (2021) 16(5) (1123–1126), (S1930043321001060), (10.1016/j.radcr.2021.02.042))",2023,"Radiology Case Reports",,"10.1016/j.radcr.2022.10.046","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146573466&doi=10.1016%2fj.radcr.2022.10.046&partnerID=40&md5=a18f9755b4311ccd1b016b26378f4e3e","Patient consent statements were not included in the published version of the following articles that appeared in previous issues of Radiology Case Reports. The appropriate patient consent statements, provided by the authors, are included below. 1. “High-resolution magnetic resonance imaging in isolated, traumatic oculomotor nerve palsy: A case report” [Radiology Case Reports, 2021; 16 (2): 384-388] DOI 10.1016/j.radcr.2020.12.001 Patient consent: Informed consent has been obtained from the involved patient; and, they have given approval for this information to be published in case report ``High-resolution magnetic resonance imaging in isolated, traumatic oculomotor nerve palsy: A case report''.2. “Detecting a subendocardial infarction in a child with coronary anomaly by three-dimensional late gadolinium enhancement MRI using compressed sensing” [Radiology Case Reports, 2021; 16 (2): 377-380] DOI 10.1016/j.radcr.2020.11.048 Patient consent: Patient consent(s) held in form(s).3. “Subdural hygroma after spontaneous rupture of an arachnoid cyst in a pediatric patient: A case report” [Radiology Case Reports, 2021; 16 (2): 309-311] DOI 10.1016/j.radcr.2020.11.036 Patient consent: Patient consent(s) held in form(s).4. “Percutaneous catheter drainage of secondary abdominal compartment syndrome: A case report” [Radiology Case Reports, 2021; 16 (3): 670-672] DOI 10.1016/j.radcr.2021.01.008 Patient consent: Written consent has been obtained.5. “Ultrasound in the diagnosis of acute-phase decompression sickness” [Radiology Case Reports, 2021; 16 (3): 698-700] DOI 10.1016/j.radcr.2021.01.004 Patient consent: Patient consent(s) held in form(s).6. “Radiological evaluation of a case of chronic intestinal pseudo-obstruction (CIPO)” [Radiology Case Reports, 2021; 16 (3): 651-655] DOI 10.1016/j.radcr.2020.12.061 Patient consent: Patient consent(s) held in form(s).7. “Aspiration technique for percutaneous endovascular retrieval of contraceptive device embolized to the pulmonary vasculature” [Radiology Case Reports, 2021; 16 (3): 571-574] DOI 10.1016/j.radcr.2020.12.049 Patient consent: Patient consent(s) held in form(s).8. “A case of pulmonary arteriovenous malformation in the setting of Rendu Osler Weber syndrome” [Radiology Case Reports, 2021; 16 (3): 483-486] DOI 10.1016/j.radcr.2020.12.024 Patient consent: Patient consent(s) held in form(s).9. “Epiploic appendagitis of the vermiform appendix––An unusual mimic of acute appendicitis” [Radiology Case Reports, 2021; 16 (3): 511-515] DOI 10.1016/j.radcr.2020.12.005 Patient consent: Patient consent(s) held in form(s).10. “Herlyn-Werner-Wunderlich syndrome with borderline serous cystadenoma of the ovary: case report and literature review” [Radiology Case Reports, 2021; 16 (3): 744-747] DOI 10.1016/j.radcr.2020.09.048 Patient consent: Patient consent(s) held in form(s).11. “True partial diphallia with associated penoscrotal transposition of two hemi-scrotums” [Radiology Case Reports, 2021; 16 (4): 760-763] DOI 10.1016/j.radcr.2020.12.031 Patient consent: Patient consent(s) held in form(s).12. “A rare case of polymicrobial brain abscess involving Actinomyces” [Radiology Case Reports, 2021; 16 (5): 1123-1126] DOI 10.1016/j.radcr.2021.02.042 Patient consent: Written consents from these patients were obtained. © 2022",,"erratum",Erratum,Scopus
"Evans C.S., Dorris H.D., Kane M.T., Mervak B., Brice J.H., Gray B., Moore C.","A Natural Language Processing and Machine Learning Approach to Identification of Incidental Radiology Findings in Trauma Patients Discharged from the Emergency Department",2023,"Annals of Emergency Medicine",1,"10.1016/j.annemergmed.2022.08.450","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141240211&doi=10.1016%2fj.annemergmed.2022.08.450&partnerID=40&md5=e827c94ab69768655c1baf08698f5193","Study objective: Patients undergoing diagnostic imaging studies in the emergency department (ED) commonly have incidental findings, which may represent unrecognized serious medical conditions, including cancer. Recognition of incidental findings frequently relies on manual review of textual radiology reports and can be overlooked in a busy clinical environment. Our study aimed to develop and validate a supervised machine learning model using natural language processing to automate the recognition of incidental findings in radiology reports of patients discharged from the ED. Methods: We performed a retrospective analysis of computed tomography (CT) reports from trauma patients discharged home across an integrated health system in 2019. Two independent annotators manually labeled CT reports for the presence of an incidental finding as a reference standard. We used regular expressions to derive and validate a random forest model using open-source and machine learning software. Final model performance was assessed across different ED types. Results: The study CT reports were divided into derivation (690 reports) and validation (282 reports) sets, with a prevalence of incidental findings of 22.3%, and 22.7%, respectively. The random forest model had an area under the curve of 0.88 (95% confidence interval [CI], 0.84 to 0.92) on the derivation set and 0.92 (95% CI, 0.88 to 0.96) on the validation set. The final model was found to have a sensitivity of 92.2%, a specificity of 79.4%, and a negative predictive value of 97.2%. Similarly, strong model performance was found when stratified to a dedicated trauma center, high-volume, and low-volume community EDs. Conclusion: Machine learning and natural language processing can classify incidental findings in CT reports of ED patients with high sensitivity and high negative predictive value across a broad range of ED settings. These findings suggest the utility of natural language processing in automating the review of free-text reports to identify incidental findings and may facilitate interventions to improve timely follow-up. © 2022 American College of Emergency Physicians",,"adult; area under the curve; Article; Caucasian; computer assisted tomography; controlled study; diagnostic imaging; diagnostic test accuracy study; emergency health service; emergency physician; emergency ward; female; follow up; health care; high volume hospital; hospital discharge; human; incidental finding; injury; interrater reliability; kidney; liver; low volume hospital; lung; machine learning; male; mediastinum; medical informatics; natural language processing; predictive value; prevalence; random forest; retrospective study; sensitivity and specificity; standard; supervised machine learning; support vector machine; uterus; hospital discharge; hospital emergency service; incidental finding; machine learning; radiology; Emergency Service, Hospital; Humans; Incidental Findings; Machine Learning; Natural Language Processing; Patient Discharge; Radiology; Retrospective Studies",Article,Scopus
"Zhang Y., Liu M., Zhang L., Wang L., Zhao K., Hu S., Chen X., Xie X.","Comparison of Chest Radiograph Captions Based on Natural Language Processing vs Completed by Radiologists",2023,"JAMA Network Open",1,"10.1001/jamanetworkopen.2022.55113","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147783090&doi=10.1001%2fjamanetworkopen.2022.55113&partnerID=40&md5=a293795ff5d1a40cd1dd671b590f5c8e","Importance: Artificial intelligence (AI) can interpret abnormal signs in chest radiography (CXR) and generate captions, but a prospective study is needed to examine its practical value. Objective: To prospectively compare natural language processing (NLP)-generated CXR captions and the diagnostic findings of radiologists. Design, Setting, and Participants: A multicenter diagnostic study was conducted. The training data set included CXR images and reports retrospectively collected from February 1, 2014, to February 28, 2018. The retrospective test data set included consecutive images and reports from April 1 to July 31, 2019. The prospective test data set included consecutive images and reports from May 1 to September 30, 2021. Exposures: A bidirectional encoder representation from a transformers model was used to extract language entities and relationships from unstructured CXR reports to establish 23 labels of abnormal signs to train convolutional neural networks. The participants in the prospective test group were randomly assigned to 1 of 3 different caption generation models: a normal template, NLP-generated captions, and rule-based captions based on convolutional neural networks. For each case, a resident drafted the report based on the randomly assigned captions and an experienced radiologist finalized the report blinded to the original captions. A total of 21 residents and 19 radiologists were involved. Main Outcomes and Measures: Time to write reports based on different caption generation models. Results: The training data set consisted of 74 082 cases (39 254 [53.0%] women; mean [SD] age, 50.0 [17.1] years). In the retrospective (n = 8126; 4345 [53.5%] women; mean [SD] age, 47.9 [15.9] years) and prospective (n = 5091; 2416 [47.5%] women; mean [SD] age, 45.1 [15.6] years) test data sets, the mean (SD) area under the curve of abnormal signs was 0.87 (0.11) in the retrospective data set and 0.84 (0.09) in the prospective data set. The residents' mean (SD) reporting time using the NLP-generated model was 283 (37) seconds - significantly shorter than the normal template (347 [58] seconds; P <.001) and the rule-based model (296 [46] seconds; P <.001). The NLP-generated captions showed the highest similarity to the final reports with a mean (SD) bilingual evaluation understudy score of 0.69 (0.24) - significantly higher than the normal template (0.37 [0.09]; P <.001) and the rule-based model (0.57 [0.19]; P <.001). Conclusions and Relevance: In this diagnostic study of NLP-generated CXR captions, prior information provided by NLP was associated with greater efficiency in the reporting process, while maintaining good consistency with the findings of radiologists.. © 2022 American Medical Association. All rights reserved.",,"adult; area under the curve; article; controlled study; convolutional neural network; female; human; human experiment; major clinical study; male; multicenter study; natural language processing; prospective study; radiologist; randomized controlled trial; resident; retrospective study; thorax radiography; artificial intelligence; clinical trial; middle aged; radiologist; Artificial Intelligence; Female; Humans; Male; Middle Aged; Natural Language Processing; Prospective Studies; Radiologists; Retrospective Studies",Article,Scopus
"Cacciamani G.E., Sanford D.I., Chu T.N., Kaneko M., De Castro Abreu A.L., Duddalwar V., Gill I.S.","Is Artificial Intelligence Replacing Our Radiology Stars? Not Yet!",2023,"European Urology Open Science",8,"10.1016/j.euros.2022.09.024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144387182&doi=10.1016%2fj.euros.2022.09.024&partnerID=40&md5=892d45ad0d2c21b5705c961f244a5e93","Artificial intelligence (AI) is here to stay and will change health care as we know it. The availability of big data and the increasing numbers of AI algorithms approved by the US Food and Drug Administration together will help in improving the quality of care for patients and in overcoming human fatigue barriers. In oncology practice, patients and providers rely on the interpretation of radiologists when making clinical decisions; however, there is considerable variability among readers, and in particular for prostate imaging. AI represents an emerging solution to this problem, for which it can provide a much-needed form of standardization. The diagnostic performance of AI alone in comparison to a combination of an AI framework and radiologist assessment for evaluation of prostate imaging has yet to be explored. Here, we compare the performance of radiologists alone versus a combination of radiologists aided by a modern computer-aided diagnosis (CAD) AI system. We show that the radiologist-CAD combination demonstrates superior sensitivity and specificity in comparison to both radiologists alone and AI alone. Our findings demonstrate that a radiologist + AI combination could perform best for detection of prostate cancer lesions. A hybrid technology-human system could leverage the benefits of AI in improving radiologist performance while also reducing physician workload, minimizing burnout, and enhancing the quality of patient care. Patient summary: Our report demonstrates the potential of artificial intelligence (AI) for improving the interpretation of prostate scans. A combination of AI and evaluation by a radiologist has the best performance in determining the severity of prostate cancer. A hybrid system that uses both AI and radiologists could maximize the quality of care for patients while reducing physician workload and burnout. © 2022 The Author(s)","Artificial intelligence; Deep learning; Machine learning; Multiparametric magnetic resonance imaging; Performance; Prostate cancer; Radiology; Radiomics","artificial intelligence; cancer diagnosis; comparative study; diagnostic value; health care quality; human; Letter; nuclear magnetic resonance imaging; patient care; prostate cancer; prostate imaging reporting and data system; radiologist; radiology; radiomics; robot-assisted prostatectomy; sensitivity and specificity; workload",Letter,Scopus
"Stewart M., Yang N., Lim R.","Provision of feedback to radiology trainees: Barriers and inefficiencies, why it matters and a potential solution",2023,"Journal of Medical Imaging and Radiation Oncology",,"10.1111/1754-9485.13497","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144072489&doi=10.1111%2f1754-9485.13497&partnerID=40&md5=909006442be70732282abd2cdb6ef9b1",[No abstract available],"quality assurance","academic achievement; automation; education program; emergency ward; human; medical education; motivation; natural language processing; Note; online system; quality control; radiographer; radiology department; radiology trainee; report comparator tool; workload; education; feedback system; questionnaire; radiography; radiology; Feedback; Humans; Internship and Residency; Radiography; Radiology; Surveys and Questionnaires",Note,Scopus
"Chambon P., Cook T.S., Langlotz C.P.","Improved Fine-Tuning of In-Domain Transformer Model for Inferring COVID-19 Presence in Multi-Institutional Radiology Reports",2023,"Journal of Digital Imaging",,"10.1007/s10278-022-00714-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141147038&doi=10.1007%2fs10278-022-00714-8&partnerID=40&md5=74a1d84a5e4a2bcaeda157991b1e779d","Building a document-level classifier for COVID-19 on radiology reports could help assist providers in their daily clinical routine, as well as create large numbers of labels for computer vision models. We have developed such a classifier by fine-tuning a BERT-like model initialized from RadBERT, its continuous pre-training on radiology reports that can be used on all radiology-related tasks. RadBERT outperforms all biomedical pre-trainings on this COVID-19 task (P<0.01) and helps our fine-tuned model achieve an 88.9 macro-averaged F1-score, when evaluated on both X-ray and CT reports. To build this model, we rely on a multi-institutional dataset re-sampled and enriched with concurrent lung diseases, helping the model to resist to distribution shifts. In addition, we explore a variety of fine-tuning and hyperparameter optimization techniques that accelerate fine-tuning convergence, stabilize performance, and improve accuracy, especially when data or computational resources are limited. Finally, we provide a set of visualization tools and explainability methods to better understand the performance of the model, and support its practical use in the clinical setting. Our approach offers a ready-to-use COVID-19 classifier and can be applied similarly to other radiology report classification tasks. © 2022, The Author(s) under exclusive licence to Society for Imaging Informatics in Medicine.","BERT; Classification; COVID-19; Natural language processing (NLP); Radiology; Transformer","Computerized tomography; Natural language processing systems; Radiation; Radiology; BERT; Fine tuning; Language processing; Natural language processing; Natural languages; Performance; Pre-training; Radiology reports; Transformer; Transformer modeling; COVID-19; human; natural language processing; radiology; research; COVID-19; Humans; Natural Language Processing; Radiology; Research Report",Article,Scopus
"Shah C., Davtyan K., Nasrallah I., Bryan R.N., Mohan S.","Artificial Intelligence-Powered Clinical Decision Support and Simulation Platform for Radiology Trainee Education",2023,"Journal of Digital Imaging",5,"10.1007/s10278-022-00713-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140484212&doi=10.1007%2fs10278-022-00713-9&partnerID=40&md5=39d8782cd8c31c8c3aac8e3b8352a413","Technological tools can redesign traditional approaches to radiology education, for example, with simulation cases and via computer-generated feedback. In this study, we investigated the use of an AI-powered, Bayesian inference-based clinical decision support (CDS) software to provide automated “real-time” feedback to trainees during interpretation of clinical and simulation brain MRI examinations. Radiology trainees participated in sessions in which they interpreted 3 brain MRIs: two cases from a routine clinical worklist (one without and one with CDS) and a teaching file-based simulation case with CDS. The CDS software required trainees to input imaging features and differential diagnoses, after which inferred diagnoses were displayed, and the case was reviewed with an attending neuroradiologist. An observer timed each case, including time spent on education, and trainees completed a survey rating their confidence in their findings and the educational value of the case. Ten trainees reviewed 75 brain MRI examinations during 25 reading sessions. Trainees had slightly lower confidence in their findings and diagnosis and rated the educational value slightly higher for simulation cases with CDS compared to clinical cases without CDS (p < 0.05). There were no significant differences in ratings of clinical cases with or without CDS. No differences in overall timing were found among the reading scenarios. Simulation cases with “CDS-provided feedback” may improve the educational value of interpreting imaging studies at a workstation without adding additional time. Further investigation will help drive innovation in trainee education, which may be particularly relevant in this era of increasing remote work and asynchronous attending review. © 2022, The Author(s) under exclusive licence to Society for Imaging Informatics in Medicine.","Artificial intelligence; Bayesian networks; Brain MRI; Education; Simulation","Computer software; Decision support systems; Diagnosis; Inference engines; Magnetic resonance imaging; Personnel training; Radiation; Radiology; Simulation platform; Bayesia n networks; Bayesian inference; Brain MRI; Clinical decision support; Computer generated; Decision support software; Simulation; Simulation platform; Technological tools; Traditional approaches; Bayesian networks; article; artificial intelligence; Bayesian network; brain; case report; clinical article; decision support system; differential diagnosis; education; human; human experiment; neuroimaging; neuroradiologist; nuclear magnetic resonance imaging; radiology; simulation; software; teaching; telecommuting; artificial intelligence; Bayes theorem; clinical competence; clinical decision support system; education; medical education; radiography; Artificial Intelligence; Bayes Theorem; Clinical Competence; Decision Support Systems, Clinical; Humans; Internship and Residency; Radiography; Radiology",Article,Scopus
"Lau W., Lybarger K., Gunn M.L., Yetisgen M.","Event-Based Clinical Finding Extraction from Radiology Reports with Pre-trained Language Model",2023,"Journal of Digital Imaging",,"10.1007/s10278-022-00717-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139980500&doi=10.1007%2fs10278-022-00717-5&partnerID=40&md5=e38d1a87d82fcf23802304a7e69fdc94","Radiology reports contain a diverse and rich set of clinical abnormalities documented by radiologists during their interpretation of the images. Comprehensive semantic representations of radiological findings would enable a wide range of secondary use applications to support diagnosis, triage, outcomes prediction, and clinical research. In this paper, we present a new corpus of radiology reports annotated with clinical findings. Our annotation schema captures detailed representations of pathologic findings that are observable on imaging (“lesions”) and other types of clinical problems (“medical problems”). The schema used an event-based representation to capture fine-grained details, including assertion, anatomy, characteristics, size, and count. Our gold standard corpus contained a total of 500 annotated computed tomography (CT) reports. We extracted triggers and argument entities using two state-of-the-art deep learning architectures, including BERT. We then predicted the linkages between trigger and argument entities (referred to as argument roles) using a BERT-based relation extraction model. We achieved the best extraction performance using a BERT model pre-trained on 3 million radiology reports from our institution: 90.9–93.4% F1 for finding triggers and 72.0–85.6% F1 for argument roles. To assess model generalizability, we used an external validation set randomly sampled from the MIMIC Chest X-ray (MIMIC-CXR) database. The extraction performance on this validation set was 95.6% for finding triggers and 79.1–89.7% for argument roles, demonstrating that the model generalized well to the cross-institutional data with a different imaging modality. We extracted the finding events from all the radiology reports in the MIMIC-CXR database and provided the extractions to the research community. © 2022, The Author(s) under exclusive licence to Society for Imaging Informatics in Medicine.","Deep learning; Event extraction; Information extraction; Natural language processing","Clinical research; Computerized tomography; Deep learning; Diagnosis; Medical problems; Natural language processing systems; Radiation; Semantics; Deep learning; Event-based; Events extractions; Information extraction; Language processing; Natural language processing; Natural languages; Performance; Radiology reports; Validation sets; Radiology; article; assertiveness; computer assisted tomography; controlled study; deep learning; extraction; gold standard; human; human experiment; natural language processing; thorax radiography; natural language processing; radiology; research; semantics; x-ray computed tomography; Humans; Natural Language Processing; Radiology; Research Report; Semantics; Tomography, X-Ray Computed",Article,Scopus
"Moezzi S.A.R., Ghaedi A., Rahmanian M., Mousavi S.Z., Sami A.","Application of Deep Learning in Generating Structured Radiology Reports: A Transformer-Based Technique",2023,"Journal of Digital Imaging",,"10.1007/s10278-022-00692-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136943469&doi=10.1007%2fs10278-022-00692-x&partnerID=40&md5=043f1421e3ef76720aa99ffea80852c3","Since radiology reports needed for clinical practice and research are written and stored in free-text narrations, extraction of relative information for further analysis is difficult. In these circumstances, natural language processing (NLP) techniques can facilitate automatic information extraction and transformation of free-text formats to structured data. In recent years, deep learning (DL)-based models have been adapted for NLP experiments with promising results. Despite the significant potential of DL models based on artificial neural networks (ANN) and convolutional neural networks (CNN), the models face some limitations to implement in clinical practice. Transformers, another new DL architecture, have been increasingly applied to improve the process. Therefore, in this study, we propose a transformer-based fine-grained named entity recognition (NER) architecture for clinical information extraction. We collected 88 abdominopelvic sonography reports in free-text formats and annotated them based on our developed information schema. The text-to-text transfer transformer model (T5) and Scifive, a pre-trained domain-specific adaptation of the T5 model, were applied for fine-tuning to extract entities and relations and transform the input into a structured format. Our transformer-based model in this study outperformed previously applied approaches such as ANN and CNN models based on ROUGE-1, ROUGE-2, ROUGE-L, and BLEU scores of 0.816, 0.668, 0.528, and 0.743, respectively, while providing an interpretable structured report. © 2022, The Author(s) under exclusive licence to Society for Imaging Informatics in Medicine.","Deep learning; Named entity recognition; Natural language processing; Relation extraction; Structured reporting; Transformers","Clinical research; Convolutional neural networks; Information retrieval; Metadata; Natural language processing systems; Network architecture; Neural network models; Radiation; Radiology; Ultrasonic imaging; Deep learning; Free texts; Language processing; Named entity recognition; Natural language processing; Natural languages; Radiology reports; Relation extraction; Structured reporting; Transformer; Deep learning; article; artificial neural network; clinical practice; convolutional neural network; deep learning; echography; extraction; human; natural language processing; radiology; information retrieval; natural language processing; radiography; Deep Learning; Humans; Information Storage and Retrieval; Natural Language Processing; Neural Networks, Computer; Radiography; Radiology",Article,Scopus
"Chambon P.J., Wu C., Steinkamp J.M., Adleberg J., Cook T.S., Langlotz C.P.","Automated deidentification of radiology reports combining transformer and ""hide in plain sight"" rule-based methods",2023,"Journal of the American Medical Informatics Association : JAMIA",1,"10.1093/jamia/ocac219","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146484482&doi=10.1093%2fjamia%2focac219&partnerID=40&md5=dd9bfe2822ab74f725c10f43590cdb80","OBJECTIVE: To develop an automated deidentification pipeline for radiology reports that detect protected health information (PHI) entities and replaces them with realistic surrogates ""hiding in plain sight."" MATERIALS AND METHODS: In this retrospective study, 999 chest X-ray and CT reports collected between November 2019 and November 2020 were annotated for PHI at the token level and combined with 3001 X-rays and 2193 medical notes previously labeled, forming a large multi-institutional and cross-domain dataset of 6193 documents. Two radiology test sets, from a known and a new institution, as well as i2b2 2006 and 2014 test sets, served as an evaluation set to estimate model performance and to compare it with previously released deidentification tools. Several PHI detection models were developed based on different training datasets, fine-tuning approaches and data augmentation techniques, and a synthetic PHI generation algorithm. These models were compared using metrics such as precision, recall and F1 score, as well as paired samples Wilcoxon tests. RESULTS: Our best PHI detection model achieves 97.9 F1 score on radiology reports from a known institution, 99.6 from a new institution, 99.5 on i2b2 2006, and 98.9 on i2b2 2014. On reports from a known institution, it achieves 99.1 recall of detecting the core of each PHI span. DISCUSSION: Our model outperforms all deidentifiers it was compared to on all test sets as well as human labelers on i2b2 2014 data. It enables accurate and automatic deidentification of radiology reports. CONCLUSIONS: A transformer-based deidentification pipeline can achieve state-of-the-art performance for deidentifying radiology reports and other medical documents. © The Author(s) 2022. Published by Oxford University Press on behalf of the American Medical Informatics Association. All rights reserved. For permissions, please email: journals.permissions@oup.com.","deidentification; machine learning; NLP; radiology; transformer","algorithm; anonymization; health care facility; human; natural language processing; radiology; retrospective study; Algorithms; Data Anonymization; Health Facilities; Humans; Natural Language Processing; Radiology; Retrospective Studies",Article,Scopus
"Ichinose A., Hatsutani T., Nakamura K., Kitamura Y., Iizuka S., Simo-Serra E., Kido S., Tomiyama N.","Visual Grounding of Whole Radiology Reports for 3D CT Images",2023,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"10.1007/978-3-031-43904-9_59","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174690182&doi=10.1007%2f978-3-031-43904-9_59&partnerID=40&md5=7611d42ab09560b19b77baefcce7fc23","Building a large-scale training dataset is an essential problem in the development of medical image recognition systems. Visual grounding techniques, which automatically associate objects in images with corresponding descriptions, can facilitate labeling of large number of images. However, visual grounding of radiology reports for CT images remains challenging, because so many kinds of anomalies are detectable via CT imaging, and resulting report descriptions are long and complex. In this paper, we present the first visual grounding framework designed for CT image and report pairs covering various body parts and diverse anomaly types. Our framework combines two components of 1) anatomical segmentation of images, and 2) report structuring. The anatomical segmentation provides multiple organ masks of given CT images, and helps the grounding model recognize detailed anatomies. The report structuring helps to accurately extract information regarding the presence, location, and type of each anomaly described in corresponding reports. Given the two additional image/report features, the grounding model can achieve better localization. In the verification process, we constructed a large-scale dataset with region-description correspondence annotations for 10,410 studies of 7,321 unique patients. We evaluated our framework using grounding accuracy, the percentage of correctly localized anomalies, as a metric and demonstrated that the combination of the anatomical segmentation and the report structuring improves the performance with a large margin over the baseline model (66.0% vs 77.8%). Comparison with the prior techniques also showed higher performance of our method. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.","Computed Tomography; Deep Learning; Vision Language; Visual Grounding","Deep learning; Image recognition; Image segmentation; Large dataset; Medical imaging; Radiology; Computed tomography; CT Image; Deep learning; Essential problems; Large-scales; Performance; Radiology reports; Training dataset; Vision language; Visual grounding; Computerized tomography",Conference Paper,Scopus
"Pellegrini C., Keicher M., Özsoy E., Navab N.","Rad-ReStruct: A Novel VQA Benchmark and Method for Structured Radiology Reporting",2023,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"10.1007/978-3-031-43904-9_40","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174687828&doi=10.1007%2f978-3-031-43904-9_40&partnerID=40&md5=7029e87996356fe34763acce15bc11cc","Radiology reporting is a crucial part of the communication between radiologists and other medical professionals, but it can be time-consuming and error-prone. One approach to alleviate this is structured reporting, which saves time and enables a more accurate evaluation than free-text reports. However, there is limited research on automating structured reporting, and no public benchmark is available for evaluating and comparing different methods. To close this gap, we introduce Rad-ReStruct, a new benchmark dataset that provides fine-grained, hierarchically ordered annotations in the form of structured reports for X-Ray images. We model the structured reporting task as hierarchical visual question answering (VQA) and propose hi-VQA, a novel method that considers prior context in the form of previously asked questions and answers for populating a structured radiology report. Our experiments show that hi-VQA achieves competitive performance to the state-of-the-art on the medical VQA benchmark VQARad while performing best among methods without domain-specific vision-language pretraining and provides a strong baseline on Rad-ReStruct. Our work represents a significant step towards the automated population of structured radiology reports and provides a valuable first benchmark for future research in this area. Our dataset and code is available at https://github.com/ChantalMP/Rad-ReStruct. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.","Structured Report Population; VQA; X-ray diagnosis","Diagnosis; Natural language processing systems; Radiology; Error prones; Medical professionals; Question Answering; Radiology reporting; Radiology reports; Structured report population; Structured reporting; Structured reports; Visual question answering; X-ray diagnosis; Benchmarking",Conference Paper,Scopus
"Bhagavan K.N., Vardhan M.S., Chowdhary M.A., Sharma R.","nav-nlp at RadSum23: Abstractive Summarization of Radiology Reports using BART Finetuning",2023,"Proceedings of the Annual Meeting of the Association for Computational Linguistics",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174542641&partnerID=40&md5=925f6f2a6fd4b23e0290e893ba95c095","This paper describes the experiments undertaken and their results as part of the BioNLP 2023 workshop. We took part in Task 1B: Radiology Report Summarization (Delbrouck et al., 2023). Multiple runs were submitted for evaluation from solutions utilizing transfer learning from pre-trained transformer models, which were then fine-tuned on the MIMIC-III dataset, for abstractive report summarization. The task was evaluated using different evaluation metrics such as ROUGEL, Bertscore, and F1-RadGraph, and the corresponding scores of our best-performing system are 32.33, 54.49, and 32.68 respectively. © 2023 Association for Computational Linguistics.",,"Computational linguistics; Natural language processing systems; Evaluation metrics; Radiology reports; Transfer learning; Transformer modeling; Radiology",Conference Paper,Scopus
"Nicolson A., Dowling J., Koopman B.","e-Health CSIRO at RadSum23: Adapting a Chest X-Ray Report Generator to Multimodal Radiology Report Summarisation",2023,"Proceedings of the Annual Meeting of the Association for Computational Linguistics",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174542103&partnerID=40&md5=70ae557fdd91066ba3788d893ce60816","We describe the participation of team e-Health CSIRO in the BioNLP RadSum task of 2023. This task aims to develop automatic summarisation methods for radiology. The subtask that we participated in was multimodal; the impression section of a report was to be summarised from a given findings section and set of Chest X-rays (CXRs) of a subject’s study. For our method, we adapted an encoder-to-decoder model for CXR report generation to the subtask. e-Health CSIRO placed seventh amongst the participating teams with a RadGraph ER F1 score of 23.9. © 2023 Association for Computational Linguistics.",,"eHealth; Natural language processing systems; Report generators; Automatic summarization; E health; Ehealth; F1 scores; Multi-modal; Participating teams; Radiology reports; Report generation; Subtask; Radiology",Conference Paper,Scopus
"Kim G., Kim H., Ji L., Bae S., Kim C., Sung M., Kim H., Yan K., Chang E., Kang J.","KU-DMIS-MSRA at RadSum23: Pre-trained Vision-Language Model for Radiology Report Summarization",2023,"Proceedings of the Annual Meeting of the Association for Computational Linguistics",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174537244&partnerID=40&md5=7aaa259e5758ca5901e7aa8200b4e236","In this paper, we introduce CheXOFA, a new pre-trained vision-language model (VLM) for the chest X-ray domain. Our model is initially pre-trained on various multimodal datasets within the general domain before being transferred to the chest X-ray domain. Following a prominent VLM, we unify various domain-specific tasks into a simple sequence-to-sequence schema. It enables the model to effectively learn the required knowledge and skills from limited resources in the domain. Demonstrating superior performance on the benchmark datasets provided by the BioNLP shared task (Delbrouck et al., 2023), our model benefits from its training across multiple tasks and domains. With subtle techniques including ensemble and factual calibration, our system achieves first place on the RadSum23 leaderboard for the hidden test set. © 2023 Association for Computational Linguistics.",,"Computational linguistics; Benchmark datasets; Domain specific; Language model; Learn+; Multi-modal dataset; Multiple domains; Performance; Radiology reports; Simple++; Specific tasks; Benchmarking",Conference Paper,Scopus
"Wajsbürt P., Tannier X.","An end-to-end neural model based on cliques and scopes for frame extraction in long breast radiology reports",2023,"Proceedings of the Annual Meeting of the Association for Computational Linguistics",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174534895&partnerID=40&md5=d7aae7e371aae38585c200188b54166a","We consider the task of automatically extracting various overlapping frames, i.e, structured entities composed of multiple labels and mentions, from long clinical breast radiology documents. While many methods exist for related topics such as event extraction, slot filling, or discontinuous entity recognition, a challenge in our study resides in the fact that clinical reports typically contain overlapping frames that span multiple sentences or paragraphs. We propose a new method that addresses these difficulties and evaluate it on a new annotated corpus. Despite the small number of documents, we show that the hybridization between knowledge injection and a learning-based system allows us to quickly obtain proper results. We will also introduce the concept of scope relations and show that it both improves the performance of our system, and provides a visual explanation of the predictions. © 2023 Association for Computational Linguistics.",,"Computational linguistics; Radiology; Breast radiology; End to end; Entity recognition; Events extractions; Frame extraction; Hybridisation; Model-based OPC; Multiple labels; Neural modelling; Radiology reports; Extraction",Conference Paper,Scopus
"Wu J., Shi D., Hasan A., Wu H.","KnowLab at RadSum23: comparing pre-trained language models in radiology report summarization",2023,"Proceedings of the Annual Meeting of the Association for Computational Linguistics",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174532836&partnerID=40&md5=f9dfc06261aef3fc376803510a7a4bb2","This paper presents our contribution to the RadSum23 shared task organized as part of the BioNLP 2023. We compared state-of-the-art generative language models in generating high-quality summaries from radiology reports. A two-stage fine-tuning approach was introduced for utilizing knowledge learnt from different datasets. We evaluated the performance of our method using a variety of metrics, including BLEU, ROUGE, Bertscore, CheXbert, and RadGraph. Our results revealed the potentials of different models in summarizing radiology reports and demonstrated the effectiveness of the two-stage fine-tuning approach. We also discussed the limitations and future directions of our work, highlighting the need for better understanding the architecture design’s effect and optimal way of fine-tuning accordingly in automatic clinical summarizations. © 2023 Association for Computational Linguistics.",,"Natural language processing systems; Radiology; Architecture designs; Fine tuning; High quality; Language model; Learn+; Performance; Radiology reports; S effect; State of the art; Computational linguistics",Conference Paper,Scopus
"Ahuir V., Segarra E., Hurtado L.-F.","ELiRF-VRAIN at BioNLP Task 1B: Radiology Report Summarization",2023,"Proceedings of the Annual Meeting of the Association for Computational Linguistics",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174515716&partnerID=40&md5=22ea23691c824dd1521de5e71ecea929","This paper presents our system at the Radiology Report Summarization Shared Task-1B of the 22nd BioNLP Workshop 2023. Inspired by the work of the BioBART model, we continuously pre-trained a general domain BART model with biomedical data to adapt it to this specific domain. In the pre-training phase, several pre-training tasks are aggregated to inject linguistic knowledge and increase the abstractivity of the generated summaries. We present the results of our models, and also, we have carried out an additional study on the lengths of the generated summaries, which has provided us with interesting information. © 2023 Association for Computational Linguistics.",,"Computational linguistics; Natural language processing systems; Biomedical data; Interesting information; Linguistic knowledge; Pre-training; Radiology reports; Training phasis; Radiology",Conference Paper,Scopus
"Chizhikova M., Díaz Galiano M.C., López L.A.U., Valdivia M.T.M.","SINAI at RadSum23: Radiology Report Summarization Based on Domain-Specific Sequence-To-Sequence Transformer Model",2023,"Proceedings of the Annual Meeting of the Association for Computational Linguistics",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174505286&partnerID=40&md5=66d83451bf2353ef47745b2310a4bde3","This paper covers participation of the SINAI team in the shared task 1B: Radiology Report Summarization at the BioNLP workshop held on ACL 2023. Our proposal follows a “sequence-to-sequence"" approach which leverages pre-trained multilingual general domain and monolingual biomedical domain pre-trained language models. The best performing system based on domain-specific model reached 33.96 F1RadGraph score which is the fourth best result among the challenge participants. This model was made publicly available on HuggingFace. We also describe an attempt of Proximal Policy Optimization Reinforcement Learning that was made in order to improve the factual correctness measured with F1RadGraph but did not lead to satisfactory results. © 2023 Association for Computational Linguistics.",,"Computational linguistics; Natural language processing systems; Radiology; Biomedical domain; Domain specific; Domain-specific modelling; Language model; Policy optimization; Radiology reports; Reinforcement learnings; Specific sequences; Transformer modeling; Reinforcement learning",Conference Paper,Scopus
"Delbrouck J.-B., Varma M., Chambon P., Langlotz C.P.","Overview of the RadSum23 Shared Task on Multi-modal and Multi-anatomical Radiology Report Summarization",2023,"Proceedings of the Annual Meeting of the Association for Computational Linguistics",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174503535&partnerID=40&md5=d7b35fc2a80dc4c336dc481508d42033","Radiology report summarization is a growing area of research. Given the Findings and/or Background sections of a radiology report, the goal is to generate a summary (called an Impression section) that highlights the key observations and conclusions of the radiology study. Recent efforts have released systems that achieve promising performance as measured by widely used summarization metrics such as BLEU and ROUGE. However, the research area of radiology report summarization currently faces two important limitations. First, most of the results are reported on private datasets. This limitation prevents the ability to reproduce results and fairly compare different systems and solutions. Secondly, to the best of our knowledge, most research is carried out on chest X-rays. To palliate these two limitations, we propose a radiology report summarization (RadSum) challenge on i) a new dataset of eleven different modalities and anatomies pairs based on the MIMIC-III database ii) a multimodal report summarization dataset based on MIMIC-CXR enhanced with a brand-new test-set from Stanford Hospital. In total, we received 112 submissions across 11 teams. © 2023 Association for Computational Linguistics.",,"Computational linguistics; Statistical tests; Multi-modal; Performance; Radiology reports; Research areas; Stanford; Test sets; Radiology",Conference Paper,Scopus
"Karn S.K., Ghosh R., Kusuma P., Farri O.","shs-nlp at RadSum23: Domain-Adaptive Pre-training of Instruction-tuned LLMs for Radiology Report Impression Generation",2023,"Proceedings of the Annual Meeting of the Association for Computational Linguistics",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174496787&partnerID=40&md5=77d3cd37193c8f21b34548b54cc4e103","Instruction-tuned generative large language models (LLMs), such as ChatGPT and Bloomz, possess excellent generalization abilities. However, they face limitations in understanding radiology reports, particularly when generating the IMPRESSIONS section from the FINDINGS section. These models tend to produce either verbose or incomplete IMPRESSIONS, mainly due to insufficient exposure to medical text data during training. We present a system that leverages large-scale medical text data for domain-adaptive pre-training of instruction-tuned LLMs, enhancing their medical knowledge and performance on specific medical tasks. We demonstrate that this system performs better in a zero-shot setting compared to several pretrain-and-finetune adaptation methods on the IMPRESSIONS generation task. Furthermore, it ranks 1st among participating systems in Task 1B: Radiology Report Summarization at the BioNLP 2023 workshop. © 2023 Association for Computational Linguistics.",,"Computational linguistics; Natural language processing systems; Zero-shot learning; Adaptation methods; Generalization ability; Language model; Large-scales; Medical knowledge; Participating systems; Performance; Pre-training; Radiology reports; Text data; Radiology",Conference Paper,Scopus
"Kim S., Nooralahzadeh F., Rohanian M., Fujimoto K., Nishio M., Sakamoto R., Rinaldi F., Krauthammer M.","Boosting Radiology Report Generation by Infusing Comparison Prior",2023,"Proceedings of the Annual Meeting of the Association for Computational Linguistics",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174492653&partnerID=40&md5=664706dd7ccd0fed25aa2d264369aeee","Recent transformer-based models have made significant strides in generating radiology reports from chest X-ray images. However, a prominent challenge remains: these models often lack prior knowledge, resulting in the generation of synthetic reports that mistakenly reference non-existent prior exams. This discrepancy can be attributed to a knowledge gap between radiologists and the generation models. While radiologists possess patient-specific prior information, the models solely receive X-ray images at a specific time point. To tackle this issue, we propose a novel approach that leverages a rule-based labeler to extract comparison prior information from radiology reports. This extracted comparison prior is then seamlessly integrated into state-of-the-art transformer-based models, enabling them to produce more realistic and comprehensive reports. Our method is evaluated on English report datasets, such as IU X-ray and MIMIC-CXR. The results demonstrate that our approach surpasses baseline models in terms of natural language generation metrics. Notably, our model generates reports that are free from false references to non-existent prior exams, setting it apart from previous models. By addressing this limitation, our approach represents a significant step towards bridging the gap between radiologists and generation models in the domain of medical report generation. © 2023 Association for Computational Linguistics.",,"Computational linguistics; Natural language processing systems; Chest X-ray image; Knowledge gaps; Patient specific; Prior information; Prior-knowledge; Radiology reports; Report generation; Specific time; Time points; X-ray image; Radiology",Conference Paper,Scopus
"Hou X., Sang G., Liu Z., Li X., Zhang Y.","Radiology Report Generation via Visual Recalibration and Context Gating-Aware",2023,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"10.1007/978-981-99-7074-2_9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174313430&doi=10.1007%2f978-981-99-7074-2_9&partnerID=40&md5=8800e735c17448f2abb5c76fce77275b","The task of radiology report generation aims to analyze medical images, extract key information, and then assist medical personnel in generating detailed and accurate reports. Therefore, automatic radiology report generation plays an important role in medical diagnosis and healthcare. However, radiology medical data face the problems of visual and text data bias: medical images are similar to each other, and the normal feature distribution is larger than the abnormal feature distribution; second, the accurate location of the lesion and the generation of accurate and coherent long text reports are important challenges. In this paper, we propose Visual Recalibration and Context Gating-aware model (VRCG) to alleviate visual and textual data bias for enhancing report generation. We employ a medical visual recalibration module to enhance the key lesion feature extraction. We use the context gating-aware module to combine lesion location and report context information to solve the problem of long-distance dependence in diagnostic reports. Meanwhile, the context gating-aware module can identify text fragments related to lesion descriptions, improve the model’s perception of lesion text information, and then generate coherent, consistent medical reporting. Extensive experiments demonstrate that our proposed model outperforms existing baseline models on a publicly available IU X-Ray dataset. The source code is available at: https://github.com/Eleanorhxd/VRCG. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","Context Gating-aware; Medical Visual Recalibration; Report Generation","Data mining; Diagnosis; Medical imaging; Medical problems; Context gating-aware; Feature distribution; Medical data; Medical personnel; Medical visual recalibration; Radiology reports; Recalibrations; Report generation; Text data; Visual data; Radiology",Conference Paper,Scopus
"Ray P.P.","Letter to the Editor: A critical evaluation on the use of large language model for radiology research",2023,"European Radiology",,"10.1007/s00330-023-10332-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174293833&doi=10.1007%2fs00330-023-10332-9&partnerID=40&md5=1ecbdc15051ed2dc92981e55190fa32b",[No abstract available],,,Letter,Scopus
"López-Úbeda P., Martín-Noguerol T., Luna A.","Reply to the letter to the editor: “A critical evaluation on the use of large language model for radiology research”",2023,"European Radiology",,"10.1007/s00330-023-10333-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174229197&doi=10.1007%2fs00330-023-10333-8&partnerID=40&md5=62ad29154cf57ed7a1dde652c1065c50",[No abstract available],,,Letter,Scopus
"Ghosh R., Karn S.K., Danu M.D., Micu L., Vunikili R., Farri O.","RadLing: Towards Effcient Radiology Report Understanding",2023,"Proceedings of the Annual Meeting of the Association for Computational Linguistics",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174227609&partnerID=40&md5=751a8b3f4d0ed0014701ef6bde4a8cc4","Most natural language tasks in the radiology domain use language models pre-trained on biomedical corpus. There are few pretrained language models trained specifcally for radiology, and fewer still that have been trained in a low data setting and gone on to produce comparable results in fne-tuning tasks. We present RadLing, a continuously pretrained language model using ELECTRA-small (Clark et al., 2020) architecture, trained using over 500K radiology reports, that can compete with state-of-the-art results for fne tuning tasks in radiology domain. Our main contribution in this paper is knowledge-aware masking which is a taxonomic knowledge-assisted pretraining task that dynamically masks tokens to inject knowledge during pretraining. In addition, we also introduce an knowledge base-aided vocabulary extension to adapt the general tokeniza-tion vocabulary to radiology domain. © ACL 2023.All rights reserved.",,"Computational linguistics; Knowledge based systems; Natural language processing systems; Data settings; Knowledge-assisted; Language model; Natural languages; Pre-training; Radiology reports; State of the art; Radiology",Conference Paper,Scopus
"Casey A., Davidson E., Grover C., Tobin R., Grivas A., Zhang H., Schrempf P., O’Neil A.Q., Lee L., Walsh M., Pellie F., Ferguson K., Cvoro V., Wu H., Whalley H., Mair G., Whiteley W., Alex B.","Understanding the performance and reliability of NLP tools: a comparison of four NLP tools predicting stroke phenotypes in radiology reports",2023,"Frontiers in Digital Health",,"10.3389/fdgth.2023.1184919","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174150809&doi=10.3389%2ffdgth.2023.1184919&partnerID=40&md5=982eee38175cde65a633d400598ad72d","Background: Natural language processing (NLP) has the potential to automate the reading of radiology reports, but there is a need to demonstrate that NLP methods are adaptable and reliable for use in real-world clinical applications. Methods: We tested the F1 score, precision, and recall to compare NLP tools on a cohort from a study on delirium using images and radiology reports from NHS Fife and a population-based cohort (Generation Scotland) that spans multiple National Health Service health boards. We compared four off-the-shelf rule-based and neural NLP tools (namely, EdIE-R, ALARM+, ESPRESSO, and Sem-EHR) and reported on their performance for three cerebrovascular phenotypes, namely, ischaemic stroke, small vessel disease (SVD), and atrophy. Clinical experts from the EdIE-R team defined phenotypes using labelling techniques developed in the development of EdIE-R, in conjunction with an expert researcher who read underlying images. Results: EdIE-R obtained the highest F1 score in both cohorts for ischaemic stroke, ≥93%, followed by ALARM+, ≥87%. The F1 score of ESPRESSO was ≥74%, whilst that of Sem-EHR is ≥66%, although ESPRESSO had the highest precision in both cohorts, 90% and 98%. For F1 scores for SVD, EdIE-R scored ≥98% and ALARM+ ≥90%. ESPRESSO scored lowest with ≥77% and Sem-EHR ≥81%. In NHS Fife, F1 scores for atrophy by EdIE-R and ALARM+ were 99%, dropping in Generation Scotland to 96% for EdIE-R and 91% for ALARM+. Sem-EHR performed lowest for atrophy at 89% in NHS Fife and 73% in Generation Scotland. When comparing NLP tool output with brain image reads using F1 scores, ALARM+ scored 80%, outperforming EdIE-R at 66% in ischaemic stroke. For SVD, EdIE-R performed best, scoring 84%, with Sem-EHR 82%. For atrophy, EdIE-R and both ALARM+ versions were comparable at 80%. Conclusions: The four NLP tools show varying F1 (and precision/recall) scores across all three phenotypes, although more apparent for ischaemic stroke. If NLP tools are to be used in clinical settings, this cannot be performed “out of the box.” It is essential to understand the context of their development to assess whether they are suitable for the task at hand or whether further training, re-training, or modification is required to adapt tools to the target task. 2023 Casey, Davidson, Grover, Tobin, Grivas, Zhang, Schrempf, O’Neil, Lee, Walsh, Pellie, Ferguson, Cvero, Wu, Whalley, Mair, Whiteley and Alex.","brain radiology; electronic health records; natural language processing; stroke phenotype","adult; aged; Article; atrophy; blood clot lysis; brain hemorrhage; brain infarction; brain size; cerebrovascular accident; cohort analysis; computer assisted tomography; delirium; electronic health record; female; gray matter; human; ischemic stroke; major clinical study; male; national health service; natural language processing; nuclear magnetic resonance imaging; phenotype; predictive value; prevalence; radiology; risk factor",Article,Scopus
"Jeblick K., Schachtner B., Dexl J., Mittermeier A., Stüber A.T., Topalis J., Weber T., Wesp P., Sabel B.O., Ricke J., Ingrisch M.","ChatGPT makes medicine easy to swallow: an exploratory case study on simplified radiology reports",2023,"European Radiology",,"10.1007/s00330-023-10213-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173436199&doi=10.1007%2fs00330-023-10213-1&partnerID=40&md5=412580f1351e68c291507e7ac6ffd025","Objectives: To assess the quality of simplified radiology reports generated with the large language model (LLM) ChatGPT and to discuss challenges and chances of ChatGPT-like LLMs for medical text simplification. Methods: In this exploratory case study, a radiologist created three fictitious radiology reports which we simplified by prompting ChatGPT with “Explain this medical report to a child using simple language.” In a questionnaire, we tasked 15 radiologists to rate the quality of the simplified radiology reports with respect to their factual correctness, completeness, and potential harm for patients. We used Likert scale analysis and inductive free-text categorization to assess the quality of the simplified reports. Results: Most radiologists agreed that the simplified reports were factually correct, complete, and not potentially harmful to the patient. Nevertheless, instances of incorrect statements, missed relevant medical information, and potentially harmful passages were reported. Conclusion: While we see a need for further adaption to the medical field, the initial insights of this study indicate a tremendous potential in using LLMs like ChatGPT to improve patient-centered care in radiology and other medical domains. Clinical relevance statement: Patients have started to use ChatGPT to simplify and explain their medical reports, which is expected to affect patient-doctor interaction. This phenomenon raises several opportunities and challenges for clinical routine. Key Points: • Patients have started to use ChatGPT to simplify their medical reports, but their quality was unknown. • In a questionnaire, most participating radiologists overall asserted good quality to radiology reports simplified with ChatGPT. However, they also highlighted a notable presence of errors, potentially leading patients to draw harmful conclusions. • Large language models such as ChatGPT have vast potential to enhance patient-centered care in radiology and other medical domains. To realize this potential while minimizing harm, they need supervision by medical experts and adaption to the medical field. Graphical Abstract: [Figure not available: see fulltext.] © 2023, The Author(s).","Natural language processing; Patient-centered care; Radiology","article; case report; ChatGPT; child; clinical article; clinical significance; exploratory research; female; human; large language model; Likert scale; male; medical expert; medical information; natural language processing; patient care; questionnaire; radiologist; radiology",Article,Scopus
"Kale K., Bhattacharyya P., Shetty A., Gune M., Shrivastava K., Lawyer R., Biswas S.","Knowledge is Power"": Constructing Knowledge Graph of Abdominal Organs and Using Them for Automatic Radiology Report Generation",2023,"Proceedings of the Annual Meeting of the Association for Computational Linguistics",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173236371&partnerID=40&md5=bacabd119927dcb2d93faf6f5d8feedd","In conventional radiology practice, the radiologist dictates the diagnosis to the transcription-ist, who then prepares a preliminary formatted report referring to the notes, after which the radiologist reviews the report, corrects the errors, and signs off. This workfow is prone to delay and error. In this paper, we report our work on automatic radiology report generation from radiologists' dictation, which is in collaboration with a startup about to become Unicorn. A major contribution of our work is the set of knowledge graphs (KGs) of ten abdominal organs- Liver, Kidney, Gallbladder, Uterus, Urinary bladder, Ovary, Pancreas, Prostate, Biliary Tree, and Bowel. Our method for constructing these KGs relies on extracting entity1-relation-entity2 triplets from a large collection (about 10,000) of free-text radiology reports. The quality and coverage of the KGs are veri-fed by two experienced radiologists (practicing for the last 30 years and 8 years, respectively). The dictation of the radiologist is automatically converted to what is called a pathological description which is the clinical description of the fndings of the radiologist during ultrasonog-raphy (USG). Our knowledge-enhanced deep learning model improves the reported BLEU-3, ROUGE-L, METEOR, and CIDEr scores of the pathological description generation by 2%, 4%, 2% and 2% respectively. To the best of our knowledge, this is the frst attempt at representing the abdominal organs in the form of knowledge graphs and utilising these graphs for the automatic generation of USG reports. A Minimum Viable Product (MVP) has been made available to the beta users, i.e., radiologists of reputed hospitals, for testing and evaluation. Our solution guarantees report generation within 30 seconds of running a scan. © ACL 2023.All rights reserved.",,"Knowledge graph; Radiology; Trees (mathematics); Abdominal organs; Biliary tree; Free texts; Knowledge graphs; Learning models; Power; Radiology reports; Report generation; Sign-off; Urinary bladder; Deep learning",Conference Paper,Scopus
"Chen Z., Varma M., Wan X., Langlotz C.P., Delbrouck J.-B.","Toward Expanding the Scope of Radiology Report Summarization to Multiple Anatomies and Modalities",2023,"Proceedings of the Annual Meeting of the Association for Computational Linguistics",1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172220600&partnerID=40&md5=5b3d31c87f77c5b3ae78acf65c2643e5","Radiology report summarization (RRS) is a growing area of research. Given the Findings section of a radiology report, the goal is to generate a summary (called an Impression section) that highlights the key observations and conclusions of the radiology study. However, RRS currently faces essential limitations. First, many prior studies conduct experiments on private datasets, preventing the reproduction of results and fair comparisons across different systems and solutions. Second, most prior approaches are evaluated solely on chest X-rays. To address these limitations, we propose a dataset (MIMIC-RRS) involving three new modalities and seven new anatomies based on the MIMIC-III and MIMIC-CXR datasets. We then conduct extensive experiments to evaluate the performance of models both within and across modality-anatomy pairs in MIMIC-RRS. In addition, we evaluate their clinical efficacy via RadGraph, a factual correctness metric. © 2023 Association for Computational Linguistics.",,"Cell proliferation; Computational linguistics; Clinical efficacy; New modality; Performance; Radiology reports; Radiology",Conference Paper,Scopus
"Pachade S., Datta S., Dong Y., Salazar-Marioni S., Abdelkhaleq R., Niktabe A., Roberts K., Sheth S.A., Giancardo L.","Self-Supervised Learning with Radiology Reports, A Comparative Analysis of Strategies for Large Vessel Occlusion and Brain CTA Images",2023,"Proceedings - International Symposium on Biomedical Imaging",,"10.1109/ISBI53787.2023.10230623","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172106164&doi=10.1109%2fISBI53787.2023.10230623&partnerID=40&md5=0bb69c9c852b05edfad4c75945ab69f9","Scarcity of labels for medical images is a significant barrier for training representation learning approaches based on deep neural networks. This limitation is also present when using imaging data collected during routine clinical care stored in picture archiving communication systems (PACS), as these data rarely have attached the high-quality labels required for medical image computing tasks. However, medical images extracted from PACS are commonly coupled with descriptive radiology reports that contain significant information and could be leveraged to pre-train imaging models, which could serve as starting points for further task-specific fine-tuning.In this work, we perform a head-to-head comparison of three different self-supervised strategies to pre-train the same imaging model on 3D brain computed tomography angiogram (CTA) images, with large vessel occlusion (LVO) detection as the downstream task. These strategies evaluate two natural language processing (NLP) approaches, one to extract 100 explicit radiology concepts (Rad-SpatialNet) and the other to create general-purpose radiology reports embeddings (Distil-BERT). In addition, we experiment with learning radiology concepts directly or by using a recent self-supervised learning approach (CLIP) that learns by ranking the distance between language and image vector embeddings. The LVO detection task was selected because it requires 3D imaging data, is clinically important, and requires the algorithm to learn outputs not explicitly stated in the radiology report.Pre-training was performed on an unlabeled dataset containing 1,542 3D CTA - reports pairs. The downstream task was tested on a labeled dataset of 402 subjects for LVO. We find that the pre-training performed with CLIP-based strategies improve the performance of the imaging model to detect LVO compared to a model trained only on the labeled data. The best performance was achieved by pre-training using the explicit radiology concepts and CLIP strategy. © 2023 IEEE.","BERT; CLIP; ischemic stroke; Large vessel occlusion","3D modeling; Computer aided diagnosis; Computerized tomography; Convolutional neural networks; Deep neural networks; Embeddings; Medical imaging; Natural language processing systems; BERT; CLIP; Communications systems; Imaging data; Imaging modeling; Ischemic strokes; Large vessel occlusion; Picture archiving; Pre-training; Radiology reports; Radiology",Conference Paper,Scopus
"Sobecki P., Jóźwiak R., Mykhalevych I.","Performance of Deep CNN and Radiologists in Prostate Cancer Classification: A Comparative Pilot Study",2023,"Lecture Notes in Networks and Systems",,"10.1007/978-3-031-37649-8_9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172007721&doi=10.1007%2f978-3-031-37649-8_9&partnerID=40&md5=37ab8de3e68e8516b73108adba1cf5e4","In recent years multiple deep-learning solutions have emerged that aim to assist radiologists in prostate cancer (PCa) diagnosis. Most of the studies however do not compare the diagnostic accuracy of the developed models to that of radiology specialists but simply report the model performance on the reference datasets. This makes it hard to infer the potential benefits and applicability of proposed methods in diagnostic workflows. In this paper, we investigate the effects of using pre-trained models in the differentiation of clinically significant PCa (csPCa) on mpMRI and report the results of conducted multi-reader multi-case pilot study involving human experts. The study aims to compare the performance of deep learning models with six radiologists varying in diagnostic experience. A subset of the ProstateX Challenge dataset counting 32 prostate lesions was used to evaluate the diagnostic accuracy of models and human raters using ROC analysis. Deep neural networks were found to achieve comparable performance to experienced readers in the diagnosis of csPCa. Results confirm the potential of deep neural networks in enhancing the cognitive abilities of radiologists in PCa assessment. © 2023, The Author(s).","Computer Aided Diagnosis; Deep learning; Prostate Cancer","Computer aided instruction; Deep neural networks; Diseases; Urology; Cancer classification; Cancer diagnosis; Deep learning; Developed model; Diagnostic accuracy; Modeling performance; Performance; Pilot studies; Potential benefits; Prostate cancers; Computer aided diagnosis",Conference Paper,Scopus
"Lewis P.B., Charalel R.A., Salei A., Cantos A.J., Dubel G.J., Kassin M.T., Garg T., Babar H.S., Brook O., Shah R., Halin N., Kleedehn M., Johnson M.S.","Challenges, Barriers, and Successes of Standardized Report Templates: Results of an Society of Interventional Radiology Survey",2023,"Journal of Vascular and Interventional Radiology",,"10.1016/j.jvir.2023.08.020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171971292&doi=10.1016%2fj.jvir.2023.08.020&partnerID=40&md5=d089b43a20773bbe85d5963cb3a59bed","Registry data are being increasingly used to establish treatment guidelines, set benchmarks, allocate resources, and make payment decisions. Although many registries rely on manual data entry, the Society of Interventional Radiology (SIR) is using automated data extraction for its VIRTEX registry. This process relies on participants using consistent terminology with highly structured data in physician-developed standardized reports (SR). To better understand barriers to adoption, a survey was sent to 3,178 SIR members. Responses were obtained from 451 interventional radiology practitioners (14.2%) from 92 unique academic and 151 unique private practices. Of these, 75% used structured reports and 32% used the SIR SR. The most common barriers to the use of these reports include SR length (35% of respondents), lack of awareness about the SR (31%), and lack of agreement on adoption within practices (27%). The results demonstrated insights regarding barriers in the use and/or adoption of SR and potential solutions. © 2023 SIR",,"adoption; adult; article; awareness; female; human; human experiment; interventional radiology; male; physician; private practice",Article,Scopus
"Chekmeyan M., Baccei S.J., Garwood E.R.","Cross-Check QA: A Quality Assurance Workflow to Prevent Missed Diagnoses by Alerting Inadvertent Discordance Between the Radiologist and Artificial Intelligence in the Interpretation of High-Acuity CT Scans",2023,"Journal of the American College of Radiology",,"10.1016/j.jacr.2023.06.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171875036&doi=10.1016%2fj.jacr.2023.06.010&partnerID=40&md5=b54096f775e79ab0039ca3ef6d0d5e04","Purpose: The aim of this study was to implement and evaluate a quality assurance (QA) workflow that leverages natural language processing to rapidly resolve inadvertent discordance between radiologists and an artificial intelligence (AI) decision support system (DSS) in the interpretation of high-acuity CT studies when the radiologist does not engage with AI DSS output. Methods: All consecutive high-acuity adult CT examinations performed in a health system between March 1, 2020, and September 20, 2022, were interpreted alongside an AI DSS (Aidoc) for intracranial hemorrhage, cervical spine fracture, and pulmonary embolus. CT studies were flagged for this QA workflow if they met three criteria: (1) negative results by radiologist report, (2) a high probability of positive results by the AI DSS, and (3) unviewed AI DSS output. In these cases, an automated e-mail notification was sent to our quality team. If discordance was confirmed on secondary review—an initially missed diagnosis—addendum and communication documentation was performed. Results: Of 111,674 high-acuity CT examinations interpreted alongside the AI DSS over this 2.5-year time period, the frequency of missed diagnoses (intracranial hemorrhage, pulmonary embolus, and cervical spine fracture) uncovered by this workflow was 0.02% (n = 26). Of 12,412 CT studies prioritized as depicting positive findings by the AI DSS, 0.4% (n = 46) were discordant, unengaged, and flagged for QA. Among these discordant cases, 57% (26 of 46) were determined to be true positives. Addendum and communication documentation was performed within 24 hours of the initial report signing in 85% of these cases. Conclusions: Inadvertent discordance between radiologists and the AI DSS occurred in a small number of cases. This QA workflow leveraged natural language processing to rapidly detect, notify, and resolve these discrepancies and prevent potential missed diagnoses. © 2023 American College of Radiology","AI; Artificial intelligence; decision support system; DSS; natural language processing; NLP; patient safety; QA; quality assurance",,Article,Scopus
"Danu M.D., Marica G., Karn S.K., Georgescu B., Mansoor A., Ghesu F., Itu L.M., Suciu C., Grbic S., Farri O., Comaniciu D.","Generation of Radiology Findings in Chest X-Ray by Leveraging Collaborative Knowledge",2023,"Procedia Computer Science",,"10.1016/j.procs.2023.08.094","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171771080&doi=10.1016%2fj.procs.2023.08.094&partnerID=40&md5=1c1d45edbf6db88d6f8eb600c34a5fb4","Among all the sub-sections in a typical radiology report, the Clinical Indications, Findings, and Impression often reflect important details about the health status of a patient. The information included in Impression is also often covered in Findings. While Findings and Impression can be deduced by inspecting the image, Clinical Indications often require additional context. The cognitive task of interpreting medical images remains the most critical and often time-consuming step in the radiology workflow. Instead of generating an end-to-end radiology report, in this paper, we focus on generating the Findings from automated interpretation of medical images, specifically chest X-rays (CXRs). Thus, this work focuses on reducing the workload of radiologists who spend most of their time either writing or narrating the Findings. Unlike past research, which addresses radiology report generation as a single-step image captioning task, we have further taken into consideration the complexity of interpreting CXR images and propose a two-step approach: (a) detecting the regions with abnormalities in the image, and (b) generating relevant text for regions with abnormalities by employing a generative large language model (LLM). This two-step approach introduces a layer of interpretability and aligns the framework with the systematic reasoning that radiologists use when reviewing a CXR. © 2023 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (https://creativecommons.org/licenses/by-nc-nd/4.0) Peer-review under responsibility of the scientific committee of the Tenth International Conference on Information Technology and Quantitative Management.","abnormalities detection; chest X-ray; collaborative knowledge; Findings generation; generative large language model; radiology report","Computational linguistics; Knowledge management; Medical imaging; Abnormality detection; Chest X-ray; Collaborative knowledge; Finding generation; Generative large language model; Health status; Language model; Radiology reports; Sub-sections; Two-step approach; Radiology",Conference Paper,Scopus
"Ye Z.","The power of the radiologist’s last word: can deep learning models accurately differentiate between high-grade gliomas and metastasis through natural language processing on radiology reports?",2023,"European Radiology",,"10.1007/s00330-023-10245-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171744014&doi=10.1007%2fs00330-023-10245-7&partnerID=40&md5=181d62b7b4d897c4720ce05bd06a72e2",[No abstract available],,,Editorial,Scopus
"Van Veen D., Van Uden C., Attias M., Pareek A., Bluethgen C., Polacin M., Chiu W., Delbrouck J.-B., Chaves J.M.Z., Langlotz C.P., Chaudhari A.S., Pauly J.","RadAdapt: Radiology Report Summarization via Lightweight Domain Adaptation of Large Language Models",2023,"Proceedings of the Annual Meeting of the Association for Computational Linguistics",1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171293616&partnerID=40&md5=2491e6786993cb92123e762547b0207c","We systematically investigate lightweight strategies to adapt large language models (LLMs) for the task of radiology report summarization (RRS). Specifically, we focus on domain adaptation via pretraining (on natural language, biomedical text, or clinical text) and via discrete prompting or parameter-efficient fine-tuning. Our results consistently achieve best performance by maximally adapting to the task via pretraining on clinical text and fine-tuning on RRS examples. Importantly, this method fine-tunes a mere 0.32% of parameters throughout the model, in contrast to end-to-end fine-tuning (100% of parameters). Additionally, we study the effect of in-context examples and out-of-distribution (OOD) training before concluding with a radiologist reader study and qualitative analysis. Our findings highlight the importance of domain adaptation in RRS and provide valuable insights toward developing effective natural language processing solutions for clinical tasks. © 2023 Association for Computational Linguistics.",,"Natural language processing systems; Radiology; Biomedical text; Domain adaptation; Effect of In; End to end; Fine tuning; Language model; Natural languages; Performance; Pre-training; Radiology reports; Computational linguistics",Conference Paper,Scopus
"Nakaura T., Yoshida N., Kobayashi N., Shiraishi K., Nagayama Y., Uetani H., Kidoh M., Hokamura M., Funama Y., Hirai T.","Preliminary assessment of automated radiology report generation with generative pre-trained transformers: comparing results to radiologist-generated reports",2023,"Japanese Journal of Radiology",,"10.1007/s11604-023-01487-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171285372&doi=10.1007%2fs11604-023-01487-y&partnerID=40&md5=e55a91de711c08290525f8db70ee5a30","Purpose: In this preliminary study, we aimed to evaluate the potential of the generative pre-trained transformer (GPT) series for generating radiology reports from concise imaging findings and compare its performance with radiologist-generated reports. Methods: This retrospective study involved 28 patients who underwent computed tomography (CT) scans and had a diagnosed disease with typical imaging findings. Radiology reports were generated using GPT-2, GPT-3.5, and GPT-4 based on the patient’s age, gender, disease site, and imaging findings. We calculated the top-1, top-5 accuracy, and mean average precision (MAP) of differential diagnoses for GPT-2, GPT-3.5, GPT-4, and radiologists. Two board-certified radiologists evaluated the grammar and readability, image findings, impression, differential diagnosis, and overall quality of all reports using a 4-point scale. Results: Top-1 and Top-5 accuracies for the different diagnoses were highest for radiologists, followed by GPT-4, GPT-3.5, and GPT-2, in that order (Top-1: 1.00, 0.54, 0.54, and 0.21, respectively; Top-5: 1.00, 0.96, 0.89, and 0.54, respectively). There were no significant differences in qualitative scores about grammar and readability, image findings, and overall quality between radiologists and GPT-3.5 or GPT-4 (p > 0.05). However, qualitative scores of the GPT series in impression and differential diagnosis scores were significantly lower than those of radiologists (p < 0.05). Conclusions: Our preliminary study suggests that GPT-3.5 and GPT-4 have the possibility to generate radiology reports with high readability and reasonable image findings from very short keywords; however, concerns persist regarding the accuracy of impressions and differential diagnoses, thereby requiring verification by radiologists. © 2023, The Author(s).","Computed tomography; Deep learning; Generative pre-trained transformer; Large language model; Radiology report",,Article,Scopus
"Kourav M., Agarwal S., Arya K.V., Petrlik I., Rodriguez C.","Automatic Chest Radiology Report Generation Using Reinforcement Learning",2023,"Lecture Notes in Networks and Systems",,"10.1007/978-981-99-1912-3_22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171150240&doi=10.1007%2f978-981-99-1912-3_22&partnerID=40&md5=1010b55265c82356e7faebfb1c2347e7","Radiology report generation is the manual task assigned to radiologists which analyze the given chest image (x-ray) of patient and generates the report based on that analysis. Many of the research is undergoing in this field to make this process automatic. However, there are a large number of difficulties which have been faced by the researchers while developing the efficient automatic report generation model. The main difficulties include the generation of clinically inaccurate reports when analyzed with the reports of the expert radiologist. The introduction of deep learning based approaches achieved tremendous advancement in these areas and can produce chest X-ray reports in a more accurate manner. BY further optimizing the deep learning based approaches, we proposed a reinforcement learning-based model that generates automated X-ray reports based on input chest X-ray images. We also developed a lookahead inference mechanism to overcome the limitation of beam search, which selects words based on policy and value networks at each particular step of time. The proposed model achieved 0.454, 0.546, 0.466, 0.410, and 0.424 for the Bleu-1, Bleu-2, Bleu-3, Bleu-4, and Rouge evaluation metrics, respectively, surpassing all available state-of-the-art algorithms. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","Chest radiology report generation; Inference mechanism; Reinforcement learning","Deep learning; Radiology; Beam search; Chest image; Chest radiology report generation; Chest X-ray image; Inference mechanism; Learning Based Models; Learning-based approach; Radiology reports; Reinforcement learnings; Report generation; Reinforcement learning",Conference Paper,Scopus
"Zhong W., Yao P.Y., Boppana S.H., Pacheco F.V., Alexander B.S., Simpson S., Gabriel R.A.","Improving case duration accuracy of orthopedic surgery using bidirectional encoder representations from Transformers (BERT) on Radiology Reports",2023,"Journal of Clinical Monitoring and Computing",,"10.1007/s10877-023-01070-w","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170398049&doi=10.1007%2fs10877-023-01070-w&partnerID=40&md5=7277cc99466be7b776677036a838cff1","Purpose: A major source of inefficiency in the operating room is the mismatch between scheduled versus actual surgical time. The purpose of this study was to demonstrate a proof-of-concept study for predicting case duration by applying natural language processing (NLP) and machine learning that interpret radiology reports for patients undergoing radius fracture repair. Methods: Logistic regression, random forest, and feedforward neural networks were tested without NLP and with bag-of-words. Another NLP method tested used feedforward neural networks and Bidirectional Encoder Representations from Transformers specifically pre-trained on clinical notes (ClinicalBERT). A total of 201 cases were included. The data were split into 70% training and 30% test sets. The average root mean squared error (RMSE) were calculated (and 95% confidence interval [CI]) from 10-fold cross-validation on the training set. The models were then tested on the test set to determine proportion of times surgical cases would have scheduled accurately if ClinicalBERT was implemented versus historic averages. Results: The average RMSE was lowest using feedforward neural networks using outputs from ClinicalBERT (25.6 min, 95% CI: 21.5–29.7), which was significantly (P < 0.001) lower than the baseline model (39.3 min, 95% CI: 30.9–47.7). Using the feedforward neural network and ClinicalBERT on the test set, the percentage of accurately predicted cases, which was defined by the actual surgical duration within 15% of the predicted surgical duration, increased from 26.8 to 58.9% (P < 0.001). Conclusion: This proof-of-concept study demonstrated the successful application of NLP and machine leaning to extract features from unstructured clinical data resulting in improved prediction accuracy for surgical case duration. © 2023, The Author(s).","Machine learning; Natural language processing; Operating room; Orthopedic surgery","Forestry; Learning systems; Machine learning; Mean square error; Natural language processing systems; Radiology; Random forests; Surgery; Concept studies; Confidence interval; Language processing; Machine-learning; Natural language processing; Natural languages; Orthopaedic surgery; Proof of concept; Radiology reports; Test sets; Feedforward neural networks",Article,Scopus
"Sethi H.S., Mohapatra S., Mali C., Dubey R.","Online for on Call: A Study Assessing the Use of Internet Resources Including ChatGPT among On-Call Radiology Residents in India",2023,"Indian Journal of Radiology and Imaging",2,"10.1055/s-0043-1772465","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170084845&doi=10.1055%2fs-0043-1772465&partnerID=40&md5=76ace3bf10a43240f1ac223dc0a872ec","Background The information-seeking behavior of the radiology residents on call has undergone modernization in the recent times given the advent of easy to access, reliable online resources, and robust artificial intelligence chatbots such as Chat Generative Pre-Trained Transformer (ChatGPT). Purpose The aim of this study was to conduct a baseline analysis among the residents to understand the best way to meet information needs in the future, spread awareness about the existing resources, and narrow down to the most preferred online resource. Methods and Materials A prospective, descriptive study was performed using an online survey instrument and was conducted among radiology residents in India. They were questioned on their demographics, frequency of on call, fatigue experienced on call, and preferred information resources and reasons for choosing them. Results A total of 286 residents participated in the survey. All residents had used the Internet radiology resources during on-call duties. The most preferred resource material was Radiopaedia followed by Radiology Assistant. IMAIOS e-Anatomy was the most preferred anatomy resource. There was significant (p < 0.05) difference in relation to the use of closed edit peer-reviewed literature among the two batches with it being used almost exclusively by third year residents. In the artificial intelligence-aided ChatGPT section, 61.8% had used the software at least once while being on call, of them 57.6% responded that the information was inaccurate, 67.2% responded that the information was insufficient to aid in diagnosis, 100% felt that the lack of images in the software made it an unlikely resource that would be used by them in the future, and 85.8% agreed that they would use it for providing reporting templates in the future. In the suggestions for upcoming versions, 100% responded that images should be included in the description provide by the chatbot, and 74.5% felt that references for the information being provided should be included as it reaffirms the reliability of the information. Conclusions Presently, we find that Radiopaedia met most of the requirements as an ideal online radiology resource according to the residents. In the present-day scenario, ChatGPT is not considered as an important on-call radiology education resource first because it lacks images which is quintessential for a budding radiologist, and second, it does not have any reference or proof for the information that it is providing. However, it may be of help to nonmedical professionals who need to understand radiology in layman's terms and to radiologists for patient report preparation and research writing. © 2023 Wolters Kluwer Medknow Publications. All rights reserved.","artificial intelligence; ChatGPT; on-call radiology; resident education",,Article,Scopus
"Shafiq H., Gilanie G., Sajid M., Ahsan M.","Dental radiology: a convolutional neural network-based approach to detect dental disorders from dental images in a real-time environment",2023,"Multimedia Systems",,"10.1007/s00530-023-01169-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169163243&doi=10.1007%2fs00530-023-01169-9&partnerID=40&md5=3003013dd042409a93163776abfcbacc","Periodontal diseases are among the most prevalent infectious conditions, affecting a major portion of people at times in their lives. As per the World Health Organization (WHO) reports, dental disease diagnosis consumes 5% to 10% of developing economies as healthcare expenditures. Bacteria present in the mouth cause inflammation around the tooth, leading to periodontal disease. In this research paper, three types of dental diseases, i.e., oral cancer, broken teeth, and dental caries, have been classified using the proposed Convolutional Neural Network (CNN)-based model. Moreover, to crossvalidate the results, different pretrained CNN models, i.e. Visual Geometry Group (VGG19), MobileNet-V2, VGG16, Inception-V3, EfficientNet-B3, ResNet-34, Efficient Net-B7, and DenseNet-201 and Support Vector Machine (SVM) have been used for experiments. Experiments have been performed on a locally developed dataset, obtained in the Department of Radiology, Bahawal Victoria Hospital, Bahawalpur, Pakistan. The dataset consists of 1067 dental images of three dental disorders, i.e., oral cancer, broken teeth, and dental caries, labeled by an expert dental surgeon. The proposed CNN model automatically identifies these dental diseases in an automated and noninvasive manner, specifically targeting periodontal conditions. The channel attention module, spatial attention module, squeeze, and excitation block, residual block, convolutional block, and Atrous Spatial Pyramid Pooling (ASPP) module have been applied in the proposed CNN model to extract features. The proposed model, consisting of 24 layers, achieved an impressive classification accuracy of 95.34% for oral cancer, broken teeth, and dental caries. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","Broken teeth; Convolutional neural network; Dental caries; Machine learning; Oral cancer; Periodontal diseases","Convolution; Convolutional neural networks; Diagnosis; Neural network models; Radiology; Support vector machines; Broken tooth; Condition; Convolutional neural network; Dental caries; Dental images; Machine-learning; Neural network model; Oral cancer; Periodontal disease; Tooth caries; Diseases",Article,Scopus
"Naveen Kumaar A., Akilandeswari J., Mathangi P.R., Kavya P., Dhanush Prabhu S., Ashwin Kumar V.","Secure radiology image browsing tool improvised using Denoising Autoencoder with Convolutional Neural Network (DAECNN)",2023,"2023 4th International Conference on Electronics and Sustainable Communication Systems, ICESC 2023 - Proceedings",,"10.1109/ICESC57686.2023.10192582","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168310513&doi=10.1109%2fICESC57686.2023.10192582&partnerID=40&md5=dc85cfb91b41f4fa38950bb7b0c7b4d5","Computers are now considered as the daily necessities for both mankind and medical science. A doctor examines a patient, with the physical interaction and then with all the reports like scans, X-rays, blood reports, and so on. In case of Radiologist, they can't frequently touch the screen or buttons while browsing the radiology report images, this may lead to radioactive contamination. A gesture-based browsing method is developed to overcome this issue by making the radiologist to browse the images without any close interactions with the device. An interface is provided for the surgeon where their hand-gestures are used for safe browsing of radiology report images using recent hand-gesture recognition methodologies. Further the accuracy of the system is increased by the proposed modified Convolutional Neural Network technique which uses De-noising Auto Encoder based CNN (DAECNN) to identify the hand-gesture made by the radiologist. A detailed study is made on the recent hand-gesture recognition methodologies used on secure browsing of radiology images based on accuracy. The proposed technique is compared with the existing deep learning methodologies such as CNN, Adaline (Adaptive Linear Neuron), DAE (Denoising Autoencoder) and the performances are examined. The findings of the research show that the DAECNN methodology outperforms the currently used classification techniques. © 2023 IEEE.","Adaline; Convolutional Neural Network; Deep Learning; Denoising Autoencoder; Gesture Detection; Image augmentation","Convolution; Deep neural networks; Gesture recognition; Learning systems; Medical imaging; Palmprint recognition; Radiology; Touch screens; Adaptive linear neurons; Auto encoders; Convolutional neural network; De-noising; Deep learning; Denoising autoencoder; Gesture detections; Hand gesture; Image augmentation; Radiology reports; Convolutional neural networks",Conference Paper,Scopus
"Kleebayoon A., Wiwanitkit V.","Large language models for structured reporting in radiology: comment",2023,"Radiologia Medica",,"10.1007/s11547-023-01687-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167672100&doi=10.1007%2fs11547-023-01687-6&partnerID=40&md5=109760fb9a2b036a9bf046d29308896e",[No abstract available],,,Letter,Scopus
"Tanida T., Müller P., Kaissis G., Rueckert D.","Interactive and Explainable Region-guided Radiology Report Generation",2023,"Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",,"10.1109/CVPR52729.2023.00718","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166345730&doi=10.1109%2fCVPR52729.2023.00718&partnerID=40&md5=64b5eb4fe78a3e9229d1f65c029106f6","The automatic generation of radiology reports has the potential to assist radiologists in the time-consuming task of report writing. Existing methods generate the full report from image-level features, failing to explicitly focus on anatomical regions in the image. We propose a simple yet effective region-guided report generation model that detects anatomical regions and then describes individual, salient regions to form the final report. While previous methods generate reports without the possibility of human intervention and with limited explainability, our method opens up novel clinical use cases through additional interactive capabilities and introduces a high degree of transparency and explainability. Comprehensive experiments demonstrate our method's effectiveness in report generation, outperforming previous state-of-the-art models, and highlight its interactive capabilities. The code and checkpoints are available at https://github.com/ttanida/rgrg. © 2023 IEEE.","cell microscopy; Medical and biological vision",,Conference Paper,Scopus
"Ray P.P.","A critical examination and suggestions for large language models for structured reporting in radiology",2023,"Radiologia Medica",,"10.1007/s11547-023-01688-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166029621&doi=10.1007%2fs11547-023-01688-5&partnerID=40&md5=7de146b7ced02f50cdb7c2e17bea335d",[No abstract available],"ChatGPT; Generative AI; Large language model; Radiology; Structured reporting",,Letter,Scopus
"Mallio C.A., Sertorio A.C., Bernetti C., Beomonte Zobel B.","Radiology, structured reporting and large language models: who is running faster?",2023,"Radiologia Medica",1,"10.1007/s11547-023-01689-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165934344&doi=10.1007%2fs11547-023-01689-4&partnerID=40&md5=171c954b1aa19f543bcbfe22d8fa145e",[No abstract available],,,Letter,Scopus
"López-Úbeda P., Martín-Noguerol T., Luna A.","Radiology in the era of large language models: the near and the dark side of the moon",2023,"European Radiology",1,"10.1007/s00330-023-09901-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164531618&doi=10.1007%2fs00330-023-09901-9&partnerID=40&md5=cfbeca45c05deb26653daa5c57941726",[No abstract available],,,Note,Scopus
"Yang E., Li M.D., Raghavan S., Deng F., Lang M., Succi M.D., Huang A.J., Kalpathy-Cramer J.","Transformer versus traditional natural language processing: how much data is enough for automated radiology report classification?",2023,"British Journal of Radiology",,"10.1259/bjr.20220769","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164517286&doi=10.1259%2fbjr.20220769&partnerID=40&md5=4371acf6cabc694f3abfd1352a3eeaa8","Objectives: Current state-of-the-art natural language processing (NLP) techniques use transformer deep-learning architectures, which depend on large training datasets. We hypothesized that traditional NLP techniques may outperform transformers for smaller radiology report datasets. Methods: We compared the performance of BioBERT, a deep-learning-based transformer model pre-trained on biomedical text, and three traditional machine-learning models (gradient boosted tree, random forest, and logistic regression) on seven classification tasks given free-text radiology reports. Tasks included detection of appendicitis, diverticulitis, bowel obstruction, and enteritis/colitis on abdomen/pelvis CT reports, ischemic infarct on brain CT/MRI reports, and medial and lateral meniscus tears on knee MRI reports (7,204 total anno-tated reports). The performance of NLP models on held-out test sets was compared after training using the full training set, and 2.5%, 10%, 25%, 50%, and 75% random subsets of the training data. Results: In all tested classification tasks, BioBERT performed poorly at smaller training sample sizes compared to non-deep-learning NLP models. Specif-ically, BioBERT required training on approximately 1,000 reports to perform similarly or better than non-deep-learning models. At around 1,250 to 1,500 training samples, the testing performance for all models began to plateau, where additional training data yielded minimal performance gain. Conclusions: With larger sample sizes, transformer NLP models achieved superior performance in radiology report binary classification tasks. However, with smaller sizes (<1000) and more imbalanced training data, traditional NLP techniques performed better. Advances in knowledge: Our benchmarks can help guide clinical NLP researchers in selecting machine-learning models according to their dataset characteristics. © 2023 The Authors. Published by the British Institute of Radiology.",,"abdominal radiography; acute appendicitis; acute diverticulitis; appendicitis; Article; automation; binary classification; brain infarction; classification algorithm; classifier; colitis; computer assisted tomography; deep learning; diverticulitis; enteritis; gradient boosted tree; human; intermethod comparison; intestine obstruction; knee radiography; lateral meniscus; logistic regression analysis; machine learning; major clinical study; natural language processing; nuclear magnetic resonance imaging; pelvis radiography; radiology; random forest; retrospective study; sample size; traditional natural language processing; transformer natural language processing; university hospital; procedures; x-ray computed tomography; Humans; Machine Learning; Magnetic Resonance Imaging; Natural Language Processing; Radiology; Tomography, X-Ray Computed",Article,Scopus
"Kwee T.C., Almaghrabi M.T., Kwee R.M.","Diagnostic radiology and its future: what do clinicians need and think?",2023,"European Radiology",2,"10.1007/s00330-023-09897-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164486476&doi=10.1007%2fs00330-023-09897-2&partnerID=40&md5=115b6adc5dfed1a275e02465e084d7ad","Objective: To investigate the view of clinicians on diagnostic radiology and its future. Methods: Corresponding authors who published in the New England Journal of Medicine and the Lancet between 2010 and 2022 were asked to participate in a survey about diagnostic radiology and its future. Results: The 331 participating clinicians gave a median score of 9 on a 0–10 point scale to the value of medical imaging in improving patient-relevant outcomes. 40.6%, 15.1%, 18.9%, and 9.5% of clinicians indicated to interpret more than half of radiography, ultrasonography, CT, and MRI examinations completely by themselves, without consulting a radiologist or reading the radiology report. Two hundred eighty-nine clinicians (87.3%) expected an increase in medical imaging utilization in the coming 10 years, whereas 9 clinicians (2.7%) expected a decrease. The need for diagnostic radiologists in the coming 10 years was expected to increase by 162 clinicians (48.9%), to remain stable by 85 clinicians (25.7%), and to decrease by 47 clinicians (14.2%). Two hundred clinicians (60.4%) expected that artificial intelligence (AI) will not make diagnostic radiologists redundant in the coming 10 years, whereas 54 clinicians (16.3%) thought the opposite. Conclusion: Clinicians who published in the New England Journal of Medicine or the Lancet attribute high value to medical imaging. They generally need radiologists for cross-sectional imaging interpretation, but for a considerable proportion of radiographs, their service is not required. Most expect medical imaging utilization and the need for diagnostic radiologists to increase in the foreseeable future, and do not expect AI to make radiologists redundant. Clinical relevance statement: The views of clinicians on radiology and its future may be used to determine how radiology should be practiced and be further developed. Key Points: • Clinicians generally regard medical imaging as high-value care and expect to use more medical imaging in the future. • Clinicians mainly need radiologists for cross-sectional imaging interpretation while they interpret a substantial proportion of radiographs completely by themselves. • The majority of clinicians expects that the need for diagnostic radiologists will not decrease (half of them even expect that we need more) and does not believe that AI will replace radiologists. © 2023, The Author(s).","Artificial intelligence; Radiology; Value-based healthcare; Workforce",,Article,Scopus
"Mottin L., Goldman J.-P., Jäggli C., Achermann R., Gobeill J., Knafou J., Ehrsam J., Wicky A., Gérard C.L., Schwenk T., Charrier M., Tsantoulis P., Lovis C., Leichtle A., Kiessling M.K., Michielin O., Pradervand S., Foufi V., Ruch P.","Multilingual RECIST classification of radiology reports using supervised learning",2023,"Frontiers in Digital Health",1,"10.3389/fdgth.2023.1195017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163714351&doi=10.3389%2ffdgth.2023.1195017&partnerID=40&md5=a6e144abf435959d6f9b0d8b9014f9e4","Objectives: The objective of this study is the exploration of Artificial Intelligence and Natural Language Processing techniques to support the automatic assignment of the four Response Evaluation Criteria in Solid Tumors (RECIST) scales based on radiology reports. We also aim at evaluating how languages and institutional specificities of Swiss teaching hospitals are likely to affect the quality of the classification in French and German languages. Methods: In our approach, 7 machine learning methods were evaluated to establish a strong baseline. Then, robust models were built, fine-tuned according to the language (French and German), and compared with the expert annotation. Results: The best strategies yield average F1-scores of 90% and 86% respectively for the 2-classes (Progressive/Non-progressive) and the 4-classes (Progressive Disease, Stable Disease, Partial Response, Complete Response) RECIST classification tasks. Conclusions: These results are competitive with the manual labeling as measured by Matthew's correlation coefficient and Cohen's Kappa (79% and 76%). On this basis, we confirm the capacity of specific models to generalize on new unseen data and we assess the impact of using Pre-trained Language Models (PLMs) on the accuracy of the classifiers. 2023 Mottin, Goldman, Jäggli, Achermann, Gobeill, Knafou, Ehrsam, Wicky, Gérard, Schwenk, Charrier, Tsantoulis, Lovis, Leichtle, Kiessling, Michielin, Pradervand, Foufi and Ruch.","language models; narrative text classification; radiology reports; RECIST; supervised machine learning","Article; artificial intelligence; automation; classification algorithm; diagnostic accuracy; diagnostic test accuracy study; disease classification; French (language); German (language); natural language processing; radiology; solid tumor; supervised machine learning",Article,Scopus
"Nimalsiri W., Hennayake M., Rathnayake K., Ambegoda T.D., Meedeniya D.","Automated Radiology Report Generation Using Transformers",2023,"ICARC 2023 - 3rd International Conference on Advanced Research in Computing: Digital Transformation for Sustainable Development",,"10.1109/ICARC57651.2023.10145699","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163564645&doi=10.1109%2fICARC57651.2023.10145699&partnerID=40&md5=77349fe98928ea833bb5ac23331d60e9","Given the rapid increase of respiratory illnesses in recent times, the demand for medical report writing for chest X- Rays (CXR) has significantly increased. In practice, a specialized medical expert has to go through an X-Ray image to compile the accompanying report, which is tedious, not scalable, and potentially prone to human error. Therefore, automatic medical report generation (AMRG) solutions for CXR as a diagnostic assistance tool could play an important role in lowering the burden on radiologists, making them more productive. However, current AMRG solutions are still lagging far behind the performance of human experts due to the reasons such as the inability to extract the most relevant features to be used for the compilation of the report. We address this by proposing MERGIS: MEdical Report Generation using the Image Segmentation approach. MERGIS is a modern transformer-based encoder-decoder model that leverages image segmentation to improve the accuracy of automatic report generation. In this approach, the CXR images are segmented before feeding into the model, enabling the encoder to extract relevant visual features of the medical image resulting in more accurate radiography reports. The proposed model outperforms the current state-of-the-art model for report generation on the MIMIC-CXR dataset with performance scores: BLUE-1 = 0.296, METEOR = 0.128, ROUGE L = 0.335, and CIDEr = 1.150. © 2023 IEEE.","Chest X-Ray; image segmentation; medical report generation; self-attention; transformer","Diagnosis; Image enhancement; Medical imaging; Signal encoding; X ray radiography; 'current; Chest X-ray; Images segmentations; Medical report generation; Performance; Radiology reports; Report generation; Respiratory illness; Self-attention; Transformer; Image segmentation",Conference Paper,Scopus
"Bosbach W.A., Senge J.F., Nemeth B., Omar S.H., Mitrakovic M., Beisbart C., Horváth A., Heverhagen J., Daneshvar K.","Ability of ChatGPT to generate competent radiology reports for distal radius fracture by use of RSNA template items and integrated AO classifier",2023,"Current Problems in Diagnostic Radiology",2,"10.1067/j.cpradiol.2023.04.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163201652&doi=10.1067%2fj.cpradiol.2023.04.001&partnerID=40&md5=75613a1aa24958b4b98fd851467aae98","The amount of acquired radiology imaging studies grows worldwide at a rapid pace. Novel information technology tools for radiologists promise an increase of reporting quality and as well quantity at the same time. Automated text report drafting is one branch of this development. We defined for the present study in total 9 cases of distal radius fracture. Command files structured according to a template of the Radiological Society of North America (RSNA) and to Arbeitsgemeinschaft Osteosynthese (AO) classifiers were given as input to the natural language processing tool ChatGPT. ChatGPT was tasked with drafting an appropriate radiology report. A parameter study (n = 5 iterations) was performed. An overall high appraisal of ChatGPT radiology report quality was obtained in a score card based assessment. ChatGPT demonstrates the capability to adjust output files in response to minor changes in input command files. Existing shortcomings were found in technical terminology and medical interpretation of findings. Text drafting tools might well support work of radiologists in the future. They would allow a radiologist to focus time on the observation of image details and patient pathology. ChatGPT can be considered a substantial step forward towards that aim. © 2023 The Author(s)",,,Article,Scopus
"Ajad A., Saini T., Niranjan K.M.","Rad-Former: Structuring Radiology Reports using Transformers",2023,"Proceedings of the 5th International Conference on Recent Advances in Information Technology, RAIT 2023",,"10.1109/RAIT57693.2023.10127096","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163184386&doi=10.1109%2fRAIT57693.2023.10127096&partnerID=40&md5=d66ad85e268132fbea911262cf197248","Several professional societies have advocated for structured reporting in radiology, citing gains in quality, but some studies have shown that rigid templates and strict adherence may be too distracting and lead to incomplete reports. To gain the advantages of structured reporting while requiring minimal change to a radiologist's work-flow, the present work proposes a two-stage abstractive summarization approach that first finds the key findings in an unstructured report and then generates and organizes descriptions of each finding into a given template. The method uses a large manually annotated dataset and a taxonomy and other domain knowledge that were prepared in consultation with several practising radiologists. It can be used to structure reports dictated by radiologists and as post- and pre-processing steps for machine-learning pipelines. On the subtask of label extraction, the method achieves significantly better performance than previous rule-based approaches and learning-based approaches that were trained on automatically extracted labels. On the task of summarization, the method achieves more than 0.5 BLEU-4 score across 8 of the 10 most common labels and serves as a strong baseline for future experiments. © 2023 IEEE.","Deep Learning; Healthcare; Radiology; Structuring; Summarization; Transformer","Deep learning; Domain Knowledge; Large dataset; Medical imaging; Annotated datasets; Deep learning; Domain knowledge; Healthcare; Radiology reports; Structured reporting; Structuring; Summarization; Transformer; Work-flows; Radiology",Conference Paper,Scopus
"Jiang Z., Cai X., Yang L., Gao D., Zhao W., Han J., Liu J., Shen D., Liu T.","Learning to Summarize Chinese Radiology Findings with a Pre-trained Encoder",2023,"IEEE Transactions on Biomedical Engineering",,"10.1109/TBME.2023.3280987","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162732532&doi=10.1109%2fTBME.2023.3280987&partnerID=40&md5=fd93cfc4905ab56f5508eb31eac30a8c","Automatic radiology report summarization has been an attractive research problem towards computer-aided diagnosis to alleviate physicians&#x0027; workload in recent years. However, existing methods for English radiology report summarization using deep learning techniques cannot be directly applied to Chinese radiology reports due to limitations of the related corpus. In response to this, we propose an abstractive summarization approach for Chinese chest radiology report. Our approach involves the construction of a pre-training corpus using a Chinese medical-related pre-training dataset, and the collection of Chinese chest radiology reports from Department of Radiology at the Second Xiangya Hospital as the fine-tuning corpus. To improve the initialization of the encoder, we introduce a new task-oriented pre-training objective called Pseudo Summary Objective on the pre-training corpus. We then develop a Chinese pre-trained language model called Chinese Medical BERT (CMBERT), which is used to initialize the encoder and fine-tuned on the abstractive summarization task. In testing our approach on a real large-scale hospital dataset, we observe that the performance of our proposed approach achieves outstanding improvement compared with other abstractive summarization models. This highlights the effectiveness of our approach in addressing the limitations of previous methods for Chinese radiology report summarization. Overall, our proposed approach demonstrates a promising direction for the automatic summarization of Chinese chest radiology reports, offering a viable solution to alleviate physicians&#x0027; workload in the field of computer-aided diagnosis. IEEE","abstractive summarization; Biological system modeling; Bit error rate; Chinese chest radiology report; Deep learning; Hospitals; pre-trained language model; Radiology; Semantics; Task analysis; Task-oriented pre-training objective","Computational linguistics; Computer aided diagnosis; Deep learning; Hospitals; Medical imaging; Modeling languages; Radiology; Statistical tests; Abstractive summarization; Biological system modeling; Bit-error rate; Chinese chest radiology report; Deep learning; Language model; Pre-trained language model; Pre-training; Radiology reports; Task analysis; Task-oriented; Task-oriented pre-training objective; Semantics",Article,Scopus
"Mithun S., Jha A.K., Sherkhane U.B., Jaiswar V., Purandare N.C., Rangarajan V., Dekker A., Puts S., Bermejo I., Wee L.","Development and validation of deep learning and BERT models for classification of lung cancer radiology reports",2023,"Informatics in Medicine Unlocked",,"10.1016/j.imu.2023.101294","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161650201&doi=10.1016%2fj.imu.2023.101294&partnerID=40&md5=150ae2bb113c1c5c383d54b9e9e17cc9","Purpose: Manual cohort building from radiology reports can be tedious. Natural Language Processing (NLP) can be used for automated cohort building. In this study, we have developed and validated an NLP approach based on deep learning (DL) to select lung cancer reports from a thoracic disease management group cohort. Materials and methods: 4064 radiology reports (CT and PET/CT) of a thoracic disease management group reported between 2014 and 2016 were used. These reports were anonymised, cleaned, text normalized and split into a training, testing, and validation set. External validation was performed on radiology reports from the MIMIC-III clinical database. We used three DL models, namely, Bi-LSTM_simple, Bi-LSTM_dropout, and Pre-trained _BERT model to predict if a report concerned lung cancer. We studied the effect of minority oversampling on all models. Results: Without oversampling, the F1 scores at 95% CI for Bi-LSTM_simple, Bi-LSTM_dropout and BERT were 0.89, 0.90, and 0.86; with oversampling, the F1 scores were 0.94, 0.94, and 0.9, on internal validation. On external validation the F1-scores of Bi-LSTM_simple, Bi-LSTM_dropout and BERT models were 0.63, 0.77 and 0.80 without oversampling and 0.72, 0.78 and 0.77 with oversampling. Conclusion: Pre-trained BERT model and Bi-LSTM_dropout models to predict a lung cancer report showed consistent performance on internal and external validation with the BERT model exhibiting superior performance. The overall F1 score decreased on external validation for both Bi-LSTM models with the Bi-LSTM_simple model showing a more significant drop. All models showed some improvement on minority oversampling. © 2023 The Authors","Artificial intelligence; Classification model; Deep learning; Lung cancer; Natural language processing; Nuclear medicine; PET/CT; Radiology reports","Article; artificial intelligence; computer assisted tomography; controlled study; deep learning; human; long short term memory network; lung cancer; natural language processing; performance indicator; positron emission tomography-computed tomography; radiology; validation process; validation study",Article,Scopus
"Wismüller A., Avondo J., Stockmaster L., Kasturi A., Vosoughi A.","Tracking the impact of global iodinated contrast agent shortage on radiology: Analysis of CT exam volumes at a major US healthcare",2023,"Progress in Biomedical Optics and Imaging - Proceedings of SPIE",,"10.1117/12.2654552","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160934969&doi=10.1117%2f12.2654552&partnerID=40&md5=c61d11e662daad17bdd580e1a24c3689","We track the impact of the current global shortage of iodinated contrast agents on radiology operations at a major US healthcare system. Using repurposed software infrastructure of a commercial AI-based image analysis vendor (Aidoc Medical, Tel Aviv, Israel), we analyzed daily volumes of radiology service request data for a total of 17,061 Computed Tomography (CT) exams before and during the contrast agent shortage (both comprising 04/01/2022 through 07/01/2022), namely 2,407 CT Pulmonary Angiography (CTPA), 3,811 non-angiography Contrast-Enhanced Thoracic CT (CE-TCT), and, for comparison, 10,843 non-contrast head CT exams. Specifically, we compared two observational periods, namely (i) a pre-shortage control period from 04/14/22 through 05/05/2022, and (ii) a contrast shortage period from 05/21/2022 through 06/11/2022. A percentage change metric of case volumes was calculated, where we report relative changes with regard to a baseline measurement period from 04/01/2022 through 04/14/2022. The two observational periods were compared for statistically significant differences. Case volumes of contrast-enhanced CT scans dropped from baseline during the contrast agent shortage period, namely by 60.66%±23.33% for CE-TCT and 42.88%±20.22% for CTPA, respectively, where statistical differences between observational periods were highly significant (p < 10-4). Our results suggest a significant reduction of contrast-enhanced chest CT exams during the observed global contrast agent shortage, where CTPA exams were slightly less affected than other non-angiography contrast-enhanced chest CT studies. We conclude that data tracking using repurposed AI image analysis service software infrastructure can quantify effects of unexpected healthcare challenges on radiology operations, such as during the observed global contrast agent shortage. © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.","Artificial Intelligence; contrast agent shortage; radiology","Angiography; Computerized tomography; Health care; Image analysis; Image enhancement; Software agents; 'current; Case Volume; Contrast agent; Contrast agent shortage; Contrast-enhanced; Global contrasts; Healthcare systems; Image-analysis; Iodinated contrast agents; Software infrastructure; Radiology",Conference Paper,Scopus
"Guo L., Hong K., Xiao Q., Qian L., Jaeger S., Zheng B., Quan S., Xia L., Cheng G., Lure Y.M.F.","Developing and assessing an AI-based multi-task prediction system to assist radiologists detecting lung diseases in reading chest x-ray images",2023,"Progress in Biomedical Optics and Imaging - Proceedings of SPIE",,"10.1117/12.2652338","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160934623&doi=10.1117%2f12.2652338&partnerID=40&md5=2dd9693babf05abb7ab8e11c3309be21","Chest x-ray radiography (CXR) is widely used in screening and detecting lung diseases. However, reading CXR images is often difficult resulting in diagnostic errors and inter-reader variability. To address this clinical challenge, a Multi-task, Optimal-recommendation, and Max-predictive Classification and Segmentation (MOM-ClaSeg) system is developed to detect and delineate different abnormal regions of interest (ROIs) on CXR, make multiple recommendations of abnormalities sorted by the generated probability scores, and automatically generate diagnostic report. MOM-ClaSeg consists of convolutional neural networks to generate a detection, finer-grained segmentation and prediction score for each ROI based on augmented MaskRCNN framework, and multi-layer perception neural networks to fuse results to generate the optimal recommendation for each detected ROI based on decision fusion framework. Total of 310,333 adult CXR containing 67,071 normal and 243,262 abnormal images depicting 307,415 confirmed ROIs of 65 different abnormalities were assembled as to train MOM-ClaSeg. An independent 22,642 CXR was assembled to test MOMClaSeg. Radiologists detected 6,646 ROIs that depict 43 different types of abnormalities on 4,068 CXR images. Comparing with radiologists' detection results, MOM-ClaSeg system detected 6,009 true-positive ROIs and 6,379 false-positive ROIs, which represents 90.3% sensitivity and 0.28 false-positive ROIs per image. For the eight common diseases, the computed areas under ROC curves ranged from 0.880 to 0.988. Additionally, 70.4% of MOM-ClaSeg system-detected abnormalities along with system-generated diagnostic reports were directly accepted by radiologists. This study presents the first AI-based multi-task prediction system to detect different abnormalities and generate diagnostic reports to assist radiologists accurately and/or efficiently detecting lung diseases. © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.","artificial intelligence; automated diagnostic report; clinical decision support system; Multi-disease detection; observer assessment study; radiograph interpretation","Biological organs; Decision support systems; Diagnosis; Medical imaging; Multilayer neural networks; Network layers; X ray radiography; Automated diagnostic report; Automated diagnostics; Clinical decision support systems; Diagnostic Report; Disease detection; Multi-disease detection; Observer assessment study; Radiograph interpretation; Region-of-interest; Regions of interest; Forecasting",Conference Paper,Scopus
"Aksoy N., Ravikumar N., Frangi A.F.","Radiology Report Generation Using Transformers Conditioned with Non-imaging Data",2023,"Progress in Biomedical Optics and Imaging - Proceedings of SPIE",,"10.1117/12.2653672","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160723481&doi=10.1117%2f12.2653672&partnerID=40&md5=e3e919d7366a49a831b6f2d6334ebba8","Medical image interpretation is central to most clinical applications such as disease diagnosis, treatment planning, and prognostication. In clinical practice, radiologists examine medical images (e.g. chest x-rays, computed tomography images, etc.) and manually compile their findings into reports, which can be a time-consuming process. Automated approaches to radiology report generation, therefore, can reduce radiologist workload and improve efficiency in the clinical pathway. While recent deep-learning approaches for automated report generation from medical images have seen some success, most studies have relied on image-derived features alone, ignoring non-imaging patient data. Although a few studies have included the word-level contexts along with the image, the use of patient demographics is still unexplored. On the other hand, prior approaches to this task commonly use encoder-decoder frameworks that consist of a convolution vision model followed by a recurrent language model. Although recurrent-based text generators have achieved noteworthy results, they had the drawback of having a limited reference window and identifying only one part of the image while generating the next word. This paper proposes a novel multi-modal transformer network that integrates chest x-ray (CXR) images and associated patient demographic information, to synthesise patient-specific radiology reports. The proposed network uses a convolutional neural network (CNN) to extract visual features from CXRs and a transformer-based encoder-decoder network that combines the visual features with semantic text embeddings of patient demographic information, to synthesise full-text radiology reports. The designed network not only alleviates the limitations of the recurrent models but also improves the encoding and generative processes by including more context in the network. Data from two public databases were used to train and evaluate the proposed approach. CXRs and reports were extracted from the MIMIC-CXR database and combined with corresponding patients’ data (gender, age, and ethnicity) from MIMIC-IV. Based on the evaluation metrics used (BLEU 1-4 and BERTScore), including patient demographic information was found to improve the quality of reports generated using the proposed approach, relative to a baseline network trained using CXRs alone. The proposed approach shows potential for enhancing radiology report generation by leveraging rich patient metadata and combining semantic text embeddings derived thereof, with medical image-derived visual features. © 2023 SPIE.","Radiology Report Generation; Self Attention; Transformer","Computerized tomography; Convolutional neural networks; Deep learning; Diagnosis; Hospital data processing; Medical imaging; Population statistics; Quality control; Radiology; Semantics; Signal encoding; Chest x-rays; Non-imaging; Patient data; Patient demographic information; Radiology report generation; Radiology reports; Report generation; Self attention; Transformer; Visual feature; Convolution",Conference Paper,Scopus
"Xiao P., Yu X., Mintz A., Wang J., Mokkarala M., Narra V.R., Marcus D.S., Bierhals A.J., Sotiras A.","A Generative-Discriminative Deep Learning Approach to Classify Radiology Reports based on the Presence of Follow Up Recommendations",2023,"Progress in Biomedical Optics and Imaging - Proceedings of SPIE",,"10.1117/12.2651950","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160707737&doi=10.1117%2f12.2651950&partnerID=40&md5=db7e4ab11d45dca3c7d8b3cdaeaa946b","Follow up imaging recommendations are often made in radiology reports. Not adhering to these recommendations can result in treatment delays, negative patient outcomes, additional medical issues, excessive testing, financial loss, and potential legal repercussions. In this paper, we present a generative-discriminative deep learning approach to classify radiology reports based on the presence of follow up recommendations. The generative model aims to produce a distributed representation of words in radiology reports. The discriminative model aims to extract local features that can be used to identify follow up recommendations. Three radiology report datasets were collected: one (n = 41417) with examinations extracted from the information system by regular expression operations, one (n = 14993) with examinations performed between January 1, 2015 to January 10, 2015 and annotated by three radiologists, and one (n = 5093) annotated by our radiologists at the time of dictation. Classification performance of the proposed hybrid model was compared with four traditional classification algorithms (random forest, logistic regression, naive bayes and support vector machine (SVM)) and three neural network-based models (fastText, Convolutional neural network (CNN), Graph convolutional network (GCN)). A visualization algorithm was used to interpret the classification results of the hybrid model. Precision, recall, accuracy, and F1 scores were calculated for all models on the test set . Experimental results show that the hybrid model had a statistically significant higher F1 score (0.942 for Hybrid-random and 0.951 for Hybrid-report) than did four traditional machine learning algorithms (random forest: 0.914, logistic regression: 0.838, naive bayes: 0.808 and SVM: 0.890) and the best-performing neural network-based model (fastText: 0.918). Our model can accurately identify radiology reports that contain follow-up recommendations. It can also automate detection of follow-up recommendation, thus streamlining workflows in a clinical setting and ensuring timely and appropriate patient care. © 2023 SPIE.","Deep learning; Follow up recommendation; Radiology report classification","Convolution; Convolutional neural networks; Learning systems; Logistic regression; Losses; Medical imaging; Patient treatment; Radiology; Random forests; Support vector machines; Deep learning; Follow up; Follow up recommendation; Hybrid model; Learning approach; Logistics regressions; Naive bayes; Radiology report classification; Radiology reports; Random forests; Deep learning",Conference Paper,Scopus
"Hadjiyski N., Vosoughi A., Wismüller A.","Cross Modal Global Local Representation Learning from Radiology Reports and X-Ray Chest Images",2023,"Progress in Biomedical Optics and Imaging - Proceedings of SPIE",,"10.1117/12.2654520","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160205329&doi=10.1117%2f12.2654520&partnerID=40&md5=f67f2e424203c125ae09b9fd17287477","Deep learning models can be applied successfully in real-work problems; however, training most of these models requires massive data. Recent methods use language and vision, but unfortunately, they rely on datasets that are not usually publicly available. Here we pave the way for further research in the multimodal language-vision domain for radiology. In this paper, we train a representation learning method that uses local and global representations of the language and vision through an attention mechanism and based on the publicly available Indiana University Radiology Report (IU-RR) dataset. Furthermore, we use the learned representations to diagnose five lung pathologies: atelectasis, cardiomegaly, edema, pleural effusion, and consolidation. Finally, we use both supervised and zero-shot classifications to extensively analyze the performance of the representation learning on the IU-RR dataset. Average Area Under the Curve (AUC) is used to evaluate the accuracy of the classifiers for classifying the five lung pathologies. The average AUC for classifying the five lung pathologies on the IU-RR test set ranged from 0.85 to 0.87 using the different training datasets, namely CheXpert and CheXphoto. These results compare favorably to other studies using UI-RR. Extensive experiments confirm consistent results for classifying lung pathologies using the multimodal global local representations of language and vision information. © 2023 SPIE.","chest X-ray; computer vision; cross-modal learning; Deep learning; natural language processing; radiology reports; zero-shot classification","Biological organs; Classification (of information); Deep learning; Image classification; Learning systems; Medical imaging; Natural language processing systems; Pathology; Radiology; Zero-shot learning; Chest X-ray; Cross-modal; Cross-modal learning; Deep learning; Language processing; Natural language processing; Natural languages; Radiology reports; Shot classification; Zero-shot classification; Computer vision",Conference Paper,Scopus
"Hallinan J.T.P.D., Zhu L., Zhang W., Ge S., Muhamat Nor F.E., Ong H.Y., Eide S.E., Cheng A.J.L., Kuah T., Lim D.S.W., Low X.Z., Yeong K.Y., AlMuhaish M.I., Alsooreti A., Kumarakulasinghe N.B., Teo E.C., Yap Q.V., Chan Y.H., Lin S., Tan J.H., Kumar N., Vellayappan B.A., Ooi B.C., Quek S.T., Makmur A.","Deep learning assessment compared to radiologist reporting for metastatic spinal cord compression on CT",2023,"Frontiers in Oncology",,"10.3389/fonc.2023.1151073","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159885520&doi=10.3389%2ffonc.2023.1151073&partnerID=40&md5=c40357c33444c262f93f7ee9d2061510","Introduction: Metastatic spinal cord compression (MSCC) is a disastrous complication of advanced malignancy. A deep learning (DL) algorithm for MSCC classification on CT could expedite timely diagnosis. In this study, we externally test a DL algorithm for MSCC classification on CT and compare with radiologist assessment. Methods: Retrospective collection of CT and corresponding MRI from patients with suspected MSCC was conducted from September 2007 to September 2020. Exclusion criteria were scans with instrumentation, no intravenous contrast, motion artefacts and non-thoracic coverage. Internal CT dataset split was 84% for training/validation and 16% for testing. An external test set was also utilised. Internal training/validation sets were labelled by radiologists with spine imaging specialization (6 and 11-years post-board certification) and were used to further develop a DL algorithm for MSCC classification. The spine imaging specialist (11-years expertise) labelled the test sets (reference standard). For evaluation of DL algorithm performance, internal and external test data were independently reviewed by four radiologists: two spine specialists (Rad1 and Rad2, 7 and 5-years post-board certification, respectively) and two oncological imaging specialists (Rad3 and Rad4, 3 and 5-years post-board certification, respectively). DL model performance was also compared against the CT report issued by the radiologist in a real clinical setting. Inter-rater agreement (Gwet’s kappa) and sensitivity/specificity/AUCs were calculated. Results: Overall, 420 CT scans were evaluated (225 patients, mean age=60 ± 11.9[SD]); 354(84%) CTs for training/validation and 66(16%) CTs for internal testing. The DL algorithm showed high inter-rater agreement for three-class MSCC grading with kappas of 0.872 (p<0.001) and 0.844 (p<0.001) on internal and external testing, respectively. On internal testing DL algorithm inter-rater agreement (κ=0.872) was superior to Rad 2 (κ=0.795) and Rad 3 (κ=0.724) (both p<0.001). DL algorithm kappa of 0.844 on external testing was superior to Rad 3 (κ=0.721) (p<0.001). CT report classification of high-grade MSCC disease was poor with only slight inter-rater agreement (κ=0.027) and low sensitivity (44.0), relative to the DL algorithm with almost-perfect inter-rater agreement (κ=0.813) and high sensitivity (94.0) (p<0.001). Conclusion: Deep learning algorithm for metastatic spinal cord compression on CT showed superior performance to the CT report issued by experienced radiologists and could aid earlier diagnosis. Copyright © 2023 Hallinan, Zhu, Zhang, Ge, Muhamat Nor, Ong, Eide, Cheng, Kuah, Lim, Low, Yeong, AlMuhaish, Alsooreti, Kumarakulasinghe, Teo, Yap, Chan, Lin, Tan, Kumar, Vellayappan, Ooi, Quek and Makmur.","artificial intelligence; CT; deep learning; Epidural spinal cord compression; metastatic epidural spinal cord compression (MESCC); metastatic spinal cord compression (MSCC); MRI; spinal metastatic disease","Article; artifact; breast cancer; cancer grading; colon cancer; computer assisted tomography; controlled study; deep learning; diagnostic test accuracy study; female; human; human tissue; learning; liver cell carcinoma; lung cancer; major clinical study; male; multiple myeloma; nuclear magnetic resonance imaging; prostate cancer; radiologist; receiver operating characteristic; renal cell carcinoma; retrospective study; sensitivity and specificity; spinal cord compression; spinal cord metastasis; spine; thoracic vertebra",Article,Scopus
"Kale K., Bhattacharyya P., Gune M., Shetty A., Lawyer R.","KGVL-BART: Knowledge Graph Augmented Visual Language BART for Radiology Report Generation",2023,"EACL 2023 - 17th Conference of the European Chapter of the Association for Computational Linguistics, Proceedings of the Conference",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159860119&partnerID=40&md5=0e22ea05b76f6c8b06521037374425fb","Timely generation of radiology reports and diagnoses is a challenge worldwide due to the enormous number of cases and shortage of radiology specialists. In this paper, we propose a Knowledge Graph Augmented Vision Language BART (KGVL-BART) model that takes as input two chest X-ray images- one frontal and the other lateral- along with tags which are diagnostic keywords, and outputs a report with the patient-specific findings. Our system development effort is divided into 3 stages: i) construction of the Chest X-ray KG (referred to as chestX-KG), ii) image feature extraction, and iii) training a KGVL-BART model using the visual, text, and KG data. The dataset we use is the well-known Indiana University Chest X-ray reports with the train, validation, and test split of 3025 instances, 300 instances, and 500 instances respectively. We construct a Chest X-Ray knowledge graph from these reports by extracting entity1-relation-entity2 triples; the triples get extracted by a rule-based tool of our own. Constructed KG is verified by two experienced radiologists (with experience of 30 years and 8 years, respectively). We demonstrate that our model- KGVL-BART- outperforms State-of-the-Art transformer-based models on standard NLG scoring metrics. We also include a qualitative evaluation of our system by experienced radiologist (with experience of 30 years) on the test data, which showed that 73% of the reports generated were fully correct, only 5.5% are completely wrong and 21.5% have important missing details though overall correct. To the best of our knowledge, ours is the first system to make use of multi-modality and domain knowledge to generate X-ray reports automatically. © 2023 Association for Computational Linguistics.",,"Computational linguistics; Data mining; Domain Knowledge; Knowledge graph; Natural language processing systems; Statistical tests; Visual languages; Chest X-ray image; Image feature extractions; Indiana University; Knowledge graphs; Patient specific; Radiology reports; Report generation; Rule based; Stage I; System development; Radiology",Conference Paper,Scopus
"Yang Z., Cherian S., Vucetic S.","Data Augmentation for Radiology Report Simplification",2023,"EACL 2023 - 17th Conference of the European Chapter of the Association for Computational Linguistics, Findings of EACL 2023",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159855476&partnerID=40&md5=f71e91b6019b61a1c8220496cef362fa","This work considers the development of a text simplification model to help patients better understand their radiology reports. This paper proposes a data augmentation approach to address the data scarcity issue caused by the high cost of manual simplification. It prompts a large foundational pre-trained language model to generate simplifications of unlabeled radiology sentences. In addition, it uses paraphrasing of labeled radiology sentences. Experimental results show that the proposed data augmentation approach enables the training of a significantly more accurate simplification model than the baselines. © 2023 Association for Computational Linguistics.",,"Computational linguistics; Data augmentation; Data scarcity; High costs; Language model; Radiology reports; Simplification models; Radiology",Conference Paper,Scopus
"Weng K.-H., Liu C.-F., Chen C.-J.","Deep Learning Approach for Negation and Speculation Detection for Automated Important Finding Flagging and Extraction in Radiology Report: Internal Validation and Technique Comparison Study",2023,"JMIR Medical Informatics",,"10.2196/46348","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159820522&doi=10.2196%2f46348&partnerID=40&md5=87ef2f2fe54de4136c499bbe7e8f1c6c","Background: Negation and speculation unrelated to abnormal findings can lead to false-positive alarms for automatic radiology report highlighting or flagging by laboratory information systems. Objective: This internal validation study evaluated the performance of natural language processing methods (NegEx, NegBio, NegBERT, and transformers). Methods: We annotated all negative and speculative statements unrelated to abnormal findings in reports. In experiment 1, we fine-tuned several transformer models (ALBERT [A Lite Bidirectional Encoder Representations from Transformers], BERT [Bidirectional Encoder Representations from Transformers], DeBERTa [Decoding-Enhanced BERT With Disentangled Attention], DistilBERT [Distilled version of BERT], ELECTRA [Efficiently Learning an Encoder That Classifies Token Replacements Accurately], ERNIE [Enhanced Representation through Knowledge Integration], RoBERTa [Robustly Optimized BERT Pretraining Approach], SpanBERT, and XLNet) and compared their performance using precision, recall, accuracy, and F1-scores. In experiment 2, we compared the best model from experiment 1 with 3 established negation and speculation-detection algorithms (NegEx, NegBio, and NegBERT). Results: Our study collected 6000 radiology reports from 3 branches of the Chi Mei Hospital, covering multiple imaging modalities and body parts. A total of 15.01% (105,755/704,512) of words and 39.45% (4529/11,480) of important diagnostic keywords occurred in negative or speculative statements unrelated to abnormal findings. In experiment 1, all models achieved an accuracy of >0.98 and F1-score of >0.90 on the test data set. ALBERT exhibited the best performance (accuracy=0.991; F1-score=0.958). In experiment 2, ALBERT outperformed the optimized NegEx, NegBio, and NegBERT methods in terms of overall performance (accuracy=0.996; F1-score=0.991), in the prediction of whether diagnostic keywords occur in speculative statements unrelated to abnormal findings, and in the improvement of the performance of keyword extraction (accuracy=0.996; F1-score=0.997). Conclusions: The ALBERT deep learning method showed the best performance. Our results represent a significant advancement in the clinical applications of computer-aided notification systems. ©Kung-Hsun Weng, Chung-Feng Liu, Chia-Jung Chen.","BERT; Bidirectional Encoder Representations from Transformers; clinical application; deep learning; natural language processing; negation; radiology; radiology report; supervised learning; transfer learning; validation study",,Article,Scopus
"Shetty S., Ananthanarayana V.S., Mahale A.","Multimodal medical tensor fusion network-based DL framework for abnormality prediction from the radiology CXRs and clinical text reports",2023,"Multimedia Tools and Applications",2,"10.1007/s11042-023-14940-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153395564&doi=10.1007%2fs11042-023-14940-x&partnerID=40&md5=832b1a0d2a5ab088dcd8c5161f2735c1","Pulmonary disease is a commonly occurring abnormality throughout this world. The pulmonary diseases include Tuberculosis, Pneumothorax, Cardiomegaly, Pulmonary atelectasis, Pneumonia, etc. A timely prognosis of pulmonary disease is essential. Increasing progress in Deep Learning (DL) techniques has significantly impacted and contributed to the medical domain, specifically in leveraging medical imaging for analysis, prognosis, and therapeutic decisions for clinicians. Many contemporary DL strategies for radiology focus on a single modality of data utilizing imaging features without considering the clinical context that provides more valuable complementary information for clinically consistent prognostic decisions. Also, the selection of the best data fusion strategy is crucial when performing Machine Learning (ML) or DL operation on multimodal heterogeneous data. We investigated multimodal medical fusion strategies leveraging DL techniques to predict pulmonary abnormality from the heterogeneous radiology Chest X-Rays (CXRs) and clinical text reports. In this research, we have proposed two effective unimodal and multimodal subnetworks to predict pulmonary abnormality from the CXR and clinical reports. We have conducted a comprehensive analysis and compared the performance of unimodal and multimodal models. The proposed models were applied to standard augmented data and the synthetic data generated to check the model’s ability to predict from the new and unseen data. The proposed models were thoroughly assessed and examined against the publicly available Indiana university dataset and the data collected from the private medical hospital. The proposed multimodal models have given superior results compared to the unimodal models. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Clinical recommendation systems; Deep learning; Disease prediction; Multimodality; Radiology; Tensor fusion networks","Clinical research; Data fusion; Deep learning; Diagnosis; Learning systems; Medical imaging; Modal analysis; Radiology; Tensors; Clinical recommendation system; Deep learning; Disease prediction; Learning techniques; Multi-modal; Multi-modality; Multimodal models; Tensor fusion; Tensor fusion network; Unimodal; Forecasting",Article,Scopus
"Kumar M.A., Panitini M., Vemulapalli S., Sai M.J.N.V.","Deep Learning based Automatic Radiology Report Generation",2023,"Proceedings of the 3rd International Conference on Artificial Intelligence and Smart Energy, ICAIS 2023",,"10.1109/ICAIS56108.2023.10073691","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152423275&doi=10.1109%2fICAIS56108.2023.10073691&partnerID=40&md5=6be7cd69a09aa18a185f92d906c3fb0f","The diagnostic x-ray examination is carried out using the chest x-ray. It is the responsibility of the radiologist to analyze the x-rays and draw conclusions from them to prescribe the proper care. Obtaining comprehensive medical reports from these x-rays is frequently time-consuming. Images of the heart, lungs, airways, spine, and chest bones can be seen in a chest x-ray. A radiologist may see thousands of x-ray images in populous nations. The goal of this project is to present a collection of the best deep-learning techniques for producing medical reports from X-ray images automatically. Deep learning algorithms have been used with models to handle this difficult task and produce correct results. Therefore, a lot of work and time can be saved if a properly trained deep learning model can generate these medical reports automatically. In this research, the text report is produced using an encoder and decoder with an attention model, while the image features are obtained using a pretrained CheXnet model. The BLEU score is used to evaluate the resulting text report. © 2023 IEEE.","Attention; Bilingual Evaluation Understudy; Chest x-rays; Chexnet; Decoder; Encoder; Radiologist","Decoding; Diagnosis; Learning algorithms; Learning systems; Medical imaging; Signal encoding; Attention; Bilingual evaluation understudy; Bilinguals; Chest x-rays; Chexnet; Decoder; Encoder; Radiologist; Radiology reports; X-ray image; Deep learning",Conference Paper,Scopus
"Dasegowda G., Bizzo B.C., Gupta R.V., Kaviani P., Ebrahimian S., Ricciardelli D., Abedi-Tari F., Neumark N., Digumarthy S.R., Kalra M.K., Dreyer K.J.","Radiologist-Trained AI Model for Identifying Suboptimal Chest-Radiographs",2023,"Academic Radiology",,"10.1016/j.acra.2023.03.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151493310&doi=10.1016%2fj.acra.2023.03.006&partnerID=40&md5=1d5798bbe6a8ad20d1398b42b0132c79","Rationale and Objectives: Suboptimal chest radiographs (CXR) can limit interpretation of critical findings. Radiologist-trained AI models were evaluated for differentiating suboptimal(sCXR) and optimal(oCXR) chest radiographs. Materials and Methods: Our IRB-approved study included 3278 CXRs from adult patients (mean age 55 ± 20 years) identified from a retrospective search of CXR in radiology reports from 5 sites. A chest radiologist reviewed all CXRs for the cause of suboptimality. The de-identified CXRs were uploaded into an AI server application for training and testing 5 AI models. The training set consisted of 2202 CXRs (n = 807 oCXR; n = 1395 sCXR) while 1076 CXRs (n = 729 sCXR; n = 347 oCXR) were used for testing. Data were analyzed with the Area under the curve (AUC) for the model's ability to classify oCXR and sCXR correctly. Results: For the two-class classification into sCXR or oCXR from all sites, for CXR with missing anatomy, AI had sensitivity, specificity, accuracy, and AUC of 78%, 95%, 91%, 0.87(95% CI 0.82-0.92), respectively. AI identified obscured thoracic anatomy with 91% sensitivity, 97% specificity, 95% accuracy, and 0.94 AUC (95% CI 0.90-0.97). Inadequate exposure with 90% sensitivity, 93% specificity, 92% accuracy, and AUC of 0.91 (95% CI 0.88-0.95). The presence of low lung volume was identified with 96% sensitivity, 92% specificity, 93% accuracy, and 0.94 AUC (95% CI 0.92-0.96). The sensitivity, specificity, accuracy, and AUC of AI in identifying patient rotation were 92%, 96%, 95%, and 0.94 (95% CI 0.91-0.98), respectively. Conclusion: The radiologist-trained AI models can accurately classify optimal and suboptimal CXRs. Such AI models at the front end of radiographic equipment can enable radiographers to repeat sCXRs when necessary. © 2023 The Association of University Radiologists","Artificial Intelligence; Computer-assisted Image processing; Quality improvement; Radiography; Thoracic Radiography","adult; area under the curve; article; artificial intelligence; controlled study; diagnostic test accuracy study; female; human; image processing; lung volume; major clinical study; male; middle aged; radiographer; radiologist; rotation; sensitivity and specificity; thorax radiography; total quality management",Article,Scopus
"Puts S., Nobel M., Zegers C., Bermejo I., Robben S., Dekker A.","How Natural Language Processing Can Aid With Pulmonary Oncology Tumor Node Metastasis Staging From Free-Text Radiology Reports: Algorithm Development and Validation",2023,"JMIR Formative Research",,"10.2196/38125","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151327663&doi=10.2196%2f38125&partnerID=40&md5=e40c61cc02d43f779de18ab18d7765c1","Background: Natural language processing (NLP) is thought to be a promising solution to extract and store concepts from free text in a structured manner for data mining purposes. This is also true for radiology reports, which still consist mostly of free text. Accurate and complete reports are very important for clinical decision support, for instance, in oncological staging. As such, NLP can be a tool to structure the content of the radiology report, thereby increasing the report’s value. Objective: This study describes the implementation and validation of an N-stage classifier for pulmonary oncology. It is based on free-text radiological chest computed tomography reports according to the tumor, node, and metastasis (TNM) classification, which has been added to the already existing T-stage classifier to create a combined TN-stage classifier. Methods: SpaCy, PyContextNLP, and regular expressions were used for proper information extraction, after additional rules were set to accurately extract N-stage. Results: The overall TN-stage classifier accuracy scores were 0.84 and 0.85, respectively, for the training (N=95) and validation (N=97) sets. This is comparable to the outcomes of the T-stage classifier (0.87-0.92). Conclusions: This study shows that NLP has potential in classifying pulmonary oncology from free-text radiological reports according to the TNM classification system as both the T- and N-stages can be extracted with high accuracy. ©Sander Puts, Martijn Nobel, Catharina Zegers, Iñigo Bermejo, Simon Robben, Andre Dekker.","classification system; clinical; clinical decision; free text; natural language processing; oncology; pulmonary; radiology; reporting",,Article,Scopus
"Park S.H.","Erratum to: Authorship Policy of the Korean Journal of Radiology Regarding Artificial Intelligence Large Language Models Such as ChatGPT (Korean J Radiol 2023;24(3):171-172, 10.3348/kjr.2023.0112)",2023,"Korean Journal of Radiology",,"10.3348/kjr.2023.0244","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151315940&doi=10.3348%2fkjr.2023.0244&partnerID=40&md5=59b162f1b453f91219a57b31ad5b10bc","On page 171, the title has been incorrectly marked as “Authorship Policy of the Korean Journal of Radiology Regarding Artificial Intelligence Large Language Models Such as ChatGTP.” The correct title is “Authorship Policy of the Korean Journal of Radiology Regarding Artificial Intelligence Large Language Models Such as ChatGPT.”. © 2023 The Korean Society of Radiology.",,"erratum",Erratum,Scopus
"Dercksen K., de Vries A.P., van Ginneken B.","SimpleRad: Patient-Friendly Dutch Radiology Reports",2023,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"10.1007/978-3-031-28241-6_18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151061498&doi=10.1007%2f978-3-031-28241-6_18&partnerID=40&md5=a36fc9de0d7265ca2549075b7e6970f6","Patients increasingly have access to their electronic health records. However, much of the content therein is not specifically written for them; instead it captures communication about a patient’s situation between medical professionals. We present SimpleRad, a prototype application to explore patient-friendly explanations of radiology terminology. In this demonstration paper, we describe the various modules currently included in SimpleRad such as an entity linker, summarizer, search page, and observation frequency estimator. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Information retrieval; Medical; Natural language processing","Frequency estimation; Natural language processing systems; Electronic health; Health records; Language processing; Medical; Medical professionals; Natural language processing; Natural languages; Observation frequencies; Radiology reports; Search page; Radiology",Conference Paper,Scopus
"Xiong S., Hu H., Liu S., Huang Y., Cheng J., Wan B.","Improving diagnostic performance of rib fractures for the night shift in radiology department using a computer-aided diagnosis system based on deep learning: A clinical retrospective study",2023,"Journal of X-Ray Science and Technology",,"10.3233/XST-221343","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150665548&doi=10.3233%2fXST-221343&partnerID=40&md5=7250bccfdca7a1e052a1b286de6557ac","OBJECTIVE: To investigate the application value of a computer-aided diagnosis (CAD) system based on deep learning (DL) of rib fractures for night shifts in radiology department. METHODS: Chest computed tomography (CT) images and structured reports were retrospectively selected from the picture archiving and communication system (PACS) for 2,332 blunt chest trauma patients. In all CT imaging examinations, two on-duty radiologists (radiologists I and II) completed reports using three different reading patterns namely, P1 = independent reading during the day shift; P2 = independent reading during the night shift; and P3 = reading with the aid of a CAD system as the concurrent reader during the night shift. The locations and types of rib fractures were documented for each reading. In this study, the reference standard for rib fractures was established by an expert group. Sensitivity and false positives per scan (FPS) were counted and compared among P1, P2, and P3. RESULTS: The reference standard verified 6,443 rib fractures in the 2,332 patients. The sensitivity of both radiologists decreased significantly in P2 compared to that in P1 (both p < 0.017). The sensitivities of both radiologists showed no statistical difference between P3 and P1 (both p > 0.017). Radiologist I’s FPS increased significantly in P2 compared to P1 (p < 0.017). The FPS of radiologist I showed no statistically significant difference between P3 and P1 (p > 0.017). The FPS of Radiologist II showed no statistical difference among all three reading patterns (p > 0.05). CONCLUSIONS: DL-based CAD systems can be integrated into the workflow of radiology departments during the night shift to improve the diagnostic performance of CT rib fractures. © 2023 – IOS Press. All rights reserved.","convolutional neural network; deep learning; Rib fractures; tomography; X-ray computed","Computer aided diagnosis; Computer aided instruction; Convolutional neural networks; Deep learning; Fracture; Learning systems; Medical imaging; Picture archiving and communication systems; Radiology; Computer aided diagnosis systems; Convolutional neural network; Deep learning; Diagnostic performance; False positive; Radiology departments; Reading patterns; Reference standard; Rib fractures; X-ray computed; Computerized tomography; blunt trauma; computer; diagnostic imaging; human; radiology; retrospective study; rib fracture; sensitivity and specificity; thorax injury; Computers; Deep Learning; Humans; Radiology; Retrospective Studies; Rib Fractures; Sensitivity and Specificity; Thoracic Injuries; Wounds, Nonpenetrating",Article,Scopus
"Gaviria-Valencia S., Murphy S.P., Kaggal V.C., McBane R.D., Rooke T.W., Chaudhry R., Alzate-Aguirre M., Arruda-Olson A.M.","Near Real-time Natural Language Processing for the Extraction of Abdominal Aortic Aneurysm Diagnoses From Radiology Reports: Algorithm Development and Validation Study",2023,"JMIR Medical Informatics",2,"10.2196/40964","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149939189&doi=10.2196%2f40964&partnerID=40&md5=5e5d1a9652a1b33394a455a2b93e5728","Background: Management of abdominal aortic aneurysms (AAAs) requires serial imaging surveillance to evaluate the aneurysm dimension. Natural language processing (NLP) has been previously developed to retrospectively identify patients with AAA from electronic health records (EHRs). However, there are no reported studies that use NLP to identify patients with AAA in near real-time from radiology reports. Objective: This study aims to develop and validate a rule-based NLP algorithm for near real-time automatic extraction of AAA diagnosis from radiology reports for case identification. Methods: The AAA-NLP algorithm was developed and deployed to an EHR big data infrastructure for near real-time processing of radiology reports from May 1, 2019, to September 2020. NLP extracted named entities for AAA case identification and classified subjects as cases and controls. The reference standard to assess algorithm performance was a manual review of processed radiology reports by trained physicians following standardized criteria. Reviewers were blinded to the diagnosis of each subject. The AAA-NLP algorithm was refined in 3 successive iterations. For each iteration, the AAA-NLP algorithm was modified based on performance compared to the reference standard. Results: A total of 360 reports were reviewed, of which 120 radiology reports were randomly selected for each iteration. At each iteration, the AAA-NLP algorithm performance improved. The algorithm identified AAA cases in near real-time with high positive predictive value (0.98), sensitivity (0.95), specificity (0.98), F1 score (0.97), and accuracy (0.97). Conclusions: Implementation of NLP for accurate identification of AAA cases from radiology reports with high performance in near real time is feasible. This NLP technique will support automated input for patient care and clinical decision support tools for the management of patients with AAA. ©Simon Gaviria-Valencia, Sean P Murphy, Vinod C Kaggal, Robert D McBane II, Thom W Rooke, Rajeev Chaudhry, Mateo Alzate-Aguirre, Adelaide M Arruda-Olson.","abdominal aortic aneurysm; algorithm; big data; electronic health record; medical records; natural language processing; radiology; radiology reports",,Article,Scopus
"Tejani A.S., Elhalawani H., Moy L., Kohli M., Kahn C.E., Jr.","Artificial Intelligence and Radiology Education",2023,"Radiology: Artificial Intelligence",,"10.1148/ryai.220084","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148302698&doi=10.1148%2fryai.220084&partnerID=40&md5=040572a8c2a30f89280a0beedfb97e0d","Implementation of artificial intelligence (AI) applications into clinical practice requires AI-savvy radiologists to ensure the safe, ethical, and effective use of these systems for patient care. Increasing demand for AI education reflects recognition of the translation of AI applications from research to clinical practice, with positive trainee attitudes regarding the influence of AI on radiology. However, barriers to AI education, such as limited access to resources, predispose to insufficient preparation for the effective use of AI in practice. In response, national organizations have sponsored formal and self-directed learning courses to provide introductory content on imaging informatics and AI. Foundational courses, such as the National Imaging Informatics Course – Radiology and the Radiological Society of North America Imaging AI Certificate, lay a framework for trainees to explore the creation, deployment, and critical evaluation of AI applications. This report includes additional resources for formal programming courses, video series from leading organizations, and blogs from AI and informatics communities. Furthermore, the scope of “AI and radiology education” includes AI-augmented radiology education, with emphasis on the potential for “precision education” that cre-ates personalized experiences for trainees by accounting for varying learning styles and inconsistent, possibly deficient, clinical case volume. © RSNA, 2022.","Artificial Intel-ligence; Imaging Informatics; Impact of AI on Education; Medical Education; Natural Language Processing; Precision Education; Use of AI in Education","Article; artificial intelligence; attitude; clinical practice; curriculum; data privacy; economics; education; human; information science; knowledge; learning style; machine learning; medical ethics; medical student; natural language processing; nuclear magnetic resonance imaging; patient care; patient safety; positive trainee attitude; radiologist; radiology; residency education; self-directed learning; training",Article,Scopus
"Laurent G., Craynest F., Thobois M., Hajjaji N.","Automatic Classification of Tumor Response From Radiology Reports With Rule-Based Natural Language Processing Integrated Into the Clinical Oncology Workflow",2023,"JCO clinical cancer informatics",2,"10.1200/CCI.22.00139","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147935215&doi=10.1200%2fCCI.22.00139&partnerID=40&md5=2096f52b9285acd7a89682b8a952f791","PURPOSE: Imaging reports in oncology provide critical information about the disease evolution that should be timely shared to tailor the clinical decision making and care coordination of patients with advanced cancer. However, tumor response stays unstructured in free-text and underexploited. Natural language processing (NLP) methods can help provide this critical information into the electronic health records (EHR) in real time to assist health care workers. METHODS: A rule-based algorithm was developed using SAS tools to automatically extract and categorize tumor response within progression or no progression categories. 2,970 magnetic resonance imaging, computed tomography scan, and positron emission tomography French reports were extracted from the EHR of a large comprehensive cancer center to build a 2,637-document training set and a 603-document validation set. The model was also tested on 189 imaging reports from 46 different radiology centers. A tumor dashboard was created in the EHR using the Timeline tool of the vis.js javascript library. RESULTS: An NLP methodology was applied to create an ontology of radiographic terms defining tumor response, mapping text to five main concepts, and application decision rules on the basis of clinical practice RECIST guidelines. The model achieved an overall accuracy of 0.88 (ranging from 0.87 to 0.94), with similar performance on both progression and no progression classification. The overall accuracy was 0.82 on reports from different radiology centers. Data were visualized and organized in a dynamic tumor response timeline. This tool was deployed successfully at our institution both retrospectively and prospectively as part of an automatic pipeline to screen reports and classify tumor response in real time for all metastatic patients. CONCLUSION: Our approach provides an NLP-based framework to structure and classify tumor response from the EHR and integrate tumor response classification into the clinical oncology workflow.",,"diagnostic imaging; human; natural language processing; neoplasm; oncology; radiology; retrospective study; workflow; Humans; Medical Oncology; Natural Language Processing; Neoplasms; Radiology; Retrospective Studies; Workflow",Article,Scopus
"Krebs B., Nataraj A., McCabe E., Clark S., Sufiyan Z., Yamamoto S.S., Zaïane O., Gross D.P.","Developing a triage predictive model for access to a spinal surgeon using clinical variables and natural language processing of radiology reports",2023,"European Spine Journal",,"10.1007/s00586-023-07552-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147347229&doi=10.1007%2fs00586-023-07552-4&partnerID=40&md5=d88427f6a7253daa7088cac0fb0b4f4f","Purpose: To utilize natural language processing (NLP) of MRI reports and various clinical variables to develop a preliminary model predictive of the need for surgery in patients with low back and neck pain. Such a model would be beneficial for informing clinical practice decisions and help reduce the number of unnecessary surgical referrals, streamlining the surgical process. Methods: A historical cohort study was conducted using de-identified data from patients referred to a spine assessment clinic. Various demographic, clinical, and radiological variables were included as potential predictors. Full-text radiology reports of patients’ MRI findings were vectorized using NLP before applying machine learning algorithms to develop models predicting who underwent surgery. Outputs from these models were then entered into a logistic regression model with clinical variables to develop a preliminary model predictive of surgical recommendations. Results: Of the 398 patients assessed, 71 underwent spine surgery. NLP variables were significant predictors in univariate analysis but did not remain in the final logistic regression model. An outcome of receiving surgery was predicted by a primary symptom of low back and leg pain (adjusted odds ratio 2.81), distal pain indicated by a pain diagram (adjusted odds ratio 2.49) and self-reported difficulties walking (adjusted odds ratio 2.73). Conclusion: A logistic regression model was created to predict which patients may require spine surgery. Simple clinical variables appeared more predictive than variables created using NLP. However, additional research with more data samples is needed to validate this model and fully evaluate the usefulness of NLP for this task. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","Back and neck pain; Predictive factors; Spinal surgery; Surgical outcome",,Article,Scopus
"Mohsan M.M., Akram M.U., Rasool G., Alghamdi N.S., Baqai M.A.A., Abbas M.","Vision Transformer and Language Model Based Radiology Report Generation",2023,"IEEE Access",1,"10.1109/ACCESS.2022.3232719","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146219653&doi=10.1109%2fACCESS.2022.3232719&partnerID=40&md5=93f2e7b328b8f5e7327282345afd3712","Recent advancements in transformers exploited computer vision problems which results in state-of-The-Art models. Transformer-based models in various sequence prediction tasks such as language translation, sentiment classification, and caption generation have shown remarkable performance. Auto report generation scenarios in medical imaging through caption generation models is one of the applied scenarios for language models and have strong social impact. In these models, convolution neural networks have been used as encoder to gain spatial information and recurrent neural networks are used as decoder to generate caption or medical report. However, using transformer architecture as encoder and decoder in caption or report writing task is still unexplored. In this research, we explored the effect of losing spatial biasness information in encoder by using pre-Trained vanilla image transformer architecture and combine it with different pre-Trained language transformers as decoder. In order to evaluate the proposed methodology, the Indiana University Chest X-Rays dataset is used where ablation study is also conducted with respect to different evaluations. The comparative analysis shows that the proposed methodology has represented remarkable performance when compared with existing techniques in terms of different performance parameters. © 2013 IEEE.","decoder; language models; radiology report; Vision transformers","Computational linguistics; Convolution; Decoding; Job analysis; Medical imaging; Modeling languages; Network architecture; Radiology; Biomedical imaging; Computational modelling; Convolutional neural network; Decoder; Decoding; Language model; Radiology reports; Task analysis; Transformer; Vision transformer; X-ray imaging; Recurrent neural networks",Article,Scopus
"Yokota S., Doi S., Fukuhara M., Mitani T., Nagashima S., Gonoi W., Imai T., Ohe K.","Application program to detect unrecognized information regarding malignant tumors in radiology reports",2023,"Health and Technology",,"10.1007/s12553-022-00724-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145218085&doi=10.1007%2fs12553-022-00724-0&partnerID=40&md5=d4a078f712cb5cf25c58adf6ff2d9b94","Purpose: Accurate disease diagnosis from radiology reports is important in medical treatment. Preventing physicians from overlooking the findings of relevant radiology reports is thus an important global issue. This study is part of a project that aims to develop and verify a program that detects and notifies physicians of diagnoses that do not appear in the patient’s medical records. Methods: In this study, we developed software functions that (1) extract diagnoses from radiology reports, (2) search medical records for the extracted diagnoses and output them and their corresponding ICD10 codes, which do not appear in the patients’ medical records, and (3) automatically execute all processes daily and notify auditors by email. We verified seven cases including diagnoses suspected of being overlooked that are automatically extracted by our system from 1,194 radiology reports. Results: By checking the output obtained from the system constructed by incorporating a high-performance sentence classifier for disease name polarity classification with AUC = 0.972, it was possible to extract disease names that physicians might have overlooked. We could extract a past actual overlooked case by this algorithm. From verifying seven cases, we assessed that the physician might not have considered one diagnosis in one case. Conclusion: These results demonstrate that the developed system is useful when auditors check patients’ medical records to confirm the status of overlooked reports and diagnoses. In future work, we will develop additional functions and tools for incorporation into the proposed system to facilitate its application in clinical practice. © 2022, The Author(s) under exclusive licence to International Union for Physical and Engineering Sciences in Medicine (IUPESM).","Electronic medical records; Missed diagnosis; Natural language processing; Patient safety; Radiology information systems","Article; cancer classification; cancer diagnosis; classification algorithm; classifier; computer assisted tomography; controlled study; cross validation; data extraction; diagnostic accuracy; diagnostic test accuracy study; e-mail; electronic medical record; false positive result; human; ICD-10; malignant neoplasm; medical record review; physician; predictive value; radiodiagnosis; reporting and data system",Article,Scopus
"Fritz B., Yi P.H., Kijowski R., Fritz J.","Radiomics and Deep Learning for Disease Detection in Musculoskeletal Radiology: An Overview of Novel MRI- and CT-Based Approaches",2023,"Investigative Radiology",15,"10.1097/RLI.0000000000000907","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143916978&doi=10.1097%2fRLI.0000000000000907&partnerID=40&md5=50d83ed9dd82c4425ced452ee3b047b8","Radiomics and machine learning-based methods offer exciting opportunities for improving diagnostic performance and efficiency in musculoskeletal radiology for various tasks, including acute injuries, chronic conditions, spinal abnormalities, and neoplasms. While early radiomics-based methods were often limited to a smaller number of higher-order image feature extractions, applying machine learning-based analytic models, multifactorial correlations, and classifiers now permits big data processing and testing thousands of features to identify relevant markers. A growing number of novel deep learning-based methods describe magnetic resonance imaging- and computed tomography-based algorithms for diagnosing anterior cruciate ligament tears, meniscus tears, articular cartilage defects, rotator cuff tears, fractures, metastatic skeletal disease, and soft tissue tumors. Initial radiomics and deep learning techniques have focused on binary detection tasks, such as determining the presence or absence of a single abnormality and differentiation of benign versus malignant. Newer-generation algorithms aim to include practically relevant multiclass characterization of detected abnormalities, such as typing and malignancy grading of neoplasms. So-called delta-radiomics assess tumor features before and after treatment, with temporal changes of radiomics features serving as surrogate markers for tumor responses to treatment. New approaches also predict treatment success rates, surgical resection completeness, and recurrence risk. Practice-relevant goals for the next generation of algorithms include diagnostic whole-organ and advanced classification capabilities. Important research objectives to fill current knowledge gaps include well-designed research studies to understand how diagnostic performances and suggested efficiency gains of isolated research settings translate into routine daily clinical practice. This article summarizes current radiomics- and machine learning-based magnetic resonance imaging and computed tomography approaches for musculoskeletal disease detection and offers a perspective on future goals and objectives. © Wolters Kluwer Health, Inc. All rights reserved.","artificial intelligence; computed tomography; knee injuries; magnetic resonance imaging; musculoskeletal abnormalities; neoplasms; neural networks (computer); radiology; sarcoma; shoulder","accuracy; adult; anterior cruciate ligament; Article; articular cartilage; artificial intelligence; bone tumor; case report; clinical article; computer assisted tomography; controlled study; convolutional neural network; deep learning; dermatomyositis; diagnostic test accuracy study; female; ganglion cyst; histopathology; human; human experiment; human tissue; knee meniscus; knee meniscus rupture; liposarcoma; machine learning; major clinical study; musculoskeletal disease; nuclear magnetic resonance imaging; polymyositis; radiology; radiomics; receiver operating characteristic; soft tissue sarcoma; nuclear magnetic resonance imaging; procedures; radiography; retrospective study; x-ray computed tomography; Deep Learning; Machine Learning; Magnetic Resonance Imaging; Radiography; Retrospective Studies; Tomography, X-Ray Computed",Article,Scopus
"Wang L., Chen J.","Improving Radiology Report Generation with Adaptive Attention",2023,"Studies in Computational Intelligence",,"10.1007/978-3-031-14771-5_21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143127642&doi=10.1007%2f978-3-031-14771-5_21&partnerID=40&md5=24c8cb274837608023a6adc789b5b0af","To avoid the tedious and laborious radiology report writing, automatic radiology reports generation has drawn great attention in recent years. As vision to language task, visual features and language features are equally important for radiology report generation. However, previous methods mainly pay attention to generating fluent reports, which neglects the eminent importance of how to better extract and utilize vision information. Keeping this in mind, we propose a novel architecture with a CLIP-based visual extractor and Multi-Head Adaptive Attention (MHAA) module to address the above two issues: through the vision-language pretrained encoders, more sufficient visual information has been explored, then during report generation, MHAA controls the visual information participating in the generation of each word. Experiments conducted on two public datasets demonstrate that our method outperforms state-of-the-art methods on all the metrics. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Adaptive attention mechanism; Radiology report generation; Visual encoder",,Book Chapter,Scopus
"Cai X., Liu S., Han J., Yang L., Liu Z., Liu T.","ChestXRayBERT: A Pretrained Language Model for Chest Radiology Report Summarization",2023,"IEEE Transactions on Multimedia",4,"10.1109/TMM.2021.3132724","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121395984&doi=10.1109%2fTMM.2021.3132724&partnerID=40&md5=f72bdfdc329a5657045af891236fcaf7","Automatically generating the 'impression' section of a radiology report given the 'findings' section can summarize as much salient information of the 'findings' section as possible, thus promoting more effective communication between radiologists and referring physicians. To significantly reduce the workload of radiologists, we develop and evaluate a novel framework of abstractive summarization methods to automatically generate the 'impression' section of chest radiology reports. Despite recent advancements in natural language process (NLP) field such as BERT and its variants, existing abstractive summarization models and methods could not be directly applied to radiology reports, partly due to domain-specific radiology terminology. In response, we develop a pre-trained language model in the chest radiology domain, named ChestXRayBERT, to solve the problem of automatically summarizing chest radiology reports. Specifically, we first collect radiology-related scientific papers as pre-training corpus and pre-train a ChestXRayBERT on it. Then, an abstractive summarization model is proposed, which consists of the pre-trained ChestXRayBERT and a Transformer decoder. Finally, the model is fine-tuned on chest X-ray reports for the abstractive summarization task. When evaluated on the publicly available OPEN-I and MIMIC-CXR datasets, the performance of our proposed model achieves significant improvement compared with other neural networks-based abstractive summarization models. In general, the proposed ChestXRayBERT demonstrates the feasibility and promise of tailoring and extending advanced NLP techniques to the domain of medical imaging and radiology, as well as in the broader biomedicine and healthcare fields in the future. © 1999-2012 IEEE.","abstractive summarization; chest radiology report; Pre-trained language model","Decoding; Natural language processing systems; Radiation; Radiology; Abstractive summarization; Biological system modeling; Biomedical imaging; Bit-error rate; Chest radiology report; Decoding; Language model; Pre-trained language model; Radiology reports; Task analysis; Transformer; Bit error rate",Article,Scopus
"Fazekas S., Budaiorcid B.K., Stollmayerorcid R., Kaposiorcid P.N., Bérczi V.","Artificial intelligence and neural networks in radiology – Basics that all radiology residents should know",2022,"IMAGING",1,"10.1556/1647.2022.00104","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146675341&doi=10.1556%2f1647.2022.00104&partnerID=40&md5=414415c4e539e978fc9696a7bd0e1dd7","The area of Artificial Intelligence is developing at a high rate. In the medical field, an extreme amount of data is created every day. As the images and the reports are quantifiable, the field of radiology aspires to deliver better, more efficient clinical care. Artificial intelligence (AI) means the simulation of human intelligence by a system or machine. It has been developed to enable machines to ""think"", which means to be able to learn, reason, predict, categorize, and solve problems concerning high amounts of data and make decisions in a more effective manner than before. Different AI methods can help radiologists with pre-screening images and identifying features. In this review, we summarize the basic concepts which are needed to understand AI. As the AI methods are expected to exceed the threshold for clinical usefulness soon, in the near future it will be inevitable to use AI in medicine. © 2022 The Author(s).","artificial intelligence; image classification; machine learning; neural networks; object detection; segmentation","adult; article; artificial intelligence; artificial neural network; human; machine learning; radiologist; radiology; resident; simulation",Article,Scopus
"Coleman M., Dipnall J.F., Jung M.C., Du L.","PreRadE: Pretraining Tasks on Radiology Images and Reports Evaluation Framework",2022,"Mathematics",,"10.3390/math10244661","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144665928&doi=10.3390%2fmath10244661&partnerID=40&md5=1446190ff3d0bdbca6b44e6f8e00d72f","Recently, self-supervised pretraining of transformers has gained considerable attention in analyzing electronic medical records. However, systematic evaluation of different pretraining tasks in radiology applications using both images and radiology reports is still lacking. We propose PreRadE, a simple proof of concept framework that enables novel evaluation of pretraining tasks in a controlled environment. We investigated three most-commonly used pretraining tasks (MLM—Masked Language Modelling, MFR—Masked Feature Regression, and ITM—Image to Text Matching) and their combinations against downstream radiology classification on MIMIC-CXR, a medical chest X-ray imaging and radiology text report dataset. Our experiments in the multimodal setting show that (1) pretraining with MLM yields the greatest benefit to classification performance, largely due to the task-relevant information learned from the radiology reports. (2) Pretraining with only a single task can introduce variation in classification performance across different fine-tuning episodes, suggesting that composite task objectives incorporating both image and text modalities are better suited to generating reliably performant models. © 2022 by the authors.","computational radiology; deep learning applications; machine learning; masked language modelling; model evaluation; multimodal; pathoanatomical classification; self-supervised learning; X-ray analysis",,Article,Scopus
"Potočnik J., Thomas E., Killeen R., Foley S., Lawlor A., Stowe J.","Automated vetting of radiology referrals: exploring natural language processing and traditional machine learning approaches",2022,"Insights into Imaging",3,"10.1186/s13244-022-01267-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135499222&doi=10.1186%2fs13244-022-01267-8&partnerID=40&md5=3a4bd44acf93012e5260d452175b2cbc","Background: With a significant increase in utilisation of computed tomography (CT), inappropriate imaging is a significant concern. Manual justification audits of radiology referrals are time-consuming and require financial resources. We aimed to retrospectively audit justification of brain CT referrals by applying natural language processing and traditional machine learning (ML) techniques to predict their justification based on the audit outcomes. Methods: Two human experts retrospectively analysed justification of 375 adult brain CT referrals performed in a tertiary referral hospital during the 2019 calendar year, using a cloud-based platform for structured referring. Cohen’s kappa was computed to measure inter-rater reliability. Referrals were represented as bag-of-words (BOW) and term frequency-inverse document frequency models. Text preprocessing techniques, including custom stop words (CSW) and spell correction (SC), were applied to the referral text. Logistic regression, random forest, and support vector machines (SVM) were used to predict the justification of referrals. A test set (300/75) was used to compute weighted accuracy, sensitivity, specificity, and the area under the curve (AUC). Results: In total, 253 (67.5%) examinations were deemed justified, 75 (20.0%) as unjustified, and 47 (12.5%) as maybe justified. The agreement between the annotators was strong (κ = 0.835). The BOW + CSW + SC + SVM outperformed other binary models with a weighted accuracy of 92%, a sensitivity of 91%, a specificity of 93%, and an AUC of 0.948. Conclusions: Traditional ML models can accurately predict justification of unstructured brain CT referrals. This offers potential for automated justification analysis of CT referrals in clinical departments. © 2022, The Author(s).","Clinical decision support; Justification audit; Machine learning; Natural language processing; Radiology referral","adult; area under the curve; article; brain; computer assisted tomography; decision support system; diagnostic test accuracy study; female; human; interrater reliability; machine learning; male; natural language processing; patient referral; radiology; random forest; retrospective study; sensitivity and specificity; support vector machine; tertiary care center",Article,Scopus
"Li J., Lin Y., Zhao P., Liu W., Cai L., Sun J., Zhao L., Yang Z., Song H., Lv H., Wang Z.","Automatic text classification of actionable radiology reports of tinnitus patients using bidirectional encoder representations from transformer (BERT) and in-domain pre-training (IDPT)",2022,"BMC Medical Informatics and Decision Making",3,"10.1186/s12911-022-01946-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135174025&doi=10.1186%2fs12911-022-01946-y&partnerID=40&md5=41b994a924b0e66872035b1b60972812","Background: Given the increasing number of people suffering from tinnitus, the accurate categorization of patients with actionable reports is attractive in assisting clinical decision making. However, this process requires experienced physicians and significant human labor. Natural language processing (NLP) has shown great potential in big data analytics of medical texts; yet, its application to domain-specific analysis of radiology reports is limited. Objective: The aim of this study is to propose a novel approach in classifying actionable radiology reports of tinnitus patients using bidirectional encoder representations from transformer BERT-based models and evaluate the benefits of in domain pre-training (IDPT) along with a sequence adaptation strategy. Methods: A total of 5864 temporal bone computed tomography(CT) reports are labeled by two experienced radiologists as follows: (1) normal findings without notable lesions; (2) notable lesions but uncorrelated to tinnitus; and (3) at least one lesion considered as potential cause of tinnitus. We then constructed a framework consisting of deep learning (DL) neural networks and self-supervised BERT models. A tinnitus domain-specific corpus is used to pre-train the BERT model to further improve its embedding weights. In addition, we conducted an experiment to evaluate multiple groups of max sequence length settings in BERT to reduce the excessive quantity of calculations. After a comprehensive comparison of all metrics, we determined the most promising approach through the performance comparison of F1-scores and AUC values. Results: In the first experiment, the BERT finetune model achieved a more promising result (AUC-0.868, F1-0.760) compared with that of the Word2Vec-based models(AUC-0.767, F1-0.733) on validation data. In the second experiment, the BERT in-domain pre-training model (AUC-0.948, F1-0.841) performed significantly better than the BERT based model(AUC-0.868, F1-0.760). Additionally, in the variants of BERT fine-tuning models, Mengzi achieved the highest AUC of 0.878 (F1-0.764). Finally, we found that the BERT max-sequence-length of 128 tokens achieved an AUC of 0.866 (F1-0.736), which is almost equal to the BERT max-sequence-length of 512 tokens (AUC-0.868,F1-0.760). Conclusion: In conclusion, we developed a reliable BERT-based framework for tinnitus diagnosis from Chinese radiology reports, along with a sequence adaptation strategy to reduce computational resources while maintaining accuracy. The findings could provide a reference for NLP development in Chinese radiology reports. © 2022, The Author(s).","Artificial intelligence; Bidirectional encoding representation of transformer; Deep learning; Natural language processing; Radiology report","diagnostic imaging; human; natural language processing; radiology; tinnitus; x-ray computed tomography; Humans; Natural Language Processing; Neural Networks, Computer; Radiology; Tinnitus; Tomography, X-Ray Computed",Article,Scopus
"Becker C.D., Kotter E., Fournier L., Martí-Bonmatí L., European Society of Radiology (ESR)","Current practical experience with artificial intelligence in clinical radiology: a survey of the European Society of Radiology",2022,"Insights into Imaging",17,"10.1186/s13244-022-01247-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134082733&doi=10.1186%2fs13244-022-01247-y&partnerID=40&md5=d38448e22a55923f01e506a274f34129","A survey among the members of European Society of Radiology (ESR) was conducted regarding the current practical clinical experience of radiologists with Artificial Intelligence (AI)-powered tools. 690 radiologists completed the survey. Among these were 276 radiologists from 229 institutions in 32 countries who had practical clinical experience with an AI-based algorithm and formed the basis of this study. The respondents with clinical AI experience included 143 radiologists (52%) from academic institutions, 102 radiologists (37%) from regional hospitals, and 31 radiologists (11%) from private practice. The use case scenarios of the AI algorithm were mainly related to diagnostic interpretation, image post-processing, and prioritisation of workflow. Technical difficulties with integration of AI-based tools into the workflow were experienced by only 49 respondents (17.8%). Of 185 radiologists who used AI-based algorithms for diagnostic purposes, 140 (75.7%) considered the results of the algorithms generally reliable. The use of a diagnostic algorithm was mentioned in the report by 64 respondents (34.6%) and disclosed to patients by 32 (17.3%). Only 42 (22.7%) experienced a significant reduction of their workload, whereas 129 (69.8%) found that there was no such effect. Of 111 respondents who used AI-based algorithms for clinical workflow prioritisation, 26 (23.4%) considered algorithms to be very helpful for reducing the workload of the medical staff whereas the others found them only moderately helpful (62.2%) or not helpful at all (14.4%). Only 92 (13.3%) of the total 690 respondents indicated that they had intentions to acquire AI tools. In summary, although the assistance of AI algorithms was found to be reliable for different use case scenarios, the majority of radiologists experienced no reduction of practical clinical workload. © 2022, The Author(s).","Artificial intelligence and workload; Artificial intelligence in imaging; Artificial intelligence in radiology; Professional issues","adult; algorithm; article; artificial intelligence; female; human; major clinical study; male; medical staff; private practice; radiologist; radiology; workflow; workload",Article,Scopus
"Mahoney M.C., McGinty G., Sanchez G.M.F., Pedraza N.R., Usta M.A., Muglia V., da Costa M.B., Ulloa B.E.G., El-Diasty T., AlBastaki U., Amarnath C., Tanomkiat W., Chaiyakum J., Liu S., Park S.H., Aoki S., Varma D., Lawler L., Rockall A., Mendonça R.A., European Society of Radiology (ESR)","Summary of the proceedings of the International Forum 2021: “A more visible radiologist can never be replaced by AI”",2022,"Insights into Imaging",,"10.1186/s13244-022-01182-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134080373&doi=10.1186%2fs13244-022-01182-y&partnerID=40&md5=db252424af2832183e209fd561e55a8c","The ESR International Forum at the ECR 2021 discussed effects of artificial intelligence on the future of radiology and the need for increased visibility of radiologists. The participating societies were invited to submit written reports detailing the current situation in their country or region. The European Society of Radiology (ESR) established the ESR International Forum in order to discuss hot topics in the profession of radiology with non-European radiological partner societies. At the ESR International Forum 2021, different strategies, initiatives and ideas were presented with regard to radiology community’s response to the changes caused by the emerging AI technology. © 2022, The Author(s).","Artificial intelligence; Future; Technology; Visibility","article; artificial intelligence; human; occupation; organization; radiologist; radiology; visibility",Article,Scopus
"Larson N., Nguyen C., Do B., Kaul A., Larson A., Wang S., Wang E., Bultman E., Stevens K., Pai J., Ha A., Boutin R., Fredericson M., Do L., Fang C.","Artificial Intelligence System for Automatic Quantitative Analysis and Radiology Reporting of Leg Length Radiographs",2022,"Journal of Digital Imaging",2,"10.1007/s10278-022-00671-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133612103&doi=10.1007%2fs10278-022-00671-2&partnerID=40&md5=9d60f58f7c95380c4371047bd26b0f7e","Leg length discrepancies are common orthopedic problems with the potential for poor functional outcomes. These are frequently assessed using bilateral leg length radiographs. The objective was to determine whether an artificial intelligence (AI)-based image analysis system can accurately interpret long leg length radiographic images. We built an end-to-end system to analyze leg length radiographs and generate reports like radiologists, which involves measurement of lengths (femur, tibia, entire leg) and angles (mechanical axis and pelvic tilt), describes presence and location of orthopedic hardware, and reports laterality discrepancies. After IRB approval, a dataset of 1,726 extremities (863 images) from consecutive examinations at a tertiary referral center was retrospectively acquired and partitioned into train/validation and test sets. The training set was annotated and used to train a fasterRCNN-ResNet101 object detection convolutional neural network. A second-stage classifier using a EfficientNet-D0 model was trained to recognize the presence or absence of hardware within extracted joint image patches. The system was deployed in a custom web application that generated a preliminary radiology report. Performance of the system was evaluated using a holdout 220 image test set, annotated by 3 musculoskeletal fellowship trained radiologists. At the object detection level, the system demonstrated a recall of 0.98 and precision of 0.96 in detecting anatomic landmarks. Correlation coefficients between radiologist and AI-generated measurements for femur, tibia, and whole-leg lengths were > 0.99, with mean error of < 1%. Correlation coefficients for mechanical axis angle and pelvic tilt were 0.98 and 0.86, respectively, with mean absolute error of < 1°. AI hardware detection demonstrated an accuracy of 99.8%. Automatic quantitative and qualitative analysis of leg length radiographs using deep learning is feasible and holds potential in improving radiologist workflow. © 2022, This is a U.S. Government work and not under copyright protection in the US; foreign copyright protection may apply.","Artificial Intelligence; Deep Learning; Leg Length Discrepancy; Radiography","Convolutional neural networks; Deep learning; Object recognition; Radiation; Radiography; Radiology; Statistical tests; Artificial intelligence systems; Automatic quantitative analysis; Correlation coefficient; Deep learning; Leg length; Leg-length discrepancies; Mechanical axes; Objects detection; Pelvic tilt; Test sets; Object detection; artificial intelligence; human; leg; procedures; radiography; radiology; retrospective study; Artificial Intelligence; Humans; Leg; Radiography; Radiology; Retrospective Studies",Article,Scopus
"Horng H., Steinkamp J., Kahn C.E., Jr., Cook T.S.","Ensemble Approaches to Recognize Protected Health Information in Radiology Reports",2022,"Journal of Digital Imaging",,"10.1007/s10278-022-00673-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132199156&doi=10.1007%2fs10278-022-00673-0&partnerID=40&md5=4187e2bbbb616f9c2b8d456382851845","Natural language processing (NLP) techniques for electronic health records have shown great potential to improve the quality of medical care. The text of radiology reports frequently constitutes a large fraction of EHR data, and can provide valuable information about patients’ diagnoses, medical history, and imaging findings. The lack of a major public repository for radiological reports severely limits the development, testing, and application of new NLP tools. De-identification of protected health information (PHI) presents a major challenge to building such repositories, as many automated tools for de-identification were trained or designed for clinical notes and do not perform sufficiently well to build a public database of radiology reports. We developed and evaluated six ensemble models based on three publically available de-identification tools: MIT de-id, NeuroNER, and Philter. A set of 1023 reports was set aside as the testing partition. Two individuals with medical training annotated the test set for PHI; differences were resolved by consensus. Ensemble methods included simple voting schemes (1-Vote, 2-Votes, and 3-Votes), a decision tree, a naïve Bayesian classifier, and Adaboost boosting. The 1-Vote ensemble achieved recall of 998 / 1043 (95.7%); the 3-Votes ensemble had precision of 1035 / 1043 (99.2%). F1 scores were: 93.4% for the decision tree, 71.2% for the naïve Bayesian classifier, and 87.5% for the boosting method. Basic voting algorithms and machine learning classifiers incorporating the predictions of multiple tools can outperform each tool acting alone in de-identifying radiology reports. Ensemble methods hold substantial potential to improve automated de-identification tools for radiology reports to make such reports more available for research use to improve patient care and outcomes. © 2022, The Author(s) under exclusive licence to Society for Imaging Informatics in Medicine.","De-identification; Ensemble models; Machine learning; Natural language processing; Protected health information (PHI); Reporting","Adaptive boosting; Diagnosis; Machine learning; Medical imaging; Natural language processing systems; Radiation; Radiology; De-identification; Ensemble models; Language processing; Machine-learning; Natural language processing; Natural languages; Protected health information; Protected health informations; Radiology reports; Reporting; Decision trees; adult; algorithm; article; case report; classifier; clinical article; consensus; decision tree; female; human; machine learning; male; medical education; medical information; natural language processing; outcome assessment; patient care; prediction; radiology; recall; Bayes theorem; electronic health record; machine learning; Bayes Theorem; Electronic Health Records; Humans; Machine Learning; Natural Language Processing; Radiology",Article,Scopus
"Becker C.D., Kotter E.","Communicating with patients in the age of online portals—challenges and opportunities on the horizon for radiologists",2022,"Insights into Imaging",3,"10.1186/s13244-022-01222-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129659565&doi=10.1186%2fs13244-022-01222-7&partnerID=40&md5=35ce56e98633d29a4f1d2dd05c2a59b0","The deployment of electronic patient portals increasingly allows patients throughout Europe to consult and share their radiology reports and images securely and timely online. Technical solutions and rules for releasing reports and images on patient portals may differ among institutions, regions and countries, and radiologists should therefore be familiar with the criteria by which reports and images are made available to their patients. Radiologists may also be solicited by patients who wish to discuss complex or critical imaging findings directly with the imaging expert who is responsible for the diagnosis. This emphasises the importance of radiologists’ communication skills as well as appropriate and efficient communication pathways and methods including electronic tools. Radiologists may also have to think about adapting reports as their final product in order to enable both referrers and patients to understand imaging findings. Actionable reports for a medical audience require structured, organ-specific terms and quantitative information, whereas patient-friendly summaries should preferably be based on consumer health language and include explanatory multimedia support or hyperlinks. Owing to the cultural and linguistic diversity in Europe dedicated solutions will require close collaboration between radiologists, patient representatives and software developers; software tools using artificial intelligence and natural language processing could potentially be useful in this context. By engaging actively in the challenges that are associated with increased communication with their patients, radiologists will not only have the opportunity to contribute to patient-centred care, but also to enhance the clinical relevance and the visibility of their profession. © 2022, The Author(s).","Online patient portals; Patient-centred communication; Patient-centred radiology; Patient-friendly radiology report; Professional issues","Article; artificial intelligence; clinical outcome; clinical practice; communication skill; computer assisted tomography; computer language; coronavirus disease 2019; cultural factor; digital imaging and communications in medicine; echography; electronic consultation; fluoroscopy; health care delivery; health care personnel; human; image quality; imaging; language ability; language processing; mammography; nuclear magnetic resonance imaging; online portal; pandemic; patient care; patient satisfaction; perception; personalized medicine; pharmacist; physician; radiography; radiologist; radiology; response evaluation criteria in solid tumors; software; training; validation process",Article,Scopus
"Lim S.S., Phan T.D., Law M., Goh G.S., Moriarty H.K., Lukies M.W., Joseph T., Clements W.","Non-radiologist perception of the use of artificial intelligence (AI) in diagnostic medical imaging reports",2022,"Journal of Medical Imaging and Radiation Oncology",8,"10.1111/1754-9485.13388","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125768581&doi=10.1111%2f1754-9485.13388&partnerID=40&md5=40daa94b9d6a0b9c73c25829054335ee","Introduction: Incorporating artificial intelligence (AI) in diagnostic medical imaging reports has the potential to improve efficiency. Although perception of radiologists, radiographers, medical students and patients on AI use in image reporting has been explored, there is limited literature on non-radiologist clinicians' opinion on this topic. Method: Single-centre online survey targeting non-radiologist medical staff conducted from May to August 2021 at a tertiary referral hospital in Melbourne, Australia. Survey questions revolved around clinicians' level of comfort acting on AI-generated reports with varying levels of radiologist involvement and scan complexity, opinion on medicolegal responsibility for erroneous AI-issued reports and perception of data privacy and security. Results: Eighty-eight responses were collected, including 47.9% of consultants. Non-radiologist clinicians across all seniorities and specialties felt significantly less comfortable acting on AI-issued reports compared with radiologist-issued reports (mean comfort radiologist 6.44/7, mean comfort AI 3.35/7, P < 0.001) but felt equally comfortable with an AI-hybrid model of care (mean comfort hybrid 6.38/7, P = 0.676). Non-radiologist clinicians believed that medicolegal responsibility with errors in AI-issued reports mostly lay with hospitals or health service providers (65.9%) and radiologists (54.5%). Regarding data privacy and security, non-radiologist clinicians felt significantly less comfortable with AI issuing image reports instead of radiologists (P < 0.001). Conclusion: A hybrid AI-generated radiologist-confirmed method of image reporting may be the ideal way of integrating AI into clinical practice based on the perception of our referring non-radiologist medical colleagues. Formal guidelines on medicolegal responsibility and data privacy should be established prior to utilising AI in the clinical setting. © 2022 The Authors. Journal of Medical Imaging and Radiation Oncology published by John Wiley & Sons Australia, Ltd on behalf of Royal Australian and New Zealand College of Radiologists.","AI; artificial intelligence; radiology; report; survey","article; artificial intelligence; Australia; clinical practice; comfort; consultation; controlled study; data privacy; diagnostic imaging; human; human experiment; medical staff; perception; practice guideline; radiologist; radiology; responsibility; security; tertiary care center; diagnostic imaging; education; perception; Artificial Intelligence; Diagnostic Imaging; Humans; Perception; Radiologists; Radiology",Article,Scopus
"Chilanga C.C., Lysdahl K.B.","Ethical impact of suboptimal referrals on delivery of care in radiology department",2022,"Journal of medical ethics",1,"10.1136/medethics-2021-107335","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122454302&doi=10.1136%2fmedethics-2021-107335&partnerID=40&md5=aee511ac4b9909101a1318fa87479065","The referral is the key source of information that enables radiologists and radiographers to provide quality services. However, the frequency of suboptimal referrals is widely reported. This research reviews the literature to illuminate the challenges suboptimal referrals present to the delivery of care in radiology departments. The concept of suboptimal referral includes information, that is; missing, insufficient, inconsistent, misleading, hard to interpret or wrong. The research uses the four ethical principles of non-maleficence, beneficence, Autonomy and Justice as an analytic framework.Suboptimal referrals can cause harm by hindering safe contrast-media administration, proper radiation protection by justification of procedures, and compassionate patient care. Suboptimal referrals also hinder promoting patient benefits from the correct choice of imaging modality and protocol, an optimal performed examination, and an accurate radiology report. Additionally, patient autonomy is compromised from the lack of information needed to facilitate benefit-risk communication. Finally, suboptimal referrals challenge justice based on lack of reasonable patient prioritising and the unfairness caused by unnecessary examinations.These findings illuminate how suboptimal referrals can inhibit good health and well-being for patients in relation to safety, missed opportunities, patient anxiety and dissatisfaction. The ethical challenges identified calls for solutions. Referral-decision support tools and artificial intelligence may improve referral quality, when implemented. Strategies addressing efforts of radiology professionals are inevitable, including gatekeeping, shared decision-making and inter-professional communication; thereby raising awareness of the importance of good referral quality and promoting commitment to ethical professional conduct. © Author(s) (or their employer(s)) 2022. No commercial re-use. See rights and permissions. Published by BMJ.","ethics; health personnel; quality of health care; radiology","artificial intelligence; beneficence; human; interpersonal communication; patient referral; procedures; radiology; Artificial Intelligence; Beneficence; Communication; Humans; Radiology; Referral and Consultation",Article,Scopus
"Wang K., Tan F., Zhu Z., Kong L.","Exploring changes in depression and radiology-related publications research focus: A bibliometrics and content analysis based on natural language processing",2022,"Frontiers in Psychiatry",1,"10.3389/fpsyt.2022.978763","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144014160&doi=10.3389%2ffpsyt.2022.978763&partnerID=40&md5=1fd40352aeffb5d18dbce16809c619cc","Objective: This study aims to construct and use natural language processing and other methods to analyze major depressive disorder (MDD) and radiology studies’ publications in the PubMed database to understand the historical growth, current state, and potential expansion trend. Methods: All MDD radiology studies publications from January 2002 to January 2022 were downloaded from PubMed using R, a statistical computing language. R and the interpretive general-purpose programming language Python were used to extract publication dates, geographic information, and abstracts from each publication’s metadata for bibliometric analysis. The generative statistical algorithm “Latent Dirichlet allocation” (LDA) was applied to identify specific research focus and trends. The unsupervised Leuven algorithm was used to build a network to identify relationships between research focus. Results: A total of 5,566 publications on MDD and radiology research were identified, and there is a rapid upward trend. The top-cited publications were 11,042, and the highly-cited publications focused on improving diagnostic performance and establishing imaging standards. Publications came from 76 countries, with the most from research institutions in the United States and China. Hospitals and radiology departments take the lead in research and have an advantage. The extensive field of study contains 12,058 Medical Subject Heading (MeSH) terms. Based on the LDA algorithm, three areas were identified that have become the focus of research in recent years, “Symptoms and treatment,” “Brain structure and imaging,” and “Comorbidities research.” Conclusion: Latent Dirichlet allocation analysis methods can be well used to analyze many texts and discover recent research trends and focus. In the past 20 years, the research on MDD and radiology has focused on exploring MDD mechanisms, establishing standards, and constructing imaging methods. Recent research focuses are “Symptoms and sleep,” “Brain structure study,” and “functional connectivity.” New progress may be made in studies on MDD complications and the combination of brain structure and metabolism. Copyright © 2022 Wang, Tan, Zhu and Kong.","bibliometric analysis; Latent Dirichlet allocation; machine learning; major depressive disorder; radiology","algorithm; Article; bibliometrics; brain structure and imaging research; brain structure study; China; comorbidities research; content analysis; diagnostic imaging; functional connectivity; hospital; human; imaging; Japan; Latent Dirichlet allocation algorithm; major depression; Medical Subject Headings; natural language processing; nuclear magnetic resonance imaging; pathophysiology; prediction; publication; radiology department; radiology related publication; research; symptoms and sleep research; symptoms and treatment research; United States",Article,Scopus
"Cury R.C., Leipsic J., Abbara S., Achenbach S., Berman D., Bittencourt M., Budoff M., Chinnaiyan K., Choi A.D., Ghoshhajra B., Jacobs J., Koweek L., Lesser J., Maroules C., Rubin G.D., Rybicki F.J., Shaw L.J., Williams M.C., Williamson E., White C.S., Villines T.C., Blankstein R.","CAD-RADS™ 2.0 – 2022 Coronary Artery Disease – Reporting and Data System.: An expert consensus document of the Society of Cardiovascular Computed Tomography (SCCT), the American College of Cardiology (ACC), the American College of Radiology (ACR) and the North America Society of Cardiovascular Imaging (NASCI)",2022,"Journal of the American College of Radiology",9,"10.1016/j.jacr.2022.09.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142504995&doi=10.1016%2fj.jacr.2022.09.012&partnerID=40&md5=fe109521c5a9125289f5ce79feae94ab","Coronary Artery Disease Reporting and Data System (CAD-RADS) was created to standardize reporting system for patients undergoing coronary CT angiography (CCTA) and to guide possible next steps in patient management. The goal of this updated 2022 CAD-RADS 2.0 is to improve the initial reporting system for CCTA by considering new technical developments in Cardiac CT, including data from recent clinical trials and new clinical guidelines. The updated CAD-RADS classification will follow an established framework of stenosis, plaque burden, and modifiers, which will include assessment of lesion-specific ischemia using CT fractional-flow-reserve (CT-FFR) or myocardial CT perfusion (CTP), when performed. Similar to the method used in the original CAD-RADS version, the determinant for stenosis severity classification will be the most severe coronary artery luminal stenosis on a per-patient basis, ranging from CAD-RADS 0 (zero) for absence of any plaque or stenosis to CAD-RADS 5 indicating the presence of at least one totally occluded coronary artery. Given the increasing data supporting the prognostic relevance of coronary plaque burden, this document will provide various methods to estimate and report total plaque burden. The addition of P1 to P4 descriptors are used to denote increasing categories of plaque burden. The main goal of CAD-RADS, which should always be interpreted together with the impression found in the report, remains to facilitate communication of test results with referring physicians along with suggestions for subsequent patient management. In addition, CAD-RADS will continue to provide a framework of standardization that may benefit education, research, peer-review, artificial intelligence development, clinical trial design, population health and quality assurance with the ultimate goal of improving patient care. © 2022 American College of Radiology","CAD-RADS; Coronary artery disease; Coronary CTA; Ischemia; Plaque burden; Report standardization terminology; Reporting and data system; Stenosis severity","Article; clinical trial (topic); computed tomographic angiography; consensus; coronary angiography; coronary artery bypass graft; coronary artery disease reporting and data system; coronary atherosclerosis; coronary stenosis; coronary stenting; diagnostic value; disease severity; disease severity assessment; fractional flow reserve; heart muscle ischemia; human; medical society; myocardial perfusion imaging; patient care; physician; practice guideline; prognosis; vulnerable plaque; artificial intelligence; cardiology; computed tomographic angiography; coronary artery disease; coronary artery obstruction; diagnostic imaging; North America; predictive value; radiology; stenosis, occlusion and obstruction; United States; Artificial Intelligence; Cardiology; Computed Tomography Angiography; Consensus; Constriction, Pathologic; Coronary Artery Disease; Coronary Stenosis; Humans; North America; Predictive Value of Tests; Radiology; United States",Article,Scopus
"López-Úbeda P., Martín-Noguerol T., Juluru K., Luna A.","Natural Language Processing in Radiology: Update on Clinical Applications",2022,"Journal of the American College of Radiology",11,"10.1016/j.jacr.2022.06.016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141455317&doi=10.1016%2fj.jacr.2022.06.016&partnerID=40&md5=88ab44f19a25de8894e424501d78eca1","Radiological reports are a valuable source of information used to guide clinical care and support research. Organizing and managing this content, however, frequently requires several manual curations because of the more common unstructured nature of the reports. However, manual review of these reports for clinical knowledge extraction is costly and time-consuming. Natural language processing (NLP) is a set of methods developed to extract structured meaning from a body of text and can be used to optimize the workflow of health care professionals. Specifically, NLP methods can help radiologists as decision support systems and improve the management of patients’ medical data. In this study, we highlight the opportunities offered by NLP in the field of radiology. A comprehensive review of the most commonly used NLP methods to extract information from radiological reports and the development of tools to improve radiological workflow using this information is presented. Finally, we review the important limitations of these tools and discuss the relevant observations and trends in the application of NLP to radiology that could benefit the field in the future. © 2022 American College of Radiology","Artificial intelligence; clinical decision support; machine learning; natural language processing; radiology domain","adult; article; artificial intelligence; decision support system; human; machine learning; natural language processing; radiologist; radiology; workflow; radiography; research; Humans; Natural Language Processing; Radiography; Radiologists; Radiology; Research Report",Article,Scopus
"Cury R.C., Leipsic J., Abbara S., Achenbach S., Berman D., Bittencourt M., Budoff M., Chinnaiyan K., Choi A.D., Ghoshhajra B., Jacobs J., Koweek L., Lesser J., Maroules C., Rubin G.D., Rybicki F.J., Shaw L.J., Williams M.C., Williamson E., White C.S., Villines T.C., Blankstein R.","CAD-RADS™ 2.0 – 2022 Coronary Artery Disease-Reporting and Data System: An Expert Consensus Document of the Society of Cardiovascular Computed Tomography (SCCT), the American College of Cardiology (ACC), the American College of Radiology (ACR), and the North America Society of Cardiovascular Imaging (NASCI)",2022,"JACC: Cardiovascular Imaging",26,"10.1016/j.jcmg.2022.07.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140807750&doi=10.1016%2fj.jcmg.2022.07.002&partnerID=40&md5=b93e134a7231ce8bd68a47241f08f283","Coronary Artery Disease Reporting and Data System (CAD-RADS) was created to standardize reporting system for patients undergoing coronary CT angiography (CCTA) and to guide possible next steps in patient management. The goal of this updated 2022 CAD-RADS 2.0 is to improve the initial reporting system for CCTA by considering new technical developments in cardiac CT, including data from recent clinical trials and new clinical guidelines. The updated CAD-RADS classification will follow an established framework of stenosis, plaque burden, and modifiers, which will include assessment of lesion-specific ischemia using CT fractional-flow-reserve (CT-FFR) or myocardial CT perfusion (CTP), when performed. Similar to the method used in the original CAD-RADS version, the determinant for stenosis severity classification will be the most severe coronary artery luminal stenosis on a per-patient basis, ranging from CAD-RADS 0 (zero) for absence of any plaque or stenosis to CAD-RADS 5 indicating the presence of at least one totally occluded coronary artery. Given the increasing data supporting the prognostic relevance of coronary plaque burden, this document will provide various methods to estimate and report total plaque burden. The addition of P1 to P4 descriptors are used to denote increasing categories of plaque burden. The main goal of CAD-RADS, which should always be interpreted together with the impression found in the report, remains to facilitate communication of test results with referring physicians along with suggestions for subsequent patient management. In addition, CAD-RADS will continue to provide a framework of standardization that may benefit education, research, peer-review, artificial intelligence development, clinical trial design, population health and quality assurance with the ultimate goal of improving patient care. © 2022 Society of Cardiovascular Computed Tomography","CAD-RADS; coronary artery disease; coronary CTA; ischemia; plaque burden; report standardization terminology; reporting and data system; stenosis severity","Article; atherosclerotic plaque; cardiac imaging; clinical trial (topic); computed tomographic angiography; computer assisted tomography; consensus development; coronary angiography; coronary artery bypass graft; coronary artery calcium score; coronary artery disease reporting and data system; coronary occlusion; coronary stenosis; disease burden; disease severity; disease severity assessment; fractional flow reserve; heart muscle ischemia; human; medical society; myocardial perfusion imaging; patient care; physician; practice guideline; prognosis; quantitative analysis; vulnerable plaque; artificial intelligence; atherosclerotic plaque; cardiology; consensus; coronary artery disease; coronary artery obstruction; diagnostic imaging; predictive value; procedures; radiology; stenosis, occlusion and obstruction; United States; Artificial Intelligence; Cardiology; Computed Tomography Angiography; Consensus; Constriction, Pathologic; Coronary Angiography; Coronary Artery Disease; Coronary Stenosis; Humans; Plaque, Atherosclerotic; Predictive Value of Tests; Radiology; United States",Article,Scopus
"Cury R.C., Leipsic J., Abbara S., Achenbach S., Berman D., Bittencourt M., Budoff M., Chinnaiyan K., Choi A.D., Ghoshhajra B., Jacobs J., Koweek L., Lesser J., Maroules C., Rubin G.D., Rybicki F.J., Shaw L.J., Williams M.C., Williamson E., White C.S., Villines T.C., Blankstein R.","CAD-RADS™ 2.0 - 2022 Coronary Artery Disease-Reporting and Data System: An Expert Consensus Document of the Society of Cardiovascular Computed Tomography (SCCT), the American College of Cardiology (ACC), the American College of Radiology (ACR), and the North America Society of Cardiovascular Imaging (NASCI)",2022,"Journal of Cardiovascular Computed Tomography",40,"10.1016/j.jcct.2022.07.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134741849&doi=10.1016%2fj.jcct.2022.07.002&partnerID=40&md5=a0efb517724cac2ff34c6901dd1f246f","Coronary Artery Disease Reporting and Data System (CAD-RADS) was created to standardize reporting system for patients undergoing coronary CT angiography (CCTA) and to guide possible next steps in patient management. The goal of this updated 2022 CAD-RADS 2.0 is to improve the initial reporting system for CCTA by considering new technical developments in Cardiac CT, including data from recent clinical trials and new clinical guidelines. The updated CAD-RADS classification will follow an established framework of stenosis, plaque burden, and modifiers, which will include assessment of lesion-specific ischemia using CT fractional-flow-reserve (CT-FFR) or myocardial CT perfusion (CTP), when performed. Similar to the method used in the original CAD-RADS version, the determinant for stenosis severity classification will be the most severe coronary artery luminal stenosis on a per-patient basis, ranging from CAD-RADS 0 (zero) for absence of any plaque or stenosis to CAD-RADS 5 indicating the presence of at least one totally occluded coronary artery. Given the increasing data supporting the prognostic relevance of coronary plaque burden, this document will provide various methods to estimate and report total plaque burden. The addition of P1 to P4 descriptors are used to denote increasing categories of plaque burden. The main goal of CAD-RADS, which should always be interpreted together with the impression found in the report, remains to facilitate communication of test results with referring physicians along with suggestions for subsequent patient management. In addition, CAD-RADS will continue to provide a framework of standardization that may benefit education, research, peer-review, artificial intelligence development, clinical trial design, population health and quality assurance with the ultimate goal of improving patient care. © 2022 Society of Cardiovascular Computed Tomography","CAD-RADS; Coronary artery disease; Coronary CTA; Ischemia; Plaque burden; Report standardization terminology; Reporting and data system; Stenosis severity","Article; computed tomographic angiography; consensus; coronary angiography; coronary artery bypass graft; coronary artery disease reporting and data system; coronary occlusion; fractional flow reserve; heart muscle perfusion; human; medical society; vulnerable plaque; artificial intelligence; atherosclerotic plaque; cardiology; coronary artery disease; coronary artery obstruction; diagnostic imaging; practice guideline; predictive value; procedures; radiology; stenosis, occlusion and obstruction; United States; Artificial Intelligence; Cardiology; Computed Tomography Angiography; Consensus; Constriction, Pathologic; Coronary Angiography; Coronary Artery Disease; Coronary Stenosis; Humans; Plaque, Atherosclerotic; Predictive Value of Tests; Radiology; United States",Article,Scopus
"Dewald C.L.A., Balandis A., Becker L.S., Hinrichs J.B., Von Falck C., Wacker F.K., Laser H., Gerbel S., Winther H.B., Apfel-Starke J.","Automated Classification of Free-Text Radiology Reports: Using Different Feature Extraction Methods to Identify Fractures of the Distal Fibula [Automatisierte Klassifizierung von radiologischen Freitext-Befunden: Analyse verschiedener Feature-Extraction-Methoden zur Identifizierung distaler Fibulafrakturen]",2022,"RoFo Fortschritte auf dem Gebiet der Rontgenstrahlen und der Bildgebenden Verfahren",,"10.1055/a-2061-6562","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165777713&doi=10.1055%2fa-2061-6562&partnerID=40&md5=e576b2d5b7e58153457a710dc5a02ef2","Purpose ?Radiology reports mostly contain free-text, which makes it challenging to obtain structured data. Natural language processing (NLP) techniques transform free-text reports into machine-readable document vectors that are important for creating reliable, scalable methods for data analysis. The aim of this study is to classify unstructured radiograph reports according to fractures of the distal fibula and to find the best text mining method. Materials & Methods ?We established a novel German language report dataset: a designated search engine was used to identify radiographs of the ankle and the reports were manually labeled according to fractures of the distal fibula. This data was used to establish a machine learning pipeline, which implemented the text representation methods bag-of-words (BOW), term frequency-inverse document frequency (TF-IDF), principal component analysis (PCA), non-negative matrix factorization (NMF), latent Dirichlet allocation (LDA), and document embedding (doc2vec). The extracted document vectors were used to train neural networks (NN), support vector machines (SVM), and logistic regression (LR) to recognize distal fibula fractures. The results were compared via cross-tabulations of the accuracy (acc) and area under the curve (AUC). Results ?In total, 3268 radiograph reports were included, of which 1076 described a fracture of the distal fibula. Comparison of the text representation methods showed that BOW achieved the best results (AUC?=?0.98; acc?=?0.97), followed by TF-IDF (AUC?=?0.97; acc?=?0.96), NMF (AUC?=?0.93; acc?=?0.92), PCA (AUC?=?0.92; acc?=?0.9), LDA (AUC?=?0.91; acc?=?0.89) and doc2vec (AUC?=?0.9; acc?=?0.88). When comparing the different classifiers, NN (AUC?=?0,91) proved to be superior to SVM (AUC?=?0,87) and LR (AUC?=?0,85). Conclusion ?An automated classification of unstructured reports of radiographs of the ankle can reliably detect findings of fractures of the distal fibula. A particularly suitable feature extraction method is the BOW model. Key Points: ? The aim was to classify unstructured radiograph reports according to distal fibula fractures. Our automated classification system can reliably detect fractures of the distal fibula. A particularly suitable feature extraction method is the BOW model. Citation Format Dewald CL, Balandis A, Becker LS et?al. Automated Classification of Free-Text Radiology Reports: Using Different Feature Extraction Methods to Identify Fractures of the Distal Fibula. Fortschr Röntgenstr 2023; 195: 713?-?719. © 2022 Georg Thieme Verlag. All rights reserved.","ankle; Automatic Classification; Data Set; Fibula Fracture; Natural Language Processing; Text Mining","ankle radiography; Article; controlled study; disease classification; distal fibula fracture; feature extraction; human; machine learning; retrospective study; algorithm; diagnostic imaging; fibula; natural language processing; procedures; radiography; radiology; Algorithms; Fibula; Machine Learning; Natural Language Processing; Radiography; Radiology",Article,Scopus
"Nguyen T., Vo T.M., Nguyen T.V., Pham H.H., Nguyen H.Q.","Learning to diagnose common thorax diseases on chest radiographs from radiology reports in Vietnamese",2022,"PLoS ONE",,"10.1371/journal.pone.0276545","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140943149&doi=10.1371%2fjournal.pone.0276545&partnerID=40&md5=b873e8ca04626a66d3a4f6057b7161b1","Deep learning, in recent times, has made remarkable strides when it comes to impressive performance for many tasks, including medical image processing. One of the contributing factors to these advancements is the emergence of large medical image datasets. However, it is exceedingly expensive and time-consuming to construct a large and trustworthy medical dataset; hence, there has been multiple research leveraging medical reports to automatically extract labels for data. The majority of this labor, however, is performed in English. In this work, we propose a data collecting and annotation pipeline that extracts information from Vietnamese radiology reports to provide accurate labels for chest X-ray (CXR) images. This can benefit Vietnamese radiologists and clinicians by annotating data that closely match their endemic diagnosis categories which may vary from country to country. To assess the efficacy of the proposed labeling technique, we built a CXR dataset containing 9,752 studies and evaluated our pipeline using a subset of this dataset. With an F1-score of at least 0.9923, the evaluation demonstrates that our labeling tool performs precisely and consistently across all classes. After building the dataset, we train deep learning models that leverage knowledge transferred from large public CXR datasets. We employ a variety of loss functions to overcome the curse of imbalanced multi-label datasets and conduct experiments with various model architectures to select the one that delivers the best performance. Our best model (CheXpert-pretrained EfficientNet-B2) yields an F1-score of 0.6989 (95% CI 0.6740, 0.7240), AUC of 0.7912, sensitivity of 0.7064 and specificity of 0.8760 for the abnormal diagnosis in general. Finally, we demonstrate that our coarse classification (based on five specific locations of abnormalities) yields comparable results to fine classification (twelve pathologies) on the benchmark CheXpert dataset for general anomaly detection while delivering better performance in terms of the average performance of all classes. Copyright: © 2022 Nguyen et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,"area under the curve; Article; atelectasis; benchmarking; cardiomegaly; classifier; clinician; data extraction; deep learning; diagnostic test accuracy study; disease classification; human; image analysis; image processing; information processing; lung consolidation; lung edema; lung lesion; medical research; pleura effusion; pneumonia; pneumothorax; radiologist; radiology; receiver operating characteristic; retrospective study; scoring system; sensitivity and specificity; thoracic fracture; thorax disease; thorax radiography; Vietnamese; Asian; diagnostic imaging; procedures; thorax; thorax radiography; Asians; Deep Learning; Humans; Radiography, Thoracic; Radiology; Thorax",Article,Scopus
"Cury R.C., Leipsic J., Abbara S., Achenbach S., Berman D., Bittencourt M., Budoff M., Chinnaiyan K., Choi A.D., Ghoshhajra B., Jacobs J., Koweek L., Lesser J., Maroules C., Rubin G.D., Rybicki F.J., Shaw L.J., Williams M.C., Williamson E., White C.S., Villines T.C., Blankstein R.","CAD-RADS™ 2.0 – 2022 Coronary Artery Disease – Reporting and Data System An Expert Consensus Document of the Society of Cardiovascular Computed Tomography (SCCT), the American College of Cardiology (ACC), the American College of Radiology (ACR) and the North America Society of Cardiovascular Imaging (NASCI)",2022,"Radiology: Cardiothoracic Imaging",5,"10.1148/ryct.220183","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140883033&doi=10.1148%2fryct.220183&partnerID=40&md5=b13962f4ca677d85a180fd28663ec007","Coronary Artery Disease Reporting and Data System (CAD-RADS) was created to standardize reporting system for patients undergoing coronary CT angiography (CCTA) and to guide possible next steps in patient management. The goal of this updated 2022 CAD-RADS 2.0 is to improve the initial reporting system for CCTA by considering new technical developments in Cardiac CT, including data from recent clinical trials and new clinical guidelines. The updated CAD-RADS classification will follow an established framework of stenosis, plaque burden, and modifiers, which will include assessment of lesion-specific ischemia using CT fractional-flow-reserve (CT-FFR) or myocardial CT perfusion (CTP), when performed. Similar to the method used in the original CAD-RADS version, the determinant for stenosis severity classification will be the most severe coronary artery luminal stenosis on a per-patient basis, ranging from CAD-RADS 0 (zero) for absence of any plaque or stenosis to CAD-RADS 5 indicating the presence of at least one totally oc-cluded coronary artery. Given the increasing data supporting the prognostic relevance of coronary plaque burden, this document will provide various methods to estimate and report total plaque burden. The addition of P1 to P4 descriptors are used to denote increasing categories of plaque burden. The main goal of CAD-RADS, which should always be interpreted together with the impression found in the report, remains to facilitate communication of test results with referring physicians along with suggestions for subsequent patient management. In addition, CAD-RADS will continue to provide a framework of standardization that may benefit education, research, peer-review, artificial intelligence development, clinical trial design, population health and quality assurance with the ultimate goal of improving patient care. © 2022 Society of Cardiovascular Computed Tomography.","CAD-RADS; Coronary Artery Disease; Coronary CTA; Ischemia; Plaque Burden; Report Standardization Termi-nology; Reporting and Data System; Stenosis Severity","antiangina pectoris agent; angina pectoris; Article; artificial intelligence; cardiac imaging; computed tomographic angiography; computer assisted tomography; coronary angiography; coronary artery aneurysm; coronary artery calcium score; coronary artery disease; coronary artery disease reporting and data system; coronary occlusion; heart infarction; human; patient care; population health; positron emission tomography; priority journal; publication; reporting and data system; thorax pain",Article,Scopus
"Olthof A.W., van Ooijen P.M.A., Cornelissen L.J.","The natural language processing of radiology requests and reports of chest imaging: Comparing five transformer models’ multilabel classification and a proof-of-concept study",2022,"Health Informatics Journal",,"10.1177/14604582221131198","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140144285&doi=10.1177%2f14604582221131198&partnerID=40&md5=20d49206446ef2916f19e673901f2f43","Background: Radiology requests and reports contain valuable information about diagnostic findings and indications, and transformer-based language models are promising for more accurate text classification. Methods: In a retrospective study, 2256 radiologist-annotated radiology requests (8 classes) and reports (10 classes) were divided into training and testing datasets (90% and 10%, respectively) and used to train 32 models. Performance metrics were compared by model type (LSTM, Bertje, RobBERT, BERT-clinical, BERT-multilingual, BERT-base), text length, data prevalence, and training strategy. The best models were used to predict the remaining 40,873 cases’ categories of the datasets of requests and reports. Results: The RobBERT model performed the best after 4000 training iterations, resulting in AUC values ranging from 0.808 [95% CI (0.757–0.859)] to 0.976 [95% CI (0.956–0.996)] for the requests and 0.746 [95% CI (0.689–0.802)] to 1.0 [95% CI (1.0–1.0)] for the reports. The AUC for the classification of normal reports was 0.95 [95% CI (0.922–0.979)]. The predicted data demonstrated variability of both diagnostic yield for various request classes and request patterns related to COVID-19 hospital admission data. Conclusion: Transformer-based natural language processing is feasible for the multilabel classification of chest imaging request and report items. Diagnostic yield varies with the information in the requests. © The Author(s) 2022.","chest imaging; data mining; machine learning; natural language processing; radiology","diagnostic imaging; human; natural language processing; radiology; research; retrospective study; COVID-19; Humans; Natural Language Processing; Radiology; Research Report; Retrospective Studies",Article,Scopus
"Paul T., Islam H., Singh N., Jampani Y., Kotapati T.V.P., Tautam P.A., Rana M.K.Z., Mandhadi V., Sharma V., Barnes M., Hammer R.D., Mosa A.S.M.","Utility of Features in a Natural-Language-Processing-Based Clinical De-Identification Model Using Radiology Reports for Advanced NSCLC Patients",2022,"Applied Sciences (Switzerland)",,"10.3390/app12199976","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139968664&doi=10.3390%2fapp12199976&partnerID=40&md5=38131416308afdb381013eae4e98f6a0","The de-identification of clinical reports is essential to protect the confidentiality of patients. The natural-language-processing-based named entity recognition (NER) model is a widely used technique of automatic clinical de-identification. The performance of such a machine learning model relies largely on the proper selection of features. The objective of this study was to investigate the utility of various features in a conditional-random-field (CRF)-based NER model. Natural language processing (NLP) toolkits were used to annotate the protected health information (PHI) from a total of 10,239 radiology reports that were divided into seven types. Multiple features were extracted by the toolkit and the NER models were built using these features and their combinations. A total of 10 features were extracted and the performance of the models was evaluated based on their precision, recall, and F1-score. The best-performing features were n-gram, prefix-suffix, word embedding, and word shape. These features outperformed others across all types of reports. The dataset we used was large in volume and divided into multiple types of reports. Such a diverse dataset made sure that the results were not subject to a small number of structured texts from where a machine learning model can easily learn the features. The manual de-identification of large-scale clinical reports is impractical. This study helps to identify the best-performing features for building an NER model for automatic de-identification from a wide array of features mentioned in the literature. © 2022 by the authors.","conditional random field (CRF); de-identification; named entity recognition (NER); natural language processing (NLP); protected health information",,Article,Scopus
"Krishnaraj A., Cook T.","Immediate Radiology Report Release to Patients: Counterpoint—Could We Be Doing More Harm Than Good?",2022,"American Journal of Roentgenology",1,"10.2214/AJR.22.27682","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138493812&doi=10.2214%2fAJR.22.27682&partnerID=40&md5=963b38a59d8d24e03b6f094ad7952252",[No abstract available],,"access to information; Article; diagnostic radiologist; family centered care; human; information processing; information retrieval; medical record; nuclear magnetic resonance imaging; patient care; patient information; radiologist; radiology; radiology report; shared decision making; teleconsultation; Humans; Radiology",Article,Scopus
"To M.-S., Lu L., Tran M., Chong C.","Preferential reporting of significant p-values in radiology journal abstracts",2022,"Clinical Radiology",1,"10.1016/j.crad.2022.05.025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133649773&doi=10.1016%2fj.crad.2022.05.025&partnerID=40&md5=4f6b8fa0c70b521ec64c706ba89ea5e0","AIM: To assess the prevalence of publication bias in the radiology literature, data-mining techniques were used to extract p-values in abstracts published in key radiology journals over the past 20 years. MATERIALS AND METHODS: A total of 34,699 abstracts published in Radiology, Investigative Radiology, European Radiology, American Journal of Roentgenology, and American Journal of Neuroradiology published between January 2000 and December 2019 were included in the analysis. Automated text mining using regular expressions was used to mine abstracts for p-values. RESULTS: The text mining algorithm detected 43,489 p-values, the majority (82.4%) of which were reported as “significant”, i.e., p<0.05. There has also been an increased propensity to report more p-values over time. The distribution of p-values showed a step change at the conventional significance threshold of 0.05. The odds ratio of a “significant” p-value being reported in the abstract compared to the full text was calculated to be 2.52 (95% confidence interval 1.78–3.58; p<0.001). Taken together, these results provide strong evidence for selective reporting of significant p-values in abstracts. CONCLUSION: Statistically significant p-values are preferentially reported in radiology journal abstracts. © 2022 The Royal College of Radiologists",,"algorithm; article; controlled study; data mining; mining; neuroradiology; prevalence; publication bias; radiology; human; publishing; United States; Humans; Publication Bias; Radiology; United States",Article,Scopus
"McGrath A.L., Dodelzon K., Awan O.A., Said N., Bhargava P.","Optimizing radiologist productivity and efficiency: Work smarter, not harder",2022,"European Journal of Radiology",8,"10.1016/j.ejrad.2021.110131","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122635777&doi=10.1016%2fj.ejrad.2021.110131&partnerID=40&md5=ae9a23469012640c81779a75e32f5920","Radiologists’ personal productivity and efficiency are critically important for both improving patient outcomes and protecting clinician well-being. There are several solutions that individuals can implement to improve personal productivity and efficiency in the radiology workroom. Strategies include understanding the psychology behind productivity, using personal productivity methodologies to accomplish daily tasks, and learning to modulate stress to optimize performance. Institutional infrastructure requirements include a robust departmental commitment to information technology and informatics, including universal log-in systems, internal websites, and dashboards. The workstation itself can be optimized by utilizing hanging protocols, customized keyboard shortcuts, hotkeys, advanced scripts, gaming mice, and other input devices. Personal devices like smartphones can be harnessed to maximize productivity by using online storage applications and radiology-specific applications to augment knowledge. Reading room layouts must be designed to minimize interruptions and workstations must consider ergonomics to prevent fatigue and strain. High-efficiency teams also need to be created to allow radiologists to delegate non-clinical tasks to reduce administrative burdens. Lastly, continued advances in artificial intelligence including the use of smart report templates will lead to substantial gains in radiologists’ productivity and efficiency. © 2021 Elsevier B.V.","Automation; Efficiency; Informatics; Productivity; Radiology; Workflow","Article; artificial intelligence; clinical protocol; data system; ergonomics; human; information processing; job stress; production efficiency; radiologist; task performance; work environment; productivity; radiologist; radiology; radiology information system; Artificial Intelligence; Efficiency; Humans; Radiologists; Radiology; Radiology Information Systems",Article,Scopus
"Rouzrokh P., Khosravi B., Faghani S., Moassefi M., Garcia D.V.V., Singh Y., Zhang K., Conte G.M., Erickson B.J.","Mitigating Bias in Radiology Machine Learning: 1. Data Handling",2022,"Radiology: Artificial Intelligence",24,"10.1148/ryai.210290","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139164638&doi=10.1148%2fryai.210290&partnerID=40&md5=8c56534ac9f13ea5eb9431a1fdb48265","Minimizing bias is critical to adoption and implementation of machine learning (ML) in clinical practice. Systematic mathematical biases produce consistent and reproducible differences between the observed and expected performance of ML systems, resulting in suboptimal performance. Such biases can be traced back to various phases of ML development: data handling, model development, and performance evaluation. This report presents 12 suboptimal practices during data handling of an ML study, explains how those practices can lead to biases, and describes what may be done to mitigate them. Authors employ an arbitrary and simplified framework that splits ML data handling into four steps: data collection, data investigation, data splitting, and feature engineering. Examples from the available research literature are provided. A Google Colaboratory Jupyter notebook includes code examples to demonstrate the sub-optimal practices and steps to prevent them. © RSNA, 2022.","Bias; Computer-aided Diagnosis (CAD); Convolu-tional Neural Network (CNN); Data Handling; Deep Learning; Machine Learning","algorithm; Article; artificial intelligence; back propagation; conceptual framework; coronavirus disease 2019; cross validation; data investigation; data splitting; digital imaging and communications in medicine; electronic health record; exploratory data analysis; feature scaling; feature engineering; generalizability; health care planning; health care policy; human; hyperparameters; image reconstruction; interview; machine learning; multivariate analysis; normal distribution; nuclear magnetic resonance imaging; performance; practice guideline; probability; publication bias; radiology; reliability; segmentation algorithm; standardization; thorax radiography; total hip replacement; training",Article,Scopus
"Faghani S., Khosravi B., Zhang K., Moassefi M., Jagtap J.M., Nugen F., Vahdati S., Kuanar S.P., Rassoulinejad-Mousavi S.M., Singh Y., Vera Garcia D.V., Rouzrokh P., Erickson B.J.","Mitigating Bias in Radiology Machine Learning: 3. Performance Metrics",2022,"Radiology: Artificial Intelligence",16,"10.1148/ryai.220061","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139163075&doi=10.1148%2fryai.220061&partnerID=40&md5=c1b84e3a7addd98f14a283f4bb9002b7","The increasing use of machine learning (ML) algorithms in clinical settings raises concerns about bias in ML models. Bias can arise at any step of ML creation, including data handling, model development, and performance evaluation. Potential biases in the ML model can be minimized by implementing these steps correctly. This report focuses on performance evaluation and discusses model fitness, as well as a set of performance evaluation toolboxes: namely, performance metrics, performance interpretation maps, and uncertainty quantification. By discussing the strengths and limitations of each toolbox, our report highlights strategies and considerations to mitigate and detect biases during performance evaluations of radiology artificial intelligence models. © RSNA, 2022.","Convolutional Neural Network (CNN); Diagnosis; Segmentation","article; artificial intelligence; convolutional neural network; machine learning; performance indicator; radiology; uncertainty",Article,Scopus
"Zhang K., Khosravi B., Vahdati S., Faghani S., Nugen F., Rassoulinejad-Mousavi S.M., Moassefi M., Jagtap J.M.M., Singh Y., Rouzrokh P., Erickson B.J.","Mitigating Bias in Radiology Machine Learning: 2. Model Development",2022,"Radiology: Artificial Intelligence",14,"10.1148/ryai.220010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139096480&doi=10.1148%2fryai.220010&partnerID=40&md5=f0d929e94ac69be3cfd93e7d07c7a905","There are increasing concerns about the bias and fairness of artificial intelligence (AI) models as they are put into clinical practice. Among the steps for implementing machine learning tools into clinical workflow, model development is an important stage where different types of biases can occur. This report focuses on four aspects of model development where such bias may arise: data augmentation, model and loss function, optimizers, and transfer learning. This report emphasizes appropriate considerations and practices that can mitigate biases in radiology AI studies. © RSNA, 2022.","Bias; Deep Learning; Machine Learning; Model; Radiology","article; artificial intelligence; clinical practice; deep learning; loss of function mutation; machine learning; radiology; transfer of learning; workflow",Article,Scopus
"Fink M.A., Kades K., Bischoff A., Moll M., Schnell M., Küchler M., Köhler G., Sellner J., Heussel C.P., Kauczor H.-U., Schlemmer H.-P., Maier-Hein K., Weber T.F., Kleesiek J.","Deep Learning–based Assessment of Oncologic Outcomes from Natural Language Processing of Structured Radiology Reports",2022,"Radiology: Artificial Intelligence",11,"10.1148/ryai.220055","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139095853&doi=10.1148%2fryai.220055&partnerID=40&md5=24a572a313aa84e90bd6388565162132","Purpose: To train a deep natural language processing (NLP) model, using data mined structured oncology reports (SOR), for rapid tumor response category (TRC) classification from free-text oncology reports (FTOR) and to compare its performance with human readers and conventional NLP algorithms. Materials and Methods: In this retrospective study, databases of three independent radiology departments were queried for SOR and FTOR dated from March 2018 to August 2021. An automated data mining and curation pipeline was developed to extract Response Evaluation Criteria in Solid Tumors–related TRCs for SOR for ground truth definition. The deep NLP bidirectional encoder represen-tations from transformers (BERT) model and three feature-rich algorithms were trained on SOR to predict TRCs in FTOR. Models’ F1 scores were compared against scores of radiologists, medical students, and radiology technologist students. Lexical and semantic analyses were conducted to investigate human and model performance on FTOR. Results: Oncologic findings and TRCs were accurately mined from 9653 of 12 833 (75.2%) queried SOR, yielding oncology reports from 10 455 patients (mean age, 60 years ± 14 [SD]; 5303 women) who met inclusion criteria. On 802 FTOR in the test set, BERT achieved better TRC classification results (F1, 0.70; 95% CI: 0.68, 0.73) than the best-performing reference linear support vector classifier (F1, 0.63; 95% CI: 0.61, 0.66) and technologist students (F1, 0.65; 95% CI: 0.63, 0.67), had similar performance to medical students (F1, 0.73; 95% CI: 0.72, 0.75), but was inferior to radiologists (F1, 0.79; 95% CI: 0.78, 0.81). Lexical complexity and semantic ambiguities in FTOR influenced human and model performance, revealing maximum F1 score drops of −0.17 and −0.19, respectively. Conclusion: The developed deep NLP model reached the performance level of medical students but not radiologists in curating oncologic outcomes from radiology FTOR. © RSNA, 2022.","Comparative Studies; Computer Applications–Detection/Diagnosis; Decision Analysis; Experimental Investigations; Neural Networks; Observer Performance; Oncology; Outcomes Analysis; Research Design; Staging; Tumor Response","adult; algorithm; Article; artificial neural network; bidirectional encoder representations from transformer; clinical assessment; clinical decision support system; comparative study; data mining; deep learning; female; free text oncology report; human; machine learning; major clinical study; medical student; middle aged; natural language processing; outcome assessment; pipeline; radiological technologist; radiologist; radiology department; response evaluation criteria in solid tumors; retrospective study; structured oncology report; support vector machine; tertiary care center; tumor response category",Article,Scopus
"Raman A.G., Jones C., Weiss C.R.","Machine Learning for Hepatocellular Carcinoma Segmentation at MRI: Radiology in Training",2022,"Radiology",1,"10.1148/radiol.212386","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137009016&doi=10.1148%2fradiol.212386&partnerID=40&md5=d9155582e586e5ce9e202684c8836b74","A 68-year-old woman with a history of hepatocellular carcinoma underwent conventional transarterial chemoembolization. Manual tumor segmentation on images, which can be used to assess disease progression, is time consuming and may suffer from interobserver reliability issues. The authors present a how-to guide to develop machine learning algorithms for fully automatic segmentation of hepatocellular carcinoma and other tumors for lesion tracking over time. © RSNA, 2022.",,"alpha fetoprotein; amlodipine besylate; calcium carbonate; colecalciferol; doxorubicin; lenvatinib; yttrium 90; abdominal discomfort; aged; Article; blood analysis; cancer growth; case report; chemoembolization; clinical article; clinical feature; clinical outcome; computer assisted tomography; female; follow up; human; human tissue; image segmentation; liver cell carcinoma; lung metastasis; machine learning; medical history; nuclear magnetic resonance imaging; primary medical care; radioembolization; tumor localization; ultrasound guided fine needle aspiration; chemoembolization; diagnostic imaging; liver cell carcinoma; liver tumor; machine learning; nuclear magnetic resonance imaging; pathology; procedures; radiology; reproducibility; Aged; Carcinoma, Hepatocellular; Chemoembolization, Therapeutic; Female; Humans; Liver Neoplasms; Machine Learning; Magnetic Resonance Imaging; Radiology; Reproducibility of Results",Article,Scopus
"Cheng P.M.","Bigram frequency analysis for detection of radiology report errors",2022,"Clinical Imaging",,"10.1016/j.clinimag.2022.06.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132858443&doi=10.1016%2fj.clinimag.2022.06.010&partnerID=40&md5=9374dff57a4bd25629afeba39ed5ed26","Purpose: This pilot study evaluates the utility of analyzing bigram frequencies for detecting radiology report errors. Methods: A corpus of 48,050 CT reports was used to enumerate the frequency of each bigram (FAB), and the expected frequency of each bigram in the corpus based on the constituent unigram frequencies (PAB). A test set consisted of a separate random sample of 200 radiology reports dictated by attendings for CT scans of the abdomen in 2019, as well as a random sample of 200 radiology reports for CT scans of the abdomen dictated in 2019 by 52 different residents or fellows prior to editing by the signing attendings. Bigrams in the test reports that occurred either rarely or not at all in the corpus were flagged for manual review by an abdominal radiologist. Findings: Of 682 n-grams flagged in attending reports, 11.6% were true errors, while of 1378 n-grams flagged in trainee reports, 7.9% were true errors. The largest group of flagged n-grams in both test sets involved bigrams that did not appear in the corpus, but whose constituent words did appear in the corpus. Subsets of 50 attending and 50 resident reports were manually reviewed, revealing that the flagging procedure had a sensitivity for errors of 58% (22/38) in the attending reports and 97% (31/32) in the resident reports. Conclusion: Bigram frequency analysis may be of practical value in reviewing radiology reports for errors. Further methodological refinement to improve the positive predictive value of error detection is required. © 2022 Elsevier Inc.","Computed tomography; Medical errors; Natural language processing; Radiology reports","Computational linguistics; Error detection; Natural language processing systems; Radiation; Radiology; Bigrams; Computed tomography; Frequency Analysis; Language processing; Medical errors; N-grams; Natural language processing; Natural languages; Radiology reports; Test sets; Computerized tomography; abdomen; adult; article; computer assisted tomography; controlled study; diagnostic test accuracy study; frequency analysis; human; human tissue; medical error; natural language processing; predictive value; radiologist; radiology; random sample; resident; x-ray computed tomography; diagnostic error; pilot study; prevention and control; Diagnostic Errors; Humans; Pilot Projects; Radiologists; Radiology; Tomography, X-Ray Computed",Article,Scopus
"Hallinan J.T.P.D., Feng M., Ng D., Sia S.Y., Tiong V.T.Y., Jagmohan P., Makmur A., Thian Y.L.","Detection of Pneumothorax with Deep Learning Models: Learning From Radiologist Labels vs Natural Language Processing Model Generated Labels",2022,"Academic Radiology",3,"10.1016/j.acra.2021.09.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116871988&doi=10.1016%2fj.acra.2021.09.013&partnerID=40&md5=5dfc735c2d86d1a508bc875300fab43f","Rationale and Objectives: To compare the performance of pneumothorax deep learning detection models trained with radiologist versus natural language processing (NLP) labels on the NIH ChestX-ray14 dataset. Materials and Methods: The ChestX-ray14 dataset consisted of 112,120 frontal chest radiographs with 5302 positive and 106, 818 negative labels for pneumothorax using NLP (dataset A). All 112,120 radiographs were also inspected by 4 radiologists leaving a visually confirmed set of 5,138 positive and 104,751 negative for pneumothorax (dataset B). Datasets A and B were used independently to train 3 convolutional neural network (CNN) architectures (ResNet-50, DenseNet-121 and EfficientNetB3). All models' area under the receiver operating characteristic curve (AUC) were evaluated with the official NIH test set and an external test set of 525 chest radiographs from our emergency department. Results: There were significantly higher AUCs on the NIH internal test set for CNN models trained with radiologist vs NLP labels across all architectures. AUCs for the NLP/radiologist-label models were 0.838 (95%CI:0.830, 0.846)/0.881 (95%CI:0.873,0.887) for ResNet-50 (p = 0.034), 0.839 (95%CI:0.831,0.847)/0.880 (95%CI:0.873,0.887) for DenseNet-121, and 0.869 (95%CI: 0.863,0.876)/0.943 (95%CI: 0.939,0.946) for EfficientNetB3 (p ≤0.001). Evaluation with the external test set also showed higher AUCs (p <0.001) for the CNN models trained with radiologist versus NLP labels across all architectures. The AUCs for the NLP/radiologist-label models were 0.686 (95%CI:0.632,0.740)/0.806 (95%CI:0.758,0.854) for ResNet-50, 0.736 (95%CI:0.686, 0.787)/0.871 (95%CI:0.830,0.912) for DenseNet-121, and 0.822 (95%CI: 0.775,0.868)/0.915 (95%CI: 0.882,0.948) for EfficientNetB3. Conclusion: We demonstrated improved performance and generalizability of pneumothorax detection deep learning models trained with radiologist labels compared to models trained with NLP labels. © 2021 The Association of University Radiologists","Computer; deep learning; Natural Language Processing (NLP); Neural Networks; Pneumothorax; Radiography; Thoracic","Article; controlled study; convolutional neural network; deep learning; emergency ward; entropy; female; human; image analysis; male; natural language processing; pneumothorax; radiodiagnosis; radiologist; residual neural network; thorax radiography; diagnostic imaging; natural language processing; pneumothorax; radiologist; retrospective study; thorax radiography; Deep Learning; Humans; Natural Language Processing; Pneumothorax; Radiography, Thoracic; Radiologists; Retrospective Studies",Article,Scopus
"Panny A., Hegde H., Glurich I., Scannapieco F.A., Vedre J.G., Vanwormer J.J., Miecznikowski J., Acharya A.","A Methodological Approach to Validate Pneumonia Encounters from Radiology Reports Using Natural Language Processing",2022,"Methods of Information in Medicine",1,"10.1055/a-1817-7008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137008369&doi=10.1055%2fa-1817-7008&partnerID=40&md5=4adbddecc1cb6fd6b5febe367ef889cf","Introduction Pneumonia is caused by microbes that establish an infectious process in the lungs. The gold standard for pneumonia diagnosis is radiologist-documented pneumonia-related features in radiology notes that are captured in electronic health records in an unstructured format. Objective The study objective was to develop a methodological approach for assessing validity of a pneumonia diagnosis based on identifying presence or absence of key radiographic features in radiology reports with subsequent rendering of diagnostic decisions into a structured format. Methods A pneumonia-specific natural language processing (NLP) pipeline was strategically developed applying Clinical Text Analysis and Knowledge Extraction System (cTAKES) to validate pneumonia diagnoses following development of a pneumonia feature-specific lexicon. Radiographic reports of study-eligible subjects identified by International Classification of Diseases (ICD) codes were parsed through the NLP pipeline. Classification rules were developed to assign each pneumonia episode into one of three categories: positive, negative, or not classified: requires manual review based on tagged concepts that support or refute diagnostic codes. Results A total of 91,998 pneumonia episodes diagnosed in 65,904 patients were retrieved retrospectively. Approximately 89% (81,707/91,998) of the total pneumonia episodes were documented by 225,893 chest X-ray reports. NLP classified and validated 33% (26,800/81,707) of pneumonia episodes classified as Pneumonia-positive, 19% as (15401/81,707) as Pneumonia-negative, and 48% (39,209/81,707) as episode classification pending further manual review. NLP pipeline performance metrics included accuracy (76.3%), sensitivity (88%), and specificity (75%). Conclusion The pneumonia-specific NLP pipeline exhibited good performance comparable to other pneumonia-specific NLP systems developed to date. © 2022 Georg Thieme Verlag. All rights reserved.","knowledge bases; natural language processing; pneumonia","diagnostic imaging; electronic health record; human; natural language processing; pneumonia; radiology; retrospective study; Electronic Health Records; Humans; Natural Language Processing; Pneumonia; Radiology; Retrospective Studies",Article,Scopus
"Yang S., Wu X., Ge S., Zhou S.K., Xiao L.","Knowledge matters: Chest radiology report generation with general and specific knowledge",2022,"Medical Image Analysis",12,"10.1016/j.media.2022.102510","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132349199&doi=10.1016%2fj.media.2022.102510&partnerID=40&md5=f67d680c5f31f03dc725ae89de90313c","Automatic chest radiology report generation is critical in clinics which can relieve experienced radiologists from the heavy workload and remind inexperienced radiologists of misdiagnosis or missed diagnose. Existing approaches mainly formulate chest radiology report generation as an image captioning task and adopt the encoder-decoder framework. However, in the medical domain, such pure data-driven approaches suffer from the following problems: 1) visual and textual bias problem; 2) lack of expert knowledge. In this paper, we propose a knowledge-enhanced radiology report generation approach introduces two types of medical knowledge: 1) General knowledge, which is input independent and provides the broad knowledge for report generation; 2) Specific knowledge, which is input dependent and provides the fine-grained knowledge for chest X-ray report generation. To fully utilize both the general and specific knowledge, we also propose a knowledge-enhanced multi-head attention mechanism. By merging the visual features of the radiology image with general knowledge and specific knowledge, the proposed model can improve the quality of generated reports. The experimental results on the publicly available IU-Xray dataset show that the proposed knowledge-enhanced approach outperforms state-of-the-art methods in almost all metrics. And the results of MIMIC-CXR dataset show that the proposed knowledge-enhanced approach is on par with state-of-the-art methods. Ablation studies also demonstrate that both general and specific knowledge can help to improve the performance of chest radiology report generation. © 2022 The Author(s)","Chest radiology report generation; Knowledge graph; Multi-head attention","Image enhancement; Knowledge graph; Medical problems; Radiation; Chest radiology report generation; General knowledge; Heavy workloads; Image captioning; Knowledge graphs; Multi-head attention; Radiology reports; Report generation; Specific knowledge; State-of-the-art methods; Radiology; article; attention; human; thorax radiography; algorithm; diagnostic error; radiography; radiology; X ray; Algorithms; Diagnostic Errors; Humans; Radiography; Radiology; X-Rays",Article,Scopus
"Dipnall J.F., Lu J., Gabbe B.J., Cosic F., Edwards E., Page R., Du L.","Comparison of state-of-the-art machine and deep learning algorithms to classify proximal humeral fractures using radiology text",2022,"European Journal of Radiology",2,"10.1016/j.ejrad.2022.110366","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130608922&doi=10.1016%2fj.ejrad.2022.110366&partnerID=40&md5=9881fb029cc4842ab1e8c2a53a554e31","Introduction: Proximal humeral fractures account for a significant proportion of all fractures. Detailed accurate classification of the type and severity of the fracture is a key component of clinical decision making, treatment and plays an important role in orthopaedic trauma research. This research aimed to assess the performance of Machine Learning (ML) multiclass classification algorithms to classify proximal humeral fractures using radiology text data. Materials and Methods: Data from adult (16 + years) patients admitted to a major trauma centre for management of their proximal humerus fracture from January 2010 to January 2019 were used (1,324). Six input text datasets were used for classification: X-ray and/or CT scan reports (primary) and concatenation of patient age and/or patient sex. One of seven Neer class labels were classified. Models were evaluated using accuracy, recall, precision, F1, and One-versus-rest scores. Results: A number of statistical ML algorithms performed acceptably and one of the BERT models, exhibiting good accuracy of 61% and an excellent one-versus-rest score above 0.8. The highest precision, recall and F1 scores were 50%, 39% and 39% respectively, being considered reasonable scores with the sparse text data used and in the context of machine learning. Conclusion: ML and BERT algorithms based on routine unstructured X-ray and CT text reports, combined with the demographics of the patient, show promise in Neer classification of proximal humeral fractures to aid research. Use of these algorithms shows potential to speed up the classification task and assist radiologist, surgeons and researchers. © 2022 Elsevier B.V.","BERT; Classification; Deep learning; Machine learning; Natural language processing; Neer; Proximal humeral fracture; Radiology","adolescent; adult; age; aged; Article; Bayesian learning; bone radiography; computer assisted tomography; controlled study; deep learning; disease classification; female; human; intermethod comparison; machine learning; major clinical study; male; measurement accuracy; measurement precision; proximal humerus fracture; random forest; sex; algorithm; diagnostic imaging; radiography; radiology; shoulder fracture; Adult; Algorithms; Deep Learning; Humans; Radiography; Radiology; Shoulder Fractures",Article,Scopus
"Miller M.I., Orfanoudaki A., Cronin M., Saglam H., So Yeon Kim I., Balogun O., Tzalidi M., Vasilopoulos K., Fanaropoulou G., Fanaropoulou N.M., Kalin J., Hutch M., Prescott B.R., Brush B., Benjamin E.J., Shin M., Mian A., Greer D.M., Smirnakis S.M., Ong C.J.","Natural Language Processing of Radiology Reports to Detect Complications of Ischemic Stroke",2022,"Neurocritical Care",5,"10.1007/s12028-022-01513-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129704206&doi=10.1007%2fs12028-022-01513-3&partnerID=40&md5=fe097fad0520394a54bcf5608a37f469","Background: Abstraction of critical data from unstructured radiologic reports using natural language processing (NLP) is a powerful tool to automate the detection of important clinical features and enhance research efforts. We present a set of NLP approaches to identify critical findings in patients with acute ischemic stroke from radiology reports of computed tomography (CT) and magnetic resonance imaging (MRI). Methods: We trained machine learning classifiers to identify categorical outcomes of edema, midline shift (MLS), hemorrhagic transformation, and parenchymal hematoma, as well as rule-based systems (RBS) to identify intraventricular hemorrhage (IVH) and continuous MLS measurements within CT/MRI reports. Using a derivation cohort of 2289 reports from 550 individuals with acute middle cerebral artery territory ischemic strokes, we externally validated our models on reports from a separate institution as well as from patients with ischemic strokes in any vascular territory. Results: In all data sets, a deep neural network with pretrained biomedical word embeddings (BioClinicalBERT) achieved the highest discrimination performance for binary prediction of edema (area under precision recall curve [AUPRC] > 0.94), MLS (AUPRC > 0.98), hemorrhagic conversion (AUPRC > 0.89), and parenchymal hematoma (AUPRC > 0.76). BioClinicalBERT outperformed lasso regression (p < 0.001) for all outcomes except parenchymal hematoma (p = 0.755). Tailored RBS for IVH and continuous MLS outperformed BioClinicalBERT (p < 0.001) and linear regression, respectively (p < 0.001). Conclusions: Our study demonstrates robust performance and external validity of a core NLP tool kit for identifying both categorical and continuous outcomes of ischemic stroke from unstructured radiographic text data. Medically tailored NLP methods have multiple important big data applications, including scalable electronic phenotyping, augmentation of clinical risk prediction models, and facilitation of automatic alert systems in the hospital setting. © 2022, Springer Science+Business Media, LLC, part of Springer Nature and Neurocritical Care Society.","Critical care; Diagnostic imaging; Natural language processing; Stroke","acute ischemic stroke; adult; aged; Article; brain edema; brain hematoma; brain hemorrhage; classifier; cohort analysis; computer assisted tomography; female; human; information processing; machine learning; major clinical study; male; natural language processing; nuclear magnetic resonance imaging; prediction; validation process; brain ischemia; diagnostic imaging; hematoma; natural language processing; radiology; Hematoma; Humans; Ischemic Stroke; Machine Learning; Natural Language Processing; Radiology",Article,Scopus
"Crombé A., Seux M., Bratan F., Bergerot J.-F., Banaste N., Thomson V., Lecomte J.-C., Gorincour G.","What Influences the Way Radiologists Express Themselves in Their Reports? A Quantitative Assessment Using Natural Language Processing",2022,"Journal of Digital Imaging",1,"10.1007/s10278-022-00619-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126840303&doi=10.1007%2fs10278-022-00619-6&partnerID=40&md5=4254379e56609a5261fe6ec839473c36","Although using standardized reports is encouraged, most emergency radiological reports in France remain in free-text format that can be mined with natural language processing for epidemiological purposes, activity monitoring or data collection. These reports are obtained under various on-call conditions by radiologists with various backgrounds. Our aim was to investigate what influences the radiologists’ written expressions. To do so, this retrospective multicentric study included 30,227 emergency radiological reports of computed tomography scans and magnetic resonance imaging involving exactly one body region, only with pathological findings, interpreted from 2019–09-01 to 2020–02-28 by 165 radiologists. After text pre-processing, one-word tokenization and use of dictionaries for stop words, polarity, sentiment and uncertainty, 11 variables depicting the structure and content of words and sentences in the reports were extracted and summarized to 3 principal components capturing 93.7% of the dataset variance. In multivariate analysis, the 1st principal component summarized the length and lexical diversity of the reports and was significantly influenced by the weekday, time slot, workload, number of examinations previously interpreted by the radiologist during the on-call period, type of examination, emergency level and radiologists’ gender (P value range: &lt; 0.0001–0.0029). The 2nd principal component summarized negative formulations, polarity and sentence length and was correlated with the number of examination previously interpreted by the radiologist, type of examination, emergency level, imaging modality and radiologists’ experience (P value range: &lt; 0.0001–0.0032). The last principal component summarized questioning, uncertainty and polarity and was correlated with the type of examination and emergency level (all P values &lt; 0.0001). Thus, the length, structure and content of emergency radiological reports were significantly influenced by organizational, radiologist- and examination-related characteristics, highlighting the subjectivity and variability in the way radiologists express themselves during their clinical activity. These findings advocate for more homogeneous practices in radiological reporting and stress the need to consider these influential features when developing models based on natural language processing. © 2022, The Author(s) under exclusive licence to Society for Imaging Informatics in Medicine.","Emergency radiology; Natural language processing; Principal component analysis; Structured reports; Teleradiology; Text mining","Computerized tomography; Data mining; Magnetic resonance imaging; Multivariant analysis; Natural language processing systems; Emergency radiology; Free texts; P-values; Principal Components; Principal-component analysis; Quantitative assessments; Structured reports; Teleradiology; Text format; Uncertainty; Principal component analysis; article; body regions; computer assisted tomography; female; gender; human; male; mining; natural language processing; nuclear magnetic resonance imaging; physiological stress; principal component analysis; quantitative analysis; radiologist; retrospective study; teleradiology; uncertainty; workload; radiologist; radiology; x-ray computed tomography; Humans; Natural Language Processing; Radiologists; Radiology; Retrospective Studies; Tomography, X-Ray Computed",Article,Scopus
"Zech J.R.","Using BERT Models to Label Radiology Reports",2022,"Radiology: Artificial Intelligence",1,"10.1148/ryai.220124","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136173944&doi=10.1148%2fryai.220124&partnerID=40&md5=7808c0c8717bf4a09f5c376582683330",[No abstract available],,"accuracy; algorithm; area under the curve; artificial intelligence; bidirectional encoder representation from transformer; computer model; data processing; deep learning; frequency; human; imaging; learning algorithm; machine learning; medical record; natural language processing; Note; performance; radiology; thorax radiography; training",Note,Scopus
"Wiggins W.F., Tejani A.S.","On the Opportunities and Risks of Foundation Models for Natural Language Processing in Radiology",2022,"Radiology: Artificial Intelligence",9,"10.1148/ryai.220119","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136166661&doi=10.1148%2fryai.220119&partnerID=40&md5=4767553611b8dab37d218c1a3de33f42",[No abstract available],,"coal; architecture; artificial intelligence; artificial neural network; breast biopsy; breast magnetic resonance imaging; breast tumor; carbon footprint; embedding; environmental impact; ethical dilemma; language; mammography; medical literature; natural language processing; Note; radiology; thorax radiography; training; transfer of learning; ultrasound",Note,Scopus
"Yan A., McAuley J., Lu X., Du J., Chang E.Y., Gentili A., Hsu C.-N.","RadBERT: Adapting Transformer-based Language Models to Radiology",2022,"Radiology: Artificial Intelligence",15,"10.1148/ryai.210258","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134878060&doi=10.1148%2fryai.210258&partnerID=40&md5=92ee914646083a5f5300466c1d7a3a43","Purpose: To investigate if tailoring a transformer-based language model to radiology is beneficial for radiology natural language processing (NLP) applications. Materials and Methods: This retrospective study presents a family of bidirectional encoder representations from transformers (BERT)– based language models adapted for radiology, named RadBERT. Transformers were pretrained with either 2.16 or 4.42 million radiology reports from U.S. Department of Veterans Affairs health care systems nationwide on top of four different initializations (BERT-base, Clinical-BERT, robustly optimized BERT pretraining approach [RoBERTa], and BioMed-RoBERTa) to create six variants of RadBERT. Each variant was fine-tuned for three representative NLP tasks in radiology: (a) abnormal sentence classification: models classified sentences in radiology reports as reporting abnormal or normal findings; (b) report coding: models assigned a diagnostic code to a given radiology report for five coding systems; and (c) report summarization: given the findings section of a radiology report, models selected key sentences that summarized the findings. Model performance was compared by bootstrap resampling with five inten-sively studied transformer language models as baselines: BERT-base, BioBERT, Clinical-BERT, BlueBERT, and BioMed-RoBERTa. Results: For abnormal sentence classification, all models performed well (accuracies above 97.5 and F1 scores above 95.0). RadBERT variants achieved significantly higher scores than corresponding baselines when given only 10% or less of 12 458 annotated training sentences. For report coding, all variants outperformed baselines significantly for all five coding systems. The variant RadBERT– BioMed-RoBERTa performed the best among all models for report summarization, achieving a Recall-Oriented Understudy for Gisting Evaluation–1 score of 16.18 compared with 15.27 by the corresponding baseline (BioMed-RoBERTa, P,.004). Conclusion: Transformer-based language models tailored to radiology had improved performance of radiology NLP tasks compared with baseline transformer language models. © RSNA, 2022.",,"article; bootstrapping; health care system; human; human experiment; natural language processing; radiology; recall; retrospective study; veteran",Article,Scopus
"Yi P.H., Kim T.K., Lin C.T.","Comparison of radiologist versus natural language processing-based image annotations for deep learning system for tuberculosis screening on chest radiographs",2022,"Clinical Imaging",3,"10.1016/j.clinimag.2022.04.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129268064&doi=10.1016%2fj.clinimag.2022.04.009&partnerID=40&md5=b6a6eefd786ad03149289ef631f7a880","Although natural language processing (NLP) can rapidly extract disease labels from radiology reports to create datasets for deep learning models, this may be less accurate than having radiologists manually review the images. In this study, we compared agreement between natural language processing (NLP) and radiologist-curated labels for possible tuberculosis (TB) on chest radiographs (CXR) and evaluated the performance of deep convolutional neural networks (DCNN) trained to identify TB using the preceding two sets of labels. We collected 10,951 CXRs from the NIH ChestX-ray14 dataset and labeled them as positive or negative for possible TB based on two methods: 1) NLP-derived disease labels and 2) radiologist-review of images. These images were used to train DCNNs on varying dataset sizes for possible TB and tested on an external dataset of 800 CXRs. Area under the ROC curve (AUC) was used to evaluate DCNNs. There was poor agreement between NLP and radiologist-curated labels for potential TB (Kappa coefficient 0.34). DCNNs trained using radiologist-curated labels had higher performance than the algorithm trained using the NLP-labels, regardless of the number of images used for training. The best-performing DCNN had an AUC of 0.88, which was trained on 10,951 images using the radiologist-annotated sets. DCNNs trained on CXRs labeled by a radiologist consistently outperformed those trained on the same CXRs labeled by NLP, highlighting the benefit of radiologists' determining groundtruth for machine learning dataset curation. © 2022","Artificial intelligence; Chest radiographs; Deep learning; Natural language processing; Tuberculosis","Convolutional neural networks; Diagnosis; Image annotation; Learning algorithms; Natural language processing systems; Radiography; Area under the ROC curve; Chest radiographs; Curation; Data set size; Deep learning; Kappa coefficient; Learning models; Performance; Radiology reports; Tuberculosis; Deep neural networks; algorithm; area under the curve; Article; controlled study; convolutional neural network; deep learning; diagnostic accuracy; human; kappa statistics; natural language processing; predictive value; radiologist; receiver operating characteristic; sensitivity and specificity; thorax radiography; tuberculosis; information processing; natural language processing; procedures; radiologist; retrospective study; thorax radiography; Data Curation; Deep Learning; Humans; Natural Language Processing; Radiography, Thoracic; Radiologists; Retrospective Studies",Article,Scopus
"Fei X., Chen P., Wei L., Huang Y., Xin Y., Li J.","Quality Management of Pulmonary Nodule Radiology Reports Based on Natural Language Processing",2022,"Bioengineering",1,"10.3390/bioengineering9060244","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131842612&doi=10.3390%2fbioengineering9060244&partnerID=40&md5=21599e1afa1299f7e24cf706f40f941f","To investigate the feasibility of automated follow-up recommendations based on findings in radiology reports, this paper proposed a Natural Language Processing model specific for Pulmonary Nodule Radiology Reports. Unstructured findings used to describe pulmonary nodules in 48,091 radiology reports were processed in this study. We established an NLP model to extract information entities from findings of radiology reports, using deep learning and conditional random-field algorithms. Subsequently, we constructed a knowledge graph comprising 168 entities and four rela-tionships, based on the export recommendations of the internationally renowned Fleischner Society for pulmonary nodules. These were employed in combination with rule templates to automatically generate follow-up recommendations. The automatically generated recommendations were then compared to the impression part of the reports to evaluate the matching rate of proper follow ups in the current situation. The NLP model identified eight types of entities with a recognition accuracy of up to 94.22%. A total of 43,898 out of 48,091 clinical reports were judged to contain appropriate follow-up recommendations, corresponding to the matching rate of 91.28%. The results show that NLP can be used on Chinese radiology reports to extract structured information at the content level, thereby realizing the prompt and intelligent follow-up suggestion generation or post-quality management of follow-up recommendations. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","knowledge graph; natural language processing; pulmonary nodule; quality management; radiology report",,Article,Scopus
"Paalvast O., Nauta M., Koelle M., Geerdink J., Vijlbrief O., Hegeman J.H., Seifert C.","Radiology report generation for proximal femur fractures using deep classification and language generation models",2022,"Artificial Intelligence in Medicine",2,"10.1016/j.artmed.2022.102281","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128847465&doi=10.1016%2fj.artmed.2022.102281&partnerID=40&md5=0e528d2f5acedcdbf0a855acaecc68b3","Proximal femur fractures represent a major health concern, and substantially contribute to the morbidity of elderly. Correct classification and diagnosis of hip fractures has a significant impact on mortality, costs and hospital stay. In this paper, we present a method and empirical validation for automatic subclassification of proximal femur fractures and Dutch radiological report generation that does not rely on manually curated data. The fracture classification model was trained on 11,000 X-ray images obtained from 5000 electronic health records in a general hospital. To generate the Dutch reports, we first trained an embedding model on 20,000 radiological reports of pelvic region fractures, and used its embeddings in the report generation model. We trained the report generation model on the 5000 radiological reports associated with the fracture cases. Our report generation model is on par with state-of-the-art in terms of BLEU and ROUGE scores. This is promising, because in contrast to those earlier works, our approach does not require manual preprocessing of either images or the reports. This boosts the applicability of automatic clinical report generation in practice. A quantitative and qualitative user study among medical students found no significant difference in provenance of real and generated reports. A qualitative, in-depth clinical relevance study with medical domain experts showed that from a human perspective the quality of the generated reports approximates the quality of the original reports and highlights challenges in creating sufficiently detailed and versatile training data for automatic radiology report generation. © 2022 The Authors","Fracture classification; Proximal femur fractures; Radiology language model; Radiology report generation; User study","Bone; Computer aided diagnosis; Embeddings; Fracture; Hospitals; Radiation; Embeddings; Fracture classification; Language model; Proximal femur; Proximal femur fracture; Radiology language model; Radiology report generation; Radiology reports; Report generation; User study; Radiology; adult; anatomical location; Article; binary classification; bone radiography; classification algorithm; controlled study; data completeness; data quality assessment; deep learning; diagnostic accuracy; diagnostic error; disease classification; disease severity; electronic health record; female; human; intermethod comparison; language processing; limit of agreement; male; medical student; pelvis fracture; pelvis radiography; proximal femur fracture; qualitative analysis; quantitative analysis; reporting and data system; semantics; usability; aged; diagnostic imaging; femur; hip fracture; language; radiography; radiology; Aged; Femur; Hip Fractures; Humans; Language; Radiography; Radiology",Article,Scopus
"Spear L.G., Dimperio J.A., Wang S.S., Do H.M., Folio L.R.","Rethinking Clinical Trial Radiology Workflows and Student Training: Integrated Virtual Student Shadowing Experience, Education, and Evaluation",2022,"Journal of Digital Imaging",,"10.1007/s10278-022-00605-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124953614&doi=10.1007%2fs10278-022-00605-y&partnerID=40&md5=8bfdeee56cadc06afd4d937f13827e7b","There is consistent demand for clinical exposure from students interested in radiology; however, the COVID-19 pandemic resulted in fewer available options and limited student access to radiology departments. Additionally, there is increased demand for radiologists to manage more complex quantification in reports on patients enrolled in clinical trials. We present an online educational curriculum that addresses both of these gaps by virtually immersing students (radiology preprocessors, or RPs) into radiologists’ workflows where they identify and measure target lesions in advance of radiologists, streamlining report quantification. RPs switched to remote work at the beginning of the COVID-19 pandemic in our National Institutes of Health (NIH). We accommodated them by transitioning our curriculum on cross-sectional anatomy and advanced PACS tools to a publicly available online curriculum. We describe collaborations between multiple academic research centers and industry through contributions of academic content to this curriculum. Further, we describe how we objectively assess educational effectiveness with cross-sectional anatomical quizzes and decreasing RP miss rates as they gain experience. Our RP curriculum generated significant interest evidenced by a dozen academic and research institutes providing online presentations including radiology modality basics and quantification in clinical trials. We report a decrease in RP miss rate percentage, including one virtual RP over a period of 1 year. Results reflect training effectiveness through decreased discrepancies with radiologist reports and improved tumor identification over time. We present our RP curriculum and multicenter experience as a pilot experience in a clinical trial research setting. Students are able to obtain useful clinical radiology experience in a virtual learning environment by immersing themselves into a clinical radiologist’s workflow. At the same time, they help radiologists improve patient care with more valuable quantitative reports, previously shown to improve radiologist efficiency. Students identify and measure lesions in clinical trials before radiologists, and then review their reports for self-evaluation based on included measurements from the radiologists. We consider our virtual approach as a supplement to student education while providing a model for how artificial intelligence will improve patient care with more consistent quantification while improving radiologist efficiency. © 2022, The Author(s) under exclusive licence to Society for Imaging Informatics in Medicine.","Artificial intelligence; Computed tomography; Medical education; Tumor quantification","Clinical research; Computer aided diagnosis; Computer aided instruction; Curricula; E-learning; Education computing; Efficiency; Medical applications; Medical education; Radiation; Radiology; Students; Tumors; Clinical trial; Miss-rate; National institute of healths; Patient care; Radiology departments; Radiology workflow; Student access; Student training; Tumor quantification; Work-flows; Computerized tomography; artificial intelligence; clinical trial; curriculum; education; human; multicenter study; pandemic; radiology; student; workflow; Artificial Intelligence; COVID-19; Curriculum; Humans; Pandemics; Radiology; Students; Workflow",Article,Scopus
"Park C.J., Yi P.H., Al Yousif H., Wang K.C.","Machine vs. Radiologist-Based Translations of RadLex: Implications for Multi-language Report Interoperability",2022,"Journal of Digital Imaging",2,"10.1007/s10278-022-00597-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124721802&doi=10.1007%2fs10278-022-00597-9&partnerID=40&md5=30c2ea982367307e1feca46d55466952","The purpose of this study was to evaluate the feasibility of translation of RadLex lexicon from English to German performed by Google Translate, using the RadLex ontology as ground truth. The same comparison was also performed for German to English translations. We determined the concordance rate of the Google Translate–rendered translations (for both English to German and German to English translations) to the official German RadLex (translations provided by the German Radiological Society) and English RadLex terms via character-by-character concordance analysis (string matching). Specific term characteristics of term character count and word count were compared between concordant and discordant translations using t-tests. Google Translate–rendered translations originally considered incongruent (2482 English terms and 2500 German terms) were then reviewed by German and English-speaking radiologists to further evaluate clinical utility. Overall success rates of both methods were calculated by adding the percentage of terms marked correct by string comparison to the percentage marked correct during manual review extrapolated to the terms that had been initially marked incorrect during string analysis. 64,632 English and 47,425 German RadLex terms were analyzed. 3507 (5.4%) of the Google Translate–rendered English to German translations were concordant with the official German RadLex terms when evaluated via character-by-character concordance. 3288 (6.9%) of the Google Translate–rendered German to English translations matched the corresponding English RadLex terms. Human review of a random sample of non-concordant machine translations revealed that 95.5% of such English to German translations were understandable, whereas 43.9% of such German to English translations were understandable. Combining both string matching and human review resulted in an overall Google Translate success rate of 95.7% for English to German translations and 47.8% for German to English translations. For certain radiologic text translation tasks, Google Translate may be a useful tool for translating multi-language radiology reports into a common language for natural language processing and subsequent labeling of datasets for machine learning. Indeed, string matching analysis alone is an incomplete method for evaluating machine translation. However, when human review of automated translation is also incorporated, measured performance improves. Additional evaluation using longer text samples and full imaging reports is needed. An apparent discordance between English to German versus German to English translation suggests that the direction of translation affects accuracy. © 2022, The Author(s) under exclusive licence to Society for Imaging Informatics in Medicine.","Artificial intelligence; Informatics; Natural language processing; RadLex; Reports; Translation","Artificial intelligence; Computational linguistics; Computer aided language translation; Interoperability; Learning algorithms; Machine translation; Rendering (computer graphics); Concordance analysis; Google translate; Ground truth; Multi languages; Ontology's; Radlex; Report; String matching; T-tests; Translation; Natural language processing systems; article; artificial intelligence; clinical evaluation; feasibility study; human; human experiment; information science; machine learning; natural language processing; ontology; radiologist; radiology; random sample; speech; language; natural language processing; publication; radiologist; translating (language); Humans; Language; Natural Language Processing; Radiologists; Translating; Translations",Article,Scopus
"Visser J.J., de Vries M., Kors J.A.","Automatic detection of actionable findings and communication mentions in radiology reports using natural language processing",2022,"European Radiology",2,"10.1007/s00330-021-08467-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122465502&doi=10.1007%2fs00330-021-08467-8&partnerID=40&md5=d923afcdff24f43f77400972d0918955","Objectives: To develop and validate classifiers for automatic detection of actionable findings and documentation of nonroutine communication in routinely delivered radiology reports. Methods: Two radiologists annotated all actionable findings and communication mentions in a training set of 1,306 radiology reports and a test set of 1,000 reports randomly selected from the electronic health record system of a large tertiary hospital. Various feature sets were constructed based on the impression section of the reports using different preprocessing steps (stemming, removal of stop words, negations, and previously known or stable findings) and n-grams. Random forest classifiers were trained to detect actionable findings, and a decision-rule classifier was trained to find communication mentions. Classifier performance was evaluated by the area under the receiver operating characteristic curve (AUC), sensitivity, and specificity. Results: On the training set, the actionable finding classifier with the highest cross-validated performance was obtained for a feature set of unigrams, after stemming and removal of negated, known, and stable findings. On the test set, this classifier achieved an AUC of 0.876 (95% CI 0.854–0.898). The classifier for communication detection was trained after negation removal, using unigrams as features. The resultant decision rule had a sensitivity of 0.841 (95% CI 0.706–0.921) and specificity of 0.990 (95% CI 0.981–0.994) on the test set. Conclusions: Automatic detection of actionable findings and subsequent communication in routinely delivered radiology reports is possible. This can serve quality control purposes and may alert radiologists to the presence of actionable findings during reporting. Key Points: • Classifiers were developed for automatic detection of the broad spectrum of actionable findings and subsequent communication mentions in routinely delivered radiology reports. • Straightforward report preprocessing and simple feature sets can produce well-performing classifiers. • The resultant classifiers show good performance for detection of actionable findings and excellent performance for detection of communication mentions. © 2021, The Author(s), under exclusive licence to European Society of Radiology.","Machine learning; Natural language processing; Personal communication; Quality control; Radiology information systems","Article; electronic health record; human; major clinical study; medical documentation; natural language processing; quality control; radiologist; sensitivity and specificity; tertiary care center; interpersonal communication; machine learning; radiology; Communication; Humans; Machine Learning; Natural Language Processing; Radiology",Article,Scopus
"Goldman J.-P., Mottin L., Zaghir J., Keszthelyi D., Lokaj B., Turbé H., Gobeil J., Ruch P., Ehrsam J., Lovis C.","Classification of Oncology Treatment Responses from French Radiology Reports with Supervised Machine Learning",2022,"Studies in Health Technology and Informatics",,"10.3233/SHTI220605","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131106917&doi=10.3233%2fSHTI220605&partnerID=40&md5=3cae5119aac4637677eb20c374f32e9a","The present study shows first attempts to automatically classify oncology treatment responses on the basis of the textual conclusion sections of radiology reports according to the RECIST classification. After a robust and extended manual annotation of 543 conclusion sections (5-to-50-word long), and after the training of several machine learning techniques (from traditional machine learning to deep learning), the best results show an accuracy score of 0.90 for a two-class classification (non-progressive vs. progressive disease) and of 0.82 for a four-class classification (complete response, partial response, stable disease, progressive disease) both with Logistic Regression approach. Some innovative solutions are further suggested to improve these scores in the future. © 2022 European Federation for Medical Informatics (EFMI) and IOS Press.","automatic classification; natural language processing; oncology; RECIST; supervised machine learning; treatment response","Deep learning; Learning algorithms; Medical informatics; Oncology; Radiation; Radiology; Supervised learning; Automatic classification; Complete response; Machine learning techniques; Manual annotation; Partial response; Progressive disease; Radiology reports; RECIST; Supervised machine learning; Treatment response; Natural language processing systems; machine learning; natural language processing; radiography; radiology; research; supervised machine learning; Machine Learning; Natural Language Processing; Radiography; Radiology; Research Report; Supervised Machine Learning",Conference Paper,Scopus
"Sebro R., Kahn C.E., Jr.","Causal Associations Among Diseases and Imaging Findings in Radiology Reports",2022,"Studies in Health Technology and Informatics",,"10.3233/SHTI220487","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131105784&doi=10.3233%2fSHTI220487&partnerID=40&md5=beacf0d66e3196f6a6905d588cd2bf56","This study explored the ability to identify causal relationships between diseases and imaging findings from their co-occurrences in radiology reports. A natural language processing (NLP) system with negative-expression filtering detected positive mentions of 16,912 disorders, interventions, and imaging findings in 1,702,462 consecutive radiology reports; the 55,564 causal relations defined by the Radiology Gamuts Ontology (RGO) served as reference standard. Conditions were considered to co-occur if they were present in reports from the same patient. The φ and κ statistics both achieved AUC0.70, P<0.001 in identifying causal relationships from pairwise co-occurrence data. Analysis of radiology reports can identify a large proportion of known causal associations among diseases and imaging findings. Automated approaches hold promise to identify causal relationships among diseases and imaging findings from their co-occurrence in text-based radiology reports. © 2022 European Federation for Medical Informatics (EFMI) and IOS Press.","Big data; Health data science; Knowledge discovery; Natural language processing; Ontologies; Radiology; Reporting","Big data; Medical informatics; Natural language processing systems; Ontology; Radiation; Radiology; Causal relations; Causal relationships; Co-occurrence; Condition; Health data; Health data science; Ontology's; Radiology reports; Reference standard; Reporting; Data mining; biological ontology; human; natural language processing; radiography; radiology; research; Biological Ontologies; Humans; Natural Language Processing; Radiography; Radiology; Research Report",Conference Paper,Scopus
"Tan T., Das B., Soni R., Fejes M., Yang H., Ranjan S., Szabo D.A., Melapudi V., Shriram K.S., Agrawal U., Rusko L., Herczeg Z., Darazs B., Tegzes P., Ferenczi L., Mullick R., Avinash G.","Multi-modal trained artificial intelligence solution to triage chest X-ray for COVID-19 using pristine ground-truth, versus radiologists",2022,"Neurocomputing",9,"10.1016/j.neucom.2022.02.040","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124906588&doi=10.1016%2fj.neucom.2022.02.040&partnerID=40&md5=0bb591b8cecc491865125a8e895e0033","The front-line imaging modalities computed tomography (CT) and X-ray play important roles for triaging COVID patients. Thoracic CT has been accepted to have higher sensitivity than a chest X-ray for COVID diagnosis. Considering the limited access to resources (both hardware and trained personnel) and issues related to decontamination, CT may not be ideal for triaging suspected subjects. Artificial intelligence (AI) assisted X-ray based application for triaging and monitoring require experienced radiologists to identify COVID patients in a timely manner with the additional ability to delineate and quantify the disease region is seen as a promising solution for widespread clinical use. Our proposed solution differs from existing solutions presented by industry and academic communities. We demonstrate a functional AI model to triage by classifying and segmenting a single chest X-ray image, while the AI model is trained using both X-ray and CT data. We report on how such a multi-modal training process improves the solution compared to single modality (X-ray only) training. The multi-modal solution increases the AUC (area under the receiver operating characteristic curve) from 0.89 to 0.93 for a binary classification between COVID-19 and non-COVID-19 cases. It also positively impacts the Dice coefficient (0.59 to 0.62) for localizing the COVID-19 pathology. To compare the performance of experienced readers to the AI model, a reader study is also conducted. The AI model showed good consistency with respect to radiologists. The DICE score between two radiologists on the COVID group was 0.53 while the AI had a DICE value of 0.52 and 0.55 when compared to the segmentation done by the two radiologists separately. From a classification perspective, the AUCs of two readers was 0.87 and 0.81 while the AUC of the AI is 0.93 based on the reader study dataset. We also conducted a generalization study by comparing our method to the-state-art methods on independent datasets. The results show better performance from the proposed method. Leveraging multi-modal information for the development benefits the single-modal inferencing. © 2022 Elsevier B.V.","Artificial intelligence; COVID-19; Multi-modal; Reader study","Classification (of information); Computerized tomography; Diagnosis; Image segmentation; Access to resources; Clinical use; COVID-19; Ground truth; High sensitivity; Imaging modality; Intelligence models; Multi-modal; Performance; Reader study; Artificial intelligence; Article; artificial intelligence; computer assisted tomography; coronavirus disease 2019; diagnostic test accuracy study; disease classification; emergency health service; human; image segmentation; information processing; intermethod comparison; mathematical computing; multimodal imaging; pristine groundtruth; radiologist; receiver operating characteristic; thorax radiography",Article,Scopus
"Kuling G., Curpen B., Martel A.L.","BI-RADS BERT and Using Section Segmentation to Understand Radiology Reports",2022,"Journal of Imaging",5,"10.3390/jimaging8050131","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130299014&doi=10.3390%2fjimaging8050131&partnerID=40&md5=96d4e1df122b325d3c1893d53c43f842","Radiology reports are one of the main forms of communication between radiologists and other clinicians, and contain important information for patient care. In order to use this information for research and automated patient care programs, it is necessary to convert the raw text into struc-tured data suitable for analysis. State-of-the-art natural language processing (NLP) domain-specific contextual word embeddings have been shown to achieve impressive accuracy for these tasks in medicine, but have yet to be utilized for section structure segmentation. In this work, we pre-trained a contextual embedding BERT model using breast radiology reports and developed a classifier that incorporated the embedding with auxiliary global textual features in order to perform section segmen-tation. This model achieved 98% accuracy in segregating free-text reports, sentence by sentence, into sections of information outlined in the Breast Imaging Reporting and Data System (BI-RADS) lexicon, which is a significant improvement over the classic BERT model without auxiliary information. We then evaluated whether using section segmentation improved the downstream extraction of clinically relevant information such as modality/procedure, previous cancer, menopausal status, purpose of exam, breast density, and breast MRI background parenchymal enhancement. Using the BERT model pre-trained on breast radiology reports, combined with section segmentation, resulted in an overall accuracy of 95.9% in the field extraction tasks. This is a 17% improvement, compared to an overall accuracy of 78.9% for field extraction with models using classic BERT embeddings and not using section segmentation. Our work shows the strength of using BERT in the analysis of radiology reports and the advantages of section segmentation by identifying the key features of patient factors recorded in breast radiology reports. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","BERT; BI-RADS; deep learning; natural language processing",,Article,Scopus
"García Mur C., García Barrado A.I., Cruz Ciria S.","Structured radiology reports: what and how structured reports for breast mri during neoadjuvant therapy: what information do committees need? [El informe radiológico: informe estructurado, ¿qué y cómo? Informe estructurado de RM mama en neoadyuvancia: ¿qué información se precisa en los comités?]",2022,"Radiologia",,"10.1016/j.rx.2022.02.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128170396&doi=10.1016%2fj.rx.2022.02.007&partnerID=40&md5=1eda84da35a0758c155c4e884dc36584","MRI is the most accurate imaging technique for the noninvasive assessment of the response to primary systemic therapy. Its diagnostic accuracy improves when morphological and functional (signal-intensity/time curves and diffusion) information are combined. The MRI reports for staging and for monitoring the response to neoadjuvant therapy must include information from clinical, histological, and radiological studies to optimize the interpretation of the findings, prediction of the response to treatment, and planning of the surgical intervention. In the context of neoadjuvant therapy, a structured MRI report makes it possible to use a common lexicon and to compare the results in conjunction with different professionals, opening a horizon toward artificial intelligence. © 2022 SERAM","Breast cancer; Magnetic resonance imaging; Primary systemic therapy; Structured radiology report","Article; artificial intelligence; breast magnetic resonance imaging; breast surgery; cancer staging; diagnostic accuracy; human; neoadjuvant therapy; radiological procedures; treatment response",Article,Scopus
"Martí-Bonmatí L., Alberich-Bayarri Á., Torregrosa A.","The radiology report: structure, style, and contents [El informe radiológico. Estructura, estilo y contenido]",2022,"Radiologia",4,"10.1016/j.rx.2022.01.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127309210&doi=10.1016%2fj.rx.2022.01.013&partnerID=40&md5=b69978debea28180e913ea5ae279c770","Radiology has advanced thanks to technological developments and the digital transformation of the field. Radiology reports have evolved from a free-text format to structured formats that integrate protocols, observations, data, aid systems, and guidelines, making it one of the most important elements in patients’ clinical histories. Using structured reports is also essential to enable data extraction for healthcare dashboards and research databases for developing artificial intelligence approaches and applying them in healthcare practice. This hybrid qualitative-quantitative report makes it possible to work with a predefined structure in complex and important areas, with a direct link to radiomic data including imaging biomarkers and their key parametric images, thus supporting automatic classification systems and aiding decision making. Moreover, structured reports reduce uncertainty and avoid the use of evasive language to minimize responsibilities. © 2022 SERAM","Diagnostic imaging; Radiology information systems; Radiology reports; Structured radiology reports","biological marker; Article; artificial intelligence; data base; data extraction; decision making; diagnostic imaging; health care practice; human; imaging; practice guideline; radiology; radiomics; uncertainty",Article,Scopus
"Donnelly L.F., Grzeszczuk R., Guimaraes C.V.","Use of Natural Language Processing (NLP) in Evaluation of Radiology Reports: An Update on Applications and Technology Advances",2022,"Seminars in Ultrasound, CT and MRI",11,"10.1053/j.sult.2022.02.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125523632&doi=10.1053%2fj.sult.2022.02.007&partnerID=40&md5=440f854779a556eb5b92ca53febfe148","Natural language processing (NLP) is focused on the computer interpretation of human language and can be used to evaluate radiology reports and has demonstrated useful applications in essentially all aspects of medical imaging delivery: interpretation of imaging data, improving image acquisition, image analysis, and increasing efficiency of imaging services. This manuscript reviews general technologic approaches to NLP at a level hopefully understandable by clinical radiologists, discusses recent advancements in NLP techniques, and discusses current and potential applications of NLP in radiology. © 2022 Elsevier Inc.",,"Article; clinical research; image processing; natural language processing; radiologist; radiology; technology; word processing; human; radiography; Humans; Natural Language Processing; Radiography; Radiology; Technology",Article,Scopus
"Li M.D., Deng F., Chang K., Kalpathy-Cramer J., Huang A.J.","Automated Radiology-Arthroscopy Correlation of Knee Meniscal Tears Using Natural Language Processing Algorithms",2022,"Academic Radiology",5,"10.1016/j.acra.2021.01.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100621697&doi=10.1016%2fj.acra.2021.01.017&partnerID=40&md5=8577cceda837108ac3fcf986dea353e0","Rationale and Objectives: Train and apply natural language processing (NLP) algorithms for automated radiology-arthroscopy correlation of meniscal tears. Materials and Methods: In this retrospective single-institution study, we trained supervised machine learning models (logistic regression, support vector machine, and random forest) to detect medial or lateral meniscus tears on free-text MRI reports. We trained and evaluated model performances with cross-validation using 3593 manually annotated knee MRI reports. To assess radiology-arthroscopy correlation, we then randomly partitioned this dataset 80:20 for training and testing, where 108 test set MRIs were followed by knee arthroscopy within 1 year. These free-text arthroscopy reports were also manually annotated. The NLP algorithms trained on the knee MRI training dataset were then evaluated on the MRI and arthroscopy report test datasets. We assessed radiology-arthroscopy agreement using the ensembled NLP-extracted findings versus manually annotated findings. Results: The NLP models showed high cross-validation performance for meniscal tear detection on knee MRI reports (medial meniscus F1 scores 0.93–0.94, lateral meniscus F1 scores 0.86–0.88). When these algorithms were evaluated on arthroscopy reports, despite never training on arthroscopy reports, performance was similar, though higher with model ensembling (medial meniscus F1 score 0.97, lateral meniscus F1 score 0.99). However, ensembling did not improve performance on knee MRI reports. In the radiology-arthroscopy test set, the ensembled NLP models were able to detect mismatches between MRI and arthroscopy reports with sensitivity 79% and specificity 87%. Conclusion: Radiology-arthroscopy correlation can be automated for knee meniscal tears using NLP algorithms, which shows promise for education and quality improvement. © 2021 The Association of University Radiologists","Knee MRI; Machine learning; Meniscal tear; Natural language processing; Radiology-arthroscopy correlation","adult; algorithm; anterior cruciate ligament rupture; Article; automation; cartilage injury; controlled study; discoid meniscus; female; human; knee arthroscopy; knee meniscus rupture; knee radiography; lateral meniscus; major clinical study; male; middle aged; natural language processing; nuclear magnetic resonance imaging; orthopedic surgeon; prevalence; quality control; radiodiagnosis; random forest; retrospective study; supervised machine learning; support vector machine; arthroscopy; diagnostic imaging; knee meniscus rupture; natural language processing; radiology; sensitivity and specificity; Arthroscopy; Humans; Magnetic Resonance Imaging; Natural Language Processing; Radiology; Retrospective Studies; Sensitivity and Specificity; Support Vector Machine; Tibial Meniscus Injuries",Article,Scopus
"Domingo J., Galal G., Huang J., Soni P., Mukhin V., Altman C., Bayer T., Byrd T., Caron S., Creamer P., Gilstrap J., Gwardys H., Hogue C., Kadiyam K., Massa M., Salamone P., Slavicek R., Suna M., Ware B., Xinos S., Yuen L., Moran T., Barnard C., Adams J.G., Etemadi M.","Preventing Delayed and Missed Care by Applying Artificial Intelligence to Trigger Radiology Imaging Follow-up",2022,"NEJM Catalyst Innovations in Care Delivery",4,"10.1056/CAT.21.0469","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133506473&doi=10.1056%2fCAT.21.0469&partnerID=40&md5=745030311c7ac4e1771a23d1dd922e98","Medical diagnostic imaging studies frequently detect findings that require further evaluation. An initiative at Northwestern Medicine was designed to prevent delays and improve outcomes by engineering reliable follow-up of radiographic findings. An artificial intelligence natural language processing (NLP) system was developed to identify radiology reports containing lung- and adrenal-related findings requiring follow-up. Over 13 months, more than 570,000 imaging studies were screened, of which more than 29,000 were flagged as containing lung-related follow-up recommendations, representing a 5.1% rate of lung-related findings occurrence on relevant imaging studies and an average of 70 findings flagged per day. Northwestern’s prospective clinical validation of the system, the first of its kind, demonstrated a sensitivity of 77.1%, specificity of 99.5%, and positive predictive value of 90.3% for lung findings requiring follow-up. To date, the workflow has generated nearly 5,000 interactions with ordering physicians and has tracked more than 2,400 follow-ups to completion. The authors conclude that NLP demonstrates significant potential to improve reliable follow-up to imaging findings and, thus, to reduce preventable morbidity in lung pathology and other high-risk and problem-prone areas of medicine. © 2022 NEJM Catalyst Innovations in Care Delivery. All rights reserved.",,,Article,Scopus
"Batch K.E., Yue J., Darcovich A., Lupton K., Liu C.C., Woodlock D.P., El Amine M.A.K., Causa-Andrieu P.I., Gazit L., Nguyen G.H., Zulkernine F., Do R.K.G., Simpson A.L.","Developing a Cancer Digital Twin: Supervised Metastases Detection From Consecutive Structured Radiology Reports",2022,"Frontiers in Artificial Intelligence",7,"10.3389/frai.2022.826402","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126739519&doi=10.3389%2ffrai.2022.826402&partnerID=40&md5=79840d361bad5edd187efdbd6f3f1133","The development of digital cancer twins relies on the capture of high-resolution representations of individual cancer patients throughout the course of their treatment. Our research aims to improve the detection of metastatic disease over time from structured radiology reports by exposing prediction models to historical information. We demonstrate that Natural language processing (NLP) can generate better weak labels for semi-supervised classification of computed tomography (CT) reports when it is exposed to consecutive reports through a patient's treatment history. Around 714,454 structured radiology reports from Memorial Sloan Kettering Cancer Center adhering to a standardized departmental structured template were used for model development with a subset of the reports included for validation. To develop the models, a subset of the reports was curated for ground-truth: 7,732 total reports in the lung metastases dataset from 867 individual patients; 2,777 reports in the liver metastases dataset from 315 patients; and 4,107 reports in the adrenal metastases dataset from 404 patients. We use NLP to extract and encode important features from the structured text reports, which are then used to develop, train, and validate models. Three models—a simple convolutional neural network (CNN), a CNN augmented with an attention layer, and a recurrent neural network (RNN)—were developed to classify the type of metastatic disease and validated against the ground truth labels. The models use features from consecutive structured text radiology reports of a patient to predict the presence of metastatic disease in the reports. A single-report model, previously developed to analyze one report instead of multiple past reports, is included and the results from all four models are compared based on accuracy, precision, recall, and F1-score. The best model is used to label all 714,454 reports to generate metastases maps. Our results suggest that NLP models can extract cancer progression patterns from multiple consecutive reports and predict the presence of metastatic disease in multiple organs with higher performance when compared with a single-report-based prediction. It demonstrates a promising automated approach to label large numbers of radiology reports without involving human experts in a time- and cost-effective manner and enables tracking of cancer progression over time. Copyright © 2022 Batch, Yue, Darcovich, Lupton, Liu, Woodlock, El Amine, Causa-Andrieu, Gazit, Nguyen, Zulkernine, Do and Simpson.","cancer; convolutional neural network (CNN); digital twins; machine learning; metastases; natural language processing (NLP); radiology; recurrent neural network (RNN)",,Article,Scopus
"Yamashita R., Bird K., Cheung P.Y.-C., Decker J.H., Flory M.N., Goff D., Morimoto L.N., Shon A., Wentland A.L., Rubin D.L., Desser T.S.","Automated Identification and Measurement Extraction of Pancreatic Cystic Lesions from Free-Text Radiology Reports Using Natural Language Processing",2022,"Radiology: Artificial Intelligence",6,"10.1148/ryai.210092","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130218706&doi=10.1148%2fryai.210092&partnerID=40&md5=cc7f1415c7f6d7a89d94043f73833c5a","Purpose: To automatically identify a cohort of patients with pancreatic cystic lesions (PCLs) and extract PCL measurements from his-torical CT and MRI reports using natural language processing (NLP) and a question answering system. Materials and Methods: Institutional review board approval was obtained for this retrospective Health Insurance Portability and Accountability Act–compliant study, and the requirement to obtain informed consent was waived. A cohort of free-text CT and MRI reports generated between January 1991 and July 2019 that covered the pancreatic region were identified. A PCL identification model was developed by modifying a rule-based information extraction model; measurement extraction was performed using a state-of-the-art question answering system. The system’s performance was evaluated against radiologists’ annotations. Results: For this study, 430 426 free-text radiology reports from 199 783 unique patients were identified. The NLP model for identify-ing PCL was applied to 1000 test samples. The interobserver agreement between the model and two radiologists was almost perfect (Fleiss k = 0.951), and the false-positive rate and true-positive rate were 3.0% and 98.2%, respectively, against consensus of radiolo-gists’ annotations as ground truths. The overall accuracy and Lin concordance correlation coefficient for measurement extraction were 0.958 and 0.874, respectively, against radiologists’ annotations as ground truths. Conclusion: An NLP-based system was developed that identifies patients with PCLs and extracts measurements from a large single-institution archive of free-text radiology reports. This approach may prove valuable to study the natural history and potential risks of PCLs and can be applied to many other use cases. © RSNA, 2022.","Abdomen/GI; Computer Applications-General (Informatics); Cysts; Informatics; Named Entity Recognition; Pancreas","Article; computer assisted tomography; controlled study; cystadenocarcinoma; diagnostic test accuracy study; electronic medical record; female; fine needle aspiration biopsy; follow up; health insurance; histopathology; history; human; information center; institutional review; intraductal papillary mucinous tumor; liver cell carcinoma; major clinical study; male; natural language processing; neuroendocrine tumor; nuclear magnetic resonance imaging; pancreas adenocarcinoma; pancreas cyst; Pancreatic Cystic Lesion; radiologist; retrospective study; sensitivity and specificity",Article,Scopus
"Zhang Y., Ou W., Zhang J., Deng J.","Category supervised cross-modal hashing retrieval for chest X-ray and radiology reports",2022,"Computers and Electrical Engineering",4,"10.1016/j.compeleceng.2021.107673","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123627014&doi=10.1016%2fj.compeleceng.2021.107673&partnerID=40&md5=eb2409233ae2b2ace9573a64e38a2875","With the wide application of radiography, massive data of chest X-ray and the associated radiology reports have been accumulated. Cross-modal retrieval between the chest X-ray and radiology reports is useful for the level of practicing radiologists and substantial other medical settings. However, existing cross-modal retrieval methods, which are mainly designed for the natural images, are not suitable for the chest X-ray images and radiology reports. In this paper, we propose a category supervised cross-modal hashing retrieval between chest X-ray and radiology reports, which learns the cross-modal similarity using a category supervised hashing network and union hashing network. Specifically, we design a category hashing network to learn hash code for each category, then use the learned category hash code as supervised information to guide the learning of images modality hash, texts modality hash. On the other hand, we propose the union hashing network to learn the correlation between two different modalities. Comprehensive experiments have been done on the public dataset MIMIC-CXR and the results show that the proposed method is on average 6.62% better than the traditional shallow method, achieved an increase of 0.57% compared to the deep cross-modal hashing (DCMH) in term of mAP. The ablation study is also implemented and the results demonstrates effectiveness of the proposed method. © 2022 Elsevier Ltd","Category supervised network; Chest X-ray; Cross-modal retrieval; Radiology reports; Union hashing network","Radiation; Radiology; X ray radiography; Category supervised network; Chest X-ray; Cross-modal; Cross-modal retrieval; Learn+; Massive data; Medical settings; Radiology reports; Supervised network; Union hashing network; Hash functions",Article,Scopus
"Sharifi H., Guenther Z.D., Leung A.N.C., Johnston L., Lai Y.K., Hsu J.L., Henry Guo H.","Head-to-head Comparison of Qualitative Radiologist Assessment with Automated Quantitative Computed Tomography Analysis for Bronchiolitis Obliterans Syndrome after Hematopoietic Cell Transplantation",2022,"Journal of Thoracic Imaging",3,"10.1097/RTI.0000000000000595","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107015718&doi=10.1097%2fRTI.0000000000000595&partnerID=40&md5=b0fb5fe48325db7d3252774795cc9cc4","Purpose: Computed tomography (CT) findings of bronchiolitis obliterans syndrome (BOS) can be nonspecific and variable. This study aims to measure the incremental value of automated quantitative lung CT analysis to clinical CT interpretation. A head-to-head comparison of quantitative CT lung density analysis by parametric response mapping (PRM) with qualitative radiologist performance in BOS diagnosis was performed. Materials and Methods: Inspiratory and end-expiratory CTs of 65 patients referred to a post-bone marrow transplant lung graft-versus-host-disease clinic were reviewed by 3 thoracic radiologists for the presence of mosaic attenuation, centrilobular opacities, airways dilation, and bronchial wall thickening. Radiologists' majority consensus diagnosis of BOS was compared with automated PRM air trapping quantification and to the gold-standard diagnosis of BOS as per National Institutes of Health (NIH) consensus criteria. Results: Using a previously established threshold of 28% air trapping on PRM, the diagnostic performance for BOS was as follows: sensitivity 56% and specificity 94% (area under the receiver operator curve [AUC]=0.75). Radiologist review of inspiratory CT images alone resulted in a sensitivity of 80% and a specificity of 69% (AUC=0.74). When radiologists assessed both inspiratory and end-expiratory CT images in combination, the sensitivity was 92% and the specificity was 59% (AUC=0.75). The highest performance was observed when the quantitative PRM report was reviewed alongside inspiratory and end-expiratory CT images, with a sensitivity of 92% and a specificity of 73% (AUC=0.83). Conclusions: In the CT diagnosis of BOS, qualitative expert radiologist interpretation was noninferior to quantitative PRM. The highest level of diagnostic performance was achieved by the combination of quantitative PRM measurements with qualitative image feature assessments. © 2021 Wolters Kluwer Health, Inc. All rights reserved.","Air trapping; Bronchiolitis obliterans syndrome; Hematopoietic stem cell transplant; Mosaic attenuation; Quantitative computed tomography","adult; airway; Article; bone marrow transplantation; bronchiolitis obliterans; cohort analysis; comparative study; computer assisted tomography; controlled study; diagnostic test accuracy study; diagnostic value; female; gold standard; graft versus host reaction; hematopoietic stem cell transplantation; human; lung; major clinical study; male; middle aged; quantitative analysis; radiologist; sensitivity and specificity; bronchiolitis obliterans; diagnostic imaging; lung transplantation; procedures; retrospective study; x-ray computed tomography; Bronchiolitis Obliterans; Hematopoietic Stem Cell Transplantation; Humans; Lung; Lung Transplantation; Radiologists; Retrospective Studies; Tomography, X-Ray Computed",Article,Scopus
"Kim E.Y., Kim Y.J., Choi W.-J., Jeon J.S., Kim M.Y., Oh D.H., Jin K.N., Cho Y.J.","Concordance rate of radiologists and a commercialized deep-learning solution for chest X-ray: Real-world experience with a multicenter health screening cohort",2022,"PLoS ONE",9,"10.1371/journal.pone.0264383","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125318690&doi=10.1371%2fjournal.pone.0264383&partnerID=40&md5=702b0a3344f48dfa9b8fb4942df21036","Purpose Lunit INSIGHT CXR (Lunit) is a commercially available deep-learning algorithm-based decision support system for chest radiography (CXR). This retrospective study aimed to evaluate the concordance rate of radiologists and Lunit for thoracic abnormalities in a multicenter health screening cohort. Methods and materials We retrospectively evaluated the radiology reports and Lunit results for CXR at several health screening centers in August 2020. Lunit was adopted as a clinical decision support system (CDSS) in routine clinical practice. Subsequently, radiologists completed their reports after reviewing the Lunit results. The DLA result was provided as a color map with an abnormality score (%) for thoracic lesions when the score was greater than the predefined cutoff value of 15%. Concordance was achieved when (a) the radiology reports were consistent with the DLA results (“accept”), (b) the radiology reports were partially consistent with the DLA results (“edit”) or had additional lesions compared with the DLA results (“add”). There was discordance when the DLA results were rejected in the radiology report. In addition, we compared the reading times before and after Lunit was introduced. Finally, we evaluated systemic usability scale questionnaire for radiologists and physicians who had experienced Lunit. Results Among 3,113 participants (1,157 men; mean age, 49 years), thoracic abnormalities were found in 343 (11.0%) based on the CXR radiology reports and 621 (20.1%) based on the Lunit results. The concordance rate was 86.8% (accept: 85.3%, edit: 0.9%, and add: 0.6%), and the discordance rate was 13.2%. Except for 479 cases (7.5%) for whom reading time data were unavailable (n = 5) or unreliable (n = 474), the median reading time increased after the clinical integration of Lunit (median, 19s vs. 14s, P < 0.001). Conclusion The real-world multicenter health screening cohort showed a high concordance of the chest X-ray report and the Lunit result under the clinical integration of the deep-learning solution. The reading time slight increased with the Lunit assistance. Copyright: © 2022 Kim et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,"adult; algorithm; article; clinical decision support system; clinical practice; cohort analysis; controlled study; deep learning; female; human; major clinical study; male; mass screening; middle aged; multicenter study; physician; questionnaire; radiologist; retrospective study; thorax radiography; usability; aged; clinical trial; mass screening; predictive value; procedures; thorax radiography; Aged; Cohort Studies; Deep Learning; Female; Humans; Male; Mass Screening; Middle Aged; Predictive Value of Tests; Radiography, Thoracic; Radiologists; Retrospective Studies",Article,Scopus
"Datta S., Roberts K.","Fine-grained spatial information extraction in radiology as two-turn question answering",2022,"International Journal of Medical Informatics",6,"10.1016/j.ijmedinf.2021.104628","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119901597&doi=10.1016%2fj.ijmedinf.2021.104628&partnerID=40&md5=5726a56567d92c4a3d9b20eda22dbfe2","Objectives: Radiology reports contain important clinical information that can be used to automatically construct fine-grained labels for applications requiring deep phenotyping. We propose a two-turn question answering (QA) method based on a transformer language model, BERT, for extracting detailed spatial information from radiology reports. We aim to demonstrate the advantage that a multi-turn QA framework provides over sequence-based methods for extracting fine-grained information. Methods: Our proposed method identifies spatial and descriptor information by answering queries given a radiology report text. We frame the extraction problem such that all the main radiology entities (e.g., finding, device, anatomy) and the spatial trigger terms (denoting the presence of a spatial relation between finding/device and anatomical location) are identified in the first turn. In the subsequent turn, various other contextual information that acts as important spatial roles with respect to a spatial trigger term are extracted along with identifying the spatial and other descriptor terms qualifying a radiological entity. The queries are constructed using separate templates for the two turns and we employ two query variations in the second turn. Results: When compared to the best-reported work on this task using a traditional sequence tagging method, the two-turn QA model exceeds its performance on every component. This includes promising improvements of 12, 13, and 12 points in the average F1 scores for identifying the spatial triggers, Figure, and Ground frame elements, respectively. Discussion: Our experiments suggest that incorporating domain knowledge in the query (a general description about a frame element) helps in obtaining better results for some of the spatial and descriptive frame elements, especially in the case of the clinical pre-trained BERT model. We further highlight that the two-turn QA approach fits well for extracting information for complex schema where the objective is to identify all the frame elements linked to each spatial trigger and finding/device/anatomy entity, thereby enabling the extraction of more comprehensive information in the radiology domain. Conclusion: Extracting fine-grained spatial information from text in the form of answering natural language queries holds potential in achieving better results when compared to more standard sequence labeling-based approaches. © 2021 Elsevier B.V.","Deep learning; Information extraction; Natural language processing; Question answering; Radiology report; Spatial information","Data mining; Deep learning; Domain Knowledge; Information retrieval; Query processing; Radiation; Radiology; Clinical information; Deep learning; Descriptors; Fine grained; Frame elements; Information extraction; Question Answering; Radiology reports; Spatial information extraction; Spatial informations; Natural language processing systems; anatomical location; article; deep learning; extraction; human; human experiment; natural language processing; radiology",Article,Scopus
"Yacoub B., Kabakus I.M., Schoepf U.J., Giovagnoli V.M., Fischer A.M., Wichmann J.L., Martinez J.D., Sharma P., Rapaka S., Sahbaee P., Hoelzer P., Burt J.R., Varga-Szemes A., Emrich T.","Performance of an Artificial Intelligence-Based Platform Against Clinical Radiology Reports for the Evaluation of Noncontrast Chest CT",2022,"Academic Radiology",6,"10.1016/j.acra.2021.02.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106240161&doi=10.1016%2fj.acra.2021.02.007&partnerID=40&md5=6567b129fc85a9b1de20617e61356e2a","Rationale and Objectives: Research on implementation of artificial intelligence (AI) in radiology workflows and its impact on reports remains scarce. In this study, we aim to assess if an AI platform would perform better than clinical radiology reports in evaluating noncontrast chest computed tomography (CT) scans. Materials and Methods: Consecutive patients who had undergone noncontrast chest CT were retrospectively identified. The radiology reports were reviewed in a binary fashion for reporting of pulmonary lesions, pulmonary emphysema, aortic dilatation, coronary artery calcifications (CAC), and vertebral compression fractures (VCF). CT scans were then processed using an AI platform. The reports’ findings and the AI results were subsequently compared to a consensus read by two board-certificated radiologists as reference. Results: A total of 100 patients (mean age: 64.2 ± 14.8 years; 57% males) were included in this study. Aortic segmentation and calcium quantification failed to be processed by AI in 2 and 3 cases, respectively. AI showed superior diagnostic performance in identifying aortic dilatation (AI: sensitivity: 96.3%, specificity: 81.4%, AUC: 0.89) vs (Reports: sensitivity: 25.9%, specificity: 100%, AUC: 0.63), p <0.001; and CAC (AI: sensitivity: 89.8%, specificity: 100, AUC: 0.95) vs (Reports: sensitivity: 75.4%, specificity: 94.9%, AUC: 0.85), p = 0.005. Reports had better performance than AI in identifying pulmonary lesions (Reports: sensitivity: 97.6%, specificity: 100%, AUC: 0.99) vs (AI: sensitivity: 92.8%, specificity: 82.4%, AUC: 0.88), p = 0.024; and VCF (Reports: sensitivity:100%, specificity: 100%, AUC: 1.0) vs (AI: sensitivity: 100%, specificity: 63.7%, AUC: 0.82), p <0.001. A comparable diagnostic performance was noted in identifying pulmonary emphysema on AI (sensitivity: 80.6%, specificity: 66.7%. AUC: 0.74) and reports (sensitivity: 74.2%, specificity: 97.1%, AUC: 0.86), p = 0.064. Conclusion: Our results demonstrate that incorporating AI support platforms into radiology workflows can provide significant added value to clinical radiology reporting. © 2021 The Association of University Radiologists","Artificial intelligence; Computed tomography, Radiology reports; Deep learning; Diagnostic performance","calcium; adult; aged; aortic disease; Article; artificial intelligence; chronic bronchitis; comparative study; compression fracture; computer assisted tomography; consensus; coronary artery calcification; data analysis software; diagnostic test accuracy study; diagnostic value; dyspnea; emphysema; female; follow up; human; lung cancer; lung emphysema; lung imaging reporting and data system; lung lesion; lung nodule; major clinical study; male; metastasis; pneumonia; predictive value; preoperative evaluation; quantitative diagnosis; radiologist; retrospective study; sarcoidosis; sensitivity and specificity; spine fracture; thorax injury; artificial intelligence; compression fracture; middle aged; procedures; radiology; spine fracture; x-ray computed tomography; Aged; Artificial Intelligence; Female; Fractures, Compression; Humans; Male; Middle Aged; Radiology; Retrospective Studies; Spinal Fractures; Tomography, X-Ray Computed",Article,Scopus
"Jungmann F., Kämpgen B., Hahn F., Wagner D., Mildenberger P., Düber C., Kloeckner R.","Natural language processing of radiology reports to investigate the effects of the COVID-19 pandemic on the incidence and age distribution of fractures",2022,"Skeletal Radiology",4,"10.1007/s00256-021-03760-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104653429&doi=10.1007%2fs00256-021-03760-5&partnerID=40&md5=1d88cbcf2aaa7f138c44f156c2bdca2a","Objective: During the COVID-19 pandemic, the number of patients presenting in hospitals because of emergency conditions decreased. Radiology is thus confronted with the effects of the pandemic. The aim of this study was to use natural language processing (NLP) to automatically analyze the number and distribution of fractures during the pandemic and in the 5 years before the pandemic. Materials and methods: We used a pre-trained commercially available NLP engine to automatically categorize 5397 radiological reports of radiographs (hand/wrist, elbow, shoulder, ankle, knee, pelvis/hip) within a 6-week period from March to April in 2015–2020 into “fracture affirmed” or “fracture not affirmed.” The NLP engine achieved an F1 score of 0.81 compared to human annotators. Results: In 2020, we found a significant decrease of fractures in general (p &lt; 0.001); the average number of fractures in 2015–2019 was 295, whereas it was 233 in 2020. In children and adolescents (p &lt; 0.001), and in adults up to 65 years (p = 0.006), significantly fewer fractures were reported in 2020. The number of fractures in the elderly did not change (p = 0.15). The number of hand/wrist fractures (p &lt; 0.001) and fractures of the elbow (p &lt; 0.001) was significantly lower in 2020 compared with the average in the years 2015–2019. Conclusion: NLP can be used to identify relevant changes in the number of pathologies as shown here for the use case fracture detection. This may trigger root cause analysis and enable automated real-time monitoring in radiology. © 2021, The Author(s).","Fracture; Natural language processing; Radiographs; Radiological reports; Radiology","adolescent; adult; age distribution; aged; ankle fracture; Article; automated real time monitoring; child; controlled study; coronavirus disease 2019; elbow fracture; female; fracture; hand fracture; hip fracture; human; incidence; information processing; knee fracture; major clinical study; male; natural language processing; natural language processing engine; pandemic; pelvis fracture; radiology; retrospective study; root cause analysis; shoulder fracture; wrist fracture; age distribution; incidence; natural language processing; pandemic; Adolescent; Age Distribution; Aged; Child; COVID-19; Humans; Incidence; Natural Language Processing; Pandemics; Radiology; SARS-CoV-2",Article,Scopus
"Syeda-Mahmood T., Shi L.","Searching for Fine-Grained Queries in Radiology Reports Using Similarity-Preserving Contrastive Embedding",2022,"Proceedings of Machine Learning Research",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164538166&partnerID=40&md5=89dd637d8c3bd93b9ab1d18978e16e24","The ability to search in unstructured reports of electronic health records requires tools that can recognize clinically meaningful fine-grained descriptions both in queries and in report sentences. Existing methods of searching reports that use either information retrieval or deep learning techniques to model use context, lack an inherent understanding of the clinical concepts or their variants that capture the same underlying clinical semantics. In this paper, we present a new search algorithm that combines principles of information retrieval and deep learning-driven textual encoding approaches with natural language analysis of sentences in reports for fine-grained descriptors of concepts. In particular, we learn a clinical similarity-preserving embedding from a chest X-ray lexicon using a new contrastive loss. This allows us to form a report index that is robust to different forms of expressing for clinical concepts in queries. The results show marked improvement in the quality of retrieved reports as judged through average recall and mean average precision over a broad range of difficult queries. © 2022 T. Syeda-Mahmood & L. Shi.",,"Deep learning; Embeddings; Information use; Semantics; Electronic health; Embeddings; Fine grained; Health records; Learning techniques; Model use; Radiology reports; Search Algorithms; Similarity preserving; Use context; Information retrieval",Conference Paper,Scopus
"Nehrer S., Meier P., DiFranco M.D., Bertalan Z., Ljuhar R.","AI in Musculoskeletal Radiology",2022,"Artificial Intelligence in Medicine",,"10.1007/978-3-030-64573-1_292","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158986846&doi=10.1007%2f978-3-030-64573-1_292&partnerID=40&md5=a2e7eabf913e3ffe529e6ff06a3e228e","Digitalization and artificial intelligence (AI) have reached orthopedics and traumatology. AI improves diagnostic accuracy in knee osteoarthritis according to the latest clinical guidelines and facilitates the (radiological) monitoring of the progression of various bone and joint diseases. AI makes it possible to detect early radiological signs and allows conclusionswith respect to progression of the disease and prognosis. By automating the report generation, patient throughput can be increased and the radiologist’s workload decreased. AI also reduces the impact of inter-rater variability in the assessment of radiographic X-ray morphologies and creates more standardized outcome measurements. © Springer Nature Switzerland AG 2022.","Artificial intelligence; Deep learning; Imaging digital data; Machine learning; Muscular skeletal disease; Neural networks",,Book Chapter,Scopus
"Kokina D.Yu., Gombolevskiy V.A., Arzamasov K.M., Andreychenko A.E., Morozov S.P.","Possibilities and limitations of using machine text-processing tools in Russian radiology reports",2022,"Digital Diagnostics",1,"10.17816/DD101099","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153930041&doi=10.17816%2fDD101099&partnerID=40&md5=e9248c2f0e09282c4935991128524938","Background: In radiology, important information can be found not only in medical images, but also in the accompanying text descriptions created by radiologists. Identification of study protocols containing certain data and extraction of these data can be useful primarily for clinical problems; however, given the large amount of such data, the development of machine analysis algorithms is necessary. Aim: To estimate the possibilities and limitations of using a tool for machine processing of radiology reports to search for pathological findings. Materials and Methods: To create an algorithm for automatic analysis of radiology reports, use cases were selected that participated in the experiment on the use of innovative technologies in the computer vision for the analysis of medical images in 2020. Mammography, chest X-ray, chest computed tomography (CT), and LDCT, were among the use cases performed in Moscow. A dictionary of keywords has been compiled. After the automatic marking of the reports by the developed tool, the results were assessed by a radiologist. The number of protocols analyzed by the radiologist for training and validation of the algorithms was 977 for mammography, 4,804 for all chest X-ray scans, 4,074 for chest CT, and 398 for chest LDCT. For the final testing of the developed algorithms, test datasets of 1,032 studies for mammography, 544 for chest X-ray, 5,000 for CT of the chest, and 1,082 studies for the LDCT of the chest were additionally labeled. Results: The best results were achieved in the search for viral pneumonia in chest CT reports (accuracy 0.996, sensitivity 0.998, and specificity 0.989) and breast cancer in mammography reports (accuracy 1.0, sensitivity 1.0, and specificity 1.0). When searching for signs of lung cancer by the algorithm, the metrics were as follows: accuracy 0.895, sensitivity 0.829, and specificity 0.936, when searching for pathological changes in the chest organs in radiography and fluorography protocols (accuracy 0.912, sensitivity 1.000, and specificity 0.844). Conclusions: Machine methods with high accuracy can be used to automatically classify the radiology reports of mammography and chest CT with viral pneumonia. The achieved accuracy is sufficient for successful application to automatically compare the conclusions of physicians and artificial intelligence models when searching for signs of lung cancer in chest CT and LDCT, pathological findings in chest X-ray. © 2022, Eco-Vector LLC. All rights reserved.","breast cancer; COVID-19 pneumonia; lung cancer; natural language processing; radiology reports",,Article,Scopus
"You J., Li D., Okumura M., Suzuki K.","JPG - Jointly Learn to Align: Automated Disease Prediction and Radiology Report Generation",2022,"Proceedings - International Conference on Computational Linguistics, COLING",1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153743081&partnerID=40&md5=9c9f6f490d8089cd63c3d3e41e07f3cb","Automated radiology report generation aims to generate paragraphs that describe fine-grained visual differences among cases, especially those between the normal and the diseased. Existing methods seldom consider the cross-modal alignment between textual and visual features and tend to ignore disease tags as an auxiliary for report generation. To bridge the gap between textual and visual information, in this study, we propose a “Jointly learning framework for automated disease Prediction and radiology report Generation (JPG)” to improve the quality of reports through the interaction between the main task (report generation) and two auxiliary tasks (feature alignment and disease prediction). The feature alignment and disease prediction help the model learn text-correlated visual features and record diseases as keywords so that it can output high-quality reports. Besides, the improved reports in turn provide additional harder samples for feature alignment and disease prediction to learn more precise visual and textual representations and improve prediction accuracy. All components are jointly trained in a manner that helps improve them iteratively and progressively. Experimental results demonstrate the effectiveness of JPG on the most commonly used IU X-RAY dataset, showing its superior performance over multiple state-of-the-art image captioning and medical report generation methods with regard to BLEU, METEOR, and ROUGE metrics. © 2022 Proceedings - International Conference on Computational Linguistics, COLING. All rights reserved.",,"Automation; Computational linguistics; Iterative methods; Medical imaging; Radiology; Cross-modal; Feature alignment; Fine grained; Learn+; Radiology reports; Report generation; Textual features; Textual information; Visual differences; Visual feature; Forecasting",Conference Paper,Scopus
"Sehanobish A., Kannan K., Abraham N., Das A., Odry B.","Meta-learning Pathologies from Radiology Reports using Variance Aware Prototypical Networks",2022,"EMNLP 2022 - Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing: Industry Track",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152949294&partnerID=40&md5=3df92b7a145d890ddf1cdbb30b775eb4","Large pretrained Transformer-based language models like BERT and GPT have changed the landscape of Natural Language Processing (NLP). However, fine tuning such models still requires a large number of training examples for each target task, thus annotating multiple datasets and training these models on various downstream tasks becomes time consuming and expensive. In this work, we propose a simple extension of the Prototypical Networks for few-shot text classification. Our main idea is to replace the class prototypes by Gaussians and introduce a regularization term that encourages the examples to be clustered near the appropriate class centroids. Experimental results show that our method outperforms various strong baselines on 13 public and 4 internal datasets. Furthermore, we use the class distributions as a tool for detecting potential out-of-distribution (OOD) data points during deployment. © 2022 Association for Computational Linguistics.",,"Classification (of information); Computational linguistics; Natural language processing systems; Text processing; Down-stream; Fine tuning; Language model; Language processing; Metalearning; Multiple data sets; Natural languages; Radiology reports; Simple++; Training example; Large dataset",Conference Paper,Scopus
"Qomariyah N.N., Araminta A.S., Reynaldi R., Senjaya M., Asri S.D.A., Kazakov D.","NLP Text Classification for COVID-19 Automatic Detection from Radiology Report in Indonesian Language",2022,"2022 5th International Seminar on Research of Information Technology and Intelligent Systems, ISRITI 2022",1,"10.1109/ISRITI56927.2022.10053077","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150224669&doi=10.1109%2fISRITI56927.2022.10053077&partnerID=40&md5=221caec10c7b35c91995193f6f145183","Radiology is used as an important assessment for patients with pulmonary disease. The radiology images are usually accompanied by a written report from a radiologist to be passed to the other referring physicians. These radiology reports are written in a natural language where they can have different systematic structures based on the language used. In our study, the radiology reports were collected from an Indonesian hospital and written in Bahasa Indonesia. We performed an automatic text classification to differentiate the information written in the radiology reports into two classes, COVID-19 and non COVID-19. To find the best model, we evaluated several embedding techniques available for Bahasa and five Machine Learning (ML) models, namely (1) XGBoost, (2) fastText, (3) LSTM, (4) Bi-LSTM and (5) IndoBERT. The result shows that IndoBERT outperformed the others with an accuracy of 98%. In terms of training speed, the shallow neural network architecture implemented with the fastText library can train the model in under one second and still result in a reasonably good accuracy of 86%. © 2022 IEEE.","COVID-19; deep learning; Natural Language Processing; text classification; word embedding","Classification (of information); Embeddings; Long short-term memory; Natural language processing systems; Network architecture; Radiology; Text processing; Automatic Detection; Deep learning; Embeddings; Indonesian languages; Language processing; Natural language processing; Natural languages; Radiology reports; Text classification; Word embedding; COVID-19",Conference Paper,Scopus
"Ramesh V., Chi N.A., Rajpurkar P.","Improving radiology report generation systems by removing hallucinated references to non-existent priors",2022,"Proceedings of Machine Learning Research",5,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150171660&partnerID=40&md5=c9fbed8c7b0f83e85ba93fee3cd9c4c8","Current deep learning models trained to generate radiology reports from chest radiographs are capable of producing clinically accurate, clear, and actionable text that can advance patient care. However, such systems all succumb to the same problem: making hallucinated references to non-existent prior reports. Such hallucinations occur because these models are trained on datasets of realworld patient reports that inherently refer to priors. To this end, we propose two methods to remove references to priors in radiology reports: (1) a GPT-3-based few-shot approach to rewrite medical reports without references to priors; and (2) a BioBERT-based token classification approach to directly remove words referring to priors. We use the aforementioned approaches to modify MIMIC-CXR, a publicly available dataset of chest X-rays and their associated free-Text radiology reports; we then retrain CXR-RePaiR, a radiology report generation system, on the adapted MIMIC-CXR dataset. We find that our re-Trained model-which we call CXR-ReDonE-outperforms previous report generation methods on clinical metrics, achieving an average BERTScore of 0.2351 (2.57% absolute improvement). We expect our ap- These authors contributed equally proach to be broadly valuable in enabling current radiology report generation systems to be more directly integrated into clinical pipelines. © 2022 P.N. Argaw, E. Healey & I.S. Kohane.","Free-Text radiology reports; Generation; Large language models; References to priors; Retrieval","Radiology; Free texts; Free-text radiology report; Generation; Generation systems; Language model; Large language model; Radiology reports; Reference to prior; Report generation; Retrieval; Deep learning",Conference Paper,Scopus
"Delbrouck J.-B., Chambon P., Bluethgen C., Tsai E., Almusa O., Langlotz C.P.","Improving the Factual Correctness of Radiology Report Generation with Semantic Rewards",2022,"Findings of the Association for Computational Linguistics: EMNLP 2022",6,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149886677&partnerID=40&md5=e29d2c7067eed528326c0264a089c569","Neural image-to-text radiology report generation systems offer the potential to improve radiology reporting by reducing the repetitive process of report drafting and identifying possible medical errors. These systems have achieved promising performance as measured by widely used NLG metrics such as BLEU and CIDEr. However, the current systems face important limitations. First, they present an increased complexity in architecture that offers only marginal improvements on NLG metrics. Secondly, these systems that achieve high performance on these metrics are not always factually complete or consistent due to both inadequate training and evaluation. Recent studies have shown the systems can be substantially improved by using new methods encouraging 1) the generation of domain entities consistent with the reference and 2) describing these entities in inferentially consistent ways. So far, these methods rely on weakly-supervised approaches (rule-based) and named entity recognition systems that are not specific to the chest X-ray domain. To overcome this limitation, we propose a new method, the RadGraph reward, to further improve the factual completeness and correctness of generated radiology reports. More precisely, we leverage the RadGraph dataset containing annotated chest X-ray reports with entities and relations between entities. On two open radiology report datasets, our system substantially improves the scores up to 14.2% and 25.3% on metrics evaluating the factual correctness and completeness of reports. © 2022 Association for Computational Linguistics.",,"Computational linguistics; Image enhancement; Medical imaging; Natural language processing systems; Radiology; Current system; Domain entities; Generation systems; Medical errors; Performance; Radiology reporting; Radiology reports; Repetitive process; Report generation; Rule based; Semantics",Conference Paper,Scopus
"Yu H., Zhang Q.","Clinically Coherent Radiology Report Generation with Imbalanced Chest X-rays",2022,"Proceedings - 2022 IEEE International Conference on Bioinformatics and Biomedicine, BIBM 2022",,"10.1109/BIBM55620.2022.9994871","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146671819&doi=10.1109%2fBIBM55620.2022.9994871&partnerID=40&md5=52af3379cff4bf3b8425cb3286703efb","Automatically generating radiology reports given radiographs has considerable promise for easing clinical workflows, reducing diagnostic errors, and ultimately streamlining clinical care. Therefore, this work has attracted much attention and early studies mainly employed cutting-edge techniques from computer vision and natural language generation to improve the readability of generated reports. However, those methods often fail to accurately convey critical information such as the presence status of disease, which is the first priority of medical image-to-text generation. Additionally, the class imbalance issues are frequently found in a number of radiographic datasets, resulting in missed diagnosis of some uncommon diseases. In this manuscript, we propose a clinically coherent radiology report generation method that introduces an additional memory-enhanced feature-wise affine transformation (MFAT) layer and an imbalance-aware clinically accurate reward (ICAR) to tackle the aforementioned issues. We evaluate the proposed method by comparing with state-of-the-art methods over both natural language generation (NLG) metrics and clinical efficacy results on two datasets, namely IU X-Ray and MIMIC-CXR. The results demonstrate that our method achieves significantly higher clinical efficacy accuracy for both common or uncommon disease annotations while still maintaining acceptably high NLG metrics for readability. © 2022 IEEE.","Chest X-ray; Encoder-decoder; Imbalance-aware clinically accurate reward; Memory-enhanced feature-wise affine transformation; Radiology report generation","Diagnosis; Natural language processing systems; Radiology; Signal encoding; Affine transformations; Chest X-ray; Clinical efficacy; Encoder-decoder; Imbalance-aware clinically accurate reward; Memory-enhanced feature-wise affine transformation; Natural language generation; Radiology report generation; Radiology reports; Report generation; Medical imaging",Conference Paper,Scopus
"Jia X., Xiong Y., Zhang J., Zhang Y., Zhu Y., Yu P.S.","Few-Shot Radiology Report Generation via Knowledge Transfer and Multi-modal Alignment",2022,"Proceedings - 2022 IEEE International Conference on Bioinformatics and Biomedicine, BIBM 2022",,"10.1109/BIBM55620.2022.9995533","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146649065&doi=10.1109%2fBIBM55620.2022.9995533&partnerID=40&md5=1bcf807e57e820baf59443656e5b39d1","Automatic radiology report generation aims at generating informative text from the given medical image, which could assist diagnosis and lighten the workload of radiologists. While some models have been proposed to study on this task, few of them paid attention to the radiology report generation for rare diseases, except for RareGen which solved this problem by enhancing the semantic representations of rare diseases. However, there still exist several problems to be addressed. The first lies in that modeling the correlations among diseases by current studies can result in the problem of frequency bias, which can affect the detection of rare diseases. The second lies in that how to get better representations of disease regions, so as to benefit their corresponding report generation in the decoding stage. To tackle these challenges, we propose a new few-shot radiology report generation model, namely FS-Gen. FS-Gen is assembled with one module for more effective detection of rare diseases in the encoding stage, and the other module for the better representation generation of disease regions in the decoding stage. Specifically, in the encoding stage, a cascade visual enhancement module is proposed to strengthen the correlations among diseases, without incurring the problem of frequency bias. On the other hand, in the decoding stage, a co-referential aligned topic generation module is introduced to simultaneously capture the location and semantic information of disease regions, by aligning the multimodal representations. Extensive experiments are conducted on real-world medical image datasets to demonstrate the effectiveness of our model. © 2022 IEEE.","Bioinformatics; deep learning; few-shot learning; report generation","Decoding; Deep learning; Diagnosis; Encoding (symbols); Knowledge management; Medical imaging; Radiology; Semantics; Signal encoding; Deep learning; Encodings; Few-shot learning; Frequency bias; Knowledge transfer; Multi-modal; Radiology reports; Rare disease; Report generation; Semantic representation; Diseases",Conference Paper,Scopus
"Qomariyah N.N., Sun T., Kazakov D.","NLP Analysis of COVID-19 Radiology Reports in Indonesian using IndoBERT",2022,"IBIOMED 2022 - Proceedings of the 2022 4th International Conference on Biomedical Engineering",,"10.1109/IBIOMED56408.2022.9988223","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146434487&doi=10.1109%2fIBIOMED56408.2022.9988223&partnerID=40&md5=21c1b8cd2869d0e3cc62fd75a2904370","The presence of COVID-19, a respiratory disease, can be detected through medical imaging, such as Chest X-Ray (CXR) and Computed Tomography (CT) scans. These radiology images can also show how the patient's condition progresses. Radiologists need to provide a written report for each image, so that other clinicians can use it in their decision making. In this study, we applied one of the Natural Language Processing (NLP) models called IndoBERT to analyze radiology reports of COVID-19 patients written in Indonesian. We performed two tasks, clustering to group reports by meaning and understand their content, and text classification to predict one of the five possible outcomes for each patient. We show the most frequent topics in radiology reports, and word scores in each topic. The IndoBERT model was fine tuned on a medical text, 'Kamus Kedokteran Dorland' in an attempt to further improve it. This proved unnecessary: on one hand, there were no additional benefits, on the other, the standard model alone achieved a very satisfactory classification accuracy of over 90 %. © 2022 IEEE.","COVID-19; IndoBERT; Indonesian language; medical outcome prediction; narrative text; Natural language processing","Classification (of information); Computerized tomography; Decision making; Medical imaging; Natural language processing systems; Radiology; Text processing; Computed tomography scan; IndoBERT; Indonesian languages; Language processing; Medical outcome prediction; Narrative text; Natural language processing; Natural languages; Outcome prediction; Radiology reports; COVID-19",Conference Paper,Scopus
"Shang C., Cui S., Li T., Wang X., Li Y., Jiang J.","MATNet: Exploiting Multi-Modal Features for Radiology Report Generation",2022,"IEEE Signal Processing Letters",,"10.1109/LSP.2022.3229844","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146215632&doi=10.1109%2fLSP.2022.3229844&partnerID=40&md5=a0f08f5bff981b74921650adc5904da6","Medical imaging is widely used in hospital clinical workflows. Assisting physicians in diagnosis by automatically generating reports from radiological images is an unmet clinical demand and requires urgent attention. However, this task suffers from two significant problems: 1) visual and textual data biases, and 2) the Transformer decoder makes no distinction between visual and non-visual words. We propose a novel multi-task approach combining natural language processing with machine learning techniques to meet this clinical need, i.e., creating fluent and accurate radiology reports. We name our system as Multi-modal Adaptive Transformer (MATNet), which consists of three key modules. First, Multi-Modal Encoder (MME) explores the relationship between radiology images and clinical notes. Second, Disease Classifier (DC) classifies the states of each disease topic and provides state-aware disease embeddings to alleviate visual data bias. Last, Adaptive Decoder (AD) dynamically measures the contribution of source signals and target signals when generating the next word. Based on our evaluations using benchmark IU-XRay and MIMIC-CXR datasets, the proposed MATNet outperformed previous state-of-the-art models on language fluency and clinical accuracy metrics such as BLEU scores. © 1994-2012 IEEE.","medical image processing; multi-modal learning; Radiology report generation","Decoding; Diagnosis; Feature extraction; Learning systems; Medical imaging; Natural language processing systems; Decoding; Features extraction; Medical images processing; MIMIC; Multi-modal; Multi-modal learning; Radiology report generation; Radiology reports; Report generation; Transformer; Radiology",Article,Scopus
"Leonardi G., Portinale L., Santomauro A.","A multimodal approach to automated generation of radiology reports using contrastive learning",2022,"CEUR Workshop Proceedings",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145606338&partnerID=40&md5=9d6219c6c4cd5b9cc8527aded1e4a61e","In the present paper, we present a preliminary and ongoing work concerning the problem of generating a suitable diagnostic report from radiology (x-ray) images. The task is tackled with a contrastive learning approach, where radiology images and textual reports are embedded in a common space, with the goal of getting similar (close in space) embeddings between a given image and the corresponding report. Once the embeddings for an image and the corresponding textual report are generated (through suitable fine-tuned models), we propose to feed them to a contrastive learning engine in such a way that image and textual embeddings are pushed close in the embedding space if image and text are related, while they are moved away otherwise. Preliminary analysis shows promising results in terms of effectiveness of the contrastive learning approach, but also suggest relevant issues to be investigated such as the importance of context and the role of suitable encoder/decoder modules to properly deal with the textual generation. © 2022 Copyright for this paper by its authors.","automated radiology report generation; contrastive learning; Multimodal machine learning","Machine learning; Radiology; Automated radiology report generation; Contrastive learning; Embeddings; Learning approach; Machine-learning; Multi-modal; Multi-modal approach; Multimodal machine learning; Radiology reports; Report generation; Embeddings",Conference Paper,Scopus
"Khoruzhaya А.N., Kozlov D.V., Arzamasov К.M., Kremneva E.I.","Text Analysis of Radiology Reports with Signs of Intracranial Hemorrhage on Brain CT Scans Using the Decision Tree Algorithm",2022,"Sovremennye Tehnologii v Medicine",,"10.17691/stm2022.14.6.04","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145208332&doi=10.17691%2fstm2022.14.6.04&partnerID=40&md5=52a8a712c7f04e3bbdfca21faf2ed0f7","The aim of the study is to create, train, and test the algorithm for the analysis of brain CT text reports using a decision tree model to solve the task of simple binary classification of presence/absence of intracranial hemorrhage (ICH) signs. Materials and Methods. The initial data is a download from the Unified Radiological Information Service of the Unified Medical Information and Analytical System (URIS UMIAS) containing 34,188 studies obtained by a non-contrast CT of the brain in 56 inpatient medical settings. Data analysis and preprocessing were carried out using NLTK (Natural Language Toolkit, version 3.6.5), a library for symbolic and statistical processing of natural language, and scikit-learn, a machine learning library containing tools for classification tasks. According to 14 selected ICH-related key words, as well as 33 stop-phrases with key words denoting absence of ICH, an automatic selection of the CT investigations and their subsequent expert verification were carried out. Two classes of investigations were formed based on the sample from 3980 protocol descriptions: containing descriptions of ICH and without them. The problem of binary classification was solved using the decision tree algorithm as a model. To evaluate the performance of the model, the CT investigations were divided randomly into samples in the ratio of 7:3. Of 3980 protocols, 2786 were assigned to the training data set, 1194 — to the test one. Results. According to the test results, the designed and trained algorithm in the binary classification of the CT reports “with signs of ICH” and “without signs of ICH” has shown sensitivity of 0.94, specificity of 0.88, F-score of 0.83. Conclusion. The developed and trained algorithm for the analysis of radiology reports has demonstrated high accuracy in relation to brain CT with signs of intracranial hemorrhage and can be used to solve binary classification problems and create appropriate data sets. However, it is limited by the need for manual revision of CT studies to ensure quality control. © 2022, Privolzhsky Research Medical University. All rights reserved.","computed tomography; decision tree algorithm; diagnostic reports; intracranial hemorrhage; machine learning; natural language processing","adult; aged; Article; binary classification; brain hemorrhage; cerebrovascular disease; clinical assessment; computer assisted tomography; controlled study; decision tree; diagnostic accuracy; diagnostic test accuracy study; epidural hemorrhage; female; human; machine learning; major clinical study; male; radiologist; randomized controlled trial; sensitivity and specificity; skull fracture; subarachnoid hemorrhage; subdural hematoma; algorithm; brain; brain hemorrhage; decision tree; diagnostic imaging; natural language processing; procedures; radiology; x-ray computed tomography; Algorithms; Brain; Decision Trees; Humans; Intracranial Hemorrhages; Natural Language Processing; Radiology; Tomography, X-Ray Computed",Article,Scopus
"Abela B., Abu-Khalaf J., Yang C.-W.R., Masek M., Gupta A.","Automated Radiology Report Generation Using a Transformer-Template System: Improved Clinical Accuracy and an Assessment of Clinical Safety",2022,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"10.1007/978-3-031-22695-3_37","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144822763&doi=10.1007%2f978-3-031-22695-3_37&partnerID=40&md5=aea9163de8138499c652489abaa611f0","Radiologists are required to write a descriptive report for each examination they perform which is a time-consuming process. Deep-learning researchers are developing models to automate this process. Currently, the most researched architecture for this task is the encoder-decoder (E-D). An issue with this approach is that these models are optimised to produce output that is more coherent and grammatically correct rather than clinically correct. The current study considers this and instead builds upon a more recent approach that generates reports using a multi-label classification model attached to a Template-based Report Generation (TRG) subsystem. In the current study two TRG models that utilise either a Transformer or CNN classifier are produced and directly compared to the most clinically accurate E-D in the literature at the time of writing. The models were trained using the MIMIC-CXR dataset, a public set of 473,057 chest X-rays and 206,563 corresponding reports. Precision, recall and F1 scores were obtained by applying a rule-based labeller to the MIMIC-CXR reports, applying those labels to the corresponding images, and then using the labeller on the generated reports. The TRG models outperformed the E-D model for clinical accuracy with the largest difference being the recall rate (T-TRG: Precision 0.38, Recall 0.58, F1 0.45; CNN-TRG: Precision 0.34, Recall 0.69, F1 0.42; E-D: Precision 0.38, Recall 0.14, F1 0.19). Examination of the quantitative metrics for each specific abnormality combined with the qualitative assessment concludes that significant progress still needs to be made before clinical integration is safe. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","CNN; Deep learning; Encoder-decoder; Medical imaging; Medical text; Templates; Transformer","Classification (of information); Decoding; Deep learning; Learning systems; Signal encoding; 'current; Deep learning; Encoder-decoder; Medical text; Multi-label classifications; Radiology reports; Report generation; Template; Template-based; Transformer; Medical imaging",Conference Paper,Scopus
"Datta S., Lam H.C., Pajouhi A., Mogalla S., Roberts K.","A Cross-document Coreference Dataset for Longitudinal Tracking across Radiology Reports",2022,"2022 Language Resources and Evaluation Conference, LREC 2022",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144432967&partnerID=40&md5=b51eff438949166bc22e4ccbc1f999ce","This paper proposes a new cross-document coreference resolution (CDCR) dataset for identifying co-referring radiological findings and medical devices across a patient's radiology reports. Our annotated corpus contains 5872 mentions (findings and devices) spanning 638 MIMIC-III radiology reports across 60 patients, covering multiple imaging modalities and anatomies. There are a total of 2292 mention chains. We describe the annotation process in detail, highlighting the complexities involved in creating a sizable and realistic dataset for radiology CDCR. We apply two baseline methods-string matching and transformer language models (BERT)-to identify cross-report coreferences. Our results indicate the requirement of further model development targeting better understanding of domain language and context to address this challenging and unexplored task. This dataset can serve as a resource to develop more advanced natural language processing CDCR methods in the future. This is one of the first attempts focusing on CDCR in the clinical domain and holds potential in benefiting physicians and clinical research through long-term tracking of radiology findings. © European Language Resources Association (ELRA), licensed under CC-BY-NC-4.0.","cross-document coreference resolution; radiology; tracking","Clinical research; Natural language processing systems; Baseline methods; Coreference resolution; Cross document coreference; Cross-document coreference resolution; Medical Devices; Multiple imaging modality; Radiological findings; Radiology reports; String matching; Tracking; Radiology",Conference Paper,Scopus
"Soni S., Gudala M., Pajouhi A., Roberts K.","RadQA: A Question Answering Dataset to Improve Comprehension of Radiology Reports",2022,"2022 Language Resources and Evaluation Conference, LREC 2022",2,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144397508&partnerID=40&md5=e665fb222233cf6a9d182c1e11c4532b","We present a radiology question answering dataset, RadQA, with 3074 questions posed against radiology reports and annotated with their corresponding answer spans (resulting in a total of 6148 question-answer evidence pairs) by physicians. The questions are manually created using the clinical referral section of the reports that take into account the actual information needs of ordering physicians and eliminate bias from seeing the answer context (and, further, organically create unanswerable questions). The answer spans are marked within the Findings and Impressions sections of a report. The dataset aims to satisfy the complex clinical requirements by including complete (yet concise) answer phrases (which are not just entities) that can span multiple lines. We conduct a thorough analysis of the proposed dataset by examining the broad categories of disagreement in annotation (providing insights on the errors made by humans) and the reasoning requirements to answer a question (uncovering the huge dependence on medical knowledge for answering the questions). The advanced transformer language models achieve the best F1 score of 63.55 on the test set, however, the best human performance is 90.31 (with an average of 84.52). This demonstrates the challenging nature of RadQA that leaves ample scope for future method research. © European Language Resources Association (ELRA), licensed under CC-BY-NC-4.0.","clinical notes; machine reading comprehension; question answering; radiology reports","Natural language processing systems; Clinical notes; F1 scores; Human performance; Language model; Machine reading comprehension; Medical knowledge; Question Answering; Radiology reports; Reading comprehension; Test sets; Radiology",Conference Paper,Scopus
"Santos G.N.M., da Silva H.E.C., Figueiredo P.T.S., Mesquita C.R.M., Melo N.S., Stefani C.M., Leite A.F.","The Introduction of Artificial Intelligence in Diagnostic Radiology Curricula: a Text and Opinion Systematic Review",2022,"International Journal of Artificial Intelligence in Education",,"10.1007/s40593-022-00324-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143651011&doi=10.1007%2fs40593-022-00324-z&partnerID=40&md5=9b0775b53089611a43f6e124a50da7f8","Background: Artificial intelligence (AI) is able to emulate human performance on a task and may improve the radiologists’ work. This text and opinion review explored the implementation of AI in diagnostic radiology education curricula at pre-licensure training/education in healthcare. The question was: what are the pedagogical possibilities, advantages and challenges of AI use in diagnostic radiology education? Methods: Primary research studies, reviews, systematic reviews, meta-analyses, letters, texts, expert opinions, expert consensus, discussion papers and guidelines about diagnostic radiology education at the undergraduate and postgraduate levels of any field of health sciences were considered. Searches were conducted on indexed databases and grey literature. Data on the context, potentials and challenges were collected from the text and opinion papers and the Joanna Briggs Institute (JBI) Critical Appraisal Checklist for Text and Opinion Papers was applied to assess methodological quality. From the experience papers, intervention, experiences and results were extracted parameters and an adapted JBI Critical Appraisal Checklist for Case Reports was applied. Results: Seventeen studies met the inclusion criteria. Personalization, training facilities and the standardization of radiology teaching were the main potentials identified. Five main challenges were also observed: the validation of AI tools in radiology education, the learning curve, universities’ aptitude to teach AI, the digitization of radiological images and how to include AI in radiology curricula. Conclusion: The necessity to update radiology curricula to include AI is a consensus. Time is required for development of the learning curve among AI developers, teachers and trainees. When and to what extent AI should be taught in radiology courses needs further exploration. © 2022, International Artificial Intelligence in Education Society.","Artificial Intelligence; Curriculum; Education; Machine Learning; Radiology","Machine learning; Paper; Radiology; Diagnostic radiology; Education curriculums; Expert opinion; Human performance; Learning curves; Machine-learning; Meta-analysis; Post-graduate levels; Research studies; Systematic Review; Curricula",Article,Scopus
"Yan S.","Memory-aligned Knowledge Graph for Clinically Accurate Radiology Image Report Generation",2022,"Proceedings of the Annual Meeting of the Association for Computational Linguistics",2,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143263380&partnerID=40&md5=84ffa813dea0931e770a76ded1dafdc1","Automatic generating the clinically accurate radiology report from X-ray images is important but challenging. The identification of multi-grained abnormal regions in image and corresponding abnormalities is difficult for data-driven neural models. In this work, we introduce a Memory-aligned Knowledge Graph (MaKG) of clinical abnormalities to better learn the visual patterns of abnormalities and their relationships by integrating it into a deep model architecture for the report generation. We carry out extensive experiments and show that the proposed MaKG deep model can improve the clinical accuracy of the generated reports. © 2022 Association for Computational Linguistics.",,"Computational linguistics; Natural language processing systems; Radiation; Radiology; Data driven; Knowledge graphs; Learn+; Modeling architecture; Neural modelling; Radiology reports; Report generation; Visual pattern; X-ray image; Knowledge graph",Conference Paper,Scopus
"Qin H., Song Y.","Reinforced Cross-modal Alignment for Radiology Report Generation",2022,"Proceedings of the Annual Meeting of the Association for Computational Linguistics",8,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143262211&partnerID=40&md5=c2e01fdc114c23615cce9f8686f090a6","Medical images are widely used in clinical decision-making, where writing radiology reports is a potential application that can be enhanced by automatic solutions to alleviate physicians' workload. In general, radiology report generation is an image-text task, where cross-modal mappings between images and texts play an important role in generating high-quality reports. Although previous studies attempt to facilitate the alignment via the co-attention mechanism under supervised settings, they suffer from lacking valid and accurate correspondences due to no annotation of such alignment. In this paper, we propose an approach with reinforcement learning (RL) over a cross-modal memory (CMM) to better align visual and textual features for radiology report generation. In detail, a shared memory is used to record the mappings between visual and textual information, and the proposed reinforced algorithm is performed to learn the signal from the reports to guide the cross-modal alignment even though such reports are not directly related to how images and texts are mapped. Experimental results on two English radiology report datasets, i.e., IU X-Ray and MIMIC-CXR, show the effectiveness of our approach, where the state-of-the-art results are achieved. We further conduct human evaluation and case study which confirm the validity of the reinforced algorithm in our approach.. © 2022 Association for Computational Linguistics.",,"Computational linguistics; Decision making; Image enhancement; Mapping; Medical imaging; Radiation; Radiology; Reinforcement; Reinforcement learning; Attention mechanisms; Clinical decision making; Cross-modal; High quality; Image texts; Quality report; Radiology reports; Reinforcement learnings; Report generation; Visual feature; Alignment",Conference Paper,Scopus
"Hu J., Li Z., Chen Z., Li Z., Wan X., Chang T.-H.","Graph Enhanced Contrastive Learning for Radiology Findings Summarization",2022,"Proceedings of the Annual Meeting of the Association for Computational Linguistics",9,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143055867&partnerID=40&md5=ed11b1ad5987b3931548567ec2d33e55","The impression section of a radiology report summarizes the most prominent observation from the findings section and is the most important section for radiologists to communicate to physicians. Summarizing findings is time-consuming and can be prone to error for inexperienced radiologists, and thus automatic impression generation has attracted substantial attention. With the encoder-decoder framework, most previous studies explore incorporating extra knowledge (e.g., static pre-defined clinical ontologies or extra background information). Yet, they encode such knowledge by a separate encoder to treat it as an extra input to their models, which is limited in leveraging their relations with the original findings. To address the limitation, we propose a unified framework for exploiting both extra knowledge and the original findings in an integrated way so that the critical information (i.e., key words and their relations) can be extracted in an appropriate way to facilitate impression generation. In detail, for each input findings, it is encoded by a text encoder, and a graph is constructed through its entities and dependency tree. Then, a graph encoder (e.g., graph neural networks (GNNs)) is adopted to model relation information in the constructed graph. Finally, to emphasize the key words in the findings, contrastive learning is introduced to map positive samples (constructed by masking non-key words) closer and push apart negative ones (constructed by masking key words). The experimental results on OpenI and MIMIC-CXR confirm the effectiveness of our proposed method. © 2022 Association for Computational Linguistics.",,"Computational linguistics; Graph neural networks; Knowledge management; Radiology; Signal encoding; Trees (mathematics); Background information; Dependency trees; Encoder-decoder; Graph neural networks; Key words; Modeling relations; Ontology's; Radiology reports; Relation information; Unified framework; Radiation",Conference Paper,Scopus
"Demir K.C., May M., Schmid A., Uder M., Breininger K., Weise T., Maier A., Yang S.H.","PoCaP Corpus: A Multimodal Dataset for Smart Operating Room Speech Assistant Using Interventional Radiology Workflow Analysis",2022,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",2,"10.1007/978-3-031-16270-1_38","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139078519&doi=10.1007%2f978-3-031-16270-1_38&partnerID=40&md5=f78bf34d89f9d9d922d63333f5fe11d8","This paper presents a new multimodal interventional radiology dataset, called PoCaP (Port Catheter Placement) Corpus. This corpus consists of speech and audio signals in German, X-ray images, and system commands collected from 31 PoCaP interventions by six surgeons with average duration of 81.4 ± 41.0 min. The corpus aims to provide a resource for developing a smart speech assistant in operating rooms. In particular, it may be used to develop a speech-controlled system that enables surgeons to control the operation parameters such as C-arm movements and table positions. In order to record the dataset, we acquired consent by the institutional review board and workers’ council in the University Hospital Erlangen and by the patients for data privacy. We describe the recording set-up, data structure, workflow and preprocessing steps, and report the first PoCaP Corpus speech recognition analysis results with 11.52% word error rate using pretrained models. The findings suggest that the data has the potential to build a robust command recognition system and will allow the development of a novel intervention support systems using speech and image processing in the medical domain. © 2022, Springer Nature Switzerland AG.","Automatic speech recognition; Interventional radiology; Multimodal interventional corpus; Operating room smart assistant; Port catheter placement; Surgical data science","Catheters; Data privacy; Medical computing; Medical imaging; Operating rooms; Radiology; Speech recognition; Automatic speech recognition; Catheter placement; Interventional; Interventional radiology; Multi-modal; Multi-modal dataset; Multimodal interventional corpus; Operating room smart assistant; Port catheter placement; Surgical data science; Radiation",Conference Paper,Scopus
"Li J., Li S., Hu Y., Tao H.","A Self-guided Framework for Radiology Report Generation",2022,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",3,"10.1007/978-3-031-16452-1_56","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139051787&doi=10.1007%2f978-3-031-16452-1_56&partnerID=40&md5=c6d8873c3ad9ba6ae4c7c7c5457956db","Automatic radiology report generation is essential to computer-aided diagnosis. Through the success of image captioning, medical report generation has been achievable. However, the lack of annotated disease labels is still the bottleneck of this area. In addition, the image-text data bias problem and complex sentences make it more difficult to generate accurate reports. To address these gaps, we present a self-guided framework (SGF), a suite of unsupervised and supervised deep learning methods to mimic the process of human learning and writing. In detail, our framework obtains the domain knowledge from medical reports without extra disease labels and guides itself to extract fined-grain visual features associated with the text. Moreover, SGF successfully improves the accuracy and length of medical report generation by incorporating a similarity comparison mechanism that imitates the process of human self-improvement through comparative practice. Extensive experiments demonstrate the utility of our SGF in the majority of cases, showing its superior performance over state-of-the-art methods. Our results highlight the capacity of the proposed framework to distinguish fined-grained visual details between words and verify its advantage in generating medical reports. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Clustering; Data bias; Report generation; Unsupervised learning","Computer aided diagnosis; Deep learning; Domain Knowledge; Learning systems; Medical imaging; Radiation; Bias problems; Clusterings; Complex sentences; Data bias; Image captioning; Image texts; Learning methods; Radiology reports; Report generation; Text data; Radiology",Conference Paper,Scopus
"Wang L., Ning M., Lu D., Wei D., Zheng Y., Chen J.","An Inclusive Task-Aware Framework for Radiology Report Generation",2022,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",2,"10.1007/978-3-031-16452-1_54","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139038233&doi=10.1007%2f978-3-031-16452-1_54&partnerID=40&md5=c05d8544644807ed25f7feb6de43457d","To avoid the tedious and laborious radiology report writing, the automatic generation of radiology reports has drawn great attention recently. Previous studies attempted to directly transfer the image captioning method to radiology report generation given the apparent similarity between these two tasks. Although these methods can generate fluent descriptions, their accuracy for abnormal structure identification is limited due to the neglecting of the highly structured property and extreme data imbalance of the radiology report generation task. Therefore, we propose a novel task-aware framework to address the above two issues, composed of a task distillation module turning the image-level report to structure-level description, a task-aware report generation module for the generation of structure-specific descriptions, along with a classification token to identify and emphasize the abnormality of each structure, and an auto-balance mask loss to alleviate the serious data imbalance between normal/abnormal descriptions as well as the imbalance among different structures. Comprehensive experiments conducted on two public datasets demonstrate that the proposed method outperforms the state-of-the-art methods by a large margin (3.5% BLEU-1 improvement on MIMIC-CXR dataset) and can effectively improve the accuracy regarding the abnormal structures. The code is available at https://github.com/Reremee/ITA. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Data imbalance; Report generation; Task-aware","Large dataset; Medical imaging; Radiation; Radiology; Automatic Generation; Data imbalance; Fluents; Image captioning; Property; Radiology reports; Report generation; Report writing; Structure identification; Task-aware; Distillation",Conference Paper,Scopus
"Yang S., Yang X., Lyu T., He X., Braithwaite D., Mehta H.J., Guo Y., Wu Y., Bian J.","A Preliminary Study of Extracting Pulmonary Nodules and Nodule Characteristics from Radiology Reports Using Natural Language Processing",2022,"Proceedings - 2022 IEEE 10th International Conference on Healthcare Informatics, ICHI 2022",1,"10.1109/ICHI54592.2022.00125","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139028288&doi=10.1109%2fICHI54592.2022.00125&partnerID=40&md5=1c2037a4e3bb97a41e8eb10349d60410","This study aims to develop a natural language processing (NLP) tool to extract the pulmonary nodules and nodule characteristics information from free-text clinical narratives. We identified a cohort of 3,080 patients who received low dose computed tomography (LDCT) at the University of Florida health system and collected their clinical narratives including radiology reports in their electronic health records (EHRs). Then, we manually annotated 394 reports as the gold-standard corpus and explored three state-of-the-art transformer-based NLP methods. The best model achieved an F1-score of 0.9279. © 2022 IEEE.","deep learning; natural language processing; nodule characteristics; pulmonary nodule","Computerized tomography; Deep learning; Medical imaging; Natural language processing systems; Radiation; Deep learning; Free texts; Language processing; Low dose; Natural language processing; Natural Language Processing Tools; Natural languages; Nodule characteristic; Pulmonary nodules; Radiology reports; Radiology",Conference Paper,Scopus
"Oian R., Fu S., Liu H.","Evaluation of Document-Level Identification of Pulmonary Nodules in Radiology Reports Using FLAIR Natural Language Processing Framework",2022,"Proceedings - 2022 IEEE 10th International Conference on Healthcare Informatics, ICHI 2022",,"10.1109/ICHI54592.2022.00093","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139015318&doi=10.1109%2fICHI54592.2022.00093&partnerID=40&md5=4e3b2b684a0ae81a7ab1ae755e04ed7c","Incidental radiographic findings are commonly found in radiology reports, can have significant clinical implications, yet frequently are missed or not followed-up on due to clinician error. This work evaluates a document-level classification task of radiology reports for a type of incidental finding, pulmonary nodules, utilizing the FLAIR NLP framework as a proof-of-concept for potential automation of identification of such findings for more consistent tracking. © 2022 IEEE.","FLAIR; incidental finding; Incidentaloma; NLP; pulmonary nodule; radiology","Information retrieval systems; Medical imaging; Radiation; Radiology; Classification tasks; FLAIR; Incidental findings; Incidentaloma; Language processing; Natural languages; Proof of concept; Pulmonary nodules; Radiographic findings; Radiology reports; Natural language processing systems",Conference Paper,Scopus
"Shi L., Syeda-Mahmood T.F., Baldwin T.","Improving Neural Models for Radiology Report Retrieval with Lexicon-based Automated Annotation",2022,"NAACL 2022 - 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Proceedings of the Conference",1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138358640&partnerID=40&md5=8f55d62cfc7db21fa2b0b8b1b4248c86","Many clinical informatics tasks that are based on electronic health records (EHR) need relevant patient cohorts to be selected based on findings, symptoms and diseases. Frequently, these conditions are described in radiology reports which can be retrieved using information retrieval (IR) methods. The latest of these techniques utilize neural IR models such as BERT trained on clinical text. However, these methods still lack semantic understanding of the underlying clinical conditions as well as ruled out findings, resulting in poor precision during retrieval. In this paper we combine clinical finding detection with supervised query match learning. Specifically, we use lexicon-driven concept detection to detect relevant findings in sentences. These findings are used as queries to train a Sentence-BERT (SBERT) model using triplet loss on matched and unmatched query-sentence pairs. We show that the proposed supervised training task remarkably improves the retrieval performance of SBERT. The trained model generalizes well to unseen queries and reports from different collections. © 2022 Association for Computational Linguistics.",,"Computational linguistics; Natural language processing systems; Radiation; Radiology; Clinical informatics; Condition; Electronic health; Health records; Information retrieval models; Lexicon-based; Neural information; Neural modelling; Radiology reports; Retrieval methods; Semantics",Conference Paper,Scopus
"Liang S., Kades K., Fink M.A., Full P.M., Weber T.F., Kleesiek J., Strube M., Maier-Hein K.","Fine-tuning BERT Models for Summarizing German Radiology Findings",2022,"ClinicalNLP 2022 - 4th Workshop on Clinical Natural Language Processing, Proceedings",4,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138254578&partnerID=40&md5=6dd162a790bd366cea30af51aeaa8ca7","Writing the conclusion section of radiology reports is essential for communicating the radiology findings and its assessment to physician in a condensed form. In this work, we employ a transformer-based Seq2Seq model for generating the conclusion section of German radiology reports. The model is initialized with the pretrained parameters of a German BERT model and fine-tuned in our downstream task on our domain data. We proposed two strategies to improve the factual correctness of the model. In the first method, next to the abstractive learning objective, we introduce an extraction learning objective to train the decoder in the model to both generate one summary sequence and extract the key findings from the source input. The second approach is to integrate the pointer mechanism into the transformer-based Seq2Seq model. The pointer network helps the Seq2Seq model to choose between generating tokens from the vocabulary or copying parts from the source input during generation. The results of the automatic and human evaluations show that the enhanced Seq2Seq model is capable of generating human-like radiology conclusions and that the improved models effectively reduce the factual errors in the generations despite the small amount of training data. © 2022 Association for Computational Linguistics.",,"Computational linguistics; Learning systems; Natural language processing systems; Radiation; Automatic evaluation; Condensed form; Down-stream; Fine tuning; Human evaluation; Human like; Learning objectives; Radiology reports; Summary sequence; Training data; Radiology",Conference Paper,Scopus
"Min D., Kim K., Lee J.H., Kim Y., Park C.M.","RRED: A Radiology Report Error Detector based on Deep Learning Framework",2022,"ClinicalNLP 2022 - 4th Workshop on Clinical Natural Language Processing, Proceedings",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138240702&partnerID=40&md5=952b920cf990e204b4e766fcd5089c0d","Radiology report is an official record of radiologists’ interpretation of patients’ radiographs and it’s a crucial component in the overall medical diagnostic process. However, it can contain various types of errors that can lead to inadequate treatment or delay in diagnosis. To address this problem, we propose a deep learning framework to detect errors in radiology reports. Specifically, our method detects errors between findings and conclusion of chest X-ray reports based on a supervised learning framework. To compensate for the lack of data availability of radiology reports with errors, we develop an error generator to systematically create artificial errors in existing reports. In addition, we introduce a Medical Knowledge-enhancing Pre-training to further utilize the knowledge of abbreviations and key phrases frequently used in the medical domain. We believe that this is the first work to propose a deep learning framework for detecting errors in radiology reports based on a rich contextual and medical understanding. Validation on our radiologist-synthesized dataset, based on MIMIC-CXR, shows 0.80 and 0.95 of the area under precision-recall curve (AUPRC) and the area under the ROC curve (AUROC) respectively, indicating that our framework can effectively detect errors in the real-world radiology reports. © 2022 Association for Computational Linguistics.",,"Computational linguistics; Deep learning; Diagnosis; Natural language processing systems; Radiation; Radiology; Data availability; Diagnostic process; Error detectors; Error generators; Key-phrase; Learning frameworks; Medical diagnostics; Medical knowledge; Pre-training; Radiology reports; Errors",Conference Paper,Scopus
"Wismüller A., Stockmaster L., Vosoughi M.A.","Re-defining Radiology Quality Assurance (QA) - Artificial Intelligence (AI)-Based QA by Restricted Investigation of Unequal Scores (AQUARIUS)",2022,"Proceedings of SPIE - The International Society for Optical Engineering",1,"10.1117/12.2622234","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136104740&doi=10.1117%2f12.2622234&partnerID=40&md5=f87bc7f3acf2711a5137033b754a3566","There is an urgent need for streamlining radiology Quality Assurance (QA) programs to make them better and faster. Here, we present a novel approach, Artificial Intelligence (AI)-Based Quality Assurance by Restricted Investigation of Unequal Scores (AQUARIUS), for re-defining radiology QA, which reduces human effort by up to several orders of magnitude over existing approaches. AQUARIUS typically includes automatic comparison of AI-based image analysis with natural language processing (NLP) on radiology reports. Only the usually small subset of cases with discordant reads is subsequently reviewed by human experts. To demonstrate the clinical applicability of AQUARIUS, we performed a clinical QA study on Intracranial Hemorrhage (ICH) detection in 1936 head CT scans from a large academic hospital. Immediately following image acquisition, scans were automatically analyzed for ICH using a commercially available software (Aidoc, Tel Aviv, Israel). Cases rated positive for ICH by AI (ICH-AI+) were automatically flagged in radiologists' reading worklists, where flagging was randomly switched off with probability 50%. Using AQUARIUS with NLP on final radiology reports and targeted expert neuroradiology review of only 29 discordantly classified cases reduced the human QA effort by 98.5%, where we found a total of six non-reported true ICH+ cases, with radiologists' missed ICH detection rates of 0.52% and 2.5% for flagged and non-flagged cases, respectively. We conclude that AQUARIUS, by combining AI-based image analysis with NLP-based pre-selection of cases for targeted human expert review, can efficiently identify missed findings in radiology studies and significantly expedite radiology QA programs in a hybrid human-machine interoperability approach. © 2022 SPIE.","AQUARIUS; Artificial intelligence; intracranial hemorrhage; natural language processing; quality assurance; radiology","Artificial intelligence; Computerized tomography; Image analysis; Medical imaging; Natural language processing systems; Radiation; Radiology; (AI)-based quality assurance by restricted investigation of unequal score; Hemorrhage detection; Human expert; Image-analysis; Intracranial hemorrhages; Language processing; Natural language processing; Natural languages; Orders of magnitude; Radiology reports; Quality assurance",Conference Paper,Scopus
"Wang S., Tang L., Lin M., Shih G., Ding Y., Peng Y.","Prior Knowledge Enhances Radiology Report Generation",2022,"AMIA ... Annual Symposium proceedings. AMIA Symposium",2,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134634978&partnerID=40&md5=1cb3da1cad1170d4ed03682ca21025d6","Radiology report generation aims to produce computer-aided diagnoses to alleviate the workload of radiologists and has drawn increasing attention recently. However, previous deep learning methods tend to neglect the mutual influences between medical findings, which can be the bottleneck that limits the quality of generated reports. In this work, we propose to mine and represent the associations among medical findings in an informative knowledge graph and incorporate this prior knowledge with radiology report generation to help improve the quality of generated reports. Experiment results demonstrate the superior performance of our proposed method on the IU X-ray dataset with a ROUGE-L of 0.384±0.007 and CIDEr of 0.340±0.011. Compared with previous works, our model achieves an average of 1.6% improvement (2.0% and 1.5% improvements in CIDEr and ROUGE-L, respectively). The experiments suggest that prior knowledge can bring performance gains to accurate radiology report generation. We will make the code publicly available at https://github.com/bionlplab/report_generation_amia2022. ©2022 AMIA - All rights reserved.",,"computer assisted diagnosis; human; radiography; radiology; radiology information system; research; Diagnosis, Computer-Assisted; Humans; Radiography; Radiology; Radiology Information Systems; Research Report",Article,Scopus
"Wang S., Lin M., Ding Y., Shih G., Lu Z., Peng Y.","Radiology Text Analysis System (RadText): Architecture and Evaluation",2022,"Proceedings - 2022 IEEE 10th International Conference on Healthcare Informatics, ICHI 2022",2,"10.1109/ICHI54592.2022.00050","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134315755&doi=10.1109%2fICHI54592.2022.00050&partnerID=40&md5=4c983fc705cdedf34d69a2b7e06f03b3","Analyzing radiology reports is a time-consuming and error-prone task, which raises the need for an efficient automated radiology report analysis system to alleviate the workloads of radiologists and encourage precise diagnosis. In this work, we present RadText, an open-source radiology text analysis system developed by Python. RadText offers an easy-to-use text analysis pipeline, including de-identification, section segmentation, sentence split and word tokenization, named entity recognition, parsing, and negation detection. RadText features a flexible modular design, provides a hybrid text processing schema, and supports raw text processing and local processing, which enables better usability and improved data privacy. Rad-Text adopts BioC as the unified interface, and also standardizes the input / output into a structured representation compatible with Observational Medical Outcomes Partnership (OMOP) Common Data Model (CDM). This allows for a more systematic approach to observational research across multiple, disparate data sources. We evaluated RadText on the MIMIC-CXR dataset, with five new disease labels we annotated for this work. RadText demonstrates highly accurate classification performances, with an average precision of, a recall of 0.94, and an F-1 score of 0.92. We have made our code, documentation, examples, and the test set available at https://github.com/bionlplab/radtext. © 2022 IEEE.","Natural Language Processing; Radiology; Text Analysis Systems","Character recognition; Data privacy; Diagnosis; Medical imaging; Natural language processing systems; Radiation; Syntactics; Text processing; Analysis system; Error prone tasks; Language processing; Natural language processing; Natural languages; Radiology reports; System evaluation; Systems architecture; Text analysis system; Text-processing; Radiology",Conference Paper,Scopus
"Karn S.K., Liu N., Schütze H., Farri O.","Differentiable Multi-Agent Actor-Critic for Multi-Step Radiology Report Summarization",2022,"Proceedings of the Annual Meeting of the Association for Computational Linguistics",7,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131819353&partnerID=40&md5=ecf742e210a29f00495df0e46da1ad4e","The IMPRESSIONS section of a radiology report about an imaging study is a summary of the radiologist's reasoning and conclusions, and it also aids the referring physician in confirming or excluding certain diagnoses. A cascade of tasks are required to automatically generate an abstractive summary of the typical information-rich radiology report. These tasks include acquisition of salient content from the report and generation of a concise, easily consumable IMPRESSIONS section. Prior research on radiology report summarization has focused on single-step end-to-end models - which subsume the task of salient content acquisition. To fully explore the cascade structure and explainability of radiology report summarization, we introduce two innovations. First, we design a two-step approach: extractive summarization followed by abstractive summarization. Second, we additionally break down the extractive part into two independent tasks: extraction of salient (1) sentences and (2) keywords. Experiments on English radiology reports from two clinical sites show our novel approach leads to a more precise summary compared to single-step and to two-step-with-single-extractive-process baselines with an overall improvement in F1 score of 3-4%. © 2022 Association for Computational Linguistics.",,"Computational linguistics; Multi agent systems; Natural language processing systems; Radiology; Actor critic; Cascade structures; Consumables; Content acquisition; End-to-end models; Multi agent; Multisteps; Radiology reports; Single-step; Two-step approach; Radiation",Conference Paper,Scopus
"Clements W., Thong L.P., Zia A., Moriarty H.K., Goh G.S.","A PROSPECTIVE STUDY ASSESSING PATIENT PERCEPTION OF THE USE OF ARTIFICIAL INTELLIGENCE IN RADIOLOGY",2022,"Asia Pacific Journal of Health Management",1,"10.24083/apjhm.v17i1.861","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130125073&doi=10.24083%2fapjhm.v17i1.861&partnerID=40&md5=4c8a51c9b845479f6eee44ad04434232","OBJECTIVE Radiology has been at the forefront of medical technology including the use of artificial intelligence (AI) and machine learning. However, there remains scant literature on the perspective of patients regarding clinical use of this technology. This study aimed to assess the opinion of radiology patients on the potential involvement of AI in the ir medical care. DESIGN A survey was given to ambulatory outpatients attending our hospital for medical imaging. The survey consisted of questions concerning comfort with radiologist reports, comfort with entirely AI reports, comfort with in -part AI reports, accuracy, data security, and medicolegal risk. SETTING Tertiary academic hospital in Melbourne, Australia. MAIN OUTCOME MEASURES Patients were surveyed for their overall comfort with the use of AI in their medical imaging using a Likert scale of 0 to 7. RESULTS 283 patient surveys were included. Patients rated comfort in their imaging being reported by a radiologist at mean of 6.5 out of 7, compared with AI alone at mean 3.5 out of 7 (p<0.0001), or in-part AI at mean 5.4 out of 7 (p<0.0001). Patients felt AI should have an accuracy of mean 91.4% to be able to be used in a clinical environment. Patients rated their current comfort with data security at mean 5.5 out of 7 however comfort with data security using AI at mean 4.4 out of 7, p<0.0001. CONCLUSIONS Patients are trusting of the holistic role of a radiologist however, remain uncomfortable with clinical use of AI as a standalone product including accuracy and data security. If AI technology is to evolve then it must do so with appropriate involvement of stakeholders, of which patients are paramount. © 2022 Australasian College of Health Service Management. All right reserved.","AI; Artificial intelligence; patient; survey","adult; article; artificial intelligence; Australia; comfort; controlled study; diagnostic imaging; female; human; information security; Likert scale; major clinical study; male; medical care; outcome assessment; outpatient; perception; prospective study; radiologist; radiology; university hospital",Article,Scopus
"Tariq A., Van Assen M., De Cecco C.N., Banerjee I.","Bridging the Gap between Structured and Free-form Radiology Reporting: A Case-study on Coronary CT Angiography",2022,"ACM Transactions on Computing for Healthcare",,"10.1145/3474831","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125739411&doi=10.1145%2f3474831&partnerID=40&md5=91e7bb1f4c8e4b2c6ce266151770bb2e","Free-form radiology reports associated with coronary computed tomography angiography (CCTA) include nuanced and complicated linguistics to report cardiovascular disease. Standardization and interpretation of such reports is crucial for clinical use of CCTA. Coronary Artery Disease Reporting and Data System (CAD-RADS) has been proposed to achieve such standardization by implementing a strict template-based report writing and assignment of a score between 0 and 5 indicating the severity of coronary artery lesions. Even after its introduction, free-form unstructured report writing remains popular among radiologists. In this work, we present our attempts at bridging the gap between structured and unstructured reporting by natural language processing. We present machine learning models that while being trained only on structured reports, can predict CAD-RADS scores by analysis of free-text of unstructured radiology reports. The best model achieves 98% accuracy on structured reports and 92% 1-margin accuracy (difference of 1 in the predicted and the actual scores) for free-form unstructured reports. Our model also performs well under very difficult circumstances including nuanced and widely varying terminology used for reporting cardiovascular functions and diseases, scarcity of labeled data for training our model, and uneven class label distribution. © 2021 Association for Computing Machinery.","CAD-RADS score prediction; deep learning; natural language processing","Computer aided design; Computerized tomography; Diseases; Heart; Learning algorithms; Natural language processing systems; Radiation; Radiology; Standardization; Computed tomography angiography; Coronary artery disease; Coronary artery disease reporting and data system score prediction; Data systems; Deep learning; Freeforms; Language processing; Natural language processing; Natural languages; Reporting systems; Deep learning; adult; Article; Bayesian learning; comparative study; computed tomographic angiography; convolutional neural network; coronary angiography; coronary artery disease reporting and data system; data accuracy; deep learning; female; human; image processing; information processing; long short term memory network; machine learning; major clinical study; male; middle aged; natural language processing; principal component analysis; priority journal; recurrent neural network",Article,Scopus
"Eskreis-Winkler S., Sutton E.J., D'Alessio D., Gallagher K., Saphier N., Stember J., Martinez D.F., Morris E.A., Pinker K.","Breast MRI Background Parenchymal Enhancement Categorization Using Deep Learning: Outperforming the Radiologist",2022,"Journal of Magnetic Resonance Imaging",5,"10.1002/jmri.28111","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124617032&doi=10.1002%2fjmri.28111&partnerID=40&md5=9203549a5bc9f0570441e8a2216d9c8d","Background: Background parenchymal enhancement (BPE) is assessed on breast MRI reports as mandated by the Breast Imaging Reporting and Data System (BI-RADS) but is prone to inter and intrareader variation. Semiautomated and fully automated BPE assessment tools have been developed but none has surpassed radiologist BPE designations. Purpose: To develop a deep learning model for automated BPE classification and to compare its performance with current standard-of-care radiology report BPE designations. Study Type: Retrospective. Population: Consecutive high-risk patients (i.e. >20% lifetime risk of breast cancer) who underwent contrast-enhanced screening breast MRI from October 2013 to January 2019. The study included 5224 breast MRIs, divided into 3998 training, 444 validation, and 782 testing exams. On radiology reports, 1286 exams were categorized as high BPE (i.e., marked or moderate) and 3938 as low BPE (i.e., mild or minimal). Field Strength/Sequence: A 1.5 T or 3 T system; one precontrast and three postcontrast phases of fat-saturated T1-weighted dynamic contrast-enhanced imaging. Assessment: Breast MRIs were used to develop two deep learning models (Slab artificial intelligence (AI); maximum intensity projection [MIP] AI) for BPE categorization using radiology report BPE labels. Models were tested on a heldout test sets using radiology report BPE and three-reader averaged consensus as the reference standards. Statistical Tests: Model performance was assessed using receiver operating characteristic curve analysis. Associations between high BPE and BI-RADS assessments were evaluated using McNemar's chi-square test (α* = 0.025). Results: The Slab AI model significantly outperformed the MIP AI model across the full test set (area under the curve of 0.84 vs. 0.79) using the radiology report reference standard. Using three-reader consensus BPE labels reference standard, our AI model significantly outperformed radiology report BPE labels. Finally, the AI model was significantly more likely than the radiologist to assign “high BPE” to suspicious breast MRIs and significantly less likely than the radiologist to assign “high BPE” to negative breast MRIs. Data Conclusion: Fully automated BPE assessments for breast MRIs could be more accurate than BPE assessments from radiology reports. Level of Evidence: 4. Technical Efficacy Stage: 3. © 2022 International Society for Magnetic Resonance in Medicine.","artificial intelligence; background parenchymal enhancement; breast MRI; cancer risk assessment; deep learning","artificial intelligence; breast tumor; diagnostic imaging; female; human; nuclear magnetic resonance imaging; procedures; radiologist; retrospective study; Artificial Intelligence; Breast Neoplasms; Deep Learning; Female; Humans; Magnetic Resonance Imaging; Radiologists; Retrospective Studies",Article,Scopus
"Sun S., Lupton K., Batch K., Nguyen H., Gazit L., Gangai N., Cho J., Nicholas K., Zulkernine F., Sevilimedu V., Simpson A., Do R.K.G.","Natural Language Processing of Large-Scale Structured Radiology Reports to Identify Oncologic Patients with or Without Splenomegaly over a 10-Year Period",2022,"JCO Clinical Cancer Informatics",,"10.1200/CCI.21.00104","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123269242&doi=10.1200%2fCCI.21.00104&partnerID=40&md5=b359e94508f23e7940f3cff334eccab7","PURPOSE: To assess the accuracy of a natural language processing (NLP) model in extracting splenomegaly described in patients with cancer in structured computed tomography radiology reports. METHODS: In this retrospective study between July 2009 and April 2019, 3,87,359 consecutive structured radiology reports for computed tomography scans of the chest, abdomen, and pelvis from 91,665 patients spanning 30 types of cancer were included. A randomized sample of 2,022 reports from patients with colorectal cancer, hepatobiliary cancer (HB), leukemia, Hodgkin lymphoma (HL), and non-HL patients was manually annotated as positive or negative for splenomegaly. NLP model training/testing was performed on 1,617/405 reports, and a new validation set of 400 reports from all cancer subtypes was used to test NLP model accuracy, precision, and recall. Overall survival was compared between the patient groups (with and without splenomegaly) using Kaplan-Meier curves. RESULTS: The final cohort included 3,87,359 reports from 91,665 patients (mean age 60.8 years; 51.2% women). In the testing set, the model achieved accuracy of 92.1%, precision of 92.2%, and recall of 92.1% for splenomegaly. In the validation set, accuracy, precision, and recall were 93.8%, 92.9%, and 86.7%, respectively. In the entire cohort, splenomegaly was most frequent in patients with leukemia (32.5%), HB (17.4%), non-HL (9.1%), colorectal cancer (8.5%), and HL (5.6%). A splenomegaly label was associated with an increased risk of mortality in the entire cohort (hazard ratio 2.10; 95% CI, 1.98 to 2.22; P < .001). CONCLUSION: Automated splenomegaly labeling by NLP of radiology report demonstrates good accuracy, precision, and recall. Splenomegaly is most frequently reported in patients with leukemia, followed by patients with HB. © 2022 American Society of Clinical Oncology.",,"abdominal radiography; adult; anus cancer; Article; bladder cancer; bone cancer; brain cancer; breast cancer; cancer patient; central nervous system cancer; cohort analysis; colorectal cancer; computer assisted diagnosis; computer assisted tomography; diagnostic accuracy; digestive system cancer; esophagus cancer; eye cancer; false positive result; female; female genital tract cancer; head and neck cancer; hepatobiliary system cancer; Hodgkin disease; human; interrater reliability; Kaposi sarcoma; leukemia; lung cancer; major clinical study; male; melanoma; middle aged; mortality risk; myeloma; natural language processing; nonhodgkin lymphoma; orbit cancer; ovary cancer; overall survival; pancreas cancer; pelvis radiography; prostate cancer; receiver operating characteristic; retrospective study; skin cancer; soft tissue cancer; splenomegaly; stomach cancer; testis cancer; thorax radiography; thyroid cancer; uterine cervix cancer; uterus cancer; colorectal tumor; diagnostic imaging; leukemia; natural language processing; radiology; splenomegaly; Colorectal Neoplasms; Female; Humans; Leukemia; Male; Middle Aged; Natural Language Processing; Radiology; Retrospective Studies; Splenomegaly",Article,Scopus
"Zhou H.-Y., Chen X., Zhang Y., Luo R., Wang L., Yu Y.","Generalized radiograph representation learning via cross-supervision between images and free-text radiology reports",2022,"Nature Machine Intelligence",23,"10.1038/s42256-021-00425-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123263270&doi=10.1038%2fs42256-021-00425-9&partnerID=40&md5=d12117884f5bb1293cd0bf2191a56afa","Pre-training lays the foundation for recent successes in radiograph analysis supported by deep learning. It learns transferable image representations by conducting large-scale fully- or self-supervised learning on a source domain; however, supervised pre-training requires a complex and labour-intensive two-stage human-assisted annotation process, whereas self-supervised learning cannot compete with the supervised paradigm. To tackle these issues, we propose a cross-supervised methodology called reviewing free-text reports for supervision (REFERS), which acquires free supervision signals from the original radiology reports accompanying the radiographs. The proposed approach employs a vision transformer and is designed to learn joint representations from multiple views within every patient study. REFERS outperforms its transfer learning and self-supervised learning counterparts on four well-known X-ray datasets under extremely limited supervision. Moreover, REFERS even surpasses methods based on a source domain of radiographs with human-assisted structured labels; it therefore has the potential to replace canonical pre-training methodologies. © 2022, The Author(s), under exclusive licence to Springer Nature Limited.",,"Deep learning; Radiation; Radiology; Supervised learning; Free texts; Image representations; Image texts; Labour-intensive; Large-scales; Learn+; Multiple views; Pre-training; Radiology reports; Transfer learning; Radiography",Article,Scopus
"Davis M.A., Gichoya J.W., Banerjee I., Sung D., Newsome J., Vey B.L., Gerard R., Khan F., Zavaletta V., Mazaheri S., Heilbrun M.E.","Balancing the Scales: An Analysis of Social Determinants of Health, Radiology Report Acuity, and Radiology Staffing Models in an Academic Health System",2022,"Journal of the American College of Radiology",,"10.1016/j.jacr.2021.08.029","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122645089&doi=10.1016%2fj.jacr.2021.08.029&partnerID=40&md5=31b562b1ec75d6e4ca357a1796f96c25","Purpose: Social determinants of health, including race and insurance status, contribute to patient outcomes. In academic health systems, care is provided by a mix of trainees and faculty members. The optimal staffing ratio of trainees to faculty members (T/F) in radiology is unknown but may be related to the complexity of patients requiring care. Hospital characteristics, patient demographics, and radiology report findings may serve as markers of risk for poor outcomes because of patient complexity. Methods: Descriptive characteristics of each hospital in an urban five-hospital academic health system, including payer distribution and race, were collected. Radiology department T/F ratios were calculated. A natural language processing model was used to classify multimodal report findings into nonacute, acute, and critical, with report acuity calculated as the fraction of acute and critical findings. Patient race, payer type, T/F ratio, and report acuity score for hospital 1, a safety net hospital, were compared with these factors for hospitals 2 to 5. Results: The fraction of patients at hospital 1 who are Black (79%) and have Medicaid insurance (28%) is significantly higher than at hospitals 2 to 5 (P < .0001), with the exception of hospital 3 (80.1% black). The T/F ratio of 1.37 at hospital 1 as well as its report acuity (28.9%) were significantly higher (P < .0001 for both). Conclusions: T/F ratio and report acuity are highest at hospital 1, which serves the most at-risk patient population. This suggests a potential overreliance on trainees at a site whose patients may require the greatest expertise to optimize care. © 2021 American College of Radiology","disparities; emergency radiology; Quality; staffing","adult; article; demography; drug safety; human; medicaid; natural language processing; race; radiology department; risk assessment; safety net hospital; social determinants of health; hospital; radiology; United States; Hospitals, Urban; Humans; Medicaid; Radiology; Social Determinants of Health; United States; Workforce",Article,Scopus
"Verma A.A., Masoom H., Pou-Prom C., Shin S., Guerzhoy M., Fralick M., Mamdani M., Razak F.","Developing and validating natural language processing algorithms for radiology reports compared to ICD-10 codes for identifying venous thromboembolism in hospitalized medical patients",2022,"Thrombosis Research",8,"10.1016/j.thromres.2021.11.020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122496056&doi=10.1016%2fj.thromres.2021.11.020&partnerID=40&md5=8a77f4e5bd3ba45746bfbf071727a8d5","Background: Identifying venous thromboembolism (VTE) from large clinical and administrative databases is important for research and quality improvement. Objective: To develop and validate natural language processing (NLP) algorithms to identify VTE from radiology reports among general internal medicine (GIM) inpatients. Methods: This cross-sectional study included GIM hospitalizations between April 1, 2010 and March 31, 2017 at 5 hospitals in Toronto, Ontario, Canada. We developed NLP algorithms to identify pulmonary embolism (PE) and deep venous thrombosis (DVT) from radiologist reports of thoracic computed tomography (CT), extremity compression ultrasound (US), and nuclear ventilation-perfusion (VQ) scans in a training dataset of 1551 hospitalizations. We compared the accuracy of our NLP algorithms, the previously-published “simpleNLP” tool, and administrative discharge diagnosis codes (ICD-10-CA) for PE and DVT to the “gold standard” manual review in a separate random sample of 4000 GIM hospitalizations. Results: Our NLP algorithms were highly accurate for identifying DVT from US, with sensitivity 0.94, positive predictive value (PPV) 0.90, and Area Under the Receiver-Operating-Characteristic Curve (AUC) 0.96; and in identifying PE from CT, with sensitivity 0.91, PPV 0.89, and AUC 0.96. Administrative diagnosis codes and the simple NLP tool were less accurate for DVT (ICD-10-CA sensitivity 0.63, PPV 0.43, AUC 0.81; simpleNLP sensitivity 0.41, PPV 0.36, AUC 0.66) and PE (ICD-10-CA sensitivity 0.83, PPV 0.70, AUC 0.91; simpleNLP sensitivity 0.89, PPV 0.62, AUC 0.92). Conclusions: Administrative diagnosis codes are unreliable in identifying VTE in hospitalized patients. We developed highly accurate NLP algorithms to identify VTE from radiology reports in a multicentre sample and have made the algorithms freely available to the academic community with a user-friendly tool (https://lks-chart.github.io/CHARTextract-docs/08-downloads/rulesets.html#venous-thromboembolism-vte-rulesets) © 2021 Elsevier Ltd","Deep vein thrombosis; ICD codes; Natural language processing; Pulmonary embolism; Validity","adult; aged; area under the curve; Article; Canada; cohort analysis; compression ultrasonography; computer assisted tomography; controlled study; cross-sectional study; deep vein thrombosis; diagnostic test accuracy study; female; hospital patient; hospitalization; human; ICD-10; imaging algorithm; internal medicine; lung embolism; major clinical study; male; middle aged; natural language processing; Ontario; predictive value; radiologist; random sample; receiver operating characteristic; sensitivity and specificity; validation study; venous thromboembolism; ventilation-perfusion scan; very elderly; algorithm; diagnostic imaging; International Classification of Diseases; lung embolism; natural language processing; radiology; venous thromboembolism; Algorithms; Cross-Sectional Studies; Hospitalization; Humans; International Classification of Diseases; Natural Language Processing; Ontario; Pulmonary Embolism; Radiology; Venous Thromboembolism",Article,Scopus
"Sirshar M., Paracha M.F.K., Akram M.U., Alghamdi N.S., Zaidi S.Z.Y., Fatima T.","Attention based automated radiology report generation using CNN and LSTM",2022,"PLoS ONE",9,"10.1371/journal.pone.0262209","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122493015&doi=10.1371%2fjournal.pone.0262209&partnerID=40&md5=a8340bb862b9e6b039388050a5814476","The automated generation of radiology reports provides X-rays and has tremendous potential to enhance the clinical diagnosis of diseases in patients. A new research direction is gaining increasing attention that involves the use of hybrid approaches based on natural language processing and computer vision techniques to create auto medical report generation systems. The auto report generator, producing radiology reports, will significantly reduce the burden on doctors and assist them in writing manual reports. Because the sensitivity of chest X-ray (CXR) findings provided by existing techniques not adequately accurate, producing comprehensive explanations for medical photographs remains a difficult task. A novel approach to address this issue was proposed, based on the continuous integration of convolutional neural networks and long short-term memory for detecting diseases, followed by the attention mechanism for sequence generation based on these diseases. Experimental results obtained by using the Indiana University CXR and MIMIC-CXR datasets showed that the proposed model attained the current state-of-the-art efficiency as opposed to other solutions of the baseline. BLEU-1, BLEU-2, BLEU-3, and BLEU-4 were used as the evaluation metrics. © 2022 Sirshar et al. This is an open",,"Article; BLEU 1 score; BLEU 2 score; BLEU 3 score; BLEU 4 score; computer assisted tomography; controlled study; convolutional neural network; diagnostic accuracy; feature learning (machine learning); human; long short term memory network; major clinical study; optical coherence tomography; probabilistic neural network; quantitative analysis; recurrent neural network; scoring system; task performance; thorax radiography; algorithm; natural language processing; procedures; radiology; thorax radiography; X ray; Algorithms; Deep Learning; Humans; Natural Language Processing; Neural Networks, Computer; Radiography, Thoracic; Radiology; X-Rays",Article,Scopus
"Daugaard Jørgensen M., Antulov R., Hess S., Lysdahlgaard S.","Convolutional neural network performance compared to radiologists in detecting intracranial hemorrhage from brain computed tomography: A systematic review and meta-analysis",2022,"European Journal of Radiology",9,"10.1016/j.ejrad.2021.110073","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119989104&doi=10.1016%2fj.ejrad.2021.110073&partnerID=40&md5=087b2ab2df91fef5ecabc05a5b19cd3a","Purpose: To compare the diagnostic accuracy of convolutional neural networks (CNN) with radiologists as the reference standard in the diagnosis of intracranial hemorrhages (ICH) with non contrast computed tomography of the cerebrum (NCTC). Methods: PubMed, Embase, Scopus, and Web of Science were searched for the period from 1 January 2012 to 20 July 2020; eligible studies included patients with and without ICH as the target condition undergoing NCTC, studies had deep learning algorithms based on CNNs and radiologists reports as the minimum reference standard. Pooled sensitivities, specificities and a summary receiver operating characteristics curve (SROC) were employed for meta-analysis. Results: 5,119 records were identified through database searching. Title-screening left 47 studies for full-text assessment and 6 studies for meta-analysis. Comparing the CNN performance to reference standards in the retrospective studies found a pooled sensitivity of 96.00% (95% CI: 93.00% to 97.00%), pooled specificity of 97.00% (95% CI: 90.00% to 99.00%) and SROC of 98.00% (95% CI: 97.00% to 99.00%), and combining retrospective and studies with external datasets found a pooled sensitivity of 95.00% (95% CI: 91.00% to 97.00%), pooled specificity of 96.00% (95% CI: 91.00% to 98.00%) and a pooled SROC of 98.00% (95% CI: 97.00% to 99.00%). Conclusion: This review found the diagnostic performance of CNNs to be equivalent to that of radiologists for retrospective studies. Out-of-sample external validation studies pooled with retrospective studies found CNN performance to be slightly worse. There is a critical need for studies with a robust reference standard and external data-set validation. © 2021 The Author(s)","Artificial Intelligence; Computed tomography; Intracranial hemorrhage; Meta-analysis; Systematic review","algorithm; Article; artificial intelligence; brain hemorrhage; brain radiography; computer assisted tomography; convolutional neural network; data base; deep learning; diagnostic accuracy; diagnostic test accuracy study; diagnostic value; evidence based medicine; external validity; human; intermethod comparison; meta analysis; radiologist; receiver operating characteristic; sensitivity and specificity; study design; systematic review; validation study; brain hemorrhage; diagnostic imaging; retrospective study; x-ray computed tomography; Humans; Intracranial Hemorrhages; Neural Networks, Computer; Radiologists; Retrospective Studies; Sensitivity and Specificity; Tomography, X-Ray Computed",Article,Scopus
"Bayrak S., Yucel E., Takci H.","Epilepsy radiology reports classification using deep learning networks",2022,"Computers, Materials and Continua",4,"10.32604/cmc.2022.018742","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116030512&doi=10.32604%2fcmc.2022.018742&partnerID=40&md5=143525736ca09794d53afca215100166","The automatic and accurate classification of Magnetic Resonance Imaging (MRI) radiology report is essential for the analysis and interpretation epilepsy and non-epilepsy. Since the majority of MRI radiology reports are unstructured, the manual information extraction is time-consuming and requires specific expertise. In this paper, a comprehensive method is proposed to classify epilepsy and non-epilepsy real brain MRI radiology text reports automatically. This method combines the Natural Language Processing technique and statistical Machine Learning methods. 122 real MRI radiology text reports (97 epilepsy, 25 non-epilepsy) are studied by our proposed method which consists of the following steps: (i) for a given text report our systems first cleans HTML/XML tags, tokenize, erase punctuation, normalize text, (ii) then it converts into MRI text reports numeric sequences by using index-based word encoding, (iii) then we applied the deep learning models that are uni-directional long short-term memory (LSTM) network, bidirectional long short-term memory (BiLSTM) network and convolutional neural network (CNN) for the classifying comparison of the data, (iv) finally, we used 70% of used for training, 15% for validation, and 15% for test observations. Unlike previous methods, this study encompasses the following objectives: (a) to extract significant text features from radiologic reports of epilepsy disease; (b) to ensure successful classifying accuracy performance to enhance epilepsy data attributes. Therefore, our study is a comprehensive comparative study with the epilepsy dataset obtained from numeric sequences by using index-based word encoding method applied for the deep learning models. The traditional method is numeric sequences by using index-based word encoding which has been made for the first time in the literature, is successful feature descriptor in the epilepsy data set. The BiLSTM network has shown a promising performance regarding the accuracy rates. We show that the larger sized medical text reports can be analyzed by our proposed method. © 2022 Tech Science Press. All rights reserved.","Deep learning networks-based text classification; Epilepsy; Feature engineering; Index-based word encoding; Natural language processing; Radiology text report analysis","Brain; Classification (of information); Long short-term memory; Magnetic resonance imaging; Natural language processing systems; Network coding; Neurology; Radiation; Radiology; Deep learning network-based text classification; Feature engineerings; Index-based word encoding; Learning models; Learning network; Memory network; Network-based; Performance; Radiology reports; Radiology text report analyse; Text processing",Article,Scopus
"Jones C.M., Danaher L., Milne M.R., Tang C., Seah J., Oakden-Rayner L., Johnson A., Buchlak Q.D., Esmaili N.","Assessment of the effect of a comprehensive chest radiograph deep learning model on radiologist reports and patient outcomes: A real-world observational study",2021,"BMJ Open",11,"10.1136/bmjopen-2021-052902","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122251911&doi=10.1136%2fbmjopen-2021-052902&partnerID=40&md5=a6f907ce5096c851500a7ee38d272b70","Objectives Artificial intelligence (AI) algorithms have been developed to detect imaging features on chest X-ray (CXR) with a comprehensive AI model capable of detecting 124 CXR findings being recently developed. The aim of this study was to evaluate the real-world usefulness of the model as a diagnostic assistance device for radiologists. Design This prospective real-world multicentre study involved a group of radiologists using the model in their daily reporting workflow to report consecutive CXRs and recording their feedback on level of agreement with the model findings and whether this significantly affected their reporting. Setting The study took place at radiology clinics and hospitals within a large radiology network in Australia between November and December 2020. Participants Eleven consultant diagnostic radiologists of varying levels of experience participated in this study. Primary and secondary outcome measures Proportion of CXR cases where use of the AI model led to significant material changes to the radiologist report, to patient management, or to imaging recommendations. Additionally, level of agreement between radiologists and the model findings, and radiologist attitudes towards the model were assessed. Results Of 2972 cases reviewed with the model, 92 cases (3.1%) had significant report changes, 43 cases (1.4%) had changed patient management and 29 cases (1.0%) had further imaging recommendations. In terms of agreement with the model, 2569 cases showed complete agreement (86.5%). 390 (13%) cases had one or more findings rejected by the radiologist. There were 16 findings across 13 cases (0.5%) deemed to be missed by the model. Nine out of 10 radiologists felt their accuracy was improved with the model and were more positive towards AI poststudy. Conclusions Use of an AI model in a real-world reporting environment significantly improved radiologist reporting and showed good agreement with radiologists, highlighting the potential for AI diagnostic support to improve clinical practice. © 2022 BMJ Publishing Group. All rights reserved.","deep learning; machine learning chest X-ray","adult; algorithm; article; artificial intelligence; Australia; case study; clinical practice; consultation; deep learning; female; human; major clinical study; male; multicenter study; observational study; patient care; prospective study; radiologist; thorax radiography; workflow; algorithm; artificial intelligence; clinical trial; radiologist; Algorithms; Artificial Intelligence; Deep Learning; Humans; Prospective Studies; Radiologists",Article,Scopus
"He Z., Li Y., Zeng W., Xu W., Liu J., Ma X., Wei J., Zeng H., Xu Z., Wang S., Wen C., Wu J., Feng C., Ma M., Qin G., Lu Y., Chen W.","Can a Computer-Aided Mass Diagnosis Model Based on Perceptive Features Learned From Quantitative Mammography Radiology Reports Improve Junior Radiologists’ Diagnosis Performance? An Observer Study",2021,"Frontiers in Oncology",2,"10.3389/fonc.2021.773389","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122098732&doi=10.3389%2ffonc.2021.773389&partnerID=40&md5=85430b9f68d3b215c4bd4363c5e887ca","Radiologists’ diagnostic capabilities for breast mass lesions depend on their experience. Junior radiologists may underestimate or overestimate Breast Imaging Reporting and Data System (BI-RADS) categories of mass lesions owing to a lack of diagnostic experience. The computer-aided diagnosis (CAD) method assists in improving diagnostic performance by providing a breast mass classification reference to radiologists. This study aims to evaluate the impact of a CAD method based on perceptive features learned from quantitative BI-RADS descriptions on breast mass diagnosis performance. We conducted a retrospective multi-reader multi-case (MRMC) study to assess the perceptive feature-based CAD method. A total of 416 digital mammograms of patients with breast masses were obtained from 2014 through 2017, including 231 benign and 185 malignant masses, from which we randomly selected 214 cases (109 benign, 105 malignant) to train the CAD model for perceptive feature extraction and classification. The remaining 202 cases were enrolled as the test set for evaluation, of which 51 patients (29 benign and 22 malignant) participated in the MRMC study. In the MRMC study, we categorized six radiologists into three groups: junior, middle-senior, and senior. They diagnosed 51 patients with and without support from the CAD model. The BI-RADS category, benign or malignant diagnosis, malignancy probability, and diagnosis time during the two evaluation sessions were recorded. In the MRMC evaluation, the average area under the curve (AUC) of the six radiologists with CAD support was slightly higher than that without support (0.896 vs. 0.850, p = 0.0209). Both average sensitivity and specificity increased (p = 0.0253). Under CAD assistance, junior and middle-senior radiologists adjusted the assessment categories of more BI-RADS 4 cases. The diagnosis time with and without CAD support was comparable for five radiologists. The CAD model improved the radiologists’ diagnostic performance for breast masses without prolonging the diagnosis time and assisted in a better BI-RADS assessment, especially for junior radiologists. Copyright © 2021 He, Li, Zeng, Xu, Liu, Ma, Wei, Zeng, Xu, Wang, Wen, Wu, Feng, Ma, Qin, Lu and Chen.","computer-aided diagnosis; convolutional neural network; diagnosis performance; digital mammographic; mass lesion","adult; analytical parameters; architectural distortion; area under the curve; Article; artificial neural network; bilateral craniocaudal; bootstrap cross validation; breast composition; breast density; breast imaging reporting and data system; breast tumor; clinical assessment; clinical evaluation; comparative study; computer aided design; computer aided diagnosis; Computer Aided Mass Diagnosis Model; controlled study; convolutional neural network; deep learning; diagnostic efficiency; diagnostic radiologist; diagnostic test accuracy study; discriminant analysis; false positive rate; female; full field digital mammography; human; major clinical study; mammography; mean square error; mediolateral oblique imaging; middle aged; multireader multicase study; pathological anatomy; perceptive feature extraction; probability; probability of malignancy; quantitative analysis; radiology; retrospective study; sensitivity and specificity; training; true positive rate; visual perception test",Article,Scopus
"Eng D.K., Khandwala N.B., Long J., Fefferman N.R., Lala S.V., Strubel N.A., Milla S.S., Filice R.W., Sharp S.E., Towbin A.J., Francavilla M.L., Kaplan S.L., Ecklund K., Prabhu S.P., Dillon B.J., Everist B.M., Anton C.G., Bittman M.E., Dennis R., Larson D.B., Seekins J.M., Silva C.T., Zandieh A.R., Langlotz C.P., Lungren M.P., Halabi S.S.","Artificial intelligence algorithm improves radiologist performance in skeletal age assessment: A prospective multicenter randomized controlled trial",2021,"Radiology",30,"10.1148/radiol.2021204021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120054469&doi=10.1148%2fradiol.2021204021&partnerID=40&md5=2401ed5c51aadcf114e5b95a33bc0bc3","Background: Previous studies suggest that use of artificial intelligence (AI) algorithms as diagnostic aids may improve the quality of skeletal age assessment, though these studies lack evidence from clinical practice. Purpose: To compare the accuracy and interpretation time of skeletal age assessment on hand radiograph examinations with and without the use of an AI algorithm as a diagnostic aid. Materials and Methods: In this prospective randomized controlled trial, the accuracy of skeletal age assessment on hand radiograph examinations was performed with (n = 792) and without (n = 739) the AI algorithm as a diagnostic aid. For examinations with the AI algorithm, the radiologist was shown the AI interpretation as part of their routine clinical work and was permitted to accept or modify it. Hand radiographs were interpreted by 93 radiologists from six centers. The primary efficacy outcome was the mean absolute difference between the skeletal age dictated into the radiologists' signed report and the average interpretation of a panel of four radiologists not using a diagnostic aid. The secondary outcome was the interpretation time. A linear mixed-effects regression model with random center- and radiologist-level effects was used to compare the two experimental groups. Results: Overall mean absolute difference was lower when radiologists used the AI algorithm compared with when they did not (5.36 months vs 5.95 months; P = .04). The proportions at which the absolute difference exceeded 12 months (9.3% vs 13.0%, P = .02) and 24 months (0.5% vs 1.8%, P = .02) were lower with the AI algorithm than without it. Median radiologist interpretation time was lower with the AI algorithm than without it (102 seconds vs 142 seconds, P = .001). Conclusion: Use of an artificial intelligence algorithm improved skeletal age assessment accuracy and reduced interpretation times for radiologists, although differences were observed between centers. © 2021 Radiological Society of North America Inc.. All rights reserved.",,"adolescent; adult; aged; Article; artificial intelligence; bone age determination; child; clinical outcome; clinical practice; controlled study; diagnostic accuracy; female; hand radiography; human; infant; major clinical study; male; newborn; prospective study; radiologist; randomized controlled trial; bone age determination; clinical trial; computer assisted diagnosis; multicenter study; preschool child; procedures; radiography; radiologist; reproducibility; sensitivity and specificity; Adolescent; Adult; Age Determination by Skeleton; Artificial Intelligence; Child; Child, Preschool; Female; Humans; Infant; Male; Prospective Studies; Radiographic Image Interpretation, Computer-Assisted; Radiography; Radiologists; Reproducibility of Results; Sensitivity and Specificity",Article,Scopus
"Davidson E.M., Poon M.T.C., Casey A., Grivas A., Duma D., Dong H., Suárez-Paniagua V., Grover C., Tobin R., Whalley H., Wu H., Alex B., Whiteley W.","The reporting quality of natural language processing studies: systematic review of studies of radiology reports",2021,"BMC Medical Imaging",10,"10.1186/s12880-021-00671-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117068924&doi=10.1186%2fs12880-021-00671-8&partnerID=40&md5=3af34d681629202fecbd6c480012397a","Background: Automated language analysis of radiology reports using natural language processing (NLP) can provide valuable information on patients’ health and disease. With its rapid development, NLP studies should have transparent methodology to allow comparison of approaches and reproducibility. This systematic review aims to summarise the characteristics and reporting quality of studies applying NLP to radiology reports. Methods: We searched Google Scholar for studies published in English that applied NLP to radiology reports of any imaging modality between January 2015 and October 2019. At least two reviewers independently performed screening and completed data extraction. We specified 15 criteria relating to data source, datasets, ground truth, outcomes, and reproducibility for quality assessment. The primary NLP performance measures were precision, recall and F1 score. Results: Of the 4,836 records retrieved, we included 164 studies that used NLP on radiology reports. The commonest clinical applications of NLP were disease information or classification (28%) and diagnostic surveillance (27.4%). Most studies used English radiology reports (86%). Reports from mixed imaging modalities were used in 28% of the studies. Oncology (24%) was the most frequent disease area. Most studies had dataset size > 200 (85.4%) but the proportion of studies that described their annotated, training, validation, and test set were 67.1%, 63.4%, 45.7%, and 67.7% respectively. About half of the studies reported precision (48.8%) and recall (53.7%). Few studies reported external validation performed (10.8%), data availability (8.5%) and code availability (9.1%). There was no pattern of performance associated with the overall reporting quality. Conclusions: There is a range of potential clinical applications for NLP of radiology reports in health services and research. However, we found suboptimal reporting quality that precludes comparison, reproducibility, and replication. Our results support the need for development of reporting standards specific to clinical NLP studies. © 2021, The Author(s).","Natural language processing; Radiology reports; Systematic review","human; information processing; natural language processing; radiography; radiology; reproducibility; research; Datasets as Topic; Humans; Natural Language Processing; Radiography; Radiology; Reproducibility of Results; Research Report",Article,Scopus
"Nakamura Y., Hanaoka S., Nomura Y., Nakao T., Miki S., Watadani T., Yoshikawa T., Hayashi N., Abe O.","Automatic detection of actionable radiology reports using bidirectional encoder representations from transformers",2021,"BMC Medical Informatics and Decision Making",12,"10.1186/s12911-021-01623-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114711064&doi=10.1186%2fs12911-021-01623-6&partnerID=40&md5=5894e67c4e39710a776ee24e2ca3e054","Background: It is essential for radiologists to communicate actionable findings to the referring clinicians reliably. Natural language processing (NLP) has been shown to help identify free-text radiology reports including actionable findings. However, the application of recent deep learning techniques to radiology reports, which can improve the detection performance, has not been thoroughly examined. Moreover, free-text that clinicians input in the ordering form (order information) has seldom been used to identify actionable reports. This study aims to evaluate the benefits of two new approaches: (1) bidirectional encoder representations from transformers (BERT), a recent deep learning architecture in NLP, and (2) using order information in addition to radiology reports. Methods: We performed a binary classification to distinguish actionable reports (i.e., radiology reports tagged as actionable in actual radiological practice) from non-actionable ones (those without an actionable tag). 90,923 Japanese radiology reports in our hospital were used, of which 788 (0.87%) were actionable. We evaluated four methods, statistical machine learning with logistic regression (LR) and with gradient boosting decision tree (GBDT), and deep learning with a bidirectional long short-term memory (LSTM) model and a publicly available Japanese BERT model. Each method was used with two different inputs, radiology reports alone and pairs of order information and radiology reports. Thus, eight experiments were conducted to examine the performance. Results: Without order information, BERT achieved the highest area under the precision-recall curve (AUPRC) of 0.5138, which showed a statistically significant improvement over LR, GBDT, and LSTM, and the highest area under the receiver operating characteristic curve (AUROC) of 0.9516. Simply coupling the order information with the radiology reports slightly increased the AUPRC of BERT but did not lead to a statistically significant improvement. This may be due to the complexity of clinical decisions made by radiologists. Conclusions: BERT was assumed to be useful to detect actionable reports. More sophisticated methods are required to use order information effectively. © 2021, The Author(s).","Actionable finding; Bidirectional encoder representations from transformers (BERT); Deep learning; Natural language processing (NLP); Radiology reports","human; machine learning; natural language processing; radiography; radiology; statistical model; Humans; Logistic Models; Machine Learning; Natural Language Processing; Radiography; Radiology",Article,Scopus
"European Society of Radiology (ESR)","Summary of the proceedings of the International Forum 2020: “Radiologists fighting COVID-19: a united response to a global crisis”",2021,"Insights into Imaging",,"10.1186/s13244-020-00959-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113980891&doi=10.1186%2fs13244-020-00959-3&partnerID=40&md5=275e28e583e9b8055cb797ce227bfc93","The ESR International Forum at the ECR 2020 discussed the current situation, activities and measures undertaken by radiologists around the world in their fight against the global COVID-19 pandemic. The participating societies were invited to submit written reports detailing the current situation in their countries or regions. The European Society of Radiology (ESR) established the ESR International Forum in order to discuss hot topics in the profession of radiology with non-European radiological partner societies. At the ESR International Forum 2020, different strategies, initiatives, and ideas were presented with regard to facing this unprecedented challenge together. © 2021, The Author(s).","COVID-19; Guidelines; Measures; Strategies","Article; artificial intelligence; coronavirus disease 2019; diabetes mellitus; diagnostic imaging; economics; government; hand washing; health care facility; health care personnel; health care policy; health care system; human; hypertension; image analysis; lung disease; medical education; nuclear magnetic resonance imaging; obesity; occupation; pandemic; paramedical personnel; practice guideline; publication; quarantine; radiologist; real time polymerase chain reaction; sensitivity and specificity; social distancing; telepharmacy; thorax radiography",Article,Scopus
"Casey A., Davidson E., Poon M., Dong H., Duma D., Grivas A., Grover C., Suárez-Paniagua V., Tobin R., Whiteley W., Wu H., Alex B.","A systematic review of natural language processing applied to radiology reports",2021,"BMC Medical Informatics and Decision Making",44,"10.1186/s12911-021-01533-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107118308&doi=10.1186%2fs12911-021-01533-7&partnerID=40&md5=79b0d64be95c87f26e8e21f9e06760dc","Background: Natural language processing (NLP) has a significant role in advancing healthcare and has been found to be key in extracting structured information from radiology reports. Understanding recent developments in NLP application to radiology is of significance but recent reviews on this are limited. This study systematically assesses and quantifies recent literature in NLP applied to radiology reports. Methods: We conduct an automated literature search yielding 4836 results using automated filtering, metadata enriching steps and citation search combined with manual review. Our analysis is based on 21 variables including radiology characteristics, NLP methodology, performance, study, and clinical application characteristics. Results: We present a comprehensive analysis of the 164 publications retrieved with publications in 2019 almost triple those in 2015. Each publication is categorised into one of 6 clinical application categories. Deep learning use increases in the period but conventional machine learning approaches are still prevalent. Deep learning remains challenged when data is scarce and there is little evidence of adoption into clinical practice. Despite 17% of studies reporting greater than 0.85 F1 scores, it is hard to comparatively evaluate these approaches given that most of them use different datasets. Only 14 studies made their data and 15 their code available with 10 externally validating results. Conclusions: Automated understanding of clinical narratives of the radiology reports has the potential to enhance the healthcare process and we show that research in this field continues to grow. Reproducibility and explainability of models are important if the domain is to move applications into clinical use. More could be done to share code enabling validation of methods on different institutional data and to reduce heterogeneity in reporting of study properties allowing inter-study comparisons. Our results have significance for researchers in the field providing a systematic synthesis of existing work to build on, identify gaps, opportunities for collaboration and avoid duplication. © 2021, The Author(s).","Natural language processing; Radiology; Systematic review","adoption; article; clinical practice; deep learning; filtration; human; metadata; narrative; natural language processing; quantitative analysis; radiology; reproducibility; synthesis; systematic review; validation process; machine learning; natural language processing; radiology information system; Humans; Machine Learning; Natural Language Processing; Radiology; Radiology Information Systems; Reproducibility of Results",Article,Scopus
"Pérez-Díez I., Pérez-Moraga R., López-Cerdán A., Salinas-Serrano J.-M., la Iglesia-Vayá M.","De-identifying Spanish medical texts - named entity recognition applied to radiology reports",2021,"Journal of Biomedical Semantics",6,"10.1186/s13326-021-00236-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103583047&doi=10.1186%2fs13326-021-00236-2&partnerID=40&md5=cd1a0786a873cbf3d24e6942c3654a6d","Background: Medical texts such as radiology reports or electronic health records are a powerful source of data for researchers. Anonymization methods must be developed to de-identify documents containing personal information from both patients and medical staff. Although currently there are several anonymization strategies for the English language, they are also language-dependent. Here, we introduce a named entity recognition strategy for Spanish medical texts, translatable to other languages. Results: We tested 4 neural networks on our radiology reports dataset, achieving a recall of 97.18% of the identifying entities. Alongside, we developed a randomization algorithm to substitute the detected entities with new ones from the same category, making it virtually impossible to differentiate real data from synthetic data. The three best architectures were tested with the MEDDOCAN challenge dataset of electronic health records as an external test, achieving a recall of 69.18%. Conclusions: The strategy proposed, combining named entity recognition tasks with randomization of entities, is suitable for Spanish radiology reports. It does not require a big training corpus, thus it could be easily extended to other languages and medical texts, such as electronic health records. © 2021, The Author(s).","Medical texts; Named entity recognition; Natural language processing; Radiology reports; Spanish","electronic health record; human; language; natural language processing; radiology; Electronic Health Records; Humans; Language; Natural Language Processing; Neural Networks, Computer; Radiology",Article,Scopus
"Kolanu N., Brown A.S., Beech A., Center J.R., White C.P.","Natural language processing of radiology reports for the identification of patients with fracture",2021,"Archives of Osteoporosis",15,"10.1007/s11657-020-00859-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098700073&doi=10.1007%2fs11657-020-00859-5&partnerID=40&md5=730d211753a86fc51e5c6ab938f6d636","Summary: Text-search software can be used to identify people at risk of re-fracture. The software studied identified a threefold higher number of people with fractures compared with conventional case finding. Automated software could assist fracture liaison services to identify more people at risk than traditional case finding. Purpose: Fracture liaison services address the post-fracture treatment gap in osteoporosis (OP). Natural language processing (NLP) is able to identify previously unrecognized patients by screening large volumes of radiology reports. The aim of this study was to compare an NLP software tool, XRAIT (X-Ray Artificial Intelligence Tool), with a traditional fracture liaison service at its development site (Prince of Wales Hospital [POWH], Sydney) and externally validate it in an adjudicated cohort from the Dubbo Osteoporosis Epidemiology Study (DOES). Methods: XRAIT searches radiology reports for fracture-related terms. At the development site (POWH), XRAIT and a blinded fracture liaison clinician (FLC) reviewed 5,089 reports and 224 presentations, respectively, of people 50 years or over during a simultaneous 3-month period. In the external cohort of DOES, XRAIT was used without modification to analyse digitally readable radiology reports (n = 327) to calculate its sensitivity and specificity. Results: XRAIT flagged 433 fractures after searching 5,089 reports (421 true fractures, positive predictive value of 97%). It identified more than a threefold higher number of fractures (421 fractures/339 individuals) compared with manual case finding (98 individuals). Unadjusted for the local reporting style in an external cohort (DOES), XRAIT had a sensitivity of 70% and specificity of 92%. Conclusion: XRAIT identifies significantly more clinically significant fractures than manual case finding. High specificity in an untrained cohort suggests that it could be used at other sites. Automated methods of fracture identification may assist fracture liaison services so that limited resources can be spent on treatment rather than case finding. © 2021, International Osteoporosis Foundation and National Osteoporosis Foundation.","Artificial intelligence; Automated fracture identification; Fracture liaison service; Health informatics; Osteoporosis","adult; aged; ankle; Article; case finding; clinical practice; clinician; controlled study; finger phalanx; fracture; fracture treatment; human; knowledge; major clinical study; middle aged; natural language processing; osteoporosis; predictive value; priority journal; radiology; sensitivity and specificity; software; software validation; validation study; wrist; artificial intelligence; diagnostic imaging; fracture; fragility fracture; natural language processing; osteoporosis; Artificial Intelligence; Fractures, Bone; Humans; Natural Language Processing; Osteoporosis; Osteoporotic Fractures; Radiology",Article,Scopus
"Eche T., Schwartz L.H., Mokrane F.-Z., Dercle L.","Toward generalizability in the deployment of artificial intelligence in radiology: Role of computation stress testing to overcome underspecification",2021,"Radiology: Artificial Intelligence",29,"10.1148/ryai.2021210097","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120527723&doi=10.1148%2fryai.2021210097&partnerID=40&md5=2b4daf6fcfc6733ee94bf11506535fdd","The clinical deployment of artificial intelligence (AI) applications in medical imaging is perhaps the greatest challenge facing radiology in the next decade. One of the main obstacles to the incorporation of automated AI-based decision-making tools in medicine is the failure of models to generalize when deployed across institutions with heterogeneous populations and imaging protocols. The most well-understood pitfall in developing these AI models is overfitting, which has, in part, been overcome by optimizing training protocols. However, overfitting is not the only obstacle to the success and generalizability of AI. Underspecification is also a serious impediment that requires conceptual understanding and correction. It is well known that a single AI pipeline, with prescribed training and testing sets, can produce several models with various levels of generalizability. Underspecification defines the inability of the pipeline to identify whether these models have embedded the structure of the underlying system by using a test set independent of, but distributed identically, to the training set. An underspecified pipeline is unable to assess the degree to which the models will be generalizable. Stress testing is a known tool in AI that can limit underspecification and, importantly, assure broad generalizability of AI models. However, the application of stress tests is new in radiologic applications. This report describes the concept of underspecification from a radiologist perspective, discusses stress testing as a specific strategy to overcome underspecification, and explains how stress tests could be designed in radiology—by modifying medical images or stratifying testing datasets. In the upcoming years, stress tests should become in radiology the standard that crash tests have become in the automotive industry. © RSNA, 2021.",,"article; artificial intelligence; decision making; diagnostic imaging; human; physiological stress; pipeline; radiologist; radiology",Article,Scopus
"Chen Y., Nan S., Tian Q., Cai H., Duan H., Lu X.","Automatic RadLex coding of Chinese structured radiology reports based on text similarity ensemble",2021,"BMC Medical Informatics and Decision Making",2,"10.1186/s12911-021-01604-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119341255&doi=10.1186%2fs12911-021-01604-9&partnerID=40&md5=a11f4872373264bf9b3c9714adb99ffa","Background: Standardized coding of plays an important role in radiology reports’ secondary use such as data analytics, data-driven decision support, and personalized medicine. RadLex, a standard radiological lexicon, can reduce subjective variability and improve clarity in radiology reports. RadLex coding of radiology reports is widely used in many countries, but translation and localization of RadLex in China are far from being established. Although automatic RadLex coding is a common way for non-standard radiology reports, the high-accuracy cross-language RadLex coding is hardly achieved due to the limitation of up-to-date auto-translation and text similarity algorithms and still requires further research. Methods: We present an effective approach that combines a hybrid translation and a Multilayer Perceptron weighting text similarity ensemble algorithm for automatic RadLex coding of Chinese structured radiology reports. Firstly, a hybrid way to integrate Google neural machine translation and dictionary translation helps to optimize the translation of Chinese radiology phrases to English. The dictionary is made up of 21,863 Chinese–English radiological term pairs extracted from several free medical dictionaries. Secondly, four typical text similarity algorithms are introduced, which are Levenshtein distance, Jaccard similarity coefficient, Word2vec Continuous bag-of-words model, and WordNet Wup similarity algorithms. Lastly, the Multilayer Perceptron model has been used to synthesize the contextual, lexical, character and syntactical information of four text similarity algorithms to promote precision, in which four similarity scores of two terms are taken as input and the output presents whether the two terms are synonyms. Results: The results show the effectiveness of the approach with an F1-score of 90.15%, a precision of 91.78% and a recall of 88.59%. The hybrid translation algorithm has no negative effect on the final coding, F1-score has increased by 21.44% and 8.12% compared with the GNMT algorithm and dictionary translation. Compared with the single similarity, the result of the MLP weighting similarity algorithm is satisfactory that has a 4.48% increase compared with the best single similarity algorithm, WordNet Wup. Conclusions: The paper proposed an innovative automatic cross-language RadLex coding approach to solve the standardization of Chinese structured radiology reports, that can be taken as a reference to automatic cross-language coding. © 2021, The Author(s).","Automatic coding; Hybrid translation; Standardized radiology reports; Text similarity ensemble","algorithm; article; human; human experiment; language; multilayer perceptron; radiology; recall; standardization; algorithm; China; natural language processing; radiology information system; Algorithms; China; Humans; Language; Natural Language Processing; Radiology; Radiology Information Systems",Article,Scopus
"Zheng C., Huang B.Z., Agazaryan A.A., Creekmur B., Osuj T.A., Gould M.K.","Natural Language Processing to Identify Pulmonary Nodules and Extract Nodule Characteristics From Radiology Reports",2021,"Chest",12,"10.1016/j.chest.2021.05.048","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118257725&doi=10.1016%2fj.chest.2021.05.048&partnerID=40&md5=9f83c44d689b2ee3feb398cac66cafa4","Background: There is an urgent need for population-based studies on managing patients with pulmonary nodules. Research Question: Is it possible to identify pulmonary nodules and associated characteristics using an automated method? Study Design and Methods: We revised and refined an existing natural language processing (NLP) algorithm to identify radiology transcripts with pulmonary nodules and greatly expanded its functionality to identify the characteristics of the largest nodule, when present, including size, lobe, laterality, attenuation, calcification, and edge. We compared NLP results with a reference standard of manual transcript review in a random test sample of 200 radiology transcripts. We applied the final automated method to a larger cohort of patients who underwent chest CT scan in an integrated health care system from 2006 to 2016, and described their demographic and clinical characteristics. Results: In the test sample, the NLP algorithm had very high sensitivity (98.6%; 95% CI, 95.0%-99.8%) and specificity (100%; 95% CI, 93.9%-100%) for identifying pulmonary nodules. For attenuation, edge, and calcification, the NLP algorithm achieved similar accuracies, and it correctly identified the diameter of the largest nodule in 135 of 141 cases (95.7%; 95% CI, 91.0%-98.4%). In the larger cohort, the NLP found 217,771 reports with nodules among 717,304 chest CT reports (30.4%). From 2006 to 2016, the number of reports with nodules increased by 150%, and the mean size of the largest nodule gradually decreased from 11 to 8.9 mm. Radiologists documented the laterality and lobe (90%-95%) more often than the attenuation, calcification, and edge characteristics (11%-14%). Interpretation: The NLP algorithm identified pulmonary nodules and associated characteristics with high accuracy. In our community practice settings, the documentation of nodule characteristics is incomplete. Our results call for better documentation of nodule findings. The NLP algorithm can be used in population-based studies to identify pulmonary nodules, avoiding labor-intensive chart review. © 2021 American College of Chest Physicians","chest CT scan; natural language processing; nodule characteristics; pulmonary nodule; radiology reports","adult; Article; computer assisted tomography; diagnostic test accuracy study; false negative result; false positive result; female; human; lung calcification; lung nodule; major clinical study; male; natural language processing; radiologist; radiology report; reporting and data system; sensitivity and specificity; algorithm; calcinosis; diagnostic imaging; dimensional measurement accuracy; documentation; lung; lung nodule; lung tumor; multiple pulmonary nodules; pathology; procedures; radiology; thorax radiography; total quality management; tumor volume; x-ray computed tomography; Algorithms; Calcinosis; Dimensional Measurement Accuracy; Documentation; Humans; Lung; Lung Neoplasms; Multiple Pulmonary Nodules; Natural Language Processing; Quality Improvement; Radiography, Thoracic; Radiology; Sensitivity and Specificity; Solitary Pulmonary Nodule; Tomography, X-Ray Computed; Tumor Burden",Article,Scopus
"Ringl H.","Personalized reference intervals will soon become standard in radiology reports",2021,"Radiology",2,"10.1148/radiol.2021211221","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118115280&doi=10.1148%2fradiol.2021211221&partnerID=40&md5=60342b31151f90bf7e1c5cf690929e31",[No abstract available],,"artificial intelligence; computer assisted tomography; deep learning; Editorial; ethnicity; geographic distribution; human; lean body weight; liver biopsy; liver size; liver weight; nuclear magnetic resonance imaging; personalized reference interval; predictive value; radiology; reference value; regression analysis; segmentation algorithm; sensitivity analysis; sex difference; standard; radiology information system; reference value; Humans; Radiology; Radiology Information Systems; Reference Values",Editorial,Scopus
"Li D., Yi P.H., Islam N., Verma R., McInnes M.D.F.","Diagnostic Radiology Residency Application Trends: Canadian Match Results From 2010-2020",2021,"Canadian Association of Radiologists Journal",5,"10.1177/0846537120971745","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096478233&doi=10.1177%2f0846537120971745&partnerID=40&md5=6b4e43764f8ff8e8615e35b6452fcea7","Introduction: Rapid advancements in artificial intelligence (AI) have generated uncertainty about the future of radiology among medical students. However, it is unclear whether this has affected radiology residency applications. The purpose of this study was to evaluate recent trends in the Canadian radiology residency match. Methods: Canadian Resident Matching Service annual data reports from 2010-2020 were collected. Statistics were extracted for Canadian medical graduates applying to radiology in the R-1 main residency match and analyzed using linear regression. Results: The number of available radiology residency positions decreased (P =.01); declining from 84 in 2010 to 81 in 2020 (mean = 83.1). The overall number of applicants did not change (P =.08, mean = 131.8). The proportion of applicants with radiology as their first choice decreased (P =.001); declining from 4.5% in 2010 to 3.1% in 2020 (mean = 3.4%). The number of applicants applying exclusively to radiology also decreased (P =.02); declining from 39 in 2010 to 16 in 2020 (mean = 23). Positions per applicant (P = 0.24, mean = 0.64), and positions per applicant with radiology as their first choice did not change (P = 0.07, mean = 0.91). Conclusion: While the overall number of students applying to radiology did not change, the number of applicants ranking radiology as their first or only choice decreased sharply. This analysis corroborates recent reports of increased workload, burnout, and declining reimbursement as well as uncertainty about the future of radiology due to advances in AI. © The Author(s) 2020.","artificial intelligence; postgraduate medical education; radiology; residency training","article; artificial intelligence; burnout; controlled study; human; linear regression analysis; postgraduate education; radiodiagnosis; reimbursement; residency education; uncertainty; workload; Canada; decision making; education; medical education; procedures; radiology; Canada; Career Choice; Education, Medical, Graduate; Humans; Internship and Residency; Radiology",Article,Scopus
"Tsuji S., Wen A., Takahashi N., Zhang H., Ogasawara K., Jiang G.","Developing a RadLex-based named entity recognition tool for mining textual radiology reports:development and performance evaluation study",2021,"Journal of Medical Internet Research",2,"10.2196/25378","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118487196&doi=10.2196%2f25378&partnerID=40&md5=5e927e7700a03bab2ada592b7f4c75c1","Background: Named entity recognition (NER) plays an important role in extracting the features of descriptions such as the name and location of a disease for mining free-text radiology reports. However, the performance of existing NER tools is limited because the number of entities that can be extracted depends on the dictionary lookup. In particular, the recognition of compound terms is very complicated because of the variety of patterns. Objective: The aim of this study is to develop and evaluate an NER tool concerned with compound terms using RadLex for mining free-text radiology reports. Methods: We leveraged the clinical Text Analysis and Knowledge Extraction System (cTAKES) to develop customized pipelines using both RadLex and SentiWordNet (a general purpose dictionary). We manually annotated 400 radiology reports for compound terms in noun phrases and used them as the gold standard for performance evaluation (precision, recall, and F-measure). In addition, we created a compound terms-enhanced dictionary (CtED) by analyzing false negatives and false positives and applied it to another 100 radiology reports for validation. We also evaluated the stem terms of compound terms by defining two measures: occurrence ratio (OR) and matching ratio (MR). Results: The F-measure of cTAKES+RadLex+general purpose dictionary was 30.9% (precision 73.3% and recall 19.6%) and that of the combined CtED was 63.1% (precision 82.8% and recall 51%). The OR indicated that the stem terms of effusion, node, tube, and disease were used frequently, but it still lacks capturing compound terms. The MR showed that 71.85% (9411/13,098) of the stem terms matched with that of the ontologies, and RadLex improved approximately 22% of the MR from the cTAKES default dictionary. The OR and MR revealed that the characteristics of stem terms would have the potential to help generate synonymous phrases using the ontologies. Conclusions: We developed a RadLex-based customized pipeline for parsing radiology reports and demonstrated that CtED and stem term analysis has the potential to improve dictionary-based NER performance with regard to expanding vocabularies. © 2021 Journal of Medical Internet Research. All rights reserved.","Named entity recognition (NER); Natural language processing (NLP); Ontology; RadLex; Stem term","Article; book; computer assisted tomography; data interoperability; data mining; false negative result; false positive result; feature extraction; human; intensive care; medical ontology; mining free text radiology report; named entity recognition tool; nuclear magnetic resonance imaging; positron emission tomography-computed tomography; radiology; radlex; Systematized Nomenclature of Medicine; data mining; natural language processing; radiography; Data Mining; Humans; Natural Language Processing; Radiography; Radiology",Article,Scopus
"Liu F., Zhou P., Baccei S.J., Masciocchi M.J., Amornsiripanitch N., Kiefe C.I., Rosen M.P.","Qualifying certainty in radiology reports through deep learning-based natural language processing",2021,"American Journal of Neuroradiology",7,"10.3174/ajnr.A7241","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117004415&doi=10.3174%2fajnr.A7241&partnerID=40&md5=7faa8a375ee5272b2c128e7f505823c3","BACKGROUND AND PURPOSE: Communication gaps exist between radiologists and referring physicians in conveying diagnostic certainty. We aimed to explore deep learning-based bidirectional contextual language models for automatically assessing diagnostic certainty expressed in the radiology reports to facilitate the precision of communication. MATERIALS AND METHODS: We randomly sampled 594 head MR imaging reports from an academic medical center. We asked 3 board-certified radiologists to read sentences from the Impression section and assign each sentence 1 of the 4 certainty categories: “Non-Definitive,” “Definitive-Mild,” “Definitive-Strong,” “Other.” Using the annotated 2352 sentences, we developed and validated a natural language-processing system based on the start-of-the-art bidirectional encoder representations from transformers (BERT), which can capture contextual uncertainty semantics beyond the lexicon level. Finally, we evaluated 3 BERT variant models and reported standard metrics including sensitivity, specificity, and area under the curve. RESULTS: A k score of 0.74 was achieved for interannotator agreement on uncertainty interpretations among 3 radiologists. For the 3 BERT variant models, the biomedical variant (BioBERT) achieved the best macro-average area under the curve of 0.931 (compared with 0.928 for the BERT-base and 0.925 for the clinical variant [ClinicalBERT]) on the validation data. All 3 models yielded high macro-average specificity (93.13%-93.65%), while the BERT-base obtained the highest macro-average sensitivity of 79.46% (compared with 79.08% for BioBERT and 78.52% for ClinicalBERT). The BioBERT model showed great generalizability on the heldout test data with a macro-average sensitivity of 77.29%, specificity of 92.89%, and area under the curve of 0.93. CONCLUSIONS: A deep transfer learning model can be developed to reliably assess the level of uncertainty communicated in a radiology report. © 2021 American Society of Neuroradiology. All rights reserved.",,"area under the curve; article; controlled study; deep learning; diagnostic test accuracy study; human; human experiment; natural language processing; nuclear magnetic resonance imaging; radiologist; radiology; semantics; sensitivity and specificity; transfer of learning; uncertainty; university hospital; language; natural language processing; radiography; Deep Learning; Humans; Language; Natural Language Processing; Radiography; Radiology",Article,Scopus
"Do R.K.G., Lupton K., Causa Andrieu P.I., Luthra A., Taya M., Batch K., Nguyen H., Rahurkar P., Gazit L., Nicholas K., Fong C.J., Gangai N., Schultz N., Zulkernine F., Sevilimedu V., Juluru K., Simpson A., Hricak H.","Patterns of metastatic disease in patients with cancer derived from natural language processing of structured CT radiology reports over a 10-year period",2021,"Radiology",14,"10.1148/radiol.2021210043","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115762717&doi=10.1148%2fradiol.2021210043&partnerID=40&md5=f414331d02858cffaba329ea48471352","Background: Patterns of metastasis in cancer are increasingly relevant to prognostication and treatment planning but have historically been documented by means of autopsy series. Purpose: To show the feasibility of using natural language processing (NLP) to gather accurate data from radiology reports for assessing spatial and temporal patterns of metastatic spread in a large patient cohort. Materials and Methods: In this retrospective longitudinal study, consecutive patients who underwent CT from July 2009 to April 2019 and whose CT reports followed a departmental structured template were included. Three radiologists manually curated a sample of 2219 reports for the presence or absence of metastases across 13 organs; these manually curated reports were used to develop three NLP models with an 80%-20% split for training and test sets. A separate random sample of 448 manually curated reports was used for validation. Model performance was measured by accuracy, precision, and recall for each organ. The best-performing NLP model was used to generate a final database of metastatic disease across all patients. For each cancer type, statistical descriptive reports were provided by analyzing the frequencies of metastatic disease at the report and patient levels. Results: In 91 665 patients (mean age ± standard deviation, 61 years ± 15; 46 939 women), 387 359 reports were labeled. The best-performing NLP model achieved accuracies from 90% to 99% across all organs. Metastases were most frequently reported in abdominopelvic (23.6% of all reports) and thoracic (17.6%) nodes, followed by lungs (14.7%), liver (13.7%), and bones (9.9%). Metastatic disease tropism is distinct among common cancers, with the most common first site being bones in prostate and breast cancers and liver among pancreatic and colorectal cancers. Conclusion: Natural language processing may be applied to cancer patients' CT reports to generate a large database of metastatic phenotypes. Such a database could be combined with genomic studies and used to explore prognostic imaging phenotypes with relevance to treatment planning. © RSNA, 2021",,"adult; Article; bone metastasis; breast cancer; cancer prognosis; cohort analysis; colorectal cancer; computer assisted tomography; feasibility study; female; human; liver metastasis; longitudinal study; lung metastasis; major clinical study; male; measurement accuracy; metastasis; middle aged; natural language processing; pancreas cancer; prostate cancer; retrospective study; tropism; electronic health record; factual database; information processing; metastasis; neoplasm; procedures; reproducibility; x-ray computed tomography; Data Management; Databases, Factual; Electronic Health Records; Feasibility Studies; Female; Humans; Longitudinal Studies; Male; Middle Aged; Natural Language Processing; Neoplasm Metastasis; Neoplasms; Reproducibility of Results; Retrospective Studies; Tomography, X-Ray Computed",Article,Scopus
"Olthof A.W., van Ooijen P.M.A., Cornelissen L.J.","Deep Learning-Based Natural Language Processing in Radiology: The Impact of Report Complexity, Disease Prevalence, Dataset Size, and Algorithm Type on Model Performance",2021,"Journal of Medical Systems",8,"10.1007/s10916-021-01761-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114371552&doi=10.1007%2fs10916-021-01761-4&partnerID=40&md5=887e4c6176114804588e8c80c4f69232","In radiology, natural language processing (NLP) allows the extraction of valuable information from radiology reports. It can be used for various downstream tasks such as quality improvement, epidemiological research, and monitoring guideline adherence. Class imbalance, variation in dataset size, variation in report complexity, and algorithm type all influence NLP performance but have not yet been systematically and interrelatedly evaluated. In this study, we investigate these factors on the performance of four types [a fully connected neural network (Dense), a long short-term memory recurrent neural network (LSTM), a convolutional neural network (CNN), and a Bidirectional Encoder Representations from Transformers (BERT)] of deep learning-based NLP. Two datasets consisting of radiologist-annotated reports of both trauma radiographs (n = 2469) and chest radiographs and computer tomography (CT) studies (n = 2255) were split into training sets (80%) and testing sets (20%). The training data was used as a source to train all four model types in 84 experiments (Fracture-data) and 45 experiments (Chest-data) with variation in size and prevalence. The performance was evaluated on sensitivity, specificity, positive predictive value, negative predictive value, area under the curve, and F score. After the NLP of radiology reports, all four model-architectures demonstrated high performance with metrics up to > 0.90. CNN, LSTM, and Dense were outperformed by the BERT algorithm because of its stable results despite variation in training size and prevalence. Awareness of variation in prevalence is warranted because it impacts sensitivity and specificity in opposite directions. © 2021, The Author(s).","Informatics; Machine learning; Natural language processing; Radiology","algorithm; area under the curve; Article; artificial intelligence; comparative study; computer assisted tomography; controlled study; deep learning; diagnostic test accuracy study; emergency ward; epiphysiolysis; human; intrarater reliability; long short term memory network; lung infiltrate; major clinical study; natural language processing; performance indicator; predictive value; prevalence; protocol compliance; radiodiagnosis; radiologist; radiology; recurrent neural network; retrospective study; sensitivity and specificity; thorax radiography; workflow; algorithm; natural language processing; prevalence; Algorithms; Deep Learning; Humans; Natural Language Processing; Prevalence; Radiology",Article,Scopus
"Kapoor N., Lacson R., Eskian M., Cochon L., Glazer D., Ip I., Khorasani R.","Variation in Radiologists’ Follow-Up Imaging Recommendations for Small Cystic Pancreatic Lesions",2021,"Journal of the American College of Radiology",3,"10.1016/j.jacr.2021.06.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110441895&doi=10.1016%2fj.jacr.2021.06.007&partnerID=40&md5=6dd517822941092815173430be59a9fd","Objective: This study aimed to determine the incidence, identify imaging and patient factors, and measure individual radiologist variation associated with follow-up recommendations for small focal cystic pancreatic lesions (FCPLs), a common incidental imaging finding. Methods: This institutional review board–approved retrospective study analyzed 146,709 reports from abdominal CTs and MRIs performed in a large academic hospital from July 1, 2016, to June 30, 2018. A trained natural language processing tool identified 4,345 reports with FCPLs, which were manually reviewed to identify those containing one or more <1.5-cm pancreatic cysts. For these patients, patient, lesion, and radiologist features and follow-up recommendations for FCPL were extracted. A nonlinear random-effects model estimated degree of variation in follow-up recommendations across radiologists at department and division levels. Results: Of 2,872 reports with FCPLs < 1.5 cm, 708 (24.7%) had FCPL-related follow-up recommendations. Average patient age was 67 years (SD ± 11). In all, 1,721 (60.0%) reports were for female patients; 59.3% of patients had only one cyst. In multivariable analysis, older patients had slightly lower follow-up recommendation rates (odds ratio [OR]: 0.98 [0.98-1.00] per additional year), and lesions associated with main duct dilatation and septation were more likely to have a follow-up recommendation (ORs: 1.93 [1.11-3.36] and 2.88 [1.89-4.38], respectively). Radiologist years in practice (P =.51), trainee presence (P =.21), and radiologist gender (P =.52) were not associated with increased follow-up recommendations. There was significant interradiologist variation in the Abdominal Imaging Division (P =.04), but not in Emergency Radiology (P =.31) or Cancer Imaging Divisions (P =.29). Discussion: Interradiologist variation significantly contributes to variability in follow-up imaging recommendations for FCPLs. © 2021","Follow-up imaging; natural language processing; pancreatic cyst","aged; Article; clinical article; emergency ward; female; follow up; human; learning algorithm; lung nodule; machine learning; male; natural language processing; nuclear magnetic resonance imaging; observational study; pancreas cyst; practice guideline; prevalence; radiodiagnosis; radiologist; retrospective study; support vector machine; university hospital; x-ray computed tomography; diagnostic imaging; follow up; pancreas tumor; radiologist; Aged; Female; Follow-Up Studies; Humans; Magnetic Resonance Imaging; Pancreatic Cyst; Pancreatic Neoplasms; Radiologists; Retrospective Studies",Article,Scopus
"Canton S.P., Dadashzadeh E., Yip L., Forsythe R., Handzel R.","Automatic Detection of Thyroid and Adrenal Incidentals Using Radiology Reports and Deep Learning",2021,"Journal of Surgical Research",3,"10.1016/j.jss.2021.03.060","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106249898&doi=10.1016%2fj.jss.2021.03.060&partnerID=40&md5=f04da575d084193245d6ed2c90e23d29","Background: Computed tomography (CT) is commonly performed when evaluating trauma patients with up to 55% showing incidental findings. Current workflows to identify and inform patients are time-consuming and prone to error. Our objective was to automatically identify thyroid and adrenal lesions in radiology reports using deep learning. Materials and methods: All trauma patients who presented to an accredited Level 1 Trauma Center between January 2008 and January 2019 were included. Radiology reports of CT scans that included either a thyroid or adrenal gland were obtained. Preprocessing included word tokenization, removal of stop words, removal of punctuation, and replacement of misspellings. A word2vec model was trained using 1.4 million radiology reports. Both training and testing reports were selected at random, manually reviewed, and were considered the gold standard. True positive cases were defined as any lesions in the thyroid or adrenal gland, respectively. Training data was used to create models that would identify reports that contained either thyroid or adrenal lesions. Our primary outcomes were sensitivity and specificity of the models using predetermined thresholds on a separate testing dataset. Results: A total of 51,771 reports were identified on 35,859 trauma patients. A total of 1,789 reports were annotated for training and 500 for testing. The thyroid model predictions resulted in a 90.0% sensitivity and 95.3% specificity. The adrenal model predictions resulted in a 92.3% sensitivity and a 91.1% specificity. A total of 240 reports were confirmed to have thyroid incidentals (mean age 69.1 yrs ± 18.9, 35% M) and 214 reports with adrenal incidentals (mean age 68.7 yrs ± 16.9, 50.5% M). Conclusions: Both the thyroid and adrenal models have excellent performance with sensitivities and specificities in the 90s. Our deep learning model has the potential to reduce administrative costs and improve the process of informing patients. © 2021","Deep learning; Incidental findings; Natural language processing; Trauma centers","adrenal gland; aged; article; computer assisted tomography; deep learning; emergency health service; female; gold standard; human; incidental finding; major clinical study; male; natural language processing; outcome assessment; prediction; radiology; sensitivity and specificity; workflow; adrenal tumor; adult; algorithm; complication; diagnostic imaging; injury; middle aged; retrospective study; thyroid tumor; x-ray computed tomography; Adrenal Gland Neoplasms; Adult; Aged; Algorithms; Clinical Decision Rules; Deep Learning; Female; Humans; Incidental Findings; Male; Middle Aged; Retrospective Studies; Sensitivity and Specificity; Thyroid Neoplasms; Tomography, X-Ray Computed; Wounds and Injuries",Article,Scopus
"Mongan J., Kalpathy-Cramer J., Flanders A., Linguraru M.G.","Rsna-miccai panel discussion: Machine learning for radiology from challenges to clinical applications",2021,"Radiology: Artificial Intelligence",3,"10.1148/ryai.2021210118","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119897122&doi=10.1148%2fryai.2021210118&partnerID=40&md5=72d705559bb60a8c572d969ca1b8559c","On October 5, 2020, the Medical Image Computing and Computer Assisted Intervention Society (MICCAI) 2020 conference hosted a virtual panel discussion with members of the Machine Learning Steering Subcommittee of the Radiological Society of North America. The MICCAI Society brings together scientists, engineers, physicians, educators, and students from around the world. Both societies share a vision to develop radiologic and medical imaging techniques through advanced quantitative imaging biomarkers and artificial intelligence. The panel elaborated on how collaborations between radiologists and machine learning scientists facilitate the creation and clinical success of imaging technology for radiology. This report presents structured highlights of the moderated dialogue at the panel. © RSNA, 2021.","Artificial Neural Network Algorithms; Back-Propagation; Machine Learning Algorithms","biological marker; Article; artificial intelligence; artificial neural network; bone age; brain hemorrhage; clinical assessment; clinical practice; cognitive bias; data science; decision support system; diagnostic imaging; digital imaging and communications in medicine; human; incentive; machine learning; medical society; pneumonia; pneumothorax; prognosis; program acceptability",Article,Scopus
"Mozayan A., Fabbri A.R., Maneevese M., Tocino I., Chheang S.","Practical guide to natural language processing for radiology",2021,"Radiographics",13,"10.1148/rg.2021200113","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114317219&doi=10.1148%2frg.2021200113&partnerID=40&md5=40a8b586041dbc4ef1a34475eb623b56","Natural language processing (NLP) is the subset of artificial intelligence focused on the computer interpretation of human language. It is an invaluable tool in the analysis, aggregation, and simplification of free text. It has already demonstrated significant potential in the analysis of radiology reports. There are abundant open-source librar-ies and tools available that facilitate its application to the benefit of radiology. Radiologists who understand its limitations and potential will be better positioned to evaluate NLP models, understand how they can improve clinical workflow, and facilitate research endeav-ors involving large amounts of human language. The advent of in-creasingly affordable and powerful computer processing, the large quantities of medical and radiologic data, and advances in machine learning algorithms have contributed to the large potential of NLP. In turn, radiology has significant potential to benefit from the ability of NLP to convert relatively standardized radiology reports to machine-readable data. NLP benefits from standardized reporting, but because of its ability to interpret free text by using context clues, NLP does not necessarily depend on it. An overview and practical approach to NLP is featured, with specific emphasis on its applications to radiology. A brief history of NLP, the strengths and chal-lenges inherent to its use, and freely available resources and tools are covered to guide further exploration and study within the field. Particular attention is devoted to the recent development of the Word2Vec and BERT (Bidirectional Encoder Representations from Transformers) language models, which have exponentially increased the power and utility of NLP for a variety of applications. © RSNA, 2021.",,"article; artificial intelligence; attention; human; human experiment; machine learning; natural language processing; radiologist; radiology; workflow; radiography; Artificial Intelligence; Humans; Machine Learning; Natural Language Processing; Radiography; Radiology",Article,Scopus
"Juluru K., Shih H.-H., Murthy K.N.K., Elnajjar P.","Bag-of-words technique in natural language processing: A primer for radiologists",2021,"Radiographics",14,"10.1148/rg.2021210025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114288808&doi=10.1148%2frg.2021210025&partnerID=40&md5=6f1add85ad5ff1bad8a87fb09d33172c","Natural language processing (NLP) is a methodology designed to extract concepts and meaning from human-generated unstructured (free-form) text. It is intended to be implemented by using computer algorithms so that it can be run on a corpus of documents quickly and reliably. To enable machine learning (ML) techniques in NLP, free-form text must be converted to a numerical repre-sentation. After several stages of preprocessing including tokeniza-tion, removal of stop words, token normalization, and creation of a master dictionary, the bag-of-words (BOW) technique can be used to represent each remaining word as a feature of the document. The preprocessing steps simplify the documents but also poten-tially degrade meaning. The values of the features in BOW can be modified by using techniques such as term count, term frequency, and term frequency–inverse document frequency. Experience and experimentation will guide decisions on which specific techniques will optimize ML performance. These and other NLP techniques are being applied in radiology. Radiologists’ understanding of the strengths and limitations of these techniques will help in communi-cation with data scientists and in implementation for specific tasks. © RSNA, 2021.",,"algorithm; human; machine learning; natural language processing; radiologist; radiology; Algorithms; Humans; Machine Learning; Natural Language Processing; Radiologists; Radiology",Article,Scopus
"Youn S.Y., Choi M.H., Kim D.H., Lee Y.J., Huisman H., Johnson E., Penzkofer T., Shabunin I., Winkel D.J., Xing P., Szolar D., Grimm R., von Busch H., Son Y., Lou B., Kamen A.","Detection and PI-RADS classification of focal lesions in prostate MRI: Performance comparison between a deep learning-based algorithm (DLA) and radiologists with various levels of experience",2021,"European Journal of Radiology",17,"10.1016/j.ejrad.2021.109894","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113212186&doi=10.1016%2fj.ejrad.2021.109894&partnerID=40&md5=7c6cf9c644bfeff7f9d8651489ad2ebf","Purpose: To compare the performance of lesion detection and Prostate Imaging-Reporting and Data System (PI-RADS) classification between a deep learning-based algorithm (DLA), clinical reports and radiologists with different levels of experience in prostate MRI. Methods: This retrospective study included 121 patients who underwent prebiopsy MRI and prostate biopsy. More than five radiologists (Reader groups 1, 2: residents; Readers 3, 4: less-experienced radiologists; Reader 5: expert) independently reviewed biparametric MRI (bpMRI). The DLA results were obtained using bpMRI. The reference standard was based on pathologic reports. The diagnostic performance of the PI-RADS classification of DLA, clinical reports, and radiologists was analyzed using AUROC. Dichotomous analysis (PI-RADS cutoff value ≥ 3 or 4) was performed, and the sensitivities and specificities were compared using McNemar's test. Results: Clinically significant cancer [CSC, Gleason score ≥ 7] was confirmed in 43 patients (35.5%). The AUROC of the DLA (0.828) for diagnosing CSC was significantly higher than that of Reader 1 (AUROC, 0.706; p = 0.011), significantly lower than that of Reader 5 (AUROC, 0.914; p = 0.013), and similar to clinical reports and other readers (p = 0.060–0.661). The sensitivity of DLA (76.7%) was comparable to those of all readers and the clinical reports at a PI-RADS cutoff value ≥ 4. The specificity of the DLA (85.9%) was significantly higher than those of clinical reports and Readers 2–3 and comparable to all others at a PI-RADS cutoff value ≥ 4. Conclusions: The DLA showed moderate diagnostic performance at a level between those of residents and an expert in detecting and classifying according to PI-RADS. The performance of DLA was similar to that of clinical reports from various radiologists in clinical practice. © 2021 Elsevier B.V.","Deep learning; Magnetic resonance imaging; Prostate; Prostate imaging reporting and data system; Prostate neoplasms","prostate specific antigen; adult; area under the curve; Article; controlled study; deep learning; diagnostic test accuracy study; diffusion coefficient; diffusion weighted imaging; electronic medical record; human; human tissue; informed consent; major clinical study; male; nuclear magnetic resonance imaging; prostate biopsy; prostate imaging reporting and data system; prostatectomy; receiver operating characteristic; retrospective study; sensitivity analysis; sensitivity and specificity; standard; T2 weighted imaging; transrectal ultrasound guided biopsy; diagnostic imaging; prostate tumor; radiologist; Deep Learning; Humans; Magnetic Resonance Imaging; Male; Prostatic Neoplasms; Radiologists; Retrospective Studies",Article,Scopus
"Olthof A.W., Shouche P., Fennema E.M., IJpma F.F.A., Koolstra R.H.C., Stirler V.M.A., van Ooijen P.M.A., Cornelissen L.J.","Machine learning based natural language processing of radiology reports in orthopaedic trauma",2021,"Computer Methods and Programs in Biomedicine",21,"10.1016/j.cmpb.2021.106304","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111254500&doi=10.1016%2fj.cmpb.2021.106304&partnerID=40&md5=37e2cb60bb55b2be339f1bf073b69456","Objectives: To compare different Machine Learning (ML) Natural Language Processing (NLP) methods to classify radiology reports in orthopaedic trauma for the presence of injuries. Assessing NLP performance is a prerequisite for downstream tasks and therefore of importance from a clinical perspective (avoiding missed injuries, quality check, insight in diagnostic yield) as well as from a research perspective (identification of patient cohorts, annotation of radiographs). Methods: Datasets of Dutch radiology reports of injured extremities (n = 2469, 33% fractures) and chest radiographs (n = 799, 20% pneumothorax) were collected in two different hospitals and labeled by radiologists and trauma surgeons for the presence or absence of injuries. NLP classification was applied and optimized by testing different preprocessing steps and different classifiers (Rule-based, ML, and Bidirectional Encoder Representations from Transformers (BERT)). Performance was assessed by F1-score, AUC, sensitivity, specificity and accuracy. Results: The deep learning based BERT model outperforms all other classification methods which were assessed. The model achieved an F1-score of (95 ± 2)% and accuracy of (96 ± 1)% on a dataset of simple reports (n= 2469), and an F1 of (83 ± 7)% with accuracy (93 ± 2)% on a dataset of complex reports (n= 799). Conclusion: BERT NLP outperforms traditional ML and rule-base classifiers when applied to Dutch radiology reports in orthopaedic trauma. © 2021","(MeSH); Informatics; Machine learning; Natural language processing; Orthopaedic trauma; Radiology","Classification (of information); Deep learning; Learning algorithms; Natural language processing systems; Radiation; Radiography; (MeSH); F1 scores; Informatics; Language processing; Machine-learning; Natural languages; Orthopedic trauma; Processing method; Processing performance; Radiology reports; Radiology; Article; artificial neural network; Bayesian learning; bidirectional encoder representations from transformers; bone injury; classification algorithm; classifier; cohort analysis; controlled study; deep learning; diagnostic accuracy; diagnostic test accuracy study; disease classification; human; limb injury; machine learning; major clinical study; natural language processing; pneumothorax; radiologist; radiology; random forest; retrospective study; rule based classifier; sensitivity and specificity; thorax radiography; trauma surgeon; machine learning; natural language processing; orthopedics; radiography; Humans; Machine Learning; Natural Language Processing; Orthopedics; Radiography; Radiology",Article,Scopus
"Richardson M.L., Adams S.J., Agarwal A., Auffermann W.F., Bhattacharya A.K., Consul N., Fotos J.S., Kelahan L.C., Lin C., Lo H.S., Nguyen X.V., Salkowski L.R., Sin J.M., Thomas R.C., Wassef S., Ikuta I.","Review of Artificial Intelligence Training Tools and Courses for Radiologists",2021,"Academic Radiology",8,"10.1016/j.acra.2020.12.026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108506186&doi=10.1016%2fj.acra.2020.12.026&partnerID=40&md5=30b32546563aa22e43070c76eed924af","Artificial intelligence (AI) systems play an increasingly important role in all parts of the imaging chain, from image creation to image interpretation to report generation. In order to responsibly manage radiology AI systems and make informed purchase decisions about them, radiologists must understand the underlying principles of AI. Our task force was formed by the Radiology Research Alliance (RRA) of the Association of University Radiologists to identify and summarize a curated list of current educational materials available for radiologists. © 2021","artificial intelligence; deep learning; education; machine learning; radiology","article; artificial intelligence; deep learning; education; human; radiologist; radiology; radiography; radiologist; Artificial Intelligence; Humans; Radiography; Radiologists; Radiology",Article,Scopus
"Lin M., Wang S., Ding Y., Zhao L., Wang F., Peng Y.","An empirical study of using radiology reports and images to improve ICU-mortality prediction",2021,"Proceedings - 2021 IEEE 9th International Conference on Healthcare Informatics, ISCHI 2021",5,"10.1109/ICHI52183.2021.00088","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118117260&doi=10.1109%2fICHI52183.2021.00088&partnerID=40&md5=d85e1e3d86eeb13242f58a3bafb6365d","The predictive Intensive Care Unit (ICU) scoring system plays an important role in ICU management for its capability of predicting important outcomes, especially mortality. There are many scoring systems that have been developed and used in the ICU. These scoring systems are primarily based on the structured clinical data contained in the electronic health record (EHR), which may suffer the loss of the important clinical information contained in the narratives and images. In this work, we build a deep learning based survival prediction model with multimodality data to predict ICU-mortality. Four sets of features are investigated: (1) physiological measurements of Simplified Acute Physiology Score (SAPS) II, (2) common thorax diseases pre-defined by radiologists, (3) BERT-based text representations, and (4) chest X-ray image features. We use the Medical Information Mart for Intensive Care IV (MIMIC-IV) dataset to evaluate the proposed model. Our model achieves the average C- index of 0.7847 (95% confidence interval, 0.7625-0.8068), which substantially exceeds that of the baseline with SAPS-II features (0.7477 (0.7238-0.7716)). Ablation studies further demonstrate the contributions of pre-defined labels (2.12%), text features (2.68%), and image features (2.96%). Our model achieves a higher average C-index than the traditional machine learning methods under the same feature fusion setting, which suggests that the deep learning methods can outperform the traditional machine learning methods in ICU-mortality prediction. These results highlight the potential of deep learning models with multimodal information to enhance ICU-mortality prediction. We make our work publicly available at https://github.com/bionlplab/mimic-icu-mortality. © 2021 IEEE.","Deep learning; Mortality prediction; Multimodal fusion","Deep learning; Forecasting; Image enhancement; Image fusion; Medical imaging; Physiology; Clinical data; Clinical information; Deep learning; Empirical studies; Image features; Machine learning methods; Mortality prediction; Multi-modal fusion; Radiology reports; Scoring systems; Intensive care units",Conference Paper,Scopus
"Shah M., Shu D., Prasath V.B.S., Ni Y., Schapiro A.H., Dufendach K.R.","Machine Learning for Detection of Correct Peripherally Inserted Central Catheter Tip Position from Radiology Reports in Infants",2021,"Applied Clinical Informatics",3,"10.1055/s-0041-1735178","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114835592&doi=10.1055%2fs-0041-1735178&partnerID=40&md5=c3c2ebd338a70025ac90ea1c3f3c38da","Background In critically ill infants, the position of a peripherally inserted central catheter (PICC) must be confirmed frequently, as the tip may move from its original position and run the risk of hyperosmolar vascular damage or extravasation into surrounding spaces. Automated detection of PICC tip position holds great promise for alerting bedside clinicians to noncentral PICCs. Objectives This research seeks to use natural language processing (NLP) and supervised machine learning (ML) techniques to predict PICC tip position based primarily on text analysis of radiograph reports from infants with an upper extremity PICC. Methods Radiographs, containing a PICC line in infants under 6 months of age, were manually classified into 12 anatomical locations based on the radiologist's textual report of the PICC line's tip. After categorization, we performed a 70/30 train/test split and benchmarked the performance of seven different (neural network, support vector machine, the naïve Bayes, decision tree, random forest, AdaBoost, and K-nearest neighbors) supervised ML algorithms. After optimization, we calculated accuracy, precision, and recall of each algorithm's ability to correctly categorize the stated location of the PICC tip. Results A total of 17,337 radiographs met criteria for inclusion and were labeled manually. Interrater agreement was 99.1%. Support vector machines and neural networks yielded accuracies as high as 98% in identifying PICC tips in central versus noncentral position (binary outcome) and accuracies as high as 95% when attempting to categorize the individual anatomical location (12-category outcome). Conclusion Our study shows that ML classifiers can automatically extract the anatomical location of PICC tips from radiology reports. Two ML classifiers, support vector machine (SVM) and a neural network, obtained top accuracies in both binary and multiple category predictions. Implementing these algorithms in a neonatal intensive care unit as a clinical decision support system may help clinicians address PICC line position. © 2021 Georg Thieme Verlag. All rights reserved.","medical error reduction; natural language processing; patient safety; radiology information systems; supervised machine learning","Bayes theorem; catheter; central venous catheterization; human; infant; machine learning; newborn; radiology; retrospective study; Bayes Theorem; Catheterization, Central Venous; Catheters; Humans; Infant; Infant, Newborn; Machine Learning; Radiology; Retrospective Studies",Article,Scopus
"Erickson B.J.","Imaging systems in radiology",2021,"Biomedical Informatics: Computer Applications in Health Care and Biomedicine: Fifth Edition",1,"10.1007/978-3-030-58721-5_22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149623098&doi=10.1007%2f978-3-030-58721-5_22&partnerID=40&md5=2b0df3cfce99e1296e9e3cfa6b628c95","Imaging has provided the ability of physicians to 'see inside' the body, enabling significantly more accurate diagnosis than was possible by physical examination. Radiological imaging is now widely used for diagnosis, and increasingly for therapeutic guidance. Its naturally digital form has also enabled artificial intelligence, and specifically deep learning to improve diagnostic accuracy and also increase the quantitative content in imaging reports. This chapter will describe the history of these systems initially replacing film images, but now producing lifelike 3D visualizations, and applying deep learning to extract information that can rival human performance. © Springer Nature Switzerland AG 2021.","Advanced Visualization System (AVS); Deep Learning; DICOM; Picture Archiving and Communications System (PACS); Radiology Information System (RIS); Speech Recognition; Teleradiology; Vendor Neutral Archive (VNA); Workflow Orchestration",,Book Chapter,Scopus
"Wiggins W.F., Kitamura F., Santos I., Prevedello L.M.","Natural language processing of radiology text reports: Interactive text classification",2021,"Radiology: Artificial Intelligence",5,"10.1148/ryai.2021210035","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113786553&doi=10.1148%2fryai.2021210035&partnerID=40&md5=b469ba70854f3c66de84a9c11bb8db84","This report presents a hands-on introduction to natural language processing (NLP) of radiology reports with deep neural networks in Google Colaboratory (Colab) to introduce readers to the rapidly evolving field of NLP. The implementation of the Google Colab notebook was designed with code hidden to facilitate learning for noncoders (ie, individuals with little or no computer programming experience). The data used for this module are the corpus of radiology reports from the Indiana University chest x-ray collection avail-able from the National Library of Medicine’s Open-I service. The module guides learners through the process of exploring the data, splitting the data for model training and testing, preparing the data for NLP analysis, and training a deep NLP model to classify the reports as normal or abnormal. Concepts in NLP, such as tokenization, numericalization, language modeling, and word embeddings, are demonstrated in the module. The module is implemented in a guided fashion with the authors presenting the material and explain-ing concepts. Interactive features and extensive text commentary are provided directly in the notebook to facilitate self-guided learning and experimentation with the module. © RSNA, 2021.",,"adult; article; deep neural network; embedding; female; human; human experiment; Indiana; learning; male; natural language processing; reading; software; thorax radiography",Article,Scopus
"Loveymi S., Dezfoulian M.H., Mansoorizadeh M.","Automatic generation of structured radiology reports for volumetric computed tomography images using question-Specific deep feature extraction and learning",2021,"Journal of Medical Signals and Sensors",4,"10.4103/jmss.JMSS_21_20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111818757&doi=10.4103%2fjmss.JMSS_21_20&partnerID=40&md5=663a9f499a3b190ab01ec361c5e529ac","Background: In today's modern medicine, the use of radiological imaging devices has spread at medical centers. Therefore, the need for accurate, reliable, and portable medical image analysis and understanding systems has been increasing constantly. Accompanying images with the required clinical information, in the form of structured reports, is very important, because images play a pivotal role in detect, planning, and diagnosis of different diseases. Report-writing can be exposure to error, tedious and labor-intensive for physicians and radiologists; to address these issues, there is a need for systems that generate medical image reports automatically and efficiently. Thus, automatic report generation systems are among the most desired applications. Methods: This research proposes an automatic structured-radiology report generation system that is based on deep learning methods. Extracting useful and descriptive image features to model the conceptual contents of the images is one of the main challenges in this regard. Considering the ability of deep neural networks (DNNs) in soliciting informative and effective features as well as lower resource requirements, tailored convolutional neural networks and MobileNets are employed as the main building blocks of the proposed system. To cope with challenges such as multi-slice medical images and diversity of questions asked in a radiology report, our system develops volume-level and question-specific deep features using DNNs. Results: We demonstrate the effectiveness of the proposed system on ImageCLEF2015 Liver computed tomography (CT) annotation task, for filling in a structured radiology report about liver CT. The results confirm the efficiency of the proposed approach, as compared to classic annotation methods. Conclusion: We have proposed a question-specific DNN-based system for filling in structured radiology reports about medical images. © 2021 Journal of Medical Signals and Sensors Published by Wolters Kluwer-Medknow.","Convolutional neural network; medical image analysis; MobileNet; radiology report generation","Article; automation; bag of visual word; bi-dimensional intrinsic mode function; binary classification; classification algorithm; clinical article; comparative study; cone beam computed tomography; content-based image retrieval; convolutional neural network; cross validation; deep learning; deep neural network; distance local binary pattern; feature extraction; gray level co-occurrence matrix; hepatography; human; image analysis; image processing; image retrieval; imaging algorithm; information processing; k nearest neighbor; machine learning; measurement accuracy; metadata; multiclass classification; radiology; scale invariant feature transform; support vector machine; three-dimensional imaging; transfer of learning",Article,Scopus
"Kao C.-Y., Lin C.-Y., Chao C.-C., Huang H.-S., Lee H.-Y., Chang C.-M., Sung K., Chen T.R., Chiang P.-C., Huang L.-T., Wang B., Liu Y.-S., Chiang J.-H., Wang C.-K., Tsai Y.-S.","Automated radiology alert system for pneumothorax detection on chest radiographs improves efficiency and diagnostic performance",2021,"Diagnostics",5,"10.3390/diagnostics11071182","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109355887&doi=10.3390%2fdiagnostics11071182&partnerID=40&md5=acc60ad646b6ff04f729ff236ee51eda","We aimed to set up an Automated Radiology Alert System (ARAS) for the detection of pneumothorax in chest radiographs by a deep learning model, and to compare its efficiency and diagnostic performance with the existing Manual Radiology Alert System (MRAS) at the tertiary medical center. This study retrospectively collected 1235 chest radiographs with pneumothorax labeling from 2013 to 2019, and 337 chest radiographs with negative findings in 2019 were separated into training and validation datasets for the deep learning model of ARAS. The efficiency before and after using the model was compared in terms of alert time and report time. During parallel running of the two systems from September to October 2020, chest radiographs prospectively acquired in the emergency department with age more than 6 years served as the testing dataset for comparison of diagnostic performance. The efficiency was improved after using the model, with mean alert time improving from 8.45 min to 0.69 min and the mean report time from 2.81 days to 1.59 days. The comparison of the diagnostic performance of both systems using 3739 chest radiographs acquired during parallel running showed that the ARAS was better than the MRAS as assessed in terms of sensitivity (recall), area under receiver operating characteristic curve, and F1 score (0.837 vs. 0.256, 0.914 vs. 0.628, and 0.754 vs. 0.407, respectively), but worse in terms of positive predictive value (PPV) (precision) (0.686 vs. 1.000). This study had successfully designed a deep learning model for pneumothorax detection on chest radiographs and set up an ARAS with improved efficiency and overall diagnostic performance. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Artificial intelligence; Deep learning; Pneumothorax; Radiology alert system","Article; comparative effectiveness; controlled study; deep learning; diagnostic accuracy; diagnostic test accuracy study; diagnostic value; emergency ward; human; major clinical study; pneumothorax; predictive value; prospective study; receiver operating characteristic; retrospective study; sensitivity and specificity; tertiary care center; thorax radiography; time",Article,Scopus
"Ginat D.","Implementation of machine learning software on the radiology worklist decreases scan view delay for the detection of intracranial hemorrhage on CT",2021,"Brain Sciences",18,"10.3390/brainsci11070832","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109173424&doi=10.3390%2fbrainsci11070832&partnerID=40&md5=cf6edf3af59abca1e51163fd1b0f61ec","Background and Purpose: Prompt identification of acute intracranial hemorrhage on CT is important. The goal of this study was to assess the impact of artificial intelligence software for prioritizing positive cases. Materials and Methods: Cases analyzed by Aidoc (Tel Aviv, Israel) software for triaging acute intracranial hemorrhage cases on non-contrast head CT were retrospectively reviewed. The scan view delay time was calculated as the difference between the time the study was completed on PACS and the time the study was first opened by a radiologist. The scan view delay was stratified by scan location, including emergency, inpatient, and outpatient. The scan view delay times for cases flagged as positive by the software were compared to those that were not flagged. Results: A total of 8723 scans were assessed by the software, including 6894 cases that were not flagged and 1829 cases that were flagged as positive. Although there was no statistically significant difference in the scan view time for emergency cases, there was a significantly lower scan view time for positive outpatient and inpatient cases flagged by the software versus negative cases, with a reduction of 604 min on average, 90% in the scan view delay (p-value < 0.0001) for outpatients, and a reduction of 38 min on average, and 10% in the scan view delay (p-value <= 0.01) for inpatients. Conclusion: The use of artificial intelligence triage software for acute intracranial hemorrhage on head CT scans is associated with a significantly shorter scan view delay for cases flagged as positive than cases not flagged among outpatients and inpatients at an academic medical center. © 2021 by the author. Licensee MDPI, Basel, Switzerland.","Artificial intelligence; CT; Head; Hemorrhage; Report; Scan view delay","Article; artificial intelligence; brain hemorrhage; computer aided design; controlled study; deep learning; diagnostic test accuracy study; health care cost; human; non contrast head CT; predictive value; radiologist; radiology; retrospective study; scan view delay; sensitivity and specificity; software; x-ray computed tomography",Article,Scopus
"Singh S., Karimi S., Ho-Shon K., Hamey L.","Show, tell and summarise: learning to generate and summarise radiology findings from medical images",2021,"Neural Computing and Applications",7,"10.1007/s00521-021-05943-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103636988&doi=10.1007%2fs00521-021-05943-6&partnerID=40&md5=bbf28945add2d35b383e7c67b5d081cd","Radiology plays a vital role in health care by viewing the human body for diagnosis, monitoring, and treatment of medical problems. In radiology practice, radiologists routinely examine medical images such as chest X-rays and describe their findings in the form of radiology reports. However, this task of reading medical images and summarising its insights is time consuming, tedious, and error-prone, which often represents a bottleneck in the clinical diagnosis process. A computer-aided diagnosis system which can automatically generate radiology reports from medical images can be of great significance in reducing workload, reducing diagnostic errors, speeding up clinical workflow, and helping to alleviate any shortage of radiologists. Existing research in radiology report generation focuses on generating the concatenation of the findings and impression sections. Also, existing work ignores important differences between normal and abnormal radiology reports. The text of normal and abnormal reports differs in style and it is difficult for a single model to learn both the text style and learn to transition from findings to impression. To alleviate these challenges, we propose a Show, Tell and Summarise model that first generates findings from chest X-rays and then summarises them to provide impression section. The proposed work generates the findings and impression sections separately, overcoming the limitation of previous research. Also, we use separate models for generating normal and abnormal radiology reports which provide true insight of model’s performance. Experimental results on the publicly available IU-CXR dataset show the effectiveness of our proposed model. Finally, we highlight limitations in the radiology report generation research and present recommendations for future work. © 2021, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.","Artificial intelligence; Chest X-rays; Computer vision; Computer-aided report generation; Deep learning; Medical imaging; Natural language processing; Radiology report generation","Computer aided diagnosis; Medical problems; Radiology; X rays; Clinical diagnosis; Clinical workflow; Computer aided diagnosis systems; Diagnostic errors; Error prones; Human bodies; Radiology reports; Single models; Medical imaging",Article,Scopus
"Kapoor N., Lacson R., Cochon L., Hammer M., Ip I., Boland G., Khorasani R.","Radiologist Variation in the Rates of Follow-up Imaging Recommendations Made for Pulmonary Nodules",2021,"Journal of the American College of Radiology",6,"10.1016/j.jacr.2020.12.031","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101879774&doi=10.1016%2fj.jacr.2020.12.031&partnerID=40&md5=89ef20052fb99fa80c12c92a46286f3d","Objective: Determine whether differences exist in rates of follow-up recommendations made for pulmonary nodules after accounting for multiple patient and radiologist factors. Methods: This Institutional Review Board–approved, retrospective study was performed at an urban academic quaternary care hospital. We analyzed 142,001 chest and abdominal CT reports from January 1, 2016, to December 31, 2018, from abdominal, thoracic, and emergency radiology subspecialty divisions. A previously validated natural language processing (NLP) tool identified 24,512 reports documenting pulmonary nodule(s), excluding reports NLP-positive for lung cancer. A second validated NLP tool identified reports with follow-up recommendations specifically for pulmonary nodules. Multivariable logistic regression was used to determine the likelihood of pulmonary nodule follow-up recommendation. Interradiologist variability was quantified within subspecialty divisions. Results: NLP classified 4,939 of 24,512 (20.1%) reports as having a follow-up recommendation for pulmonary nodule. Male patients comprised 45.3% (11,097) of the patient cohort; average patient age was 61.4 years (±14.1 years). The majority of reports were from outpatient studies (62.7%, 15,376 of 24,512), were chest CTs (75.9%, 18,615 of 24,512), and were interpreted by thoracic radiologists (63.7%, 15,614 of 24,512). In multivariable analysis, studies for male patients (odds ratio [OR]: 0.9 [0.8-0.9]) and abdominal CTs (OR: 0.6 [0.6-0.7] compared with chest CT) were less likely to have a pulmonary nodule follow-up recommendation. Older patients had higher rates of follow-up recommendation (OR: 1.01 for each additional year). Division-level analysis showed up to 4.3-fold difference between radiologists in the probability of making a follow-up recommendation for a pulmonary nodule. Discussion: Significant differences exist in the probability of making a follow-up recommendation for pulmonary nodules among radiologists within the same subspecialty division. © 2021 American College of Radiology","Follow-up recommendation; pulmonary nodule; radiologist variation","adult; Article; cohort analysis; controlled study; female; follow up; hospital patient; human; lung nodule; major clinical study; male; natural language processing; outpatient; patient care; radiologist; retrospective study; sensitivity and specificity; support vector machine; diagnostic imaging; lung tumor; middle aged; radiologist; x-ray computed tomography; Follow-Up Studies; Humans; Lung Neoplasms; Male; Middle Aged; Radiologists; Retrospective Studies; Solitary Pulmonary Nodule; Tomography, X-Ray Computed",Article,Scopus
"Schrempf P., Watson H., Park E., Pajak M., MacKinnon H., Muir K.W., Harris-Birtill D., O’Neil A.Q.","Templated Text Synthesis for Expert-Guided Multi-Label Extraction from Radiology Reports",2021,"Machine Learning and Knowledge Extraction",4,"10.3390/make3020015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113449876&doi=10.3390%2fmake3020015&partnerID=40&md5=053fd41dcb3eca008798623e9da89454","Training medical image analysis models traditionally requires large amounts of expertly annotated imaging data which is time-consuming and expensive to obtain. One solution is to automatically extract scan-level labels from radiology reports. Previously, we showed that, by extending BERT with a per-label attention mechanism, we can train a single model to perform automatic extraction of many labels in parallel. However, if we rely on pure data-driven learning, the model sometimes fails to learn critical features or learns the correct answer via simplistic heuristics (e.g., that “likely” indicates positivity), and thus fails to generalise to rarer cases which have not been learned or where the heuristics break down (e.g., “likely represents prominent VR space or lacunar infarct” which indicates uncertainty over two differential diagnoses). In this work, we propose template creation for data synthesis, which enables us to inject expert knowledge about unseen entities from medical ontologies, and to teach the model rules on how to label difficult cases, by producing relevant training examples. Using this technique alongside domain-specific pre-training for our underlying BERT architecture i.e., PubMedBERT, we improve F1 micro from 0.903 to 0.939 and F1 macro from 0.512 to 0.737 on an independent test set for 33 labels in head CT reports for stroke patients. Our methodology offers a practical way to combine domain knowledge with machine learning for text classification tasks. © 2021 by the authors.","BERT; data synthesis; NLP; radiology report labelling; templates",,Article,Scopus
"Babar Z., van Laarhoven T., Zanzotto F.M., Marchiori E.","Evaluating diagnostic content of AI-generated radiology reports of chest X-rays",2021,"Artificial Intelligence in Medicine",10,"10.1016/j.artmed.2021.102075","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105694251&doi=10.1016%2fj.artmed.2021.102075&partnerID=40&md5=c78a8231e4b1e1b7bda6586cd0c382b4","Radiology reports are of core importance for the communication between the radiologist and clinician. A computer-aided radiology report system can assist radiologists in this task and reduce variation between reports thus facilitating communication with the medical doctor or clinician. Producing a well structured, clear, and clinically well-focused radiology report is essential for high-quality patient diagnosis and care. Despite recent advances in deep learning for image caption generation, this task remains highly challenging in a medical setting. Research has mainly focused on the design of tailored machine learning methods for this task, while little attention has been devoted to the development of evaluation metrics to assess the quality of AI-generated documents. Conventional quality metrics for natural language processing methods like the popular BLEU score, provide little information about the quality of the diagnostic content of AI-generated radiology reports. In particular, because radiology reports often use standardized sentences, BLEU scores of generated reports can be high while they lack diagnostically important information. We investigate this problem and propose a new measure that quantifies the diagnostic content of AI-generated radiology reports. In addition, we exploit the standardization of reports by generating a sequence of sentences. That is, instead of using a dictionary of words, as current image captioning methods do, we use a dictionary of sentences. The assumption underlying this choice is that radiologists use a well-focused vocabulary of ‘standard’ sentences, which should suffice for composing most reports. As a by-product, a significant training speed-up is achieved compared to models trained on a dictionary of words. Overall, results of our investigation indicate that standard validation metrics for AI-generated documents are weakly correlated with the diagnostic content of the reports. Therefore, these measures should be not used as only validation metrics, and measures evaluating diagnostic content should be preferred in such a medical context. © 2021 The Authors","Assessment of results’ quality; Automated radiology report generation","Deep learning; Learning systems; Medical imaging; Natural language processing systems; Radiation; Radiology; Computer-aided radiologies; Evaluation metrics; Machine learning methods; Medical settings; NAtural language processing; Patient diagnosis; Radiology reports; Standard validations; Diagnosis; article; attention; controlled study; deep learning; human; natural language processing; quantitative analysis; radiologist; standardization; thorax radiography; velocity; vocabulary; machine learning; radiology; radiology information system; X ray; Humans; Machine Learning; Natural Language Processing; Radiology; Radiology Information Systems; X-Rays",Article,Scopus
"Weikert T., Francone M., Abbara S., Baessler B., Choi B.W., Gutberlet M., Hecht E.M., Loewe C., Mousseaux E., Natale L., Nikolaou K., Ordovas K.G., Peebles C., Prieto C., Salgado R., Velthuis B., Vliegenthart R., Bremerich J., Leiner T.","Machine learning in cardiovascular radiology: ESCR position statement on design requirements, quality assessment, current applications, opportunities, and challenges",2021,"European Radiology",12,"10.1007/s00330-020-07417-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096316681&doi=10.1007%2fs00330-020-07417-0&partnerID=40&md5=552fad8a76188405dc196acf9c5f01d1","Abstract: Machine learning offers great opportunities to streamline and improve clinical care from the perspective of cardiac imagers, patients, and the industry and is a very active scientific research field. In light of these advances, the European Society of Cardiovascular Radiology (ESCR), a non-profit medical society dedicated to advancing cardiovascular radiology, has assembled a position statement regarding the use of machine learning (ML) in cardiovascular imaging. The purpose of this statement is to provide guidance on requirements for successful development and implementation of ML applications in cardiovascular imaging. In particular, recommendations on how to adequately design ML studies and how to report and interpret their results are provided. Finally, we identify opportunities and challenges ahead. While the focus of this position statement is ML development in cardiovascular imaging, most considerations are relevant to ML in radiology in general. Key Points: • Development and clinical implementation of machine learning in cardiovascular imaging is a multidisciplinary pursuit. • Based on existing study quality standard frameworks such as SPIRIT and STARD, we propose a list of quality criteria for ML studies in radiology. • The cardiovascular imaging research community should strive for the compilation of multicenter datasets for the development, evaluation, and benchmarking of ML algorithms. © 2020, The Author(s).","Artificial intelligence; Consensus; Diagnostic techniques, cardiovascular; Machine learning; Radiology","algorithm; article; artificial intelligence; benchmarking; consensus; diagnostic procedure; equipment design; human; machine learning; multicenter study (topic); radiology; algorithm; clinical trial; medical society; multicenter study; radiography; Algorithms; Humans; Machine Learning; Radiography; Radiology; Societies, Medical",Article,Scopus
"Yu A.Y.X., Liu Z.A., Pou-Prom C., Lopes K., Kapral M.K., Aviv R.I., Mamdani M.","Automating stroke data extraction from free-text radiology reports using natural language processing: Instrument validation study",2021,"JMIR Medical Informatics",5,"10.2196/24381","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105480303&doi=10.2196%2f24381&partnerID=40&md5=2b509711e20f1ec48106ad7f1c5f87db","Background: Diagnostic neurovascular imaging data are important in stroke research, but obtaining these data typically requires laborious manual chart reviews. Objective: We aimed to determine the accuracy of a natural language processing (NLP) approach to extract information on the presence and location of vascular occlusions as well as other stroke-related attributes based on free-text reports. Methods: From the full reports of 1320 consecutive computed tomography (CT), CT angiography, and CT perfusion scans of the head and neck performed at a tertiary stroke center between October 2017 and January 2019, we manually extracted data on the presence of proximal large vessel occlusion (primary outcome), as well as distal vessel occlusion, ischemia, hemorrhage, Alberta stroke program early CT score (ASPECTS), and collateral status (secondary outcomes). Reports were randomly split into training (n=921) and validation (n=399) sets, and attributes were extracted using rule-based NLP. We reported the sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and the overall accuracy of the NLP approach relative to the manually extracted data. Results: The overall prevalence of large vessel occlusion was 12.2%. In the training sample, the NLP approach identified this attribute with an overall accuracy of 97.3% (95.5% sensitivity, 98.1% specificity, 84.1% PPV, and 99.4% NPV). In the validation set, the overall accuracy was 95.2% (90.0% sensitivity, 97.4% specificity, 76.3% PPV, and 98.5% NPV). The accuracy of identifying distal or basilar occlusion as well as hemorrhage was also high, but there were limitations in identifying cerebral ischemia, ASPECTS, and collateral status. Conclusions: NLP may improve the efficiency of large-scale imaging data collection for stroke surveillance and research. © 2021 JMIR Medical Informatics.","Data extraction; Diagnostic imaging; Imaging; Natural language processing; Neurovascular; Stroke; Stroke surveillance; Surveillance",,Article,Scopus
"Jain S., Smit A., Truong S.Q.H., Nguyen C.D.T., Huynh M.-T., Jain M., Young V.A., Ng A.Y., Lungren M.P., Rajpurkar P.","VisualCheXbert: Addressing the discrepancy between radiology report labels and image labels",2021,"ACM CHIL 2021 - Proceedings of the 2021 ACM Conference on Health, Inference, and Learning",7,"10.1145/3450439.3451862","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104095234&doi=10.1145%2f3450439.3451862&partnerID=40&md5=360bbd4bbe4f62931aefdbe433c2b1b7","Automatic extraction of medical conditions from free-text radiology reports is critical for supervising computer vision models to interpret medical images. In this work, we show that radiologists labeling reports significantly disagree with radiologists labeling corresponding chest X-ray images, which reduces the quality of report labels as proxies for image labels. We develop and evaluate methods to produce labels from radiology reports that have better agreement with radiologists labeling images. Our best performing method, called VisualCheXbert, uses a biomedically-pretrained BERT model to directly map from a radiology report to the image labels, with a supervisory signal determined by a computer vision model trained to detect medical conditions from chest X-ray images. We find that VisualCheXbert outperforms an approach using an existing radiology report labeler by an average F1 score of 0.14 (95% CI 0.12, 0.17). We also find that VisualCheXbert better agrees with radiologists labeling chest X-ray images than do radiologists labeling the corresponding radiology reports by an average F1 score across several medical conditions of between 0.12 (95% CI 0.09, 0.15) and 0.21 (95% CI 0.18, 0.24). © 2021 Owner/Author.","BERT; chest X-ray diagnosis; medical report labeling; natural language processing","Computer vision; Radiation; Radiology; Automatic extraction; Chest X-ray image; F1 scores; Free texts; Labeling image; Medical conditions; Radiology reports; Medical imaging",Conference Paper,Scopus
"Bizzo B.C., Almeida R.R., Alkasab T.K.","Computer-Assisted Reporting and Decision Support in Standardized Radiology Reporting for Cancer Imaging",2021,"JCO clinical cancer informatics",2,"10.1200/CCI.20.00129","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104446901&doi=10.1200%2fCCI.20.00129&partnerID=40&md5=59267ca0c234df2e11c62986cb248914","PURPOSE: Recent advances in structured reporting are providing an opportunity to enhance cancer imaging assessment to drive value-based care and improve patient safety. METHODS: The computer-assisted reporting and decision support (CAR/DS) framework has been developed to enable systematic ingestion of guidelines as clinical decision structured reporting tools embedded within the radiologist's workflow. RESULTS: CAR/DS tools can reduce the radiology reporting variability and increase compliance with clinical guidelines. The lung cancer use-case is used to describe various scenarios of a cancer imaging structured reporting pathway, including incidental findings, screening, staging, and restaging or continued care. Various aspects of these tools are also described using cancer-related examples for different imaging modalities and applications such as calculators. Such systems can leverage artificial intelligence (AI) algorithms to assist with the generation of structured reports and there are opportunities for new AI applications to be created using the structured data associated with CAR/DS tools. CONCLUSION: These AI-enabled systems are starting to allow information from multiple sources to be integrated and inserted into structured reports to drive improvements in clinical decision support and patient care.",,"algorithm; artificial intelligence; clinical decision support system; computer; human; radiology; Algorithms; Artificial Intelligence; Computers; Decision Support Systems, Clinical; Humans; Radiology",Article,Scopus
"Tan B.S., Dunnick N.R., Gangi A., Goergen S., Jin Z.-Y., Neri E., Nomura C.H., Pitcher R.D., Yee J., Mahmood U.","RSNA international trends: A global perspective on the COVID-19 pandemic and radiology in late 2020",2021,"Radiology",15,"10.1148/RADIOL.2020204267","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103473595&doi=10.1148%2fRADIOL.2020204267&partnerID=40&md5=54b96e951000c367f6078bfcc942e713","The coronavirus disease 2019 pandemic has challenged and changed health care systems around the world. There has been a heterogeneity of disease burden, health care resources, and nonimaging testing availability, both geographically and over time. In parallel, there has been a continued increase in understanding how the disease affects patients, effectiveness of therapeutic options, and factors that modulate transmission risk. In this report, radiology experts in representative countries from around the world share insights gained from local experience. These insights provide a guidepost to help address management challenges as cases continue to rise in many parts of the world and suggest modifications in workflow that are likely to continue after this pandemic subsides. © RSNA, 2021",,"Article; artificial intelligence; Australia; Brazil; China; clinical effectiveness; clinical protocol; coronavirus disease 2019; diagnostic imaging; France; health care disparity; health care planning; health care system; health disparity; health service; human; Human immunodeficiency virus infection; infection control; infection risk; interventional radiology; Italy; lockdown; low income country; medical resource shortage; pandemic; practice guideline; process development; rural hospital; tuberculosis; United States; workforce; diagnostic imaging; epidemiology; global health; international cooperation; lung; medical society; North America; pandemic; radiology; COVID-19; Global Health; Humans; Internationality; Lung; North America; Pandemics; Radiology; SARS-CoV-2; Societies, Medical",Article,Scopus
"Sugimoto K., Takeda T., Oh J.-H., Wada S., Konishi S., Yamahata A., Manabe S., Tomiyama N., Matsunaga T., Nakanishi K., Matsumura Y.","Extracting clinical terms from radiology reports with deep learning",2021,"Journal of Biomedical Informatics",11,"10.1016/j.jbi.2021.103729","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102976882&doi=10.1016%2fj.jbi.2021.103729&partnerID=40&md5=74413790407020212974253b6a80b2c6","Extracting clinical terms from free-text format radiology reports is a first important step toward their secondary use. However, there is no general consensus on the kind of terms to be extracted. In this paper, we propose an information model comprising three types of clinical entities: observations, clinical findings, and modifiers. Furthermore, to determine its applicability for in-house radiology reports, we extracted clinical terms with state-of-the-art deep learning models and compared the results. We trained and evaluated models using 540 in-house chest computed tomography (CT) reports annotated by multiple medical experts. Two deep learning models were compared, and the effect of pre-training was explored. To investigate the generalizability of the model, we evaluated the use of other institutional chest CT reports. The micro F1-score of our best performance model using in-house and external datasets were 95.36% and 94.62%, respectively. Our results indicated that entities defined in our information model were suitable for extracting clinical terms from radiology reports, and the model was sufficiently generalizable to be used with dataset from other institutions. © 2021 The Author(s)","Deep Learning; Information Extraction; Natural Language Processing; Radiology Report","Computerized tomography; Information theory; Learning systems; Radiation; Radiology; Clinical terms; Information Modeling; Learning models; Medical experts; Performance Model; Radiology reports; Secondary use; State of the art; Deep learning; Article; clinical observation; computer assisted tomography; deep learning; diagnostic error; diagnostic imaging; human; priority journal; radiodiagnosis; radiology; scoring system; treatment planning; natural language processing; radiology information system; research; x-ray computed tomography; Deep Learning; Natural Language Processing; Radiology; Radiology Information Systems; Research Report; Tomography, X-Ray Computed",Article,Scopus
"Steinkamp J., Chambers C., Lalevic D., Cook T.","Automatic Fully-Contextualized Recommendation Extraction from Radiology Reports",2021,"Journal of Digital Imaging",5,"10.1007/s10278-021-00423-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101016773&doi=10.1007%2fs10278-021-00423-8&partnerID=40&md5=0b18ee5f135c8a896adbbc41ebe62a1a","Recommendations are a key component of radiology reports. Automatic extraction of recommendations would facilitate tasks such as recommendation tracking, quality improvement, and large-scale descriptive studies. Existing report-parsing systems are frequently limited to recommendations for follow-up imaging studies, operate at the sentence or document level rather than the individual recommendation level, and do not extract important contextualizing information. We present a neural network architecture capable of extracting fully contextualized recommendations from any type of radiology report. We identified six major “questions” necessary to capture the majority of context associated with a recommendation: recommendation, time period, reason, conditionality, strength, and negation. We developed a unified task representation by allowing questions to refer to answers to other questions. Our representation allows for a single system to perform named entity recognition (NER) and classification tasks. We annotated 2272 radiology reports from all specialties, imaging modalities, and multiple hospitals across our institution. We evaluated the performance of a long short-term memory (LSTM) architecture on the six-question task. The single-task LSTM model achieves a token-level performance of 89.2% at recommendation extraction, and token-level performances between 85 and 95% F1 on extracting modifying features. Our model extracts all types of recommendations, including follow-up imaging, tissue biopsies, and clinical correlation, and can operate in real time. It is feasible to extract complete contextualized recommendations of all types from arbitrary radiology reports. The approach is likely generalizable to other clinical entities referenced in radiology reports, such as radiologic findings or diagnoses. © 2021, Society for Imaging Informatics in Medicine.","Information extraction; Machine learning; Natural language processing; Radiology reports","Extraction; Image processing; Network architecture; Radiation; Radiology; Syntactics; Automatic extraction; Classification tasks; Descriptive studies; Imaging modality; Named entity recognition; Quality improvement; Radiology reports; Task representation; Long short-term memory; article; controlled study; extraction; follow up; human; machine learning; multicenter study; natural language processing; radiology; short term memory; language; natural language processing; radiology information system; research; Humans; Language; Natural Language Processing; Neural Networks, Computer; Radiology; Radiology Information Systems; Research Report",Article,Scopus
"Dahl F.A., Rama T., Hurlen P., Brekke P.H., Husby H., Gundersen T., Nytrø Ø., Øvrelid L.","Neural classification of Norwegian radiology reports: using NLP to detect findings in CT-scans of children",2021,"BMC medical informatics and decision making",9,"10.1186/s12911-021-01451-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102700796&doi=10.1186%2fs12911-021-01451-8&partnerID=40&md5=b0ec469333c3d3b7d0e3631fff29959c","BACKGROUND: With a motivation of quality assurance, machine learning techniques were trained to classify Norwegian radiology reports of paediatric CT examinations according to their description of abnormal findings. METHODS: 13.506 reports from CT-scans of children, 1000 reports from CT scan of adults and 1000 reports from X-ray examination of adults were classified as positive or negative by a radiologist, according to the presence of abnormal findings. Inter-rater reliability was evaluated by comparison with a clinician's classifications of 500 reports. Test-retest reliability of the radiologist was performed on the same 500 reports. A convolutional neural network model (CNN), a bidirectional recurrent neural network model (bi-LSTM) and a support vector machine model (SVM) were trained on a random selection of the children's data set. Models were evaluated on the remaining CT-children reports and the adult data sets. RESULTS: Test-retest reliability: Cohen's Kappa = 0.86 and F1 = 0.919. Inter-rater reliability: Kappa = 0.80 and F1 = 0.885. Model performances on the Children-CT data were as follows. CNN: (AUC = 0.981, F1 = 0.930), bi-LSTM: (AUC = 0.978, F1 = 0.927), SVM: (AUC = 0.975, F1 = 0.912). On the adult data sets, the models had AUC around 0.95 and F1 around 0.91. CONCLUSIONS: The models performed close to perfectly on its defined domain, and also performed convincingly on reports pertaining to a different patient group and a different modality. The models were deemed suitable for classifying radiology reports for future quality assurance purposes, where the fraction of the examinations with abnormal findings for different sub-groups of patients is a parameter of interest.","Machine learning; Natural language processing; Reproducibility of results; Tomography; X-ray computed","adult; child; human; radiography; radiology; reproducibility; x-ray computed tomography; Adult; Child; Humans; Neural Networks, Computer; Radiography; Radiology; Reproducibility of Results; Tomography, X-Ray Computed",Article,Scopus
"Muttanahally K.S., Vyas R., Mago J., Tadinada A.","Usefulness of artificial intelligence-based virtual assistants in oral and maxillofacial radiology report writing",2021,"World Journal of Dentistry",1,"10.5005/jp-journals-10015-1807","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107469389&doi=10.5005%2fjp-journals-10015-1807&partnerID=40&md5=686b8142f2f742f6a4b08ff98b82d98b","Aim and objective: This study aimed to evaluate the usefulness of four voice-based virtual assistants in oral and maxillofacial radiology report writing. Materials and methods: A questionnaire consisting of 100 questions was queried to 4 commercially available voice-based virtual assistants namely Alexa, Siri, Cortana, and Google Assistant. The questions were divided based on five categories. The categorization was based on the frequency and reason for a radiologist to refer to either a textbook or an online resource before diagnosing and finalizing a radiology report. Two evaluators queried the devices and rated them on a 4-point modified Likert scale. Results: In the order of efficiency, Google Assistant was the most efficient followed by Cortana, Siri, and Alexa. A significant difference between the examiners was observed with Cortana in anatomy, dental anatomy, differential diagnosis, and pathology. Conclusion: In this small study that queried only four voice-powered virtual assistants, it showed that they were helpful and convenient in responding to questions regarding oral and maxillofacial radiology. But there is significant scope for expansion in the number of topics and type of information delivered before these can be used specifically in oral and maxillofacial radiology report writing. Clinical significance: Oral radiologists often gather additional and updated information regarding various topics like disease-specific features, genetic mutations, and differential diagnoses which they typically get from a textbook or a website. Artificial intelligence-based virtual assistants offer radiologists a simple voice-activated interface to gather this information and can immensely help when additional information is required. © Jaypee Brothers Medical Publishers.","Alexa; Artificial intelligence; Cortana; Google Assistant; Siri",,Article,Scopus
"Li M.D., Lang M., Deng F., Chang K., Buch K., Rincon S., Mehan W.A., Leslie-Mazwi T.M., Kalpathy-Cramer J.","Analysis of stroke detection during the COVID-19 pandemic using natural language processing of radiology reports",2021,"American Journal of Neuroradiology",21,"10.3174/AJNR.A6961","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100685134&doi=10.3174%2fAJNR.A6961&partnerID=40&md5=dede9dff85800f52bb825147bcc809a2","BACKGROUND AND PURPOSE: The coronavirus disease 2019 (COVID-19) pandemic has led to decreases in neuroimaging volume. Our aim was to quantify the change in acute or subacute ischemic strokes detected on CT or MR imaging during the pandemic using natural language processing of radiology reports. MATERIALS AND METHODS: We retrospectively analyzed 32,555 radiology reports from brain CTs and MRIs from a comprehensive stroke center, performed from March 1 to April 30 each year from 2017 to 2020, involving 20,414 unique patients. To detect acute or subacute ischemic stroke in free-text reports, we trained a random forest natural language processing classifier using 1987 randomly sampled radiology reports with manual annotation. Natural language processing classifier generalizability was evaluated using 1974 imaging reports from an external dataset. RESULTS: The natural language processing classifier achieved a 5-fold cross-validation classification accuracy of 0.97 and an F1 score of 0.74, with a slight underestimation (-5%) of actual numbers of acute or subacute ischemic strokes in cross-validation. Importantly, cross-validation performance stratified by year was similar. Applying the classifier to the complete study cohort, we found an estimated 24% decrease in patients with acute or subacute ischemic strokes reported on CT or MR imaging from March to April 2020 compared with the average from those months in 2017-2019. Among patients with stroke-related order indications, the estimated proportion who underwent neuroimaging with acute or subacute ischemic stroke detection significantly increased from 16% during 2017-2019 to 21% in 2020 (P =.01). The natural language processing classifier performed worse on external data. CONCLUSIONS: Acute or subacute ischemic stroke cases detected by neuroimaging decreased during the COVID-19 pandemic, though a higher proportion of studies ordered for stroke were positive for acute or subacute ischemic strokes. Natural language processing approaches can help automatically track acute or subacute ischemic stroke numbers for epidemiologic studies, though local classifier training is important due to radiologist reporting style differences. © 2021 American Society of Neuroradiology. All rights reserved.",,"5 fold cross validation; adult; Article; brain angiography; brain ischemia; chronicity; classifier; cohort analysis; computed tomographic angiography; controlled study; coronavirus disease 2019; cross validation; diagnostic accuracy; female; human; magnetic resonance angiography; major clinical study; male; natural language processing; neuroimaging; pandemic; random forest; retrospective study; cerebrovascular accident; complication; diagnostic imaging; machine learning; middle aged; procedures; radiology; virology; Cohort Studies; COVID-19; Female; Humans; Machine Learning; Male; Middle Aged; Natural Language Processing; Neuroimaging; Radiology; Retrospective Studies; SARS-CoV-2; Stroke",Article,Scopus
"Sykes D., Grivas A., Grover C., Tobin R., Sudlow C., Whiteley W., McIntosh A., Whalley H., Alex B.","Comparison of rule-based and neural network models for negation detection in radiology reports",2021,"Natural Language Engineering",9,"10.1017/S1351324920000509","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096433917&doi=10.1017%2fS1351324920000509&partnerID=40&md5=513540b08a1da238db6ff79682a3b2b6","Using natural language processing, it is possible to extract structured information from raw text in the electronic health record (EHR) at reasonably high accuracy. However, the accurate distinction between negated and non-negated mentions of clinical terms remains a challenge. EHR text includes cases where diseases are stated not to be present or only hypothesised, meaning a disease can be mentioned in a report when it is not being reported as present. This makes tasks such as document classification and summarisation more difficult. We have developed the rule-based EdIE-R-Neg, part of an existing text mining pipeline called EdIE-R (Edinburgh Information Extraction for Radiology reports), developed to process brain imaging reports, (https://www.ltg.ed.ac.uk/software/edie-r/) and two machine learning approaches; one using a bidirectional long short-term memory network and another using a feedforward neural network. These were developed on data from the Edinburgh Stroke Study (ESS) and tested on data from routine reports from NHS Tayside (Tayside). Both datasets consist of written reports from medical scans. These models are compared with two existing rule-based models: pyConText (Harkema et al. 2009. Journal of Biomedical Informatics 42(5), 839-851), a python implementation of a generalisation of NegEx, and NegBio (Peng et al. 2017. NegBio: A high-performance tool for negation and uncertainty detection in radiology reports. arXiv e-prints, p. arXiv:1712.05898), which identifies negation scopes through patterns applied to a syntactic representation of the sentence. On both the test set of the dataset from which our models were developed, as well as the largely similar Tayside test set, the neural network models and our custom-built rule-based system outperformed the existing methods. EdIE-R-Neg scored highest on F1 score, particularly on the test set of the Tayside dataset, from which no development data were used in these experiments, showing the power of custom-built rule-based systems for negation detection on datasets of this size. The performance gap of the machine learning models to EdIE-R-Neg on the Tayside test set was reduced through adding development Tayside data into the ESS training set, demonstrating the adaptability of the neural network models. © 2021 Natural Language Engineering. All rights reserved.","Corpus annotation; Information extraction; Machine learning; Natural language processing for biomedical texts; Text data mining","Brain mapping; Character recognition; Information retrieval systems; Machine learning; Natural language processing systems; Radiation; Radiology; Statistical tests; Tantalum compounds; Text mining; Biomedical informatics; Document Classification; Electronic health record; High-performance tools; Machine learning models; NAtural language processing; Structured information; Syntactic representation; Feedforward neural networks",Article,Scopus
"Tung E.L., Dibble E.H., Jindal G., Movson J.S., Swenson D.W.","Implementation and Impact of a Comprehensive Radiology Report Categorization System on Communication of Important Results",2021,"Journal of the American College of Radiology",6,"10.1016/j.jacr.2020.07.026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100023803&doi=10.1016%2fj.jacr.2020.07.026&partnerID=40&md5=ff6525d4d413ac116f7d521981121b26","Purpose: Effective communication of important imaging results is critical to patient care but difficult to accomplish efficiently. To improve communication at their institution, the authors introduced a radiology report categorization system (RADCAT) that organizes diagnostic imaging reports and uses automated communication systems. The study objectives were to (1) describe RADCAT's design, (2) evaluate its implementation for appropriate imaging, and (3) evaluate the communication of important, nonurgent results with recommended follow-up. Methods: This retrospective study was performed in a multihospital adult and pediatric tertiary referral academic health system. The intervention, a radiology report categorization system with five levels of acuity and IT-supported communication workflows, was globally implemented in November 2017. The primary outcomes were the successful implementation of RADCAT to appropriate diagnostic imaging reports and the successful communication of important, nonurgent results with recommended follow-up to ordering providers and patients by the radiology quality assurance team. Results: Over 18 months after implementation, 740,625 radiology reports were categorized under the RADCAT system, with 42%, 28%, and 30% from the emergency department, inpatient, and outpatient settings, respectively. A random selection of 100 studies from the 23,718 total reports without RADCAT categorization identified 4 diagnostic radiology reports that erroneously lacked RADCAT grading. In 2019, of the 38,701 studies with nonurgent imaging follow-up recommendations, 38,692 (nearly 100.0%) were successfully communicated to providers or patients on the basis of quality assurance data. Conclusions: A comprehensive radiology report categorization system was successfully implemented across a multihospital adult and pediatric health system, demonstrating reliable communication of imaging results with recommendations for nonacute imaging follow-up. © 2020 American College of Radiology","alert notification; communication system; Critical test result; incidental findings; structured reporting","adult; article; child; diagnostic imaging; emergency ward; female; follow up; human; incidental finding; male; outcome assessment; outpatient; patient referral; quality control; radiodiagnosis; retrospective study; workflow; hospital management; interpersonal communication; radiology; Child; Communication; Hospital Communication Systems; Humans; Radiology; Retrospective Studies; Workflow",Article,Scopus
"Johnson R.J., MacKenzie D.","Medicolegal considerations of radiology report writing in the new pjmirodigm of artificial intelligence",2021,"Journal of Medical Imaging and Radiation Oncology",1,"10.1111/1754-9485.13126","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096657208&doi=10.1111%2f1754-9485.13126&partnerID=40&md5=2899fde8817507f5042941eab49f09f6",[No abstract available],"artificial intelligence; liability; medicolegal; negligence","algorithm; Article; artificial intelligence; cost benefit analysis; decision making; evidence based practice; human; insurance; medical liability; medicolegal aspect; negligence; radiologist; radiology; sensitivity and specificity; writing; Artificial Intelligence; Humans; Radiologists; Radiology; Writing",Article,Scopus
"Tung E.L., Dibble E.H., Jindal G., Movson J.S., Swenson D.W.","Survey of radiologists and emergency department providers after implementation of a global radiology report categorization system",2021,"Emergency Radiology",2,"10.1007/s10140-020-01824-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088702283&doi=10.1007%2fs10140-020-01824-y&partnerID=40&md5=785ca544499e723874f0eb067c8a55ac","Purpose: Breakdown in communication of important imaging results threatens patient safety and risks malpractice claims. To facilitate closed-loop communication, our institution developed a unique radiology report categorization (RADCAT) system employing automated alert notification systems. This study aimed to understand users’ initial experiences with the RADCAT system and obtain feedback. Methods: Web-based surveys were distributed to radiologists and emergency department (ED) providers at our hospital system within 1 year of institution-wide RADCAT implementation. Survey designs differed based on clinical setting. Most prompts utilized declarative statements with 5-point agreement Likert scales. Closed-response data was analyzed with descriptive statistics. Results: Response rates among radiologists and ED providers were 59.4% (63/106) and 38.4% (69/211), respectively. 78.0% (46/59) of radiologists and 60.9% (42/69) of ED providers agreed that RADCAT improves patient care. Of radiologists, 84.1% (53/63) agreed that RADCAT design is intuitive, and 57.6% (34/59) agreed that RADCAT improves efficiency. Of ED providers, 69.6% (48/69) agreed that RADCAT appropriately differentiates urgent and non-urgent findings, and 65.2% (45/69) agreed that auto-population of discharge documents with imaging results containing follow-up recommendations protects them from liability. Only 35.6% (21/59) of radiologists and 21.7% (15/69) of ED providers agreed that RADCAT implementation decreased reading room visits by ordering providers. Open-response feedback showed that some ED providers find RADCAT too complex while some radiologists desire improved transparency regarding imaging study communication status. Conclusion: Since its implementation, RADCAT has been well received among radiologists and ED providers with agreement that it improves patient care and effectively distinguishes and communicates important imaging findings. © 2020, American Society of Emergency Radiology.","Alert notification; Communication system; Critical test result; Information technology solutions; Satisfaction survey; Structured reporting","adult; article; case report; clinical article; emergency ward; female; follow up; hospital planning; human; information technology; Likert scale; male; patient care; radiologist; radiology; satisfaction; electronic health record; hospital emergency service; hospital management; interdisciplinary communication; questionnaire; Adult; Electronic Health Records; Emergency Service, Hospital; Female; Hospital Communication Systems; Humans; Interdisciplinary Communication; Male; Radiologists; Surveys and Questionnaires",Article,Scopus
"Kurowecki D., Lee S.Y., Monteiro S., Finlay K.","Resident Physicians' Perceptions of Diagnostic Radiology and the Declining Interest in the Specialty",2021,"Academic Radiology",10,"10.1016/j.acra.2020.01.016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080034498&doi=10.1016%2fj.acra.2020.01.016&partnerID=40&md5=0e52f2f534661114945dd54d0de63661","Rationale and Objectives: The relative competitiveness of radiology and the number of first-choice applicants to diagnostic radiology have steadily declined over the past decade. The purpose of this study was to identify factors contributing to the declining interest in diagnostic radiology as a career and to explore factors affecting specialty choice. Materials and Methods: A retrospective survey was distributed to resident physicians at a single academic center between July and August 2017. Participants identified factors affecting career choice and evaluated level of agreement with statements regarding radiology using 5-point Likert scales. Higher scores indicated stronger agreement. Results: One hundred and fifty-two resident physicians from Canada participated (21.5% response rate): 20 radiology and 132 nonradiology. Of the total, 27% were registered in postgraduate year (PGY) 1, 23% in PGY 2, 15% in PGY 3, 19% in PGY 4, and 16% in PGY 5, or above. Sixty-one percent of the respondents self-reported as female, 34% as male, and 5% as other/unknown. Of those in radiology, 40% self-reported as female, 55% as male, and 5% as other/unknown, compared to 64% female, 31% male, and 5% other/unknown in other specialties. Regardless of specialty, positive clinical/mentoring experiences strongly affected career choice. Radiology residents were attracted to diverse pathology (M = 4.5) and positive staff/resident interactions (M = 4.4). Nonradiology residents were deterred by lack of patient contact (M = 3.9) and dark work environment (M = 3.6). Resident physicians who had applied to radiology were more likely to report positive mentorship during medical school, disagree that technology will replace radiologists, and desire a higher income specialty (Wald = 56.6, p < 0.001). More recent graduates showed a higher level of concern regarding the potential negative impact of technology and outsourcing on the profession (F (3, 189) = 2.6, p = 0.05). Several trainees (21%) considered radiology, but lacked mentorship (52%) and identified job market concerns (29%). Conclusion: More recent graduates are relatively more concerned about technology replacing radiologists, and radiology applicants have less concern about artificial intelligence replacing radiologists. As positive interactions with radiologists and mentorship are key influencers, our results advocate for early training exposure and reinforcement regarding the positive outlook of the profession. © 2020 The Association of University Radiologists","Diagnostic radiology; Medical education; Resident physicians","adult; article; artificial intelligence; Canada; case report; clinical article; decision making; female; human; job market; Likert scale; male; medical school; mentor; mentoring; perception; postgraduate student; radiodiagnosis; radiologist; reinforcement; resident; retrospective study; work environment; education; medical education; perception; physician; questionnaire; radiology; Artificial Intelligence; Canada; Career Choice; Female; Humans; Internship and Residency; Male; Perception; Physicians; Radiology; Retrospective Studies; Surveys and Questionnaires",Article,Scopus
"Lee H.G., Sholle E., Beecy A., Al’Aref S., Peng Y.","Leveraging Deep Representations of Radiology Reports in Survival Analysis for Predicting Heart Failure Patient Mortality",2021,"NAACL-HLT 2021 - 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Proceedings of the Conference",3,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131807761&partnerID=40&md5=ab0cae2315897e5db95a5e641019090e","Utilizing clinical texts in survival analysis is difficult because they are largely unstructured. Current automatic extraction models fail to capture textual information comprehensively since their labels are limited in scope. Furthermore, they typically require a large amount of data and high-quality expert annotations for training. In this work, we present a novel method of using BERT-based hidden layer representations of clinical texts as covariates for proportional hazards models to predict patient survival outcomes. We show that hidden layers yield notably more accurate predictions than predefined features, outperforming the previous baseline model by 5.7% on average across C-index and time-dependent AUC. We make our work publicly available at https://github.com/bionlplab/heart_failure_mortality. © 2021 Association for Computational Linguistics.",,"Bioinformatics; Forecasting; 'current; Automatic extraction; Data quality; Extraction modeling; Heart failure; Hidden layers; Large amounts of data; Radiology reports; Survival analysis; Textual information; Computational linguistics",Conference Paper,Scopus
"Nooralahzadeh F., Gonzalez N.P., Frauenfelder T., Fujimoto K., Krauthammer M.","Progressive Transformer-Based Generation of Radiology Reports",2021,"Findings of the Association for Computational Linguistics, Findings of ACL: EMNLP 2021",5,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129136021&partnerID=40&md5=98051b270f429a177509d226d584671a","Inspired by Curriculum Learning, we propose a consecutive (i.e., image-to-text-to-text) generation framework where we divide the problem of radiology report generation into two steps. Contrary to generating the full radiology report from the image at once, the model generates global concepts from the image in the first step and then reforms them into finer and coherent texts using a transformer architecture. We follow the transformer-based sequence-tosequence paradigm at each step. We improve upon the state-of-the-art on two benchmark datasets. © 2021 Association for Computational Linguistics.",,"Computational linguistics; Radiology; Benchmark datasets; Radiology reports; Report generation; State of the art; Text generations; Radiation",Conference Paper,Scopus
"Khan M.S., Landman B.A., Deppen S.A., Matheny M.E.","Intrinsic Evaluation of Contextual and Non-contextual Word Embeddings using Radiology Reports",2021,"AMIA ... Annual Symposium proceedings. AMIA Symposium",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126866108&partnerID=40&md5=34efbb89fc72e3fcd6f94ea3fbc1bd7a","Many clinical natural language processing methods rely on non-contextual word embedding (NCWE) or contextual word embedding (CWE) models. Yet, few, if any, intrinsic evaluation benchmarks exist comparing embedding representations against clinician judgment. We developed intrinsic evaluation tasks for embedding models using a corpus of radiology reports: term pair similarity for NCWEs and cloze task accuracy for CWEs. Using surveys, we quantified the agreement between clinician judgment and embedding model representations. We compare embedding models trained on a custom radiology report corpus (RRC), a general corpus, and PubMed and MIMIC-III corpora (P&MC). Cloze task accuracy was equivalent for RRC and P&MC models. For term pair similarity, P&MC-trained NCWEs outperformed all other NCWE models (ρspearman 0.61 vs. 0.27-0.44). Among models trained on RRC, fastText models often outperformed other NCWE models and spherical embeddings provided overly optimistic representations of term pair similarity. ©2021 AMIA - All rights reserved.",,"human; information processing; Medline; natural language processing; radiology; semantics; Data Collection; Humans; Natural Language Processing; PubMed; Radiology; Semantics",Article,Scopus
"Santos T., Kallas O.N., Newsome J., Rubin D., Gichoya J.W., Banerjee I.","A Fusion NLP Model for the Inference of Standardized Thyroid Nodule Malignancy Scores from Radiology Report Text",2021,"AMIA ... Annual Symposium proceedings. AMIA Symposium",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126841133&partnerID=40&md5=83019e9efe400b3d991236d9993aa8c5","Radiology reports are a rich resource for advancing deep learning applications for medical images, facilitating the generation of large-scale annotated image databases. Although the ambiguity and subtlety of natural language poses a significant challenge to information extraction from radiology reports. Thyroid Imaging Reporting and Data Systems (TI-RADS) has been proposed as a system to standardize ultrasound imaging reports for thyroid cancer screening and diagnosis, through the implementation of structured templates and a standardized thyroid nodule malignancy risk scoring system; however there remains significant variation in radiologist practice when it comes to diagnostic thyroid ultrasound interpretation and reporting. In this work, we propose a computerized approach using a contextual embedding and fusion strategy for the large-scale inference of TI-RADS final assessment categories from narrative ultrasound (US) reports. The proposed model has achieved high accuracy on an internal data set, and high performance scores on an external validation dataset. ©2021 AMIA - All rights reserved.",,"diagnostic imaging; human; information processing; pathology; radiology; retrospective study; thyroid nodule; thyroid tumor; Data Systems; Humans; Radiology; Retrospective Studies; Thyroid Neoplasms; Thyroid Nodule",Article,Scopus
"Di Noto T., Atat C., Teiga E.G., Hegi M., Hottinger A., Cuadra M.B., Hagmann P., Richiardi J.","Diagnostic Surveillance of High-Grade Gliomas: Towards Automated Change Detection Using Radiology Report Classification",2021,"Communications in Computer and Information Science",1,"10.1007/978-3-030-93733-1_30","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126258135&doi=10.1007%2f978-3-030-93733-1_30&partnerID=40&md5=a340c7a9a8e37456aba6ac1fec122b7f","Natural Language Processing (NLP) on electronic health records (EHRs) can be used to monitor the evolution of pathologies over time to facilitate diagnosis and improve decision-making. In this study, we designed an NLP pipeline to classify Magnetic Resonance Imaging (MRI) radiology reports of patients with high-grade gliomas. Specifically, we aimed to distinguish reports indicating changes in tumors between one examination and the follow-up examination (treatment response/tumor progression versus stability). A total of 164 patients with 361 associated reports were retrieved from routine imaging, and reports were labeled by one radiologist. First, we assessed which embedding is more suitable when working with limited data, in French, from a specific domain. To do so, we compared a classic embedding techniques, TF-IDF, to a neural embedding technique, Doc2Vec, after hyperparameter optimization for both. A random forest classifier was used to classify the reports into stable (unchanged tumor) or unstable (changed tumor). Second, we applied the post-hoc LIME explainability tool to understand the decisions taken by the model. Overall, classification results obtained in repeated 5-fold cross-validation with TF-IDF reached around 89% AUC and were significantly better than those achieved with Doc2Vec (Wilcoxon signed-rank test, P= 0.009 ). The explainability toolkit run on TF-IDF revealed some interesting patterns: first, words indicating change such as progression were rightfully frequent for reports classified as unstable; similarly, words indicating no change such as not were frequent for reports classified as stable. Lastly, the toolkit discovered misleading words such as T2 which are clearly not directly relevant for the task. All the code used for this study is made available. © 2021, Springer Nature Switzerland AG.","Diagnostic surveillance; Doc2Vec; LIME model explainability; Natural Language Processing (NLP); Term Frequency - Inverse Document Frequency (TF-IDF)","Decision trees; Diagnosis; Embeddings; Lime; Magnetic resonance imaging; Radiation; Radiology; Syntactics; Tumors; Classifieds; Diagnostic surveillance; Doc2vec; Embedding technique; High-grade gliomas; LIME model explainability; Natural language processing; Radiology reports; Term frequency - inverse document frequency; Term frequencyinverse document frequency (TF-IDF); Natural language processing systems",Conference Paper,Scopus
"Jia X., Xiong Y., Zhang J., Zhang Y., Suzanne B., Zhu Y., Tang C.","Radiology Report Generation for Rare Diseases via Few-shot Transformer",2021,"Proceedings - 2021 IEEE International Conference on Bioinformatics and Biomedicine, BIBM 2021",3,"10.1109/BIBM52615.2021.9669825","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125169606&doi=10.1109%2fBIBM52615.2021.9669825&partnerID=40&md5=88c52f40c9d56e42a28fb01fe6c64488","Reliable automatic radiology report generation is highly desired to reduce the labor-intensive and error-prone workload for healthcare workers. While some multi-modal learning models have been proposed to study on this task, few of them paid attention to the radiology report generation for rare diseases, except for RareGen which solved this problem by enhancing the semantic representations of rare diseases. However, there still exist several open problems to be addressed. The first lies in the low proportion of disease regions in an image, making the visual information redundant or irrelevant to rare diseases to be encoded. The second lies in that correlations modeled in the encoding stage may not be effectively decoded in the decoding stage due to the multi-modal representation. To address these two issues, we propose a few-shot Transformer radiology report generation model, namely TransGen, for rare diseases. It integrates the advantages of Transformer with two key modules assembled. Specifically, in the encoding stage, a Semantic-aware Visual Learning (SVL) module is introduced to capture the regions of rare diseases. Following that, in the decoding stage, a Memory Augmented Semantic Enhancement (MASE) module is proposed to enhance intermediate representations. It could make full use of the semantic information contained in the historical-generated sentences to benefit report generation involving rare diseases. Extensive experiments have been conducted on two public datasets of IU X-Ray and MIMIC-CXR to demonstrate the effectiveness of our proposed model. © 2021 IEEE.","Bioinformatics; Data Mining; Few-Short Learning; Radiology Report Generation; Transformer","Decoding; Diseases; Encoding (symbols); Radiation; Radiology; Semantics; Signal encoding; Error prones; Few-short learning; Healthcare workers; Labour-intensive; Multi-modal learning; Radiology report generation; Radiology reports; Rare disease; Report generation; Transformer; Data mining",Conference Paper,Scopus
"Kondadadi R., Manchanda S., Ngo J., McCormack R.","Optum at MEDIQA 2021: Abstractive Summarization of Radiology Reports using simple BART Finetuning",2021,"Proceedings of the 20th Workshop on Biomedical Language Processing, BioNLP 2021",6,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123953924&partnerID=40&md5=93b5046d80ecf0bb041e8bafaa1f326b","This paper describes experiments undertaken and their results as part of the BioNLP MEDIQA 2021 challenge. We participated in Task 3: Radiology Report Summarization. Multiple runs were submitted for evaluation, from solutions leveraging transfer learning from pre-trained transformer models, which were then fine tuned on a subset of MIMIC-CXR, for abstractive report summarization. The task was evaluated using ROUGE and our best performing system obtained a ROUGE-2 score of 0.392. © 2021 Association for Computational Linguistics",,"Computational linguistics; Natural language processing systems; Radiology; Radiology reports; Simple++; Transfer learning; Transformer modeling; Radiation",Conference Paper,Scopus
"Mahajan D., Tsou C.-H., Liang J.J.","IBMResearch at MEDIQA 2021: Toward Improving Factual Correctness of Radiology Report Abstractive Summarization",2021,"Proceedings of the 20th Workshop on Biomedical Language Processing, BioNLP 2021",6,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123932621&partnerID=40&md5=f3d7400a9cbe8b93dad955f5dd78a0f2","Although recent advances in abstractive summarization systems have achieved high scores on standard natural language metrics like ROUGE, their lack of factual consistency remains an open challenge for their use in sensitive real-world settings such as clinical practice. In this work, we propose a novel approach to improve factual correctness of a summarization system by re-ranking the candidate summaries based on a factual vector of the summary. We applied this process during our participation in MEDIQA 2021 Task 3: Radiology Report Summarization, where the task is to generate an impression summary of a radiology report, given findings and background as inputs. In our system, we first used a transformer-based encoder-decoder model to generate top N candidate impression summaries for a report, then trained another transformer-based model to predict a 14-observations-vector of the impression based on the findings and background of the report, and finally, utilized this vector to re-rank the candidate summaries. We also employed a source-specific ensembling technique to accommodate for distinct writing styles from different radiology report sources. Our approach yielded 2nd place in the challenge. © 2021 Association for Computational Linguistics",,"Computational linguistics; Natural language processing systems; Radiology; Clinical practices; Encoder-decoder; Natural languages; Observation vectors; Radiology reports; Re-ranking; Real world setting; Summarization systems; Writing style; Radiation",Conference Paper,Scopus
"Antunez L., Castellanos J., Raposo G., Murga C.","A flexible AI pipeline for medical imaging in a radiology work flow",2021,"Proceedings of SPIE - The International Society for Optical Engineering",,"10.1117/12.2606146","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123047604&doi=10.1117%2f12.2606146&partnerID=40&md5=6a27c8e6866f30ae61e58b41e5e5edff","Medical imaging analysis is an effective technique and process for visualizing the human body's interior to diagnose, monitor, and treat medical conditions. Artificial Intelligence (AI) brings new opportunities for improvement, with multiple applications in all levels of the radiology workflow. This paper presents a solution that leverages state-of-the-art models and architectures to assemble a modular pipeline for detection, segmentation, measurement, and scoring, that builds up to an optimized clinical report for medical imaging analysis and diagnosis. The proposed approach is designed to be flexible and tailor-made to an end facility's needs and data, helping the radiologist's effectiveness. © 2021 SPIE.","3D convolutional neural networks; Artificial intelligence; Computed tomography; Lung cancer; Lung nodules; Medical imaging pipeline; Radiology work flow","Biological organs; Computerized tomography; Convolutional neural networks; Diagnosis; Medical imaging; Pipelines; Radiation; 3d convolutional neural network; Convolutional neural network; Human bodies; Imaging analysis; Imaging pipelines; Lung Cancer; Lung nodule; Medical imaging pipeline; Radiology work flow; Work-flows; Radiology",Conference Paper,Scopus
"Hu J., Li J., Chen Z., Shen Y., Song Y., Wan X., Chang T.-H.","Word Graph Guided Summarization for Radiology Findings",2021,"Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",7,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121793886&partnerID=40&md5=f05366167c1a7211b2409adacad63215","Radiology reports play a critical role in communicating medical findings to physicians. In each report, the impression section summarizes essential radiology findings. In clinical practice, writing impression is highly demanded yet time-consuming and prone to errors for radiologists. Therefore, automatic impression generation has emerged as an attractive research direction to facilitate such clinical practice. Existing studies mainly focused on introducing salient word information to the general text summarization framework to guide the selection of the key content in radiology findings. However, for this task, a model needs not only capture the important words in findings but also accurately describe their relations so as to generate high-quality impressions. In this paper, we propose a novel method for automatic impression generation, where a word graph is constructed from the findings to record the critical words and their relations, then a Word Graph guided Summarization model (WGSUM) is designed to generate impressions with the help of the word graph. Experimental results on two datasets, OPENI and MIMIC-CXR, confirm the validity and effectiveness of our proposed approach, where the state-of-the-art results are achieved on both datasets. Further experiments are also conducted to analyze the impact of different graph designs to the performance of our method. © 2021 Association for Computational Linguistics",,"Clinical research; Computational linguistics; Natural language processing systems; Radiation; Clinical practices; Graph design; High quality; Novel methods; Performance; Radiology reports; State of the art; Summarization models; Text Summarisation; Word graphs; Radiology",Conference Paper,Scopus
"Amador-Domínguez E., Serrano E., Manrique D., Bajo J.","A case-based reasoning model powered by deep learning for radiology report recommendation",2021,"International Journal of Interactive Multimedia and Artificial Intelligence",3,"10.9781/ijimai.2021.08.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121046667&doi=10.9781%2fijimai.2021.08.011&partnerID=40&md5=ab7649417924dd59b073bc1903f8bb06","Case-Based Reasoning models are one of the most used reasoning paradigms in expert-knowledge-driven areas. One of the most prominent fields of use of these systems is the medical sector, where explainable models are required. However, these models are considerably reliant on user input and the introduction of relevant curated data. Deep learning approaches offer an analogous solution, where user input is not required. This paper proposes a hybrid Case-Based Reasoning, Deep Learning framework for medical-related applications, focusing on the generation of medical reports. The proposal combines the explainability and user-focused approach of case-based reasoning models with the deep learning techniques performance. Moreover, the framework is fully modular to fit a wide variety of tasks and data, such as real-time sensor captured data, images, or text, to name a few. An implementation of the proposed framework focusing on radiology report generation assistance is provided. This implementation is used to evaluate the proposal, showing that it can provide meaningful and accurate corrections, even when the amount of information available is minimal. Additional tests on the optimization degree of the case base are also performed, evidencing how the proposed framework can optimize this base to achieve optimal performance. © 2021, Universidad Internacional de la Rioja. All rights reserved.","Case-Based Reasoning; Deep Learning; Entity Recognition; Medical Radiology; Natural Language Processing",,Article,Scopus
"Dai S., Wang Q., Lyu Y., Zhu Y.","BDKG at MEDIQA 2021: System Report for the Radiology Report Summarization Task",2021,"Proceedings of the 20th Workshop on Biomedical Language Processing, BioNLP 2021",9,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119861269&partnerID=40&md5=99614ceea26cf871e01b3da3df1ce358","This paper presents our winning system at the Radiology Report Summarization track of the MEDIQA 2021 shared task. Radiology report summarization automatically summarizes radiology findings into free-text impressions. This year’s task emphasizes the generalization and transfer ability of participating systems. Our system is built upon a pre-trained Transformer encoder-decoder architecture, i.e., PEGASUS, deployed with an additional domain adaptation module to particularly handle the transfer and generalization issue. Heuristics like ensemble and text normalization are also used. Our system is conceptually simple yet highly effective, achieving a ROUGE-2 score of 0.436 on test set and ranked the 1st place among all participating systems. © 2021 Association for Computational Linguistics",,"Computational linguistics; Natural language processing systems; Radiology; Adaptation module; Domain adaptation; Encoder-decoder architecture; Free texts; Generalisation; Participating systems; Radiology reports; Simple++; Test sets; Text Normalisation; Radiation",Conference Paper,Scopus
"Nguyen M.H., Hoang V., Nguyen T.A., Bui T.H.","Automatic radiology report editing through voice",2021,"Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119179276&partnerID=40&md5=a7930929c2e1e699e439d9ecb70d7d79","We present a system that allows radiologists to edit the radiology report through their voices. This is a function in our bigger system at VinBrain LLC that uses AI algorithms to assist radiologists with chest x-ray diagnosis, the system can suggest the abnormalities, then bases on the radiologist’s confirmations or conclusions to automatically generate the report using predefined templates. We then allow the radiologist to freely edit the report using voice. The system combines two components, the first is the Speech Recognition System (SRS), and the second is the Natural Language Understanding System (NLUS) that executes the user’s command. The user can delete, modify or add an arbitrary whole sentence. In addition, we successfully developed an SRS for such a non-mainstream language as Vietnamese and adapted it for the radiology domain. Copyright © 2021 ISCA.","Natural language understanding; radiology reporting; Speech recognition; Voice recognition","Radiation; Radiology; Speech; Speech communication; AI algorithms; Chest x-rays; Natural language understanding; Radiology reporting; Radiology reports; Report editing; Speech recognition systems; Two-component; Vietnamese; X-ray diagnosis; Speech recognition",Conference Paper,Scopus
"Delbrouck J.-B., Zhang H., Rubin D.L.","QIAI at MEDIQA 2021: Multimodal Radiology Report Summarization",2021,"Proceedings of the 20th Workshop on Biomedical Language Processing, BioNLP 2021",8,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119142552&partnerID=40&md5=2d7f555962f185acff6fa92e17d2caf8","This paper describes the solution of the QIAI lab sent to the Radiology Report Summarization (RRS) challenge at MEDIQA 2021. This paper aims to investigate whether using multimodality during training improves the summarizing performances of the model at test-time. Our preliminary results shows that taking advantage of the visual features from the x-rays associated to the radiology reports leads to higher evaluation metrics compared to a text-only baseline system. These improvements are reported according to the automatic evaluation metrics METEOR, BLEU and ROUGE scores. Our experiments can be fully replicated at the following address: https://github.com/jbdel/vilmedic. © 2021 Association for Computational Linguistics",,"Computational linguistics; Natural language processing systems; Radiology; Automatic evaluation; Baseline systems; Evaluation metrics; Multi-modal; Multi-modality; Performance; Radiology reports; Test time; Visual feature; Radiation",Conference Paper,Scopus
"Chen Z., Shen Y., Song Y., Wan X.","Cross-modal memory networks for radiology report generation",2021,"ACL-IJCNLP 2021 - 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Proceedings of the Conference",28,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118956000&partnerID=40&md5=49dbbe60cc8e76e977a4ad078e4401ba","Medical imaging plays a significant role in clinical practice of medical diagnosis, where the text reports of the images are essential in understanding them and facilitating later treatments. By generating the reports automatically, it is beneficial to help lighten the burden of radiologists and significantly promote clinical automation, which already attracts much attention in applying artificial intelligence to medical domain. Previous studies mainly follow the encoder-decoder paradigm and focus on the aspect of text generation, with few studies considering the importance of cross-modal mappings and explicitly exploit such mappings to facilitate radiology report generation. In this paper, we propose a cross-modal memory networks (CMN) to enhance the encoder-decoder framework for radiology report generation, where a shared memory is designed to record the alignment between images and texts so as to facilitate the interaction and generation across modalities. Experimental results illustrate the effectiveness of our proposed model, where state-of-the-art performance is achieved on two widely used benchmark datasets, i.e., IU X-Ray and MIMIC-CXR. Further analyses also prove that our model is able to better align information from radiology images and texts so as to help generating more accurate reports in terms of clinical indicators. © 2021 Association for Computational Linguistics",,"Benchmarking; Computational linguistics; Decoding; Diagnosis; Mapping; Medical imaging; Radiation; Radiology; Signal encoding; Clinical automation; Clinical practices; Cross-modal; Encoder-decoder; Medical domains; Memory network; Radiology reports; Report generation; Shared memory; Text generations; Image enhancement",Conference Paper,Scopus
"Bhawsar P.M.S., Abubakar M., Schmidt M.K., Camp N., Cessna M.H., Duggan M.A., Garciaclosas M., Almeida J.S.","Browser-based data annotation, active learning, and real-time distribution of artificial intelligence models: From tumor tissue microarrays to COVID-19 radiology",2021,"Journal of Pathology Informatics",2,"10.4103/jpi.jpi_100_20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116859715&doi=10.4103%2fjpi.jpi_100_20&partnerID=40&md5=306f50b0ae0a0a819158530bf260e2a3","Background: Artificial intelligence (AI) is fast becoming the tool of choice for scalable and reliable analysis of medical images. However, constraints in sharing medical data outside the institutional or geographical space, as well as difficulties in getting AI models and modeling platforms to work across different environments, have led to a 'reproducibility crisis' in digital medicine. Methods: This study details the implementation of a web platform that can be used to mitigate these challenges by orchestrating a digital pathology AI pipeline, from raw data to model inference, entirely on the local machine. We discuss how this federated platform provides governed access to data by consuming the Application Program Interfaces exposed by cloud storage services, allows the addition of user-defined annotations, facilitates active learning for training models iteratively, and provides model inference computed directly in the web browser at practically zero cost. The latter is of particular relevance to clinical workflows because the code, including the AI model, travels to the user's data, which stays private to the governance domain where it was acquired. Results: We demonstrate that the web browser can be a means of democratizing AI and advancing data socialization in medical imaging backed by consumer-facing cloud infrastructure such as Box.com. As a case study, we test the accompanying platform end-to-end on a large dataset of digital breast cancer tissue microarray core images. We also showcase how it can be applied in contexts separate from digital pathology by applying it to a radiology dataset containing COVID-19 computed tomography images. Conclusions: The platform described in this report resolves the challenges to the findable, accessible, interoperable, reusable stewardship of data and AI models by integrating with cloud storage to maintain user-centric governance over the data. It also enables distributed, federated computation for AI inference over those data and proves the viability of client-side AI in medical imaging. Availability: The open-source application is publicly available at https://episphere.github.io/path, with a short video demonstration at https://youtu.be/z59jToy2TxE. © 2021 International Journal of Preventive Medicine.","Artificial intelligence; client-side artificial intelligence; consumer-facing governance; TensorFlowJS; web computing",,Article,Scopus
"Ji Z., Shaikh M.A., Moukheiber D., Srihari S.N., Peng Y., Gao M.","Improving Joint Learning of Chest X-Ray and Radiology Report by Word Region Alignment",2021,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",4,"10.1007/978-3-030-87589-3_12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116482184&doi=10.1007%2f978-3-030-87589-3_12&partnerID=40&md5=288e43c385787c7043644686dabe728d","Self-supervised learning provides an opportunity to explore unlabeled chest X-rays and their associated free-text reports accumulated in clinical routine without manual supervision. This paper proposes a Joint Image Text Representation Learning Network (JoImTeRNet) for pre-training on chest X-ray images and their radiology reports. The model was pre-trained on both the global image-sentence level and the local image region-word level for visual-textual matching. Both are bidirectionally constrained on Cross-Entropy based and ranking-based Triplet Matching Losses. The region-word matching is calculated using the attention mechanism without direct supervision about their mapping. The pre-trained multi-modal representation learning paves the way for downstream tasks concerning image and/or text encoding. We demonstrate the representation learning quality by cross-modality retrievals and multi-label classifications on two datasets: OpenI-IU and MIMIC-CXR. Our code is available at https://github.com/mshaikh2/JoImTeR_MLMI_2021. © 2021, Springer Nature Switzerland AG.","Attention; Multi-modality; Self-supervised learning","Medical computing; Medical imaging; Radiation; Radiology; Supervised learning; Attention; Clinical routine; Free texts; Image texts; Joint learning; Matchings; Multi-modality; Radiology reports; Region alignments; Self-supervised learning; Classification (of information)",Conference Paper,Scopus
"Datta S., Khanpara S., Riascos R.F., Roberts K.","Leveraging Spatial Information in Radiology Reports for Ischemic Stroke Phenotyping",2021,"AMIA ... Annual Symposium proceedings. AMIA Symposium",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115279008&partnerID=40&md5=e6e748d0f4eee1720bd86ac3eb1cc213","Classifying fine-grained ischemic stroke phenotypes relies on identifying important clinical information. Radiology reports provide relevant information with context to determine such phenotype information. We focus on stroke phenotypes with location-specific information: brain region affected, laterality, stroke stage, and lacunarity. We use an existing fine-grained spatial information extraction system-Rad-SpatialNet-to identify clinically important information and apply simple domain rules on the extracted information to classify phenotypes. The performance of our proposed approach is promising (recall of 89.62% for classifying brain region and 74.11% for classifying brain region, side, and stroke stage together). Our work demonstrates that an information extraction system based on a fine-grained schema can be utilized to determine complex phenotypes with the inclusion of simple domain rules. These phenotypes have the potential to facilitate stroke research focusing on post-stroke outcome and treatment planning based on the stroke location. ©2021 AMIA - All rights reserved.",,"brain ischemia; cerebrovascular accident; diagnostic imaging; human; information retrieval; radiology; Brain Ischemia; Humans; Information Storage and Retrieval; Ischemic Stroke; Radiology; Stroke",Article,Scopus
"Cotik V., Alemany L.A., Filippo D., Luque F., Roller R., Vivaldi J., Ayach A., Carranza F., Defrancesca L., Dellanzo A., Urquiza M.F.","Overview of CLEF eHealth Task 1 - SpRadIE: A challenge on information extraction from Spanish radiology reports",2021,"CEUR Workshop Proceedings",10,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113539310&partnerID=40&md5=fcc0249f8cccb65c80ea6f38cda44cc6","This paper provides an overview of SpRadIE, the Multilingual Information Extraction Task of CLEF eHealth 2021 evaluation lab. The challenge targets information extraction from Spanish radiology reports, and aims at providing a standard evaluation framework to contribute to the advancement in the field of clinical natural language processing in Spanish. Overall seven different teams participated, trying to detect seven named entities and hedge cues. Information extraction from radiology reports has particular challenges, such as domain specific language, telegraphic style, abundance of non-standard abbreviations and a large number of discontinuous, as well as overlapping entities. Participants addressed these challenges using a variety of different classifiers and introduced multiple solutions. The most successful approaches rely on multiple neural classifiers in order to deal with overlapping entities. As a result of the challenge, a manually annotated dataset of radiology reports in Spanish has been made available. To our knowledge this is the first public challenge for named entity recognition and hedge cue detection for radiology reports in Spanish. © 2021 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).","BioNLP; EHealth; Radiology reports; Spanish information extraction","eHealth; Information retrieval; Natural language processing systems; Problem oriented languages; Radiation; Wooden fences; Domain specific languages; Multiple solutions; Named entity recognition; NAtural language processing; Neural classifiers; Radiology reports; Spanish Radiology; Standard evaluations; Radiology",Conference Paper,Scopus
"Suárez-Paniagua V., Dong H., Casey A.","A multi-BERT hybrid system for named entity recognition in Spanish radiology reports",2021,"CEUR Workshop Proceedings",3,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113448838&partnerID=40&md5=88b1a7d0904eb5648fb37347ad45fd5d","The present work describes the proposed methods by the EdIE-KnowLab team in Information Extraction Task of CLEF eHealth 2021, SpRadIE Task 1. This task focuses on detecting and classifying relevant mentions in ultrasonography reports. The architecture developed is an ensemble of multiple BERT (multi-BERT) systems, one per each entity type, together with a generated dictionary and available off-the-shelf tools, Google Healthcare Natural Language API and GATECloud's Measurement Expression Annotator system, applied to the documents translated into English with word alignment from the neural machine translation tool, Microsoft Translator API. Our best system configuration (multi-BERT with a dictionary) achieves 85.51% and 80.04% F1 for Lenient and Exact metrics, respectively. Thus, the system ranked first out of 17 submissions from 7 teams that participated in this shared task. Our system also achieved the best Recall merging the previous predictions to the results given by English-translated texts and cross-lingual word alignment (83.87% Lenient match and 78.71% Exact match). The overall results demonstrate the potential of pre-trained language models and cross-lingual word alignment for limited corpus and low-resource NER in the clinical domain. © 2021 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).","BERT; Deep learning; Machine translation; Named entity recognition; Radiology reports","Computational linguistics; Computer aided language translation; Hybrid systems; Natural language processing systems; Cross-lingual; Language model; Machine translations; Named entity recognition; Natural languages; Spanish Radiology; System configurations; Word alignment; Alignment",Conference Paper,Scopus
"García-Largo M.Á.M.-C., Segura-Bedmar I.","Extracting information from radiology reports by natural language processing and deep learning",2021,"CEUR Workshop Proceedings",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113428598&partnerID=40&md5=c244dff63cd160706c8fcd773dfe95ab","Radiology reports are texts that include the description and interpretation of ultrasound images. The automatic processing of these texts, if well performed, can help healthcare professionals and the diagnosis. This work is part of the Information Extraction from Spanish radiology reports task (SpRadIE) of CLEF eHealth 2021. Regarding the case of study of this work, it is remarkable the correct detection of unusual findings because they can affect the patient's health. Furthermore, it can help health professionals and researchers to be focused on problematic cases. Three different models have been proposed to face that task, evaluating and comparing their performance. Conditional Random Field (CRF), Bidirectional Long Short-Term Memory-Conditional Random Field (BiLSTM-CRF) and Bidirectional Encoders Representation from Transformers(BERT). With BiLSTM-CRF, two different approaches have been used: the use of randomized initialized vectors and the use of a pre-trained word embedding in Spanish. Both will appear more detailed in the paper. The task is complex and some of the reasons are: reports are written in Spanish, the extensive number of types of entities and the ambiguity in the language used by the doctors in the reports. The best results have been obtained by the CRF model, which has obtained a Lenient F1 score of 77% for a dataset that contained most of the words in the training dataset and a 67% of Lenient score for the dataset with words that are not present in the dataset used to train the model. © 2021 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).","BERT; BiLSTM-CRF; CRF; Information extraction; Named-entity recognition; Natural language processing; Radiology reports","Natural language processing systems; Radiation; Radiology; Random processes; Ultrasonic applications; Automatic processing; Conditional random field; Extracting information; Health care professionals; Health professionals; NAtural language processing; Spanish Radiology; Ultrasound images; Deep learning",Conference Paper,Scopus
"Putelli L., Gerevini A.E., Lavelli A., Maroldi R., Serina I.","Attention-Based Explanation in a Deep Learning Model For Classifying Radiology Reports",2021,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",6,"10.1007/978-3-030-77211-6_42","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111366839&doi=10.1007%2f978-3-030-77211-6_42&partnerID=40&md5=dac071bd8566720243c2dd6bc82c56f6","Although deep learning techniques have obtained remarkable results in clinical text analysis, the delicacy of this application domain requires also that these models can be easily understood by the hospital staff. The attention mechanism, which assigns numerical weights representing the contribution of each word to the predictive task, can be exploited for identifying the textual evidence the prediction is based on. In this paper, we investigate the explainability of an attention-based classification model for radiology reports collected from an Italian hospital. The identified explanations are compared with a set of manual annotations made by the domain experts in order to analyze the usefulness of the attention mechanism in our context. © 2021, Springer Nature Switzerland AG.",,"Hospitals; Learning systems; Radiation; Radiology; Attention mechanisms; Classification models; Domain experts; Learning models; Learning techniques; Manual annotation; Radiology reports; Text analysis; Deep learning",Conference Paper,Scopus
"Miura Y., Zhang Y., Tsai E.B., Langlotz C.P., Jurafsky D.","Improving Factual Completeness and Consistency of Image-to-Text Radiology Report Generation",2021,"NAACL-HLT 2021 - 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Proceedings of the Conference",30,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109061772&partnerID=40&md5=92e731c0820afb3552bcd316d1d68adc","Neural image-to-text radiology report generation systems offer the potential to improve radiology reporting by reducing the repetitive process of report drafting and identifying possible medical errors. However, existing report generation systems, despite achieving high performances on natural language generation metrics such as CIDEr or BLEU, still suffer from incomplete and inconsistent generations. Here we introduce two new simple rewards to encourage the generation of factually complete and consistent radiology reports: one that encourages the system to generate radiology domain entities consistent with the reference, and one that uses natural language inference to encourage these entities to be described in inferentially consistent ways. We combine these with the novel use of an existing semantic equivalence metric (BERTScore). We further propose a report generation system that optimizes these rewards via reinforcement learning. On two open radiology report datasets, our system substantially improved the F1 score of a clinical information extraction performance by +22.1 (∆ + 63.9%). We further show via a human evaluation and a qualitative analysis that our system leads to generations that are more factually complete and consistent compared to the baselines. © 2021 Association for Computational Linguistics.",,"Computational linguistics; Image enhancement; Medical imaging; Natural language processing systems; Radiation; Reinforcement learning; Semantics; Domain entities; Generation systems; Medical errors; Natural language generation; Performance; Radiology reporting; Radiology reports; Repetitive process; Report generation; Simple++; Radiology",Conference Paper,Scopus
"Kurisinkel L.J., Aw A.T., Chen N.F.","Coherent and Concise Radiology Report Generation via Context Specific Image Representations and Orthogonal Sentence States",2021,"NAACL-HLT 2021 - 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Industry Papers",4,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109060907&partnerID=40&md5=c8704b331e68b51ba6f455025ded9a6a","Neural models for text generation are often designed in an end-to-end fashion, typically with zero control over intermediate computations, limiting their practical usability in downstream applications. In this work, we incorporate explicit means into neural models to ensure topical continuity, content comprehensiveness and informativeness of automatically generated radiology reports. We propose a method to compute image representations specific to each sentential context to minimize hallucination caused by sequence-to-sequence approaches and to further eliminate redundant content by exploiting diverse sentence states. We conduct experiments to generate radiology reports from medical images of chest x-rays using MIMIC-CXR. Our model outperforms baselines by up to 18% and 29% respective in the evaluation for informativeness and content ordering respectively on objective metrics and 16% on human validations. © 2021 Association for Computational Linguistics.",,"Computational linguistics; Image representation; Medical imaging; Natural language processing systems; Radiation; Automatically generated; Downstream applications; End to end; Image representations; Informativeness; Neural modelling; Radiology reports; Report generation; Text generations; Zero control; Radiology",Conference Paper,Scopus
"Helwan A., Ma'Aitah M.K.S., Hamdan H., Ozsahin D.U., Tuncyurek O.","Radiologists versus Deep Convolutional Neural Networks: A Comparative Study for Diagnosing COVID-19",2021,"Computational and Mathematical Methods in Medicine",15,"10.1155/2021/5527271","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106970606&doi=10.1155%2f2021%2f5527271&partnerID=40&md5=c9e301b230212938ec667e15edafd0de","The reverse transcriptase polymerase chain reaction (RT-PCR) is still the routinely used test for the diagnosis of SARS-CoV-2 (COVID-19). However, according to several reports, RT-PCR showed a low sensitivity and multiple tests may be required to rule out false negative results. Recently, chest computed tomography (CT) has been an efficient tool to diagnose COVID-19 as it is directly affecting the lungs. In this paper, we investigate the application of pre-trained models in diagnosing patients who are positive for COVID-19 and differentiating it from normal patients, who tested negative for coronavirus. The study aims to compare the generalization capabilities of deep learning models with two thoracic radiologists in diagnosing COVID-19 chest CT images. A dataset of 3000 images was obtained from the Near East Hospital, Cyprus, and used to train and to test the three employed pre-trained models. In a test set of 250 images used to evaluate the deep neural networks and the radiologists, it was found that deep networks (ResNet-18, ResNet-50, and DenseNet-201) can outperform the radiologists in terms of higher accuracy (97.8%), sensitivity (98.1%), specificity (97.3%), precision (98.4%), and F1-score (198.25%), in classifying COVID-19 images. © 2021 Abdulkader Helwan et al.",,"Classification (of information); Computerized tomography; Convolutional neural networks; Deep learning; Diagnosis; Polymerase chain reaction; Statistical tests; Comparative studies; Coronaviruses; False negatives; Generalization capability; Learning models; Low sensitivity; Multiple test; Reverse-transcriptase polymerase chain reactions; Deep neural networks; adult; Article; comparative study; controlled study; convolutional neural network; coronavirus disease 2019; deep learning; deep neural network; diagnostic accuracy; digital imaging and communications in medicine; human; major clinical study; medical expert; Middle East; radiodiagnosis; radiologist; retrospective study; sensitivity and specificity; systematic review; thorax radiography; transfer of learning; x-ray computed tomography; computer assisted diagnosis; diagnostic error; diagnostic imaging; epidemiology; expert witness; factual database; lung; mathematical phenomena; pandemic; procedures; x-ray computed tomography; COVID-19; COVID-19 Testing; Databases, Factual; Deep Learning; Diagnosis, Computer-Assisted; Diagnostic Errors; Expert Testimony; Humans; Lung; Mathematical Concepts; Neural Networks, Computer; Pandemics; Radiologists; SARS-CoV-2; Tomography, X-Ray Computed",Article,Scopus
"Dai Z., Li Z., Han L.","BoneBert: A BERT-based Automated Information Extraction System of Radiology Reports for Bone Fracture Detection and Diagnosis",2021,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",5,"10.1007/978-3-030-74251-5_21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105880821&doi=10.1007%2f978-3-030-74251-5_21&partnerID=40&md5=1032c5a3c1ebdc7619cec92448e52bfd","Radiologists make the diagnoses of bone fractures through examining X-ray radiographs and document them in radiology reports. Applying information extraction techniques on such radiology reports to retrieve the information of bone fracture diagnosis could yield a source of structured data for medical cohort studies, image labelling and decision support concerning bone fractures. In this study, we proposed an information extraction system of Bone X-ray radiology reports to retrieve the details of bone fracture detection and diagnosis, based on a bio-medically pre-trained Bidirectional Encoder Representations from Transformers (BERT) natural language processing (NLP) model by Google. The model, named as BoneBert, was first trained on annotations automatically generated by a handcrafted rule-based labelling system using a dataset of 6,048 X-ray radiology reports and then fine-tuned on a small set of 4,890 expert annotations. Thus, the model was trained in a “semi-supervised” fashion. We evaluated the performance of the proposed model and compared it with the conventional rule-based labelling system on two typical tasks: Assertion Classification (AC) for bone fracture status detection (positive, negative or uncertainty) and Named Entity Recognition (NER) related to the fracture type, the bone type and location of a fracture occurs. BoneBert outperformed the rule-based system in both tasks, showing great potential for automated information extraction of the detection and diagnosis of bone fracture from radiology reports, such as, the clinical status, type and location of bone fracture, and more related observations. © 2021, Springer Nature Switzerland AG.","Electronic medical records; Machine learning; Natural language processing; Semisupervised learning","Data handling; Decision support systems; Diagnosis; Fracture; Information retrieval; Labels; Medical imaging; Radiology; X rays; Automated information; Automatically generated; Detection and diagnosis; Expert annotations; Information extraction systems; Information extraction techniques; Named entity recognition; NAtural language processing; Natural language processing systems",Conference Paper,Scopus
"Zhang Z., Citardi D., Wang D., Genc Y., Shan J., Fan X.","Patients’ perceptions of using artificial intelligence (AI)-based technology to comprehend radiology imaging data",2021,"Health Informatics Journal",15,"10.1177/14604582211011215","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105112796&doi=10.1177%2f14604582211011215&partnerID=40&md5=cd29d398761b74523c69f4ce17df566d","Results of radiology imaging studies are not typically comprehensible to patients. With the advances in artificial intelligence (AI) technology in recent years, it is expected that AI technology can aid patients’ understanding of radiology imaging data. The aim of this study is to understand patients’ perceptions and acceptance of using AI technology to interpret their radiology reports. We conducted semi-structured interviews with 13 participants to elicit reflections pertaining to the use of AI technology in radiology report interpretation. A thematic analysis approach was employed to analyze the interview data. Participants have a generally positive attitude toward using AI-based systems to comprehend their radiology reports. AI is perceived to be particularly useful in seeking actionable information, confirming the doctor’s opinions, and preparing for the consultation. However, we also found various concerns related to the use of AI in this context, such as cyber-security, accuracy, and lack of empathy. Our results highlight the necessity of providing AI explanations to promote people’s trust and acceptance of AI. Designers of patient-centered AI systems should employ user-centered design approaches to address patients’ concerns. Such systems should also be designed to promote trust and deliver concerning health results in an empathetic manner to optimize the user experience. © The Author(s) 2021.","acceptability; artificial intelligence; healthcare consumer; patient portals; radiology report","adult; AIDS patient; article; artificial intelligence; clinical article; computer security; consultation; consumer; empathy; female; human; male; medical record; perception; radiology; semi structured interview; thematic analysis; trust; user-centered design; diagnostic imaging; perception; technology; Artificial Intelligence; Diagnostic Imaging; Humans; Perception; Radiology; Technology",Article,Scopus
"Alfarghaly O., Khaled R., Elkorany A., Helal M., Fahmy A.","Automated radiology report generation using conditioned transformers",2021,"Informatics in Medicine Unlocked",50,"10.1016/j.imu.2021.100557","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104432862&doi=10.1016%2fj.imu.2021.100557&partnerID=40&md5=0a842d5021baa5a04675b767f5c493ec","Radiology report writing in hospitals is a time-consuming task that also requires experience from the involved radiologists. This paper proposes a deep learning model to automatically generate radiology reports given a chest x-ray image from the public IU-Xray dataset. Our work consists of three stages: (1) Fine-tune a pre-trained Chexnet to predict specific tags from the image. (2) Calculate weighted semantic features from the predicted tag's pre-trained embeddings. (3) Condition a pre-trained GPT2 model on the visual and semantic features to generate the full medical reports. We analyze the generated reports using word-overlap metrics while also adding new meaningful semantic-based similarity metrics. The proposed model, which we call CDGPT2, surpassed most non-hierarchical recurrent models and transformer-based models in quantitative metrics while being considerably faster to train. Moreover, the model does not require a specific vocabulary and can be trained on different datasets without changing the architecture. Furthermore, we include a qualitative analysis from a radiologist from Egypt's national institute of cancer which showed that 61.6% of the generated reports on the test set were expertly written, and only 10% contained false information. We represent the first work to condition a pre-trained transformer on visual and semantic features to generate medical reports and to include semantic similarity metrics in the quantitative analysis of the generated reports. © 2021 The Authors","Deep learning; GPT2; Report generation; Transfer learning; Transformers; X-ray","article; cancer recurrence; deep learning; Egypt; embedding; human; qualitative analysis; quantitative analysis; radiologist; thorax radiography; transfer of learning; vocabulary; X ray",Article,Scopus
"Lacson R., Cochon L., Ching P.R., Odigie E., Kapoor N., Gagne S., Hammer M.M., Khorasani R.","Integrity of clinical information in radiology reports documenting pulmonary nodules",2021,"Journal of the American Medical Informatics Association",2,"10.1093/jamia/ocaa209","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100358556&doi=10.1093%2fjamia%2focaa209&partnerID=40&md5=81fa7f90823aa614641ae85a0f6895da","Objective: Quantify the integrity, measured as completeness and concordance with a thoracic radiologist, of documenting pulmonary nodule characteristics in CT reports and assess impact on making follow-up recommendations. Materials and Methods: This Institutional Review Board-approved, retrospective cohort study was performed at an academic medical center. Natural language processing was performed on radiology reports of CT scans of chest, abdomen, or spine completed in 2016 to assess presence of pulmonary nodules, excluding patients with lung cancer, of which 300 reports were randomly sampled to form the study cohort. Documentation of nodule characteristics were manually extracted from reports by 2 authors with 20% overlap. CT images corresponding to 60 randomly selected reports were further reviewed by a thoracic radiologist to record nodule characteristics. Documentation completeness for all characteristics were reported in percentage and compared using χ2 analysis. Concordance with a thoracic radiologist was reported as percentage agreement; impact on making follow-up recommendations was assessed using kappa. Results: Documentation completeness for pulmonary nodule characteristics differed across variables (range = 2%-90%, P <. 001). Concordance with a thoracic radiologist was 75% for documenting nodule laterality and 29% for size. Follow-up recommendations were in agreement in 67% and 49% of reports when there was lack of completeness and concordance in documenting nodule size, respectively. Discussion: Essential pulmonary nodule characteristics were under-reported, potentially impacting recommendations for pulmonary nodule follow-up. Conclusion: Lack of documentation of pulmonary nodule characteristics in radiology reports is common, with potential for compromising patient care and clinical decision support tools. © 2020 The Author(s). Published by Oxford University Press on behalf of the American Medical Informatics Association. All rights reserved.","diagnostic imaging; electronic medical records, solitary pulmonary nodule; health information technology; patient safety","abdomen; adult; aged; Article; clinical decision support system; cohort analysis; computer assisted tomography; electronic health record; female; follow up; ground glass opacity; human; image analysis; institutional review; lung nodule; major clinical study; male; medical documentation; medical informatics; patient care; radiologist; radiology; retrospective study; spine; thorax; diagnostic imaging; documentation; electronic health record; lung nodule; middle aged; multiple pulmonary nodules; natural language processing; pathology; radiology information system; thorax radiography; x-ray computed tomography; Aged; Documentation; Electronic Health Records; Female; Humans; Male; Middle Aged; Multiple Pulmonary Nodules; Natural Language Processing; Radiography, Thoracic; Radiology Information Systems; Retrospective Studies; Solitary Pulmonary Nodule; Tomography, X-Ray Computed",Article,Scopus
"Liu H., Zhang Z., Xu Y., Wang N., Huang Y., Yang Z., Jiang R., Chen H.","Use of BERT (Bidirectional Encoder Representations from Transformers)-Based Deep Learning Method for Extracting Evidences in Chinese Radiology Reports: Development of a Computer-Aided Liver Cancer Diagnosis Framework",2021,"Journal of Medical Internet Research",25,"10.2196/19689","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099894025&doi=10.2196%2f19689&partnerID=40&md5=91056b35865a1eb443ff5e7f0e2854aa","Background: Liver cancer is a substantial disease burden in China. As one of the primary diagnostic tools for detecting liver cancer, dynamic contrast-enhanced computed tomography provides detailed evidences for diagnosis that are recorded in free-text radiology reports. Objective: The aim of our study was to apply a deep learning model and rule-based natural language processing (NLP) method to identify evidences for liver cancer diagnosis automatically. Methods: We proposed a pretrained, fine-tuned BERT (Bidirectional Encoder Representations from Transformers)-based BiLSTM-CRF (Bidirectional Long Short-Term Memory-Conditional Random Field) model to recognize the phrases of APHE (hyperintense enhancement in the arterial phase) and PDPH (hypointense in the portal and delayed phases). To identify more essential diagnostic evidences, we used the traditional rule-based NLP methods for the extraction of radiological features. APHE, PDPH, and other extracted radiological features were used to design a computer-aided liver cancer diagnosis framework by random forest. Results: The BERT-BiLSTM-CRF predicted the phrases of APHE and PDPH with an F1 score of 98.40% and 90.67%, respectively. The prediction model using combined features had a higher performance (F1 score, 88.55%) than those using APHE and PDPH (84.88%) or other extracted radiological features (83.52%). APHE and PDPH were the top 2 essential features for liver cancer diagnosis. Conclusions: This work was a comprehensive NLP study, wherein we identified evidences for the diagnosis of liver cancer from Chinese radiology reports, considering both clinical knowledge and radiology findings. The BERT-based deep learning method for the extraction of diagnostic evidence achieved state-of-the-art performance. The high performance proves the feasibility of the BERT-BiLSTM-CRF model in information extraction from Chinese radiology reports. The findings of our study suggest that the deep learning-based method for automatically identifying evidences for diagnosis can be extended to other types of Chinese clinical texts. © 2021 Journal of Medical Internet Research. All rights reserved.","Bert; Bilstm-crf; Computer-aided diagnosis; Information extraction; Natural language processing; Radiology reports","Article; cancer diagnosis; Chinese; clinical feature; computer aided design; controlled study; deep learning; feasibility study; feature extraction; liver cancer; natural language processing; radiology; China; computer assisted diagnosis; human; information retrieval; liver tumor; natural language processing; procedures; China; Deep Learning; Diagnosis, Computer-Assisted; Humans; Information Storage and Retrieval; Liver Neoplasms; Natural Language Processing; Radiology",Article,Scopus
"Hou D., Zhao Z., Hu S.","Multi-label learning with visual-semantic embedded knowledge graph for diagnosis of radiology imaging",2021,"IEEE Access",13,"10.1109/ACCESS.2021.3052794","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099726535&doi=10.1109%2fACCESS.2021.3052794&partnerID=40&md5=9de3a7ce25502abf954401f37c6942c1","A significant task of automatic diagnosis for radiology imaging, especially for chest X-rays, is to identify disease types, which can be viewed as a multi-label learning problem. Prior state-of-the-art approaches adopted the graph convolutional network to model the correlations among disease labels. However, the utilization of medical reports paired with radiology images is neglected in such approaches. Hence, at least two novel improvements are proposed in this paper. First, disease label embeddings are pre-trained on the total radiology reports, and these semantic features along with encoded X-ray features are fused in a transformer encoder for graph initialization. Second, to expand the representation ability of the graph, extra medical terms from radiology reports are mined and added to the graph model as auxiliary nodes without changing the size of the output space. Experiments conducted on two public chest-X-ray datasets demonstrate the outstanding performance over compared models and the advantages of the proposed improvements. © 2013 IEEE.","Auxiliary nodes; Chest-X-ray diagnosis; Graph convolutional network; Multi-label learning; Visual-semantic feature fusion","Convolutional neural networks; Graph theory; Knowledge representation; Learning systems; Medical imaging; Radiology; Semantics; X rays; Automatic diagnosis; Convolutional networks; Knowledge graphs; Multi-label learning; Radiology reports; Semantic features; State-of-the-art approach; Visual semantics; Diagnosis",Article,Scopus
"Chen T.L., Emerling M., Chaudhari G.R., Chillakuru Y.R., Seo Y., Vu T.H., Sohn J.H.","Domain specific word embeddings for natural language processing in radiology",2021,"Journal of Biomedical Informatics",10,"10.1016/j.jbi.2020.103665","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099191183&doi=10.1016%2fj.jbi.2020.103665&partnerID=40&md5=db4cc959c3658001e3975982db80768e","Background: There has been increasing interest in machine learning based natural language processing (NLP) methods in radiology; however, models have often used word embeddings trained on general web corpora due to lack of a radiology-specific corpus. Purpose: We examined the potential of Radiopaedia to serve as a general radiology corpus to produce radiology specific word embeddings that could be used to enhance performance on a NLP task on radiological text. Materials and methods: Embeddings of dimension 50, 100, 200, and 300 were trained on articles collected from Radiopaedia using a GloVe algorithm and evaluated on analogy completion. A shallow neural network using input from either our trained embeddings or pre-trained Wikipedia 2014 + Gigaword 5 (WG) embeddings was used to label the Radiopaedia articles. Labeling performance was evaluated based on exact match accuracy and Hamming loss. The McNemar's test with continuity and the Benjamini-Hochberg correction and a 5×2 cross validation paired two-tailed t-test were used to assess statistical significance. Results: For accuracy in the analogy task, 50-dimensional (50-D) Radiopaedia embeddings outperformed WG embeddings on tumor origin analogies (p < 0.05) and organ adjectives (p < 0.01) whereas WG embeddings tended to outperform on inflammation location and bone vs. muscle analogies (p < 0.01). The two embeddings had comparable performance on other subcategories. In the labeling task, the Radiopaedia-based model outperformed the WG based model at 50, 100, 200, and 300-D for exact match accuracy (p < 0.001, p < 0.001, p < 0.01, and p < 0.05, respectively) and Hamming loss (p < 0.001, p < 0.001, p < 0.01, and p < 0.05, respectively). Conclusion: We have developed a set of word embeddings from Radiopaedia and shown that they can preserve relevant medical semantics and augment performance on a radiology NLP task. Our results suggest that the cultivation of a radiology-specific corpus can benefit radiology NLP models in the future. © 2020 Elsevier Inc.","Analogy completion; Multi-label classification; Natural language processing; Word embeddings","Embeddings; Radiation; Radiology; Semantics; Cross validation; Domain specific; McNemar's tests; NAtural language processing; Statistical significance; T-tests; Web Corpora; Wikipedia; Natural language processing systems; analogical reasoning; Article; artificial neural network; controlled study; intermethod comparison; measurement accuracy; medical literature; natural language processing; priority journal; radiology; semantics; machine learning; Unified Medical Language System; Machine Learning; Natural Language Processing; Radiology; Semantics; Unified Medical Language System",Article,Scopus
"Coppola F., Faggioni L., Regge D., Giovagnoni A., Golfieri R., Bibbolino C., Miele V., Neri E., Grassi R.","Artificial intelligence: radiologists’ expectations and opinions gleaned from a nationwide online survey",2021,"Radiologia Medica",89,"10.1007/s11547-020-01205-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083992832&doi=10.1007%2fs11547-020-01205-y&partnerID=40&md5=c4618de1f45f0ff20f02204655771265","Purpose: To report the results of a nationwide online survey on artificial intelligence (AI) among radiologist members of the Italian Society of Medical and Interventional Radiology (SIRM). Methods and materials: All members were invited to the survey as an initiative by the Imaging Informatics Chapter of SIRM. The survey consisted of 13 questions about the participants’ demographic information, perceived advantages and issues related to AI implementation in radiological practice, and their overall opinion about AI. Results: In total, 1032 radiologists (equaling 9.5% of active SIRM members for the year 2019) joined the survey. Perceived AI advantages included a lower diagnostic error rate (750/1027, 73.0%) and optimization of radiologists’ work (697/1027, 67.9%). The risk of a poorer professional reputation of radiologists compared with non-radiologists (617/1024, 60.3%), and increased costs and workload due to AI system maintenance and data analysis (399/1024, 39.0%) were seen as potential issues. Most radiologists stated that specific policies should regulate the use of AI (933/1032, 90.4%) and were not afraid of losing their job due to it (917/1032, 88.9%). Overall, 77.0% of respondents (794/1032) were favorable to the adoption of AI, whereas 18.0% (186/1032) were uncertain and 5.0% (52/1032) were unfavorable. Conclusions: Radiologists had a mostly positive attitude toward the implementation of AI in their working practice. They were not concerned that AI will replace them, but rather that it might diminish their professional reputation. © 2020, Italian Society of Medical Radiology.","Artificial intelligence; Online survey; Radiology","adoption; adult; article; artificial intelligence; attitude; clinical article; data analysis; demography; diagnostic error; expectation; female; human; human experiment; information science; male; radiologist; radiology; workload; health personnel attitude; Italy; medical society; questionnaire; Artificial Intelligence; Attitude of Health Personnel; Humans; Italy; Radiologists; Societies, Medical; Surveys and Questionnaires",Article,Scopus
"Rao B., Zohrabian V., Cedeno P., Saha A., Pahade J., Davis M.A.","Utility of Artificial Intelligence Tool as a Prospective Radiology Peer Reviewer — Detection of Unreported Intracranial Hemorrhage",2021,"Academic Radiology",40,"10.1016/j.acra.2020.01.035","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080049476&doi=10.1016%2fj.acra.2020.01.035&partnerID=40&md5=039be54b3a37c3346d895fdeafca16b2","Rationale and Objectives: Misdiagnosis of intracranial hemorrhage (ICH) can adversely impact patient outcomes. The increasing workload on the radiologists may increase the chance of error and compromise the quality of care provided by the radiologists. Materials and Methods: We used an FDA approved artificial intelligence (AI) solution based on a convolutional neural network to assess the prevalence of ICH in scans, which were reported as negative for ICH. We retrospectively applied the AI solution to all consecutive noncontrast computed tomography (CT) head scans performed at eight imaging sites affiliated to our institution. Results: In the 6565 noncontrast CT head scans, which met the inclusion criteria, 5585 scans were reported to have no ICH (“negative-by-report” cases). We applied AI solution to these “negative-by-report” cases. AI solution suggested there were ICH in 28 of these scans (“negative-by-report” and “positive-by-AI solution”). After consensus review by three neuroradiologists, 16 of these scans were found to have ICH, which was not reported (missed diagnosis by radiologists), with a false-negative rate of radiologists for ICH detection at 1.6%. Most commonly missed ICH was overlying the cerebral convexity and in the parafalcine regions. Conclusion: Our study demonstrates that an AI solution can help radiologists to diagnose ICH and thus decrease the error rate. AI solution can serve as a prospective peer review tool for non-contrast head CT scans to identify ICH and thus minimize false negatives. © 2020 The Association of University Radiologists","Artificial intelligence; Intracranial hemorrhage; Peer-review","adult; Article; artificial intelligence; brain hemorrhage; clinical trial; computer assisted tomography; convolutional neural network; diagnostic accuracy; diagnostic error; diagnostic test accuracy study; human; image processing; major clinical study; medical record; neuroradiologist; peer review; predictive value; prevalence; priority journal; prospective study; scoring system; sensitivity and specificity; subarachnoid hemorrhage; subdural hematoma; brain hemorrhage; diagnostic imaging; radiology; retrospective study; Artificial Intelligence; Humans; Intracranial Hemorrhages; Prospective Studies; Radiology; Retrospective Studies",Article,Scopus
"Jia X., Xiong Y., Zhang J., Zhang Y., Zhu Y.","Few-shot Radiology Report Generation for Rare Diseases",2020,"Proceedings - 2020 IEEE International Conference on Bioinformatics and Biomedicine, BIBM 2020",4,"10.1109/BIBM49941.2020.9313563","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100344988&doi=10.1109%2fBIBM49941.2020.9313563&partnerID=40&md5=57a2d64ff3b831aaf8b9956078995e66","Automatic radiology report generation that interprets medical images and writes their diagnostic reports is in high demand, as the manual written-report can be laborintensive and error-prone. By this context so far, some radiology report generation models have been proposed already which can hardly detect rare diseases accurately due to insufficient training data of such diseases. Radiology report generation task is therefore severely challenged while involving the rare disease. To tackle this problem, we propose a few-shot Radiology report Generation model, namely RareGen, assembled with two components for better semantic representations learning which can benefit rare disease detection and their diagnosis report generation. Specifically, a few-shot learning generative network is introduced for generating artificial medical instances for rare diseases. Moreover, a disease graph convolution is proposed to model and strengthen the intrinsic correlations among diseases, which allows knowledge transfer from regular diseases to those rare diseases. To the best of our knowledge, this is the first study that focuses on rare disease diagnosis report generation from radiology data. Extensive experiments are conducted to demonstrate the effectiveness of our model. © 2020 IEEE.","Bioinformatics; Data Mining; Few-Shot Learning; Report Generation","Bioinformatics; Diagnosis; Knowledge management; Medical imaging; Radiation; Radiology; Semantics; Diagnostic Report; Error prones; Knowledge transfer; Radiology reports; Report generation; Semantic representation; Training data; Two-component; Diseases",Conference Paper,Scopus
"Daoud M.K., Otair M.","The role of artificial intelligence and the internet of things in the development of medical radiology (an experimental study on magnetic resonance imaging)",2020,"Proceedings - 2020 International Conference on Intelligent Computing and Human-Computer Interaction, ICHCI 2020",3,"10.1109/ICHCI51889.2020.00011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106417932&doi=10.1109%2fICHCI51889.2020.00011&partnerID=40&md5=c0f0fa6f91640cf92e44da1f1bd94bf4","This study presented a new technology in the medical radiology sector through artificial intelligence and the Internet of things, and the study provided applicable experiments on the magnetic resonance imaging device that lead to real, error-free diagnostic results based on the introduction of artificial intelligence techniques Reading and analyzing the images with the standard anatomy stored in them and providing a report Detailed information about the patient's condition. © 2020 IEEE.","Component: Artificial Intelligence; Internet of things; Magnetic Resonance Imaging; Medical Radiology","Diagnosis; Intelligent computing; Internet of things; Magnetic resonance imaging; Medical imaging; Radiation; Radiology; Artificial intelligence techniques; Magnetic resonance imaging device; Medical radiology; Human computer interaction",Conference Paper,Scopus
"Heo T.S., Kim Y.S., Choi J.M., Jeong Y.S., Seo S.Y., Lee J.H., Jeon J.P., Kim C.","Prediction of stroke outcome using natural language processing-based machine learning of radiology report of brain MRI",2020,"Journal of Personalized Medicine",23,"10.3390/jpm10040286","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098140463&doi=10.3390%2fjpm10040286&partnerID=40&md5=d95fd13cefa4d3819f4e28bf75abacbe","Brain magnetic resonance imaging (MRI) is useful for predicting the outcome of patients with acute ischemic stroke (AIS). Although deep learning (DL) using brain MRI with certain image biomarkers has shown satisfactory results in predicting poor outcomes, no study has assessed the usefulness of natural language processing (NLP)-based machine learning (ML) algorithms using brain MRI free-text reports of AIS patients. Therefore, we aimed to assess whether NLP-based ML algorithms using brain MRI text reports could predict poor outcomes in AIS patients. This study included only English text reports of brain MRIs examined during admission of AIS patients. Poor outcome was defined as a modified Rankin Scale score of 3–6, and the data were captured by trained nurses and physicians. We only included MRI text report of the first MRI scan during the admission. The text dataset was randomly divided into a training and test dataset with a 7:3 ratio. Text was vectorized to word, sentence, and document levels. In the word level approach, which did not consider the sequence of words, and the “bag-of-words” model was used to reflect the number of repetitions of text token. The “sent2vec” method was used in the sensation-level approach considering the sequence of words, and the word embedding was used in the document level approach. In addition to conventional ML algorithms, DL algorithms such as the convolutional neural network (CNN), long short-term memory, and multilayer perceptron were used to predict poor outcomes using 5-fold cross-validation and grid search techniques. The performance of each ML classifier was compared with the area under the receiver operating characteristic (AUROC) curve. Among 1840 subjects with AIS, 645 patients (35.1%) had a poor outcome 3 months after the stroke onset. Random forest was the best classifier (0.782 of AUROC) using a word-level approach. Overall, the document-level approach exhibited better performance than did the word-or sentence-level approaches. Among all the ML classifiers, the multi-CNN algorithm demonstrated the best classification performance (0.805), followed by the CNN (0.799) algorithm. When predicting future clinical outcomes using NLP-based ML of radiology free-text reports of brain MRI, DL algorithms showed superior performance over the other ML algorithms. In particular, the prediction of poor outcomes in document-level NLP DL was improved more by multi-CNN and CNN than by recurrent neural network-based algorithms. NLP-based DL algorithms can be used as an important digital marker for unstructured electronic health record data DL prediction. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Deep learning; Functional outcome; Ischemic stroke; Machine learning; Magnetic resonance imaging; Natural language processing","aged; Article; artificial neural network; cerebrovascular accident; classification algorithm; clinical outcome; controlled study; convolutional neural network; diagnostic test accuracy study; electronic health record; female; functional magnetic resonance imaging; human; machine learning; major clinical study; male; National Institutes of Health Stroke Scale; natural language processing; neuroimaging; nuclear magnetic resonance imaging; perceptron; percutaneous thrombectomy; prediction; prospective study; Rankin scale; receiver operating characteristic; sensitivity and specificity; support vector machine",Article,Scopus
"Lewandrowski K.-U., Muraleedharan N., Eddy S.A., Sobti V., Reece B.D., León J.F.R., Shah S.","Artificial intelligence comparison of the radiologist report with endoscopic predictors of successful transforaminal decompression for painful conditions of the lumber spine: Application of deep learning algorithm interpretation of routine lumbar magnetic resonance imaging scan",2020,"International Journal of Spine Surgery",10,"10.14444/7130","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097662052&doi=10.14444%2f7130&partnerID=40&md5=f3427804612faa0935b4946809ae96a2","Background: Identifying pain generators in multilevel lumbar degenerative disc disease is not trivial but is crucial for lasting symptom relief with the targeted endoscopic spinal decompression surgery. Artificial intelligence (AI) applications of deep learning neural networks to the analysis of routine lumbar MRI scans could help the primary care and endoscopic specialist physician to compare the radiologist’s report with a review of endoscopic clinical outcomes. Objective: To analyze and compare the probability of predicting successful outcome with lumbar spinal endoscopy by using the radiologist’s MRI grading and interpretation of the radiologic image with a novel AI deep learning neural network (Multus Radbote) as independent prognosticators. Methods: The location and severity of foraminal stenosis were analyzed using comparative ordinal grading by the radiologist, and a contiguous grading by the AI network in patients suffering from lateral recess and foraminal stenosis due to lumbar herniated disc. The compressive pathology definitions were extracted from the radiologist lumbar MRI reports from 65 patients with a total of 383 levels for the central canal – (0) no disc bulge/protrusion/canal stenosis, (1) disc bulge without canal stenosis, (2) disc bulge resulting in canal stenosis, and (3) disc herniation/protrusion/extrusion resulting in canal stenosis. Both neural foramina were assessed with either – (0) neural foraminal stenosis absent, or (1) neural foramina are stenosis present. Reporting criteria for the pathologies at each disc level and, when available, the grading of severity were extracted and assigned into two categories: ‘‘Normal,’’ and ‘‘Stenosis.’’ Clinical outcomes were graded using dichotomized modified Macnab criteria considering Excellent and Good results as ‘‘Improved,’’ and Fair and Poor outcomes as ‘‘Not Improved.’’ Binary logistic regression analysis was used to predict the probability of the AI- and radiologist grading of stenosis at the 88 foraminal decompression sites to result in ‘‘Improved’’ outcomes. Results: The average age of the 65 patients was 62.7 þ/- 12.7 years. They consisted of 51 (54.3%) males and 43 (45.7%) females. At an average final follow-up of 57.4 þ/- 12.57, Macnab outcome analysis showed that 86.4% of the 88 foraminal decompressions resulted in Excellent and Good (Improved) clinical outcomes. The stenosis grading by the radiologist showed an average severity score of 4.71 þ/- 2.626, and the average AI severity grading was 5.65 þ/- 3.73. Logit regression probability analysis of the two independent prognosticators showed that both the grading by the radiologist (86.2%; odds ratio 1.264) and the AI grading (86.4%; odds ratio 1.267) were nearly equally predictive of a successful outcome with the endoscopic decompression. Conclusions: Deep learning algorithms are capable of identifying lumbar foraminal compression due to herniated disc. The treatment outcome was correlated to the decompression of the directly visualized corresponding pathology during the lumbar endoscopy. This research should be extended to other validated pain generators in the lumbar spine. © International Society for the Advancement of Spine Surgery","Artificial intelligence; Deep neural network learning; Endoscopic decompression; Herniated disc; Magnetic resonance imaging","adult; Article; artificial intelligence; clinical outcome; controlled study; decompression surgery; deep learning; deep neural network; disease severity; dysesthesia; endoscopic surgery; endoscopy; entropy; female; follow up; human; intervertebral disk hernia; lumbar disk hernia; lumbar spine; major clinical study; male; nuclear magnetic resonance imaging; outcome assessment; priority journal; radiologist; retrospective study; vertebral canal stenosis",Article,Scopus
"López-Úbeda P., Díaz-Galiano M.C., Martín-Noguerol T., Ureña-López A., Martín-Valdivia M.-T., Luna A.","Detection of unexpected findings in radiology reports: A comparative study of machine learning approaches",2020,"Expert Systems with Applications",15,"10.1016/j.eswa.2020.113647","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086822208&doi=10.1016%2fj.eswa.2020.113647&partnerID=40&md5=ff73c8dd6ae97fbc168d74eb703863b4","This study explores machine learning methods for the detection of unexpected findings in Spanish radiology reports. Regarding radiological reports, unexpected findings are the set of radiological signs identified at a certain imaging modality exam which meet two characteristics: they are not apparently related with the a priori expected results of the radiological exam and involve a clinical emergency or urgency situation that must be reported shortly to the prescribing physician or another medical specialist as well as to the patient in order to preserve life and/or prevent dangerous occurrences. Several traditional machine learning and deep learning classification algorithms are evaluated and compared. To carry out the task we use 5947 anonymous radiology reports from HT médica. Experimental results suggest that the performance of the Convolutional Neural Networks models are better than traditional machine learning. The best F1 score for the identification of an unexpected finding was 90%. Finally, we also perform an error analysis which will guide us to achieve better results in the future. © 2020 Elsevier Ltd","Deep learning; Machine learning; Natural language processing; Spanish radiology reports; Text report classification; Unexpected findings","Convolutional neural networks; Deep learning; Medical imaging; Radiation; Radiology; Classification algorithm; Comparative studies; F1 scores; Imaging modality; Machine learning approaches; Machine learning methods; Radiology reports; Spanish Radiology; Learning systems",Article,Scopus
"Steinkamp J.M., Pomeranz T., Adleberg J., Kahn C.E., Jr., Cook T.S.","Evaluation of automated public de-identification tools on a corpus of radiology reports",2020,"Radiology: Artificial Intelligence",6,"10.1148/ryai.2020190137","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114075292&doi=10.1148%2fryai.2020190137&partnerID=40&md5=68751c86591e3c63b312eeb0db5a941a","Purpose: To evaluate publicly available de-identification tools on a large corpus of narrative-text radiology reports. Materials and Methods: In this retrospective study, 21 categories of protected health information (PHI) in 2503 radiology reports were annotated from a large multihospital academic health system, collected between January 1, 2012 and January 8, 2019. A subset consisting of 1023 reports served as a test set; the remainder were used as domain-specific training data. The types and frequencies of PHI present within the reports were tallied. Five public de-identification tools were evaluated: MITRE Identification Scrubber Toolkit, U.S. National Library of Medicine‒Scrubber, Massachusetts Institute of Technology de-identification software, Emory Health Information DE-identification (HIDE) software, and Neuro named-entity recognition (NeuroNER). The tools were compared using metrics including recall, precision, and F1 score (the harmonic mean of recall and precision) for each category of PHI. Results: The annotators identified 3528 spans of PHI text within the 2503 reports. Cohen k for interrater agreement was 0.938. Dates accounted for the majority of PHI found in the dataset of radiology reports (n = 2755 [78%]). The two best-performing tools both used machine learning methods—NeuroNER (precision, 94.5%; recall, 92.6%; microaveraged F1 score [F1], 93.6%) and Emory HIDE (precision, 96.6%; recall, 88.2%; F1, 92.2%)—but none exceeded 50% F1 on the important patient names category. Conclusion: PHI appeared infrequently within the corpus of reports studied, which created difficulties for training machine learning systems. Out-of-the-box de-identification tools achieved limited performance on the corpus of radiology reports, suggesting the need for further advancements in public datasets and trained models. © RSNA, 2020.",,"adult; algorithm; Article; artificial intelligence; certification; clinical decision support system; computer aided design; computer model; electronic health record; health care personnel; human; interrater reliability; machine learning; Massachusetts; medical information; natural language processing; prevalence; radiology; retrospective study; scoring system; total quality management; training",Article,Scopus
"Kapoor N., Lacson R., Khorasani R.","Workflow Applications of Artificial Intelligence in Radiology and an Overview of Available Tools",2020,"Journal of the American College of Radiology",20,"10.1016/j.jacr.2020.08.016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093075810&doi=10.1016%2fj.jacr.2020.08.016&partnerID=40&md5=3d73b4f97f6a79c421324f0df6e310b2","In the past decade, there has been tremendous interest in applying artificial intelligence (AI) to improve the field of radiology. Currently, numerous AI applications are in development, with potential benefits spanning all steps of the imaging chain from test ordering to report communication. AI has been proposed as a means to optimize patient scheduling, improve worklist management, enhance image acquisition, and help radiologists interpret diagnostic studies. Although the potential for AI in radiology appears almost endless, the field is still in the early stages, with many uses still theoretical, in development, or limited to single institutions. Moreover, although the current use of AI in radiology has emphasized its clinical applications, some of which are in the distant future, it is increasingly clear that AI algorithms could also be used in the more immediate future for a variety of noninterpretive and quality improvement uses. Such uses include the integration of AI into electronic health record systems to reduce unwarranted variation in radiologists’ follow-up recommendations and to improve other dimensions of radiology report quality. In the end, the potential of AI in radiology must be balanced with acknowledgment of its current limitations regarding generalizability and data privacy. © 2020 American College of Radiology","Artificial intelligence; machine learning; natural language processing","adult; article; artificial intelligence; electronic health record; follow up; human; machine learning; natural language processing; patient scheduling; privacy; radiologist; radiology; theoretical study; total quality management; workflow",Article,Scopus
"Pathak S., Van Rossen J., Vijlbrief O., Geerdink J., Seifert C., Van Keulen M.","Post-Structuring Radiology Reports of Breast Cancer Patients for Clinical Quality Assurance",2020,"IEEE/ACM Transactions on Computational Biology and Bioinformatics",8,"10.1109/TCBB.2019.2914678","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074121545&doi=10.1109%2fTCBB.2019.2914678&partnerID=40&md5=cf99b8d165d1e2a49330aaab3db13b4c","Hospitals often set protocols based on well defined standards to maintain the quality of patient reports. To ensure that the clinicians conform to the protocols, quality assurance of these reports is needed. Patient reports are currently written in free-text format, which complicates the task of quality assurance. In this paper, we present a machine learning based natural language processing system for automatic quality assurance of radiology reports on breast cancer. This is achieved in three steps: we i) identify the top-level structure (headings) of the report, ii) classify the report content into the top-level headings, and iii) convert the free-text detailed findings in the report to a semi-structured format (post-structuring). Top level structure and content of report were predicted with an F1 score of 0.97 and 0.94, respectively, using Support Vector Machine (SVM) classifiers. For automatic structuring, our proposed hierarchical Conditional Random Field (CRF) outperformed the baseline CRF with an F1 score of 0.78 versus 0.71. The determined structure of the report is represented in semi-structured XML format of the free-text report, which helps to easily visualize the conformance of the findings to the protocols. This format also allows easy extraction of specific information for other purposes such as search, evaluation, and research. © 2004-2012 IEEE.","automatic structuring; conditional random field; post-structuring; Quality assurance; radiology reports","Diseases; Object oriented programming; Quality assurance; Radiation; Radiology; Random processes; Support vector machines; Turing machines; Breast Cancer; Conditional random field; Level structure; Radiology reports; Semi-structured; Set protocols; Specific information; XML format; Natural language processing systems; breast tumor; computer assisted diagnosis; diagnostic imaging; electronic health record; female; health care quality; human; machine learning; natural language processing; radiology information system; support vector machine; Breast Neoplasms; Electronic Health Records; Female; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Natural Language Processing; Quality Assurance, Health Care; Radiology Information Systems; Support Vector Machine",Article,Scopus
"Nguyen E., Theodorakopoulos D., Pathak S., Geerdink J., Vijlbrief O., Van Keulen M., Seifert C.","A hybrid text classification and language generation model for automated summarization of dutch breast cancer radiology reports",2020,"Proceedings - 2020 IEEE 2nd International Conference on Cognitive Machine Intelligence, CogMI 2020",4,"10.1109/CogMI50398.2020.00019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100619408&doi=10.1109%2fCogMI50398.2020.00019&partnerID=40&md5=91dc8bb14ecb5f73059556b5595a6c0d","Breast cancer diagnosis is based on radiology reports describing observations made from medical imagery, such as X-rays obtained during mammography. The reports are written by radiologists and contain a conclusion summarizing the observations. Manually summarizing the reports is time-consuming and leads to high text variability. This paper investigates the automated summarization of Dutch radiology reports. We propose a hybrid model consisting of a language model (encoder-decoder with attention) and a separate BI-RADS score classifier. The summarization model achieved a ROUGE-L F1 score of 51.5% on the Dutch reports, which is comparable to results in other languages and other domains. For the BI-RADS classification, the language model (accuracy 79.1 %) was outperformed by a separate classifier (accuracy 83.3 %), leading us to propose a hybrid approach for radiology report summarization. Our qualitative evaluation with experts found the generated conclusions to be comprehensible and to cover mostly relevant content, and the main focus for improvement should be their factual correctness. While the current model is not accurate enough to be employed in clinical practice, our results indicate that hybrid models might be a worthwhile direction for future research. © 2020 IEEE.","Abstractive Summarization; Attention Mechanism; Breast Cancer; Deep Learning; Encoder-Decoder; Radiology Reports","Artificial intelligence; Classification (of information); Clinical research; Computational linguistics; Diagnosis; Diseases; Radiation; Radiology; Breast cancer diagnosis; Clinical practices; Current modeling; Language generation; Qualitative evaluations; Radiology reports; Summarization models; Text classification; Text processing",Conference Paper,Scopus
"Wu J.T., Wong K.C.L., Gur Y., Ansari N., Karargyris A., Sharma A., Morris M., Saboury B., Ahmad H., Boyko O., Syed A., Jadhav A., Wang H., Pillai A., Kashyap S., Moradi M., Syeda-Mahmood T.","Comparison of Chest Radiograph Interpretations by Artificial Intelligence Algorithm vs Radiology Residents",2020,"JAMA Network Open",54,"10.1001/jamanetworkopen.2020.22779","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092801660&doi=10.1001%2fjamanetworkopen.2020.22779&partnerID=40&md5=d53432958f7d2f27246706d0e66e846c","Importance: Chest radiography is the most common diagnostic imaging examination performed in emergency departments (EDs). Augmenting clinicians with automated preliminary read assistants could help expedite their workflows, improve accuracy, and reduce the cost of care. Objective: To assess the performance of artificial intelligence (AI) algorithms in realistic radiology workflows by performing an objective comparative evaluation of the preliminary reads of anteroposterior (AP) frontal chest radiographs performed by an AI algorithm and radiology residents. Design, Setting, and Participants: This diagnostic study included a set of 72 findings assembled by clinical experts to constitute a full-fledged preliminary read of AP frontal chest radiographs. A novel deep learning architecture was designed for an AI algorithm to estimate the findings per image. The AI algorithm was trained using a multihospital training data set of 342126 frontal chest radiographs captured in ED and urgent care settings. The training data were labeled from their associated reports. Image-based F1 score was chosen to optimize the operating point on the receiver operating characteristics (ROC) curve so as to minimize the number of missed findings and overcalls per image read. The performance of the model was compared with that of 5 radiology residents recruited from multiple institutions in the US in an objective study in which a separate data set of 1998 AP frontal chest radiographs was drawn from a hospital source representative of realistic preliminary reads in inpatient and ED settings. A triple consensus with adjudication process was used to derive the ground truth labels for the study data set. The performance of AI algorithm and radiology residents was assessed by comparing their reads with ground truth findings. All studies were conducted through a web-based clinical study application system. The triple consensus data set was collected between February and October 2018. The comparison study was preformed between January and October 2019. Data were analyzed from October to February 2020. After the first round of reviews, further analysis of the data was performed from March to July 2020. Main Outcomes and Measures: The learning performance of the AI algorithm was judged using the conventional ROC curve and the area under the curve (AUC) during training and field testing on the study data set. For the AI algorithm and radiology residents, the individual finding label performance was measured using the conventional measures of label-based sensitivity, specificity, and positive predictive value (PPV). In addition, the agreement with the ground truth on the assignment of findings to images was measured using the pooled κ statistic. The preliminary read performance was recorded for AI algorithm and radiology residents using new measures of mean image-based sensitivity, specificity, and PPV designed for recording the fraction of misses and overcalls on a per image basis. The 1-sided analysis of variance test was used to compare the means of each group (AI algorithm vs radiology residents) using the F distribution, and the null hypothesis was that the groups would have similar means. Results: The trained AI algorithm achieved a mean AUC across labels of 0.807 (weighted mean AUC, 0.841) after training. On the study data set, which had a different prevalence distribution, the mean AUC achieved was 0.772 (weighted mean AUC, 0.865). The interrater agreement with ground truth finding labels for AI algorithm predictions had pooled κ value of 0.544, and the pooled κ for radiology residents was 0.585. For the preliminary read performance, the analysis of variance test was used to compare the distributions of AI algorithm and radiology residents' mean image-based sensitivity, PPV, and specificity. The mean image-based sensitivity for AI algorithm was 0.716 (95% CI, 0.704-0.729) and for radiology residents was 0.720 (95% CI, 0.709-0.732) (P =.66), while the PPV was 0.730 (95% CI, 0.718-0.742) for the AI algorithm and 0.682 (95% CI, 0.670-0.694) for the radiology residents (P <.001), and specificity was 0.980 (95% CI, 0.980-0.981) for the AI algorithm and 0.973 (95% CI, 0.971-0.974) for the radiology residents (P <.001). Conclusions and Relevance: These findings suggest that it is possible to build AI algorithms that reach and exceed the mean level of performance of third-year radiology residents for full-fledged preliminary read of AP frontal chest radiographs. This diagnostic study also found that while the more complex findings would still benefit from expert overreads, the performance of AI algorithms was associated with the amount of data available for training rather than the level of difficulty of interpretation of the finding. Integrating such AI systems in radiology workflows for preliminary interpretations has the potential to expedite existing radiology workflows and address resource scarcity while improving overall accuracy and reducing the cost of care.. © 2020 Royal Society of Chemistry. All rights reserved.",,"adult; algorithm; analysis of variance; area under the curve; article; artificial intelligence; consensus; controlled study; deep learning; diagnostic test accuracy study; emergency ward; hospital patient; human; interrater reliability; kappa statistics; null hypothesis; prediction; predictive value; prevalence; receiver operating characteristic; resident; sensitivity and specificity; thorax radiography; workflow; algorithm; artificial intelligence; computer assisted diagnosis; devices; diagnostic imaging; health care quality; medical education; procedures; radiography; thorax; Algorithms; Area Under Curve; Artificial Intelligence; Humans; Internship and Residency; Quality of Health Care; Radiographic Image Interpretation, Computer-Assisted; Radiography; ROC Curve; Thorax",Article,Scopus
"Bernaerts A., Barbier L., Abeloos J., De Backer T., Bosmans F., Vanhoenacker F.M., Casselman J.","Cone Beam Computed Tomography Imaging in Dental Implants: A Primer for Clinical Radiologists",2020,"Seminars in Musculoskeletal Radiology",1,"10.1055/s-0040-1701496","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092753509&doi=10.1055%2fs-0040-1701496&partnerID=40&md5=9f04846438b4a4421917b466492cbea7","With the introduction of cone beam computed tomography (CBCT) into dentistry in the 1990s, radiologists have become more frequently involved in dental implant planning. This article describes the information that should be included in a radiology report to achieve a successful implantation. The justification to use CBCT during the preoperative planning phase is based on the need to evaluate patient-specific anatomy in detail (general condition of the jaw, bone quantity, and bone quality), the application of more advanced surgical techniques (maxillary sinus augmentation procedure, zygomatic implants), and the integrated presurgical planning and virtual patient approach. Postoperatively, CBCT is used when implant retrieval is anticipated and two-dimensional radiographs have not provided sufficient information, for evaluation of graft healing, or to assess complications, mostly related to neurovascular trauma. © 2020 Georg Thieme Verlag. All rights reserved.","alveolar ridge augmentation; Cone beam computed tomography; dental implants; imaging; implant failure","anatomy; Article; blood vessel injury; bone necrosis; bone quality; cone beam computed tomography; evaluation study; fracture; healing; human; jaw; mandible; maxillary sinus; medical device complication; nerve injury; nose cavity; osseointegration; panoramic radiography; perforation; periimplantitis; planning; postoperative complication; postoperative period; preoperative evaluation; priority journal; prosthesis infection; radiologist; surgical technique; zygoma; cone beam computed tomography; diagnostic imaging; procedures; tooth; tooth implant; Cone-Beam Computed Tomography; Dental Implants; Humans; Tooth",Article,Scopus
"Callen A.L., Dupont S.M., Price A., Laguna B., McCoy D., Do B., Talbott J., Kohli M., Narvid J.","Between Always and Never: Evaluating Uncertainty in Radiology Reports Using Natural Language Processing",2020,"Journal of Digital Imaging",6,"10.1007/s10278-020-00379-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089522169&doi=10.1007%2fs10278-020-00379-1&partnerID=40&md5=92d813cd4c1de06551d6135ad10e2c46","The ideal radiology report reduces diagnostic uncertainty, while avoiding ambiguity whenever possible. The purpose of this study was to characterize the use of uncertainty terms in radiology reports at a single institution and compare the use of these terms across imaging modalities, anatomic sections, patient characteristics, and radiologist characteristics. We hypothesized that there would be variability among radiologists and between subspecialities within radiology regarding the use of uncertainty terms and that the length of the impression of a report would be a predictor of use of uncertainty terms. Finally, we hypothesized that use of uncertainty terms would often be interpreted by human readers as “hedging.” To test these hypotheses, we applied a natural language processing (NLP) algorithm to assess and count the number of uncertainty terms within radiology reports. An algorithm was created to detect usage of a published set of uncertainty terms. All 642,569 radiology report impressions from 171 reporting radiologists were collected from 2011 through 2015. For validation, two radiologists without knowledge of the software algorithm reviewed report impressions and were asked to determine whether the report was “uncertain” or “hedging.” The relationship between the presence of 1 or more uncertainty terms and the human readers’ assessment was compared. There were significant differences in the proportion of reports containing uncertainty terms across patient admission status and across anatomic imaging subsections. Reports with uncertainty were significantly longer than those without, although report length was not significantly different between subspecialities or modalities. There were no significant differences in rates of uncertainty when comparing the experience of the attending radiologist. When compared with reader 1 as a gold standard, accuracy was 0.91, sensitivity was 0.92, specificity was 0.9, and precision was 0.88, with an F1-score of 0.9. When compared with reader 2, accuracy was 0.84, sensitivity was 0.88, specificity was 0.82, and precision was 0.68, with an F1-score of 0.77. Substantial variability exists among radiologists and subspecialities regarding the use of uncertainty terms, and this variability cannot be explained by years of radiologist experience or differences in proportions of specific modalities. Furthermore, detection of uncertainty terms demonstrates good test characteristics for predicting human readers’ assessment of uncertainty. © 2020, Society for Imaging Informatics in Medicine.","Diagnostic uncertainty; Natural language processing","Natural language processing systems; Radiation; Radiology; Anatomic sections; Gold standards; Human readers; Imaging modality; NAtural language processing; Patient admissions; Radiology reports; Software algorithms; Uncertainty analysis; adult; algorithm; article; controlled study; gold standard; hospital admission; human; natural language processing; radiologist; radiology; reading; sensitivity and specificity; software; uncertainty; radiology information system; research; uncertainty; Humans; Natural Language Processing; Radiology; Radiology Information Systems; Research Report; Uncertainty",Article,Scopus
"Mayampurath A., Churpek M.M., Su X., Shah S., Munroe E., Patel B., Dligach D., Afshar M.","External Validation of an Acute Respiratory Distress Syndrome Prediction Model Using Radiology Reports",2020,"Critical Care Medicine",5,"10.1097/CCM.0000000000004468","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089820233&doi=10.1097%2fCCM.0000000000004468&partnerID=40&md5=cbdda293121c9359b7d2a736d315dda0","Objectives: Acute respiratory distress syndrome is frequently under recognized and associated with increased mortality. Previously, we developed a model that used machine learning and natural language processing of text from radiology reports to identify acute respiratory distress syndrome. The model showed improved performance in diagnosing acute respiratory distress syndrome when compared to a rule-based method. In this study, our objective was to externally validate the natural language processing model in patients from an independent hospital setting. Design: Secondary analysis of data across five prospective clinical studies. Setting: An urban, tertiary care, academic hospital. Patients: Adult patients admitted to the medical ICU and at-risk for acute respiratory distress syndrome. Interventions: None. Measurements and Main Results: The natural language processing model was previously derived and internally validated in burn, trauma, and medical patients at Loyola University Medical Center. Two machine learning models were examined with the following text features from qualifying radiology reports: 1) word representations (n-grams) and 2) standardized clinical named entity mentions mapped from the National Library of Medicine Unified Medical Language System. The models were externally validated in a cohort of 235 patients at the University of Chicago Medicine, among which 110 (47%) were diagnosed with acute respiratory distress syndrome by expert annotation. During external validation, the n-gram model demonstrated good discrimination between acute respiratory distress syndrome and nonacute respiratory distress syndrome patients (C-statistic, 0.78; 95% CI, 0.72-0.84). The n-gram model had a higher discrimination for acute respiratory distress syndrome when compared with the standardized named entity model, although not statistically significant (C-statistic 0.78 vs 0.72; p = 0.09). The most important features in the model had good face validity for acute respiratory distress syndrome characteristics but differences in frequencies did occur between hospital settings. Conclusions: Our computable phenotype for acute respiratory distress syndrome had good discrimination in external validation and may be used by other health systems for case-identification. Discrepancies in feature representation are likely due to differences in characteristics of the patient cohorts. Copyright © 2020 by the Society of Critical Care Medicine and Wolters Kluwer Health, Inc. All Rights Reserved.","acute lung injury; acute respiratory distress syndrome; machine learning; natural language processing; respiratory failure; validation","adult; age; aged; diagnostic imaging; female; hospital; hospital mortality; human; image processing; intensive care unit; machine learning; male; middle aged; mortality; natural language processing; procedures; prospective study; reproducibility; respiratory distress syndrome; sex factor; socioeconomics; thorax radiography; university hospital; Academic Medical Centers; Adult; Age Factors; Aged; Female; Hospital Mortality; Hospitals, Urban; Humans; Image Processing, Computer-Assisted; Intensive Care Units; Machine Learning; Male; Middle Aged; Natural Language Processing; Prospective Studies; Radiography, Thoracic; Reproducibility of Results; Respiratory Distress Syndrome; Sex Factors; Socioeconomic Factors",Article,Scopus
"Olthof A.W., Leusveld A.L.M., de Groot J.C., Callenbach P.M.C., van Ooijen P.M.A.","Contextual Structured Reporting in Radiology: Implementation and Long-Term Evaluation in Improving the Communication of Critical Findings",2020,"Journal of Medical Systems",6,"10.1007/s10916-020-01609-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088639132&doi=10.1007%2fs10916-020-01609-3&partnerID=40&md5=0b9ccbc105a148fdc53ca636e2093eaf","Structured reporting contributes to the completeness of radiology reports and improves quality. Both the content and the structure are essential for successful implementation of structured reporting. Contextual structured reporting is tailored to a specific scenario and can contain information retrieved from the context. Critical findings detected by imaging need urgent communication to the referring physician. According to guidelines, the occurrence of this communication should be documented in the radiology reports and should contain when, to whom and how was communicated. In free-text reporting, one or more of these required items might be omitted. We developed a contextual structured reporting template to ensure complete documentation of the communication of critical findings. The WHEN and HOW items were included automatically, and the insertion of the WHO-item was facilitated by the template. A pre- and post-implementation study demonstrated a substantial improvement in guideline adherence. The template usage improved in the long-term post-implementation study compared with the short-term results. The two most often occurring categories of critical findings are “infection / inflammation” and “oncology”, corresponding to the a large part of urgency level 2 (to be reported within 6 h) and level 3 (to be reported within 6 days), respectively. We conclude that contextual structured reporting is feasible for required elements in radiology reporting and for automated insertion of context-dependent data. Contextual structured reporting improves guideline adherence for communication of critical findings. © 2020, The Author(s).","Communication; Medical informatics; Quality improvement; Radiology","Article; clinical evaluation; clinical practice; feasibility study; human; infection; inflammation; interpersonal communication; medical documentation; oncology; patient care; physician; protocol compliance; radiology; documentation; radiography; radiology information system; Communication; Documentation; Humans; Radiography; Radiology; Radiology Information Systems",Article,Scopus
"Michell H., Johnston G.P., Morris C.S.","Erratum: Uncomplicated percutaneous IVC filter removal following implantation time of 6033 days (Radiology Case Reports (2020) 15(7) (1078–1082), (S1930043320301783), (10.1016/j.radcr.2020.05.008))",2020,"Radiology Case Reports",,"10.1016/j.radcr.2020.06.025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087382345&doi=10.1016%2fj.radcr.2020.06.025&partnerID=40&md5=d169ed2b36ba983bb71b191645deb7a5","Most patients have a time limited indication for inferior vena cava filtration. When the indication has expired, a retrievable inferior vena cava filter should be removed percutaneously, unless the risks of retrieval outweigh the benefits. Over time, long term indwelling inferior vena cava filters may experience complications, such as strut penetration, migration, thrombosis, tilt, fracture, and inferior vena cava stenosis. Long term indwelling retrievable inferior vena cava filters may become embedded in the wall of the inferior vena cava, making percutaneous retrieval difficult. However, this is not always the case, and they also may be easily and safely removed using simple techniques. We present a case of a long term indwelling retrievable inferior vena cava filter that was easily removed using simple techniques, 16.5 years after placement. IntroductionPulmonary embolism (PE) is a major cause of morbidity and mortality in the United States and usually occurs secondary to venous thromboembolism [1]. The current standard of treatment for venous thromboembolism leading to PE is medical anticoagulation therapy [2]. However, certain patients at risk for developing PE have either a contraindication to anticoagulation (eg, recent hemorrhage, recent surgery), complication of anticoagulation, or experience a failure of anticoagulation. Inferior vena cava (IVC) filters are minimally invasive mechanical devices placed into the IVC of patients who cannot be treated with anticoagulation [3]. Because IVC filters have the potential to remain within the body over extended periods of time, complications can occur, such as caval wall penetration, migration, thrombosis, tilt, fracture, and IVC stenosis [4]. These potential complications have stressed recent emphasis of IVC filter removal, especially when the filter is no longer indicated [5]. However, the very complications associated with longer filter dwell times give many providers pause as it relates to removal, despite several advanced techniques for filter removal published in the literature [6–8]. The longest retrievable Günther-Tulip IVC filter (Cook Medical Corp., Bloomington, IN) has remained in place before percutaneous removal has been 15.5 years [9]. We present a case of an uneventful, successful percutaneous IVC filter removal with a dwell time of 6033 days (16.5 years).Case reportA 38-year-old man with a past medical history of hypothyroidism presented from an outside hospital in 2003 as a multitrauma following a snowmobile accident. The patient was helmeted when he collided head-on with another snowmobile. The patient suffered subdural and epidural hematomas, a cardiac contusion with MRI evidence of tear and tamponade, lung contusions, a grade IV splenic laceration, bilateral grade II renal lacerations, and multiple comminuted fractures to his left scapula, left wrist and multiple ribs. Neurosurgery recommended conservative management with close clinical follow-up given the size and location of the subdural and epidural hematomas. The patient was taken to interventional radiology (IR) where he underwent successful splenic artery embolization. Because of the setting of multitrauma with an expected protraction of his nonmobile, a Günther-Tulip Vena Cava Filter was also placed for PE prophylaxis (Fig. 1). The patient recovered from his injuries, other than chronic neuromuscular dysfunction of his left arm, and experienced no venous thromboembolic events. Unfortunately, the patient was lost to follow-up, as he temporarily moved to another state, and his IVC filter was not removed. After 16.5 years, the patient returned to our IR clinic expressing the desire to have the uncomplicated, IVC filter removed. He explained that he no longer wished to have his IVC filter in place, even though he was asymptomatic related to the IVC filter. The patient was counseled regarding the risk of removal of IVC filters with long dwell times, as mentioned in the introduction. The interventional radiologist ultimately made the decision to remove the IVC filter. Preprocedure CT imaging demonstrated grade 1 to 2 penetrations of the 4 struts through the IVC wall, based on the Oh classification [4]. There was no additional involvement of the penetrated struts with any adjacent structure, nor was there evidence of filter thrombus, tilt, migration, or fracture (Figs. 2A and 2B). Informed consent was obtained following the explanation of the risks and benefits of the procedure and of moderate sedation. In the IR suite the patient was placed in the supine position. Conscious sedation was achieved with a total of 150 mcg of intravenous fentanyl and 3.5 mg of intravenous midazolam. Local anesthesia was achieved with 1% buffered lidocaine. Initial digital radiographic images demonstrated an intact Günther-Tulip IVC filter (Fig. 3). Via a right internal jugular vein approach, the IVC was accessed and a flush catheter was advanced down into the IVC. An initial inferior venacavogram demonstrated no evidence of IVC thrombus (Fig. 4). Through a 10-French sheath, a nitinol snare device (Amplatz Goose Neck Snare, Medtronic, Minneapolis, MN) was used to engage the hook of the IVC filter (Fig. 5). The sheath was easily advanced over the IVC filter, collapsing it (Fig. 6). The filter was pulled completely into the sheath and the intact IVC filter was completely removed from the patient. Inspection of the IVC filter demonstrated no fracture or missing components. A final inferior venacavogram demonstrated a normal IVC with no evidence of contrast media extravasation, stenosis, thrombosis, or dissection (Fig. 7). The patient tolerated the procedure well and without procedure-related complication. At 7-month follow-up, the patient was asymptomatic, continued to endorse no ill effects from the procedure, and remained in his usual state of health.DiscussionThis case demonstrates the prospect of uneventful IVC filter removal for filters that have been in place for an extended period of time. A more challenging retrieval was anticipated due to suspected ingrowth of the IVC filter into the IVC wall secondary to endothelialization from a long dwell time. However, the IVC filter was percutaneously removed effortlessly and without complication, using simple technique with a loop snare. Any endothelialization of the IVC filter that was present did not impede retrieval. This case also demonstrates that long dwell times do not necessarily limit the possibility for simple and safe percutaneous removal. At this time and with the limitations of a single case report, we cannot fully identify and assess factors that predict a straightforward retrieval. However, it is important to note the filter type in this case, a Günther-Tulip IVC filter, does seem to be amenable to percutaneous retrieval using simple techniques after a prolonged dwell time. Another important factor used to assess ease or possibility of retrieval using simple technique was proper evaluation of the IVC filter and patient's anatomy with preprocedure imaging. Though imaging cannot always demonstrate endothelialization or IVC wall ingrowth, known as IVC filter embedding, it can provide other important information, such as filter tilt, which may predispose to embedding of the retrieval hook into the wall of the IVC. Preprocedure imaging will also assess for thrombus in the IVC filter or IVC, strut penetration, or fracture. This is only a single case study and should not be assumed to represent all cases of long dwell time retrievable IVC filters. However, this does further illustrate the possibility for expeditious and uneventful percutaneous removal. These encouraging findings point to the need of more studies regarding removal of IVC filters with long dwell times in an effort to continue to improve on long-term management of these devices. © 2020 The Authors","Gunther-Tulip IVC filter; IVC filter complications; IVC filter strut penetration; Removal IVC filter; Retrievable inferior vena cava filter","erratum",Erratum,Scopus
"Xie F., Chen Q., Zhou Y., Chen W., Bautista J., Nguyen E.T., Parker R.A., Wu B.U.","Characterization of patients with advanced chronic pancreatitis using natural language processing of radiology reports",2020,"PLoS ONE",7,"10.1371/journal.pone.0236817","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089714505&doi=10.1371%2fjournal.pone.0236817&partnerID=40&md5=2437ad017262eb1c0058f950a18a42c8","Study aim To develop and apply a natural language processing algorithm for characterization of patients diagnosed with chronic pancreatitis in a diverse integrated U.S. healthcare system. Methods Retrospective cohort study including patients initially diagnosed with chronic pancreatitis (CP) within a regional integrated healthcare system between January 1, 2006 and December 31, 2015. Imaging reports from these patients were extracted from the electronic medical record system and split into training, validation and implementation datasets. A natural language processing (NLP) algorithm was first developed through the training dataset to identify specific features (atrophy, calcification, pseudocyst, cyst and main duct dilatation) from free-text radiology reports. The validation dataset was applied to validate the performance by comparing against the manual chart review. The developed algorithm was then applied to the implementation dataset. We classified patients with calcification(s) or ≧2 radiographic features as advanced CP. We compared etiology, comorbid conditions, treatment parameters as well as survival between advanced CP and others diagnosed during the study period. Results 6,346 patients were diagnosed with CP during the study period with 58,085 radiology studies performed. For individual features, NLP yielded sensitivity from 88.7% to 95.3%, specificity from 98.2% to 100.0%. A total of 3,672 patients met cohort inclusion criteria: 1,330 (36.2%) had evidence of advanced CP. Patients with advanced CP had increased frequency of smoking (57.8% vs. 43.0%), diabetes (47.6% vs. 35.9%) and underweight body mass index (6.6% vs. 3.6%), all p<0.001. Mortality from pancreatic cancer was higher in advanced CP (15.3/1,000 person-year vs. 2.8/1,000, p<0.001). Underweight BMI (HR 1.6, 95% CL 1.2, 2.1), smoking (HR 1.4, 95% CL 1.1, 1.7) and diabetes (HR 1.4, 95% CL 1.2, 1.6) were independent risk factors for mortality. Conclusion Patients with advanced CP experienced increased disease-related complications and pancreatic cancer-related mortality. Excess all-cause mortality was driven primarily by potentially modifiable risk factors including malnutrition, smoking and diabetes. © 2020 Xie et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,"adult; aged; all cause mortality; Article; cancer mortality; chronic pancreatitis; clinical assessment; clinical feature; cohort analysis; comorbidity; controlled study; diabetes mellitus; diagnostic accuracy; diagnostic test accuracy study; disease association; female; follow up; hazard ratio; health care planning; human; major clinical study; male; medical record review; mortality rate; mortality risk; natural language processing; predictive value; retrospective study; sensitivity and specificity; smoking; survival analysis; underweight; validation study; body mass; chronic pancreatitis; diabetic complication; diagnostic imaging; image processing; Kaplan Meier method; middle aged; mortality; pancreas; pancreas tumor; pathology; proportional hazards model; risk factor; x-ray computed tomography; Adult; Aged; Body Mass Index; Diabetes Complications; Female; Humans; Image Processing, Computer-Assisted; Kaplan-Meier Estimate; Male; Middle Aged; Natural Language Processing; Pancreas; Pancreatic Neoplasms; Pancreatitis, Chronic; Proportional Hazards Models; Retrospective Studies; Risk Factors; Sensitivity and Specificity; Smoking; Tomography, X-Ray Computed",Article,Scopus
"Datta S., Si Y., Rodriguez L., Shooshan S.E., Demner-Fushman D., Roberts K.","Understanding spatial language in radiology: Representation framework, annotation, and spatial relation extraction from chest X-ray reports using deep learning",2020,"Journal of Biomedical Informatics",17,"10.1016/j.jbi.2020.103473","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087509481&doi=10.1016%2fj.jbi.2020.103473&partnerID=40&md5=8c0ac8533e0fdc95215014812a2abc27","Radiology reports contain a radiologist's interpretations of images, and these images frequently describe spatial relations. Important radiographic findings are mostly described in reference to an anatomical location through spatial prepositions. Such spatial relationships are also linked to various differential diagnoses and often described through uncertainty phrases. Structured representation of this clinically significant spatial information has the potential to be used in a variety of downstream clinical informatics applications. Our focus is to extract these spatial representations from the reports. For this, we first define a representation framework based on the Spatial Role Labeling (SpRL) scheme, which we refer to as Rad-SpRL. In Rad-SpRL, common radiological entities tied to spatial relations are encoded through four spatial roles: TRAJECTOR, LANDMARK, DIAGNOSIS, and HEDGE, all identified in relation to a spatial preposition (or SPATIAL INDICATOR). We annotated a total of 2,000 chest X-ray reports following Rad-SpRL. We then propose a deep learning-based natural language processing (NLP) method involving word and character-level encodings to first extract the SPATIAL INDICATORs followed by identifying the corresponding spatial roles. Specifically, we use a bidirectional long short-term memory (Bi-LSTM) conditional random field (CRF) neural network as the baseline model. Additionally, we incorporate contextualized word representations from pre-trained language models (BERT and XLNet) for extracting the spatial information. We evaluate both gold and predicted SPATIAL INDICATORs to extract the four types of spatial roles. The results are promising, with the highest average F1 measure for SPATIAL INDICATOR extraction being 91.29 (XLNet); the highest average overall F1 measure considering all the four spatial roles being 92.9 using gold INDICATORs (XLNet); and 85.6 using predicted INDICATORs (BERT pre-trained on MIMIC notes). The corpus is available in Mendeley at http://dx.doi.org/10.17632/yhb26hfz8n.1 and https://github.com/krobertslab/datasets/blob/master/Rad-SpRL.xml. © 2020 Elsevier Inc.","Deep learning; NLP; Radiology report; Spatial relations","Diagnosis; Extraction; Gold; Long short-term memory; Natural language processing systems; Radiology; Random processes; X ray radiography; X rays; Anatomical locations; Conditional random field; Differential diagnosis; NAtural language processing; Radiographic findings; Spatial informations; Spatial relationships; Spatial representations; Deep learning; Article; conceptual framework; deep learning; human; information processing; long term memory; natural language processing; nerve cell network; prediction; priority journal; radiology; short term memory; thorax radiography; language; X ray; Deep Learning; Language; Natural Language Processing; Radiology; X-Rays",Article,Scopus
"Fritz B., Marbach G., Civardi F., Fucentese S.F., Pfirrmann C.W.A.","Deep convolutional neural network-based detection of meniscus tears: comparison with radiologists and surgery as standard of reference",2020,"Skeletal Radiology",32,"10.1007/s00256-020-03410-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081967056&doi=10.1007%2fs00256-020-03410-2&partnerID=40&md5=b3128b6db234e66702a2d43b5d0327e6","Objective: To clinically validate a fully automated deep convolutional neural network (DCNN) for detection of surgically proven meniscus tears. Materials and methods: One hundred consecutive patients were retrospectively included, who underwent knee MRI and knee arthroscopy in our institution. All MRI were evaluated for medial and lateral meniscus tears by two musculoskeletal radiologists independently and by DCNN. Included patients were not part of the training set of the DCNN. Surgical reports served as the standard of reference. Statistics included sensitivity, specificity, accuracy, ROC curve analysis, and kappa statistics. Results: Fifty-seven percent (57/100) of patients had a tear of the medial and 24% (24/100) of the lateral meniscus, including 12% (12/100) with a tear of both menisci. For medial meniscus tear detection, sensitivity, specificity, and accuracy were for reader 1: 93%, 91%, and 92%, for reader 2: 96%, 86%, and 92%, and for the DCNN: 84%, 88%, and 86%. For lateral meniscus tear detection, sensitivity, specificity, and accuracy were for reader 1: 71%, 95%, and 89%, for reader 2: 67%, 99%, and 91%, and for the DCNN: 58%, 92%, and 84%. Sensitivity for medial meniscus tears was significantly different between reader 2 and the DCNN (p = 0.039), and no significant differences existed for all other comparisons (all p ≥ 0.092). The AUC-ROC of the DCNN was 0.882, 0.781, and 0.961 for detection of medial, lateral, and overall meniscus tear. Inter-reader agreement was very good for the medial (kappa = 0.876) and good for the lateral meniscus (kappa = 0.741). Conclusion: DCNN-based meniscus tear detection can be performed in a fully automated manner with a similar specificity but a lower sensitivity in comparison with musculoskeletal radiologists. © 2020, The Author(s).","Artificial intelligence; Data accuracy; Magnetic resonance imaging; Neural networks (computer); Tibial meniscus injuries","adolescent; adult; aged; Article; clinical assessment; clinical evaluation; convolutional neural network; deep learning; diagnostic accuracy; diagnostic test accuracy study; female; human; image processing; intermethod comparison; knee arthroscopy; knee meniscus rupture; knee pain; major clinical study; male; nuclear magnetic resonance imaging; priority journal; radiologist; receiver operating characteristic; retrospective study; sensitivity and specificity; arthroscopy; clinical competence; comparative study; diagnostic imaging; knee meniscus rupture; middle aged; standard; Adolescent; Adult; Aged; Arthroscopy; Clinical Competence; Female; Humans; Magnetic Resonance Imaging; Male; Middle Aged; Neural Networks, Computer; Radiologists; Reference Standards; Retrospective Studies; Sensitivity and Specificity; Tibial Meniscus Injuries",Article,Scopus
"Nobel J.M., Puts S., Bakers F.C.H., Robben S.G.F., Dekker A.L.A.J.","Natural Language Processing in Dutch Free Text Radiology Reports: Challenges in a Small Language Area Staging Pulmonary Oncology",2020,"Journal of Digital Imaging",13,"10.1007/s10278-020-00327-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079768060&doi=10.1007%2fs10278-020-00327-z&partnerID=40&md5=806ed0f6a4ee8ecba09553cf513e2ace","Reports are the standard way of communication between the radiologist and the referring clinician. Efforts are made to improve this communication by, for instance, introducing standardization and structured reporting. Natural Language Processing (NLP) is another promising tool which can improve and enhance the radiological report by processing free text. NLP as such adds structure to the report and exposes the information, which in turn can be used for further analysis. This paper describes pre-processing and processing steps and highlights important challenges to overcome in order to successfully implement a free text mining algorithm using NLP tools and machine learning in a small language area, like Dutch. A rule-based algorithm was constructed to classify T-stage of pulmonary oncology from the original free text radiological report, based on the items tumor size, presence and involvement according to the 8th TNM classification system. PyContextNLP, spaCy and regular expressions were used as tools to extract the correct information and process the free text. Overall accuracy of the algorithm for evaluating T-stage was 0,83 in the training set and 0,87 in the validation set, which shows that the approach in this pilot study is promising. Future research with larger datasets and external validation is needed to be able to introduce more machine learning approaches and perhaps to reduce required input efforts of domain-specific knowledge. However, a hybrid NLP approach will probably achieve the best results. © 2020, Society for Imaging Informatics in Medicine.","Classification system; Free text; Machine learning; Natural language processing; Radiology; Reporting","Learning algorithms; Learning systems; Machine learning; Object oriented programming; Oncology; Radiation; Radiology; Text mining; Classification system; Domain-specific knowledge; Free texts; Machine learning approaches; NAtural language processing; Reporting; Rule based algorithms; Structured reporting; Natural language processing systems; algorithm; article; cancer size; cancer staging; human; human experiment; machine learning; mining; natural language processing; pilot study; radiology; data mining; machine learning; Data Mining; Machine Learning; Natural Language Processing; Pilot Projects; Radiology",Article,Scopus
"Sugimoto K., Takeda T., Wada S., Yamahata A., Konishi S., Manabe S., Matsumura Y.","End-to-end approach for structuring radiology reports",2020,"Studies in Health Technology and Informatics",,"10.3233/SHTI200151","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086942509&doi=10.3233%2fSHTI200151&partnerID=40&md5=30063e91153629d5518af7ddeeeeacd0","Radiology reports include various types of clinical information that are used for patient care. Reports are also expected to have secondary uses (e.g., clinical research and the development of decision support systems). For secondary use, it is necessary to extract information from the report and organize it in a structured format. Our goal is to build an application to transform radiology reports written in a free-text form into a structured format. To this end, we propose an end-to-end method that consists of three elements. First, we built a neural network model to extract clinical information from the reports. We experimented on a dataset of chest X-ray reports. Second, we transformed the extracted information into a structured format. Finally, we built a tool that enabled the transformation of terms in reports to standard forms. Through our end-to-end method, we could obtain a structured radiology dataset that was easy to access for secondary use. © 2020 European Federation for Medical Informatics (EFMI) and IOS Press.","Information Extraction; Natural Language Processing; Radiology Report","Clinical research; Decision support systems; Medical informatics; Radiation; Chest x-rays; Clinical information; Extract informations; Free texts; Neural network model; Patient care; Radiology reports; Secondary use; Radiology; artificial neural network; conference paper; controlled study; extraction; human; natural language processing; thorax radiography; radiology; radiology information system; research; software; writing; Humans; Natural Language Processing; Neural Networks, Computer; Radiology; Radiology Information Systems; Research Report; Software; Writing",Conference Paper,Scopus
"Dhrangadhariya A., Millius S., Thouly C., Rizk B., Fournier D., Müller H., Brat H.","Automating quality control for structured standardized radiology reports using text analysis",2020,"Studies in Health Technology and Informatics",,"10.3233/SHTI200122","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086936490&doi=10.3233%2fSHTI200122&partnerID=40&md5=605fb1a7ce0f700b2e5cbc18ee49f409","Radiology reports describe the findings of a radiologist in an imaging examination, produced for another clinician in order to answer to a clinical indication. Sometimes, the report does not fully answer the question asked, despite guidelines for the radiologist. In this article, a system that controls the quality of reports automatically is described. It notably maps the free text onto MeSH terms and checks if the anatomy and disease terms match in the indication and conclusion of a report. The agreement between manual checks of experienced radiologists and the system is high with automatic checks requiring only a fraction of time. Being able to quality control all reports has the potential to improve report quality and thus limit misunderstandings, loosing time for requesting more information and possibly avoid medical mistakes. © 2020 European Federation for Medical Informatics (EFMI) and IOS Press.","Quality Control; Radiology Reports; Text Analysis","Medical informatics; Radiation; Radiology; Free texts; MeSH terms; Radiology reports; Text analysis; Quality control; human; quality control; radiologist; radiology information system; research; Humans; Quality Control; Radiologists; Radiology Information Systems; Research Report",Conference Paper,Scopus
"Ong C.J., Orfanoudaki A., Zhang R., Caprasse F.P.M., Hutch M., Ma L., Fard D., Balogun O., Miller M.I., Minnig M., Saglam H., Prescott B., Greer D.M., Smirnakis S., Bertsimas D.","Machine learning and natural language processing methods to identify ischemic stroke, acuity and location from radiology reports",2020,"PLoS ONE",43,"10.1371/journal.pone.0234908","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086752555&doi=10.1371%2fjournal.pone.0234908&partnerID=40&md5=d61325a639d643eab6f9de4de72f4eff","Accurate, automated extraction of clinical stroke information from unstructured text has several important applications. ICD-9/10 codes can misclassify ischemic stroke events and do not distinguish acuity or location. Expeditious, accurate data extraction could provide considerable improvement in identifying stroke in large datasets, triaging critical clinical reports, and quality improvement efforts. In this study, we developed and report a comprehensive framework studying the performance of simple and complex stroke-specific Natural Language Processing (NLP) and Machine Learning (ML) methods to determine presence, location, and acuity of ischemic stroke from radiographic text. We collected 60,564 Computed Tomography and Magnetic Resonance Imaging Radiology reports from 17,864 patients from two large academic medical centers. We used standard techniques to featurize unstructured text and developed neurovascular specific word GloVe embeddings. We trained various binary classification algorithms to identify stroke presence, location, and acuity using 75% of 1,359 expert-labeled reports. We validated our methods internally on the remaining 25% of reports and externally on 500 radiology reports from an entirely separate academic institution. In our internal population, GloVe word embeddings paired with deep learning (Recurrent Neural Networks) had the best discrimination of all methods for our three tasks (AUCs of 0.96, 0.98, 0.93 respectively). Simpler NLP approaches (Bag of Words) performed best with interpretable algorithms (Logistic Regression) for identifying ischemic stroke (AUC of 0.95), MCA location (AUC 0.96), and acuity (AUC of 0.90). Similarly, GloVe and Recurrent Neural Networks (AUC 0.92, 0.89, 0.93) generalized better in our external test set than BOW and Logistic Regression for stroke presence, location and acuity, respectively (AUC 0.89, 0.86, 0.80). Our study demonstrates a comprehensive assessment of NLP techniques for unstructured radiographic text. Our findings are suggestive that NLP/ML methods can be used to discriminate stroke features from large data cohorts for both clinical and research-related investigations. © 2020 Public Library of Science. All rights reserved.",,"accuracy; algorithm; apparent diffusion coefficient; area under the curve; Article; artificial intelligence; automation; brain ischemia; classification algorithm; controlled study; deep learning; health care quality; human; ICD-10; ICD-9; incidental finding; interrater reliability; linguistics; logistic regression analysis; machine learning; magnetic resonance angiography; major clinical study; middle cerebral artery; natural language processing; nuclear magnetic resonance imaging; radiodiagnosis; recurrent neural network; x-ray computed tomography; automatic speech recognition; brain ischemia; cerebrovascular accident; diagnostic imaging; image processing; patient acuity; procedures; Brain Ischemia; Humans; Image Processing, Computer-Assisted; Machine Learning; Patient Acuity; Speech Recognition Software; Stroke",Article,Scopus
"Sohail S.","Radiology of COVID-19 - Imaging the pulmonary damage",2020,"Journal of the Pakistan Medical Association",2,"10.5455/JPMA.21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086297604&doi=10.5455%2fJPMA.21&partnerID=40&md5=75ec6fe293081ac8b22a996823c05ee9","A large part of the world is presently in the grip of the coronavirus disease (COVID-19) by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2 virus), declared a pandemic in March 2020. This document is a brief commentary of the imaging modalities used in the screening, diagnosis and management of COVID-19 pneumonia. Chest x-rays, especially portable, still form a part of majority of official guidelines, with reports of the suggestive radiologic features. The potential of CT scan and ultrasound is also realised, with earlier detection rate. Typical radiologic findings of bilateral, asymmetrical, crazy-paved ground glass opacification, consolidation, reverse halo sign, opacities, progressing to fibrosis are well described for both the X-ray and CT scan. Atypical findings include airway changes, pleural effusion, pulmonary nodules and acute pulmonary embolism. Absence of lymphadenopathy, pleural effusion and pneumothorax is notable. The role of portable lung ultrasound, reported to be useful in emergency, is yet to be established in the guidelines. Disinfection of the equipment is a major concern. Governmental guidelines still advocate X-ray despite professional societies increasingly recommending CT scan. © 2020 Pakistan Medical Association. All rights reserved.","Artificial intelligence; Chest X-ray; COVID-19; CT scan; Ground glass opacification; Radiology; Sub-pleural consolidation; Ultrasound","Article; community acquired pneumonia; computer assisted tomography; coronavirus disease 2019; diagnostic value; disease severity; echography; human; interstitial pneumonia; lung embolism; lung fibrosis; lung injury; lung nodule; lymphadenopathy; pleura effusion; pneumothorax; radiodiagnosis; sensitivity and specificity; thorax radiography; virus pneumonia; Betacoronavirus; computer assisted diagnosis; coronavirus disease 2019; Coronavirus infection; diagnostic imaging; lung; pandemic; pathology; Severe acute respiratory syndrome coronavirus 2; thorax radiography; virus pneumonia; x-ray computed tomography; Betacoronavirus; Coronavirus Infections; Humans; Lung; Pandemics; Pneumonia, Viral; Radiographic Image Interpretation, Computer-Assisted; Radiography, Thoracic; Tomography, X-Ray Computed; Ultrasonography",Article,Scopus
"Sorin V., Barash Y., Konen E., Klang E.","Deep Learning for Natural Language Processing in Radiology—Fundamentals and a Systematic Review",2020,"Journal of the American College of Radiology",86,"10.1016/j.jacr.2019.12.026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079519854&doi=10.1016%2fj.jacr.2019.12.026&partnerID=40&md5=309ee5d1701965029d04de748510a999","Purpose: Natural language processing (NLP) enables conversion of free text into structured data. Recent innovations in deep learning technology provide improved NLP performance. We aimed to survey deep learning NLP fundamentals and review radiology-related research. Methods: This systematic review was reported according to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines. We searched for deep learning NLP radiology studies published up to September 2019. MEDLINE, Scopus, and Google Scholar were used as search databases. Results: Ten relevant studies published between 2018 and 2019 were identified. Deep learning models applied for NLP in radiology are convolutional neural networks, recurrent neural networks, long short-term memory networks, and attention networks. Deep learning NLP applications in radiology include flagging of diagnoses such as pulmonary embolisms and fractures, labeling follow-up recommendations, and automatic selection of imaging protocols. Deep learning NLP models perform as well as or better than traditional NLP models. Conclusion: Research and use of deep learning NLP in radiology is increasing. Acquaintance with this technology can help prepare radiologists for the coming changes in their field. © 2020 American College of Radiology","Convolutional neural networks; deep learning; machine learning; natural language processing; radiology","Article; convolutional neural network; deep learning; follow up; fracture; human; long short term memory network; long term memory; lung embolism; Medline; natural language processing; Preferred Reporting Items for Systematic Reviews and Meta-Analyses; radiology; recurrent neural network; Scopus; short term memory; systematic review",Article,Scopus
"Weikert T., Nesic I., Cyriac J., Bremerich J., Sauter A.W., Sommer G., Stieltjes B.","Towards automated generation of curated datasets in radiology: Application of natural language processing to unstructured reports exemplified on CT for pulmonary embolism",2020,"European Journal of Radiology",8,"10.1016/j.ejrad.2020.108862","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080872886&doi=10.1016%2fj.ejrad.2020.108862&partnerID=40&md5=8c4535b94eb45de3db6d1a88642f683d","Purpose: To design and evaluate a self-trainable natural language processing (NLP)-based procedure to classify unstructured radiology reports. The method enabling the generation of curated datasets is exemplified on CT pulmonary angiogram (CTPA) reports. Method: We extracted the impressions of CTPA reports created at our institution from 2016 to 2018 (n = 4397; language: German). The status (pulmonary embolism: yes/no) was manually labelled for all exams. Data from 2016/2017 (n = 2801) served as a ground truth to train three NLP architectures that only require a subset of reference datasets for training to be operative. The three architectures were as follows: a convolutional neural network (CNN), a support vector machine (SVM) and a random forest (RF) classifier. Impressions of 2018 (n = 1377) were kept aside and used for general performance measurements. Furthermore, we investigated the dependence of classification performance on the amount of training data with multiple simulations. Results: The classification performance of all three models was excellent (accuracies: 97 %–99 %; F1 scores 0.88–0.97; AUCs: 0.993–0.997). Highest accuracy was reached by the CNN with 99.1 % (95 % CI 98.5–99.6 %). Training with 470 labelled impressions was sufficient to reach an accuracy of > 93 % with all three NLP architectures. Conclusion: Our NLP-based approaches allow for an automated and highly accurate retrospective classification of CTPA reports with manageable effort solely using unstructured impression sections. We demonstrated that this approach is useful for the classification of radiology reports not written in English. Moreover, excellent classification performance is achieved at relatively small training set sizes. © 2020 Elsevier B.V.","Classification; Computed tomography angiography; Data curation; Natural language processing; Pulmonary embolism","aged; Article; computed tomographic angiography; controlled study; convolutional neural network; diagnostic accuracy; disease classification; female; human; image analysis; image processing; lung embolism; major clinical study; male; natural language processing; predictive value; priority journal; random forest; receiver operating characteristic; retrospective study; sensitivity and specificity; support vector machine; area under the curve; computer assisted diagnosis; diagnostic imaging; information processing; lung embolism; procedures; pulmonary artery; x-ray computed tomography; Aged; Area Under Curve; Datasets as Topic; Female; Humans; Image Interpretation, Computer-Assisted; Male; Natural Language Processing; Neural Networks, Computer; Pulmonary Artery; Pulmonary Embolism; Retrospective Studies; Support Vector Machine; Tomography, X-Ray Computed",Article,Scopus
"Salimin L., Barber F., Limbada M., Khalil O., Williams S.","Acute ICH in patients identified as being treated with either warfarin or direct-acting oral anticoagulant agents (DOACs) from a radiology perspective; a cross-sectional observational of 2359 emergency CT head studies",2020,"Clinical Radiology",6,"10.1016/j.crad.2019.11.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076957782&doi=10.1016%2fj.crad.2019.11.007&partnerID=40&md5=83f90cc9159b91dd97559707170c6c07","AIM: To determine and compare the rates of acute intracranial haemorrhage (ICH) in emergency computed tomography (CT) head studies performed on patients treated with either warfarin or a direct-acting oral anticoagulant agent (DOAC) in a real-world acute setting from a radiology service perspective. METHOD: A retrospective automated search was undertaken via the hospital's radiology information system (RIS) for emergency CT head studies performed over a 2-year period where the clinical details indicated treatment with warfarin or a DOAC. The report of each scan was reviewed for the presence of unequivocal ICH. Duplicate and follow-up scans were excluded. Other parameters (trauma history and time of scan) were also reviewed. RESULTS: Following exclusions, 2,359 cases were eligible for analysis; 1,822 patients were treated with warfarin and 537 treated with DOACs. One hundred and nineteen CT heads, of which 104 were treated with warfarin and 15 treated with DOACs, were positive for various types of ICH. The positive rate for ICH was lower in the DOACs group than the warfarin group; 2.7% (number needed to scan: 37) versus 5.7% (number needed to scan: 17.5; p=0.0067). This is also true in a cohort of patients who had traumatic head injury; 2.14% (number needed to scan: 46.7) versus 5.80% (number needed to scan: 17.2; p=0.02). CONCLUSION: The present study has shown a lower rate of ICH in patients treated with DOACs compared to those treated with warfarin in an acute setting. A similar trend is demonstrated in a cohort of patients with a history of traumatic head injury. © 2019",,"apixaban; dabigatran; edoxaban; rivaroxaban; warfarin; anticoagulant agent; blood clotting factor 10a inhibitor; warfarin; adult; aged; Article; ataxia; brain hemorrhage; computer assisted tomography; emergency care; female; follow up; head injury; human; major clinical study; male; priority journal; retrospective study; sensory dysfunction; speech disorder; treatment indication; very elderly; visual disorder; weakness; brain hemorrhage; comparative study; cross-sectional study; diagnostic imaging; hospital emergency service; middle aged; oral drug administration; procedures; risk factor; x-ray computed tomography; Administration, Oral; Adult; Aged; Aged, 80 and over; Anticoagulants; Cross-Sectional Studies; Emergency Service, Hospital; Factor Xa Inhibitors; Female; Humans; Intracranial Hemorrhages; Male; Middle Aged; Retrospective Studies; Risk Factors; Tomography, X-Ray Computed; Warfarin",Article,Scopus
"Loveymi S., Dezfoulian M.H., Mansoorizadeh M.","Generate Structured Radiology Report from CT Images Using Image Annotation Techniques: Preliminary Results with Liver CT",2020,"Journal of Digital Imaging",6,"10.1007/s10278-019-00298-w","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075238483&doi=10.1007%2fs10278-019-00298-w&partnerID=40&md5=f17f2438a56b204615081fa5df9304ac","A medical annotation system for radiology images extracts clinically useful information from the images, allowing the machines to infer useful abstract semantics and become capable of automatic reasoning and making diagnostic decision. It also supplies human-interpretable explanation for the images. We have implemented a computerized framework that, given a liver CT image, predicts radiological annotations with high accuracy, in order to generate a structured report, which includes predicting very specific high-level semantic content. Each report of a liver CT image is related to different inhomogeneous parts like the liver, lesion, and vessel. We put forward a claim that gathering all kinds of features is not suitable for filling all parts of the report. As a matter of fact, for each group of annotations, one should find and extract the best feature that results in the best answers for that specific annotation. To this end, the main challenge is discovering the relationships between these specific semantic concepts and their association with the low-level image features. Our framework was implemented by combining a set of the state-of-the-art low-level imaging features. In addition, we propose a novel feature (DLBP (deep local binary pattern)) based on LBP that incorporates multi-slice analysis in CT images and further improves the performance. In order to model our annotation system, two methods were used, namely multi-class support vector machine (SVM) and random subspace (RS) which is an ensemble learning method. Applying this representation leads to a high prediction accuracy of 93.1% despite its relatively low dimension in comparison with the existing works. © 2019, Society for Imaging Informatics in Medicine.","Computed tomography; Deep local binary pattern; Liver CT images; Medical image annotation","Diagnosis; Image analysis; Image annotation; Image enhancement; Medical imaging; Medical information systems; Radiation; Radiology; Semantics; Support vector machines; Automatic reasoning; Diagnostic decisions; High level semantics; Liver CT; Local binary patterns; Low-level image features; Multi-class support vector machines; Prediction accuracy; Computerized tomography; diagnostic imaging; human; information processing; liver; radiology; semantics; x-ray computed tomography; Data Curation; Humans; Liver; Radiology; Semantics; Tomography, X-Ray Computed",Article,Scopus
"Lou R., Lalevic D., Chambers C., Zafar H.M., Cook T.S.","Automated Detection of Radiology Reports that Require Follow-up Imaging Using Natural Language Processing Feature Engineering and Machine Learning Classification",2020,"Journal of Digital Imaging",31,"10.1007/s10278-019-00271-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072225850&doi=10.1007%2fs10278-019-00271-7&partnerID=40&md5=02560d92e4e8e4a1bc09f4c56e4f4c1d","While radiologists regularly issue follow-up recommendations, our preliminary research has shown that anywhere from 35 to 50% of patients who receive follow-up recommendations for findings of possible cancer on abdominopelvic imaging do not return for follow-up. As such, they remain at risk for adverse outcomes related to missed or delayed cancer diagnosis. In this study, we develop an algorithm to automatically detect free text radiology reports that have a follow-up recommendation using natural language processing (NLP) techniques and machine learning models. The data set used in this study consists of 6000 free text reports from the author’s institution. NLP techniques are used to engineer 1500 features, which include the most informative unigrams, bigrams, and trigrams in the training corpus after performing tokenization and Porter stemming. On this data set, we train naive Bayes, decision tree, and maximum entropy models. The decision tree model, with an F1 score of 0.458 and accuracy of 0.862, outperforms both the naive Bayes (F1 score of 0.381) and maximum entropy (F1 score of 0.387) models. The models were analyzed to determine predictive features, with term frequency of n-grams such as “renal neoplasm” and “evalu with enhanc” being most predictive of a follow-up recommendation. Key to maximizing performance was feature engineering that extracts predictive information and appropriate selection of machine learning algorithms based on the feature set. © 2019, Society for Imaging Informatics in Medicine.","Artificial intelligence; Binary classification; Follow-up; Machine learning; Natural language processing; Structured reporting","Artificial intelligence; Classifiers; Decision trees; Diagnosis; Diseases; Entropy; Feature extraction; Learning systems; Machine learning; Natural language processing systems; Personnel training; Radiation; Radiology; Trees (mathematics); Binary classification; Decision tree modeling; Follow up; Machine learning classification; Machine learning models; NAtural language processing; Predictive information; Structured reporting; Learning algorithms; Bayes theorem; follow up; human; machine learning; natural language processing; radiology; Bayes Theorem; Follow-Up Studies; Humans; Machine Learning; Natural Language Processing; Radiology",Article,Scopus
"Dalal S., Hombal V., Weng W.-H., Mankovich G., Mabotuwana T., Hall C.S., Fuller J., III, Lehnert B.E., Gunn M.L.","Determining Follow-Up Imaging Study Using Radiology Reports",2020,"Journal of Digital Imaging",12,"10.1007/s10278-019-00260-w","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071505601&doi=10.1007%2fs10278-019-00260-w&partnerID=40&md5=34e81dd12145b87c6c5154647d6fbcd8","Radiology reports often contain follow-up imaging recommendations. Failure to comply with these recommendations in a timely manner can lead to delayed treatment, poor patient outcomes, complications, unnecessary testing, lost revenue, and legal liability. The objective of this study was to develop a scalable approach to automatically identify the completion of a follow-up imaging study recommended by a radiologist in a preceding report. We selected imaging-reports containing 559 follow-up imaging recommendations and all subsequent reports from a multi-hospital academic practice. Three radiologists identified appropriate follow-up examinations among the subsequent reports for the same patient, if any, to establish a ground-truth dataset. We then trained an Extremely Randomized Trees that uses recommendation attributes, study meta-data and text similarity of the radiology reports to determine the most likely follow-up examination for a preceding recommendation. Pairwise inter-annotator F-score ranged from 0.853 to 0.868; the corresponding F-score of the classifier in identifying follow-up exams was 0.807. Our study describes a methodology to automatically determine the most likely follow-up exam after a follow-up imaging recommendation. The accuracy of the algorithm suggests that automated methods can be integrated into a follow-up management application to improve adherence to follow-up imaging recommendations. Radiology administrators could use such a system to monitor follow-up compliance rates and proactively send reminders to primary care providers and/or patients to improve adherence. © 2019, Society for Imaging Informatics in Medicine.","Follow-up studies; Medical informatics applications; Natural language processing; Radiology; Supervised machine learning","Learning algorithms; Medical informatics; Natural language processing systems; Patient treatment; Radiation; Supervised learning; Trees (mathematics); Follow-up Studies; Ground-truth dataset; Management applications; Medical informatics applications; NAtural language processing; Primary-care providers; Scalable approach; Supervised machine learning; Radiology; administrative personnel; adult; article; case report; classifier; clinical article; female; follow up; human; male; medical informatics; metadata; natural language processing; primary medical care; radiologist; radiology; randomized controlled trial; supervised machine learning; algorithm; diagnostic imaging; follow up; radiology information system; Algorithms; Diagnostic Imaging; Follow-Up Studies; Humans; Radiology; Radiology Information Systems",Article,Scopus
"Wood D.A., Lynch J., Kafiabadi S., Guilhem E., Busaidi A.A., Montvila A., Varsavsky T., Siddiqui J., Gadapa N., Townend M., Kiik M., Patel K., Barker G., Ourselin S., Cole J.H., Booth T.C.","Automated Labelling using an Attention model for Radiology reports of MRI scans (ALARM)",2020,"Proceedings of Machine Learning Research",13,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163054994&partnerID=40&md5=c8b4976d31ccba2c5678b194f2854748","Labelling large datasets for training high-capacity neural networks is a major obstacle to the development of deep learning-based medical imaging applications. Here we present a transformer-based network for magnetic resonance imaging (MRI) radiology report classification which automates this task by assigning image labels on the basis of free-text expert radiology reports. Our model’s performance is comparable to that of an expert radiologist, and better than that of an expert physician, demonstrating the feasibility of this approach. We make our code available for researchers to label their own MRI datasets for medical imaging applications. © 2020 D.A. Wood1 et al.",,"Deep learning; Large dataset; Medical imaging; Radiology; Text processing; Attention model; Automated labeling; Free texts; High capacity; High-capacity; Imaging applications; Labelings; Large datasets; Neural-networks; Radiology reports; Magnetic resonance imaging",Conference Paper,Scopus
"Sahl A., Hasan S.","Radiology Reports Automated Annotation Performance: Rule-Based Machine Learning Vs Deep Learning",2020,"IET Conference Proceedings",1,"10.1049/icp.2021.0893","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153945572&doi=10.1049%2ficp.2021.0893&partnerID=40&md5=d8294b4d8171e15d4663934cd0b1308e","Currently the availability of medical images data itself is not a challenge, but the acquisition of relevant annotations/labelling for these images is. An unsolved challenge in medical image analysis and its related radiology reports is to turn the radiology reports into an accurate annotations or structured labels in an automated manner using Natural Language Processing (NLP). Traditional rule-based Machine Learning (ML) and Deep Learning (DL) algorithms are two approaches which were used in the extraction and annotation of radiology text reports. This paper provides a comparison of the performance of traditional rule-based machine learning to that of using deep learning algorithms in the extraction and annotation of radiology text reports using natural language processing (NLP). It presents an accurate analysis of the two discussed approaches and supports such with critical evidence related to the effects both approaches have on the issue of radiological reporting. According to the evaluation of the obtained data, the research concludes that Deep Learning (DL) models perform with higher efficiency than both the TML and validated NLP classifiers in terms of accuracy in extracting the required text information from the free-text radiology reports. © 2020 The Institution of Engineering and Technology.","Annotation; Deep learning (DL); Natural Language Processing (NLP); Radiology Reports; Traditional machine learning (TML)","Classification (of information); Deep learning; Extraction; Learning algorithms; Learning systems; Medical imaging; Natural language processing systems; Radiation; Annotation; Annotation performance; Deep learning; Language processing; Machine-learning; Natural language processing; Natural languages; Radiology reports; Rule based; Traditional machine learning; Radiology",Conference Paper,Scopus
"Datta S., Godfrey-Stovall J., Roberts K.","RadLex Normalization in Radiology Reports",2020,"AMIA ... Annual Symposium proceedings. AMIA Symposium",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105330787&partnerID=40&md5=5c457171383f0174ec880d82bdf96411","Radiology reports have been widely used for extraction of various clinically significant information about patients' imaging studies. However, limited research has focused on standardizing the entities to a common radiology-specific vocabulary. Further, no study to date has attempted to leverage RadLex for standardization. In this paper, we aim to normalize a diverse set of radiological entities to RadLex terms. We manually construct a normalization corpus by annotating entities from three types of reports. This contains 1706 entity mentions. We propose two deep learning-based NLP methods based on a pre-trained language model (BERT) for automatic normalization. First, we employ BM25 to retrieve candidate concepts for the BERT-based models (re-ranker and span detector) to predict the normalized concept. The results are promising, with the best accuracy (78.44%) obtained by the span detector. Additionally, we discuss the challenges involved in corpus construction and propose new RadLex terms. ©2020 AMIA - All rights reserved.",,"controlled vocabulary; diagnostic imaging; documentation; human; natural language processing; procedures; radiology; radiology information system; Unified Medical Language System; Deep Learning; Diagnostic Imaging; Documentation; Humans; Natural Language Processing; Radiology; Radiology Information Systems; Unified Medical Language System; Vocabulary, Controlled",Article,Scopus
"Grivas A., Alex B., Grover C., Tobin R., Whiteley W.","Not a cute stroke: Analysis of rule- And neural network-based information extraction systems for brain radiology reports",2020,"EMNLP 2020 - 11th International Workshop on Health Text Mining and Information Analysis, LOUHI 2020, Proceedings of the Workshop",12,"10.18653/v1/2020.louhi-1.4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102829357&doi=10.18653%2fv1%2f2020.louhi-1.4&partnerID=40&md5=347873dc79db81dbe3bd0b176c6f759b","We present an in-depth comparison of three clinical information extraction (IE) systems designed to perform entity recognition and negation detection on brain imaging reports: EdIE-R, a bespoke rule-based system, and two neural network models, EdIE-BiLSTM and EdIE-BERT, both multi-task learning models with a BiLSTM and BERT encoder respectively. We compare our models both on an in-sample and an out-of-sample dataset containing mentions of stroke findings and draw on our error analysis to suggest improvements for effective annotation when building clinical NLP models for a new domain. Our analysis finds that our rule-based system outperforms the neural models on both datasets and seems to generalise to the out-of-sample dataset. On the other hand, the neural models do not generalise negation to the out-of-sample dataset, despite metrics on the in-sample dataset suggesting otherwise. © 2020 Association for Computational Linguistics",,"Computational linguistics; Information retrieval; Information retrieval systems; Learning systems; Natural language processing systems; Entity recognition; Information extraction systems; Network-based; Neural modelling; Neural network model; Neural-networks; Radiology reports; Rules based systems; Sample dataset; Stroke analysis; Brain mapping",Conference Paper,Scopus
"Chen Z., Song Y., Chang T.-H., Wan X.","Generating radiology reports via memory-driven transformer",2020,"EMNLP 2020 - 2020 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference",95,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101392842&partnerID=40&md5=ad1e6319662f331b1f854775447c3554","Medical imaging is frequently used in clinical practice and trials for diagnosis and treatment. Writing imaging reports is time-consuming and can be error-prone for inexperienced radiologists. Therefore, automatically generating radiology reports is highly desired to lighten the workload of radiologists and accordingly promote clinical automation, which is an essential task to apply artificial intelligence to the medical domain. In this paper, we propose to generate radiology reports with memory-driven Transformer, where a relational memory is designed to record key information of the generation process and a memory-driven conditional layer normalization is applied to incorporating the memory into the decoder of Transformer. Experimental results on two prevailing radiology report datasets, IU X-Ray and MIMIC-CXR, show that our proposed approach outperforms previous models with respect to both language generation metrics and clinical evaluations. Particularly, this is the first work reporting the generation results on MIMIC-CXR to the best of our knowledge. Further analyses also demonstrate that our approach is able to generate long reports with necessary medical terms as well as meaningful image-text attention mappings. © 2020 Association for Computational Linguistics",,"Computational linguistics; Medical imaging; Radiation; Radiology; Clinical automation; Clinical practices; Clinical trial; Error prones; Generation process; Language generation; Medical domains; Normalisation; Radiology reports; Relational memory; Diagnosis",Conference Paper,Scopus
"Smit A., Jain S., Rajpurkar P., Pareek A., Ng A.Y., Lungren M.P.","CheXbert: Combining automatic labelers and expert annotations for accurate radiology report labeling using BERT",2020,"EMNLP 2020 - 2020 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference",43,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100854895&partnerID=40&md5=e025102487e0feb1337a57d844b793ad","The extraction of labels from radiology text reports enables large-scale training of medical imaging models. Existing approaches to report labeling typically rely either on sophisticated feature engineering based on medical domain knowledge or manual annotations by experts. In this work, we introduce a BERT-based approach to medical image report labeling that exploits both the scale of available rule-based systems and the quality of expert annotations. We demonstrate superior performance of a biomedically pretrained BERT model first trained on annotations of a rule-based labeler and then fine-tuned on a small set of expert annotations augmented with automated backtranslation. We find that our final model, CheXbert, is able to outperform the previous best rule-based labeler with statistical significance, setting a new SOTA for report labeling on one of the largest datasets of chest x-rays. © 2020 Association for Computational Linguistics",,"Computational linguistics; Medical imaging; Radiation; Domain knowledge; Expert annotations; Feature engineerings; Imaging modeling; Knowledge annotations; Labelings; Large-scales; Medical domains; Radiology reports; Rule based; Radiology",Conference Paper,Scopus
"Wu J.T., Syed A., Ahmad H., Pillai A., Gur Y., Jadhav A., Gruhl D., Kato L., Moradi M., Syeda-Mahmood T.","AI Accelerated Human-in-the-loop Structuring of Radiology Reports",2020,"AMIA ... Annual Symposium proceedings. AMIA Symposium",11,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098387658&partnerID=40&md5=090a095e0fa1eeacf94bda1ded6629e9","Rule-based Natural Language Processing (NLP) pipelines depend on robust domain knowledge. Given the long tail of important terminology in radiology reports, it is not uncommon for standard approaches to miss items critical for understanding the image. AI techniques can accelerate the concept expansion and phrasal grouping tasks to efficiently create a domain specific lexicon ontology for structuring reports. Using Chest X-ray (CXR) reports as an example, we demonstrate that with robust vocabulary, even a simple NLP pipeline can extract 83 directly mentioned abnormalities (Ave. recall=93.83%, precision=94.87%) and 47 abnormality/normality descriptions of key anatomies. The richer vocabulary enables identification of additional label mentions in 10 out of 13 labels (compared to baseline methods). Furthermore, it captures expert insight into critical differences between observed and inferred descriptions, and image quality issues in reports. Finally, we show how the CXR ontology can be used to anatomically structure labeled output. ©2020 AMIA - All rights reserved.",,"factual database; human; natural language processing; radiology; research; Databases, Factual; Humans; Natural Language Processing; Radiology; Research Report",Article,Scopus
"Zhang Y., Wang X., Xu Z., Yu Q., Yuille A., Xu D.","When radiology report generation meets knowledge graph",2020,"AAAI 2020 - 34th AAAI Conference on Artificial Intelligence",88,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098369038&partnerID=40&md5=a56455265823fc30aa2daac2091c82d3","Automatic radiology report generation has been an attracting research problem towards computer-aided diagnosis to alleviate the workload of doctors in recent years. Deep learning techniques for natural image captioning are successfully adapted to generating radiology reports. However, radiology image reporting is different from the natural image captioning task in two aspects: 1) the accuracy of positive disease keyword mentions is critical in radiology image reporting in comparison to the equivalent importance of every single word in a natural image caption; 2) the evaluation of reporting quality should focus more on matching the disease keywords and their associated attributes instead of counting the occurrence of N-gram. Based on these concerns, we propose to utilize a pre-constructed graph embedding module (modeled with a graph convolutional neural network) on multiple disease findings to assist the generation of reports in this work. The incorporation of knowledge graph allows for dedicated feature learning for each disease finding and the relationship modeling between them. In addition, we proposed a new evaluation metric for radiology image reporting with the assistance of the same composed graph. Experimental results demonstrate the superior performance of the methods integrated with the proposed graph embedding module on a publicly accessible dataset (IU-RR) of chest radiographs compared with previous approaches using both the conventional evaluation metrics commonly adopted for image captioning and our proposed ones. Copyright 2020, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",,"Computer aided diagnosis; Convolutional neural networks; Deep learning; Embeddings; Knowledge representation; Learning systems; Quality control; Radiology; Chest radiographs; Evaluation metrics; Knowledge graphs; Learning techniques; Publicly accessible; Radiology reports; Relationship model; Research problems; Radiation",Conference Paper,Scopus
"Zhang Y., Merck D., Tsai E.B., Manning C.D., Langlotz C.P.","Optimizing the factual correctness of a summary: A study of summarizing radiology reports",2020,"Proceedings of the Annual Meeting of the Association for Computational Linguistics",68,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098209131&partnerID=40&md5=239266cffc87ad41d8817fd00b377813","Neural abstractive summarization models are able to generate summaries which have high overlap with human references. However, existing models are not optimized for factual correctness, a critical metric in real-world applications. In this work, we develop a general framework where we evaluate the factual correctness of a generated summary by fact-checking it automatically against its reference using an information extraction module. We further propose a training strategy which optimizes a neural summarization model with a factual correctness reward via reinforcement learning. We apply the proposed method to the summarization of radiology reports, where factual correctness is a key requirement. On two separate datasets collected from hospitals, we show via both automatic and human evaluation that the proposed approach substantially improves the factual correctness and overall quality of outputs over a competitive neural summarization system, producing radiology summaries that approach the quality of human-authored ones. © 2020 Association for Computational Linguistics",,"Computational linguistics; Natural language processing systems; Quality control; Radiation; Radiology; Automatic evaluation; Critical metrics; Human evaluation; Overall quality; Radiology reports; Real-world; Reinforcement learnings; Summarization models; Summarization systems; Training strategy; Reinforcement learning",Conference Paper,Scopus
"Datta S., Ulinski M., Godfrey-Stovall J., Khanpara S., Riascos-Castaneda R.F., Roberts K.","Rad-SpatialNet: A frame-based resource for fine-grained spatial relations in radiology reports",2020,"LREC 2020 - 12th International Conference on Language Resources and Evaluation, Conference Proceedings",10,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096527021&partnerID=40&md5=fa5352153ff0c6b5e1c7f11ec197c4f8","This paper proposes a representation framework for encoding spatial language in radiology based on frame semantics. The framework is adopted from the existing SpatialNet representation in the general domain with the aim to generate more accurate representations of spatial language used by radiologists. We describe Rad-SpatialNet in detail along with illustrating the importance of incorporating domain knowledge in understanding the varied linguistic expressions involved in different radiological spatial relations. This work also constructs a corpus of 400 radiology reports of three examination types (chest X-rays, brain MRIs, and babygrams) annotated with fine-grained contextual information according to this schema. Spatial trigger expressions and elements corresponding to a spatial frame are annotated. We apply BERT-based models (BERTBASE and BERTLARGE) to first extract the trigger terms (lexical units for a spatial frame) and then to identify the related frame elements. The results of BERTLARGE are decent, with F1 of 77.89 for spatial trigger extraction and an overall F1 of 81.61 and 66.25 across all frame elements using gold and predicted spatial triggers respectively. This frame-based resource can be used to develop and evaluate more advanced natural language processing (NLP) methods for extracting fine-grained spatial information from radiology text in the future. © European Language Resources Association (ELRA), licensed under CC-BY-NC","Frame semantics; Radiology; Spatial relations","Natural language processing systems; Radiology; Semantics; Contextual information; Domain knowledge; Linguistic expressions; NAtural language processing; Radiology reports; Spatial informations; Spatial language; Spatial relations; Radiation",Conference Paper,Scopus
"Osorno-Castillo K., Fonnegra R.D., Díaz G.M.","Integration of Machine Learning Models in PACS Systems to Support Diagnostic in Radiology Services",2020,"Communications in Computer and Information Science",1,"10.1007/978-3-030-61834-6_20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094124027&doi=10.1007%2f978-3-030-61834-6_20&partnerID=40&md5=eea7a56b7f678770227d7dce9c7c04dd","In recent years, machine learning models have been introduced to solve many problems in medical imaging, such as segmentation, classification, and disease prediction. Unfortunately, most of them are useless for the physician due that they are not available tools that are part of their workflow. At present, Picture Archiving and Communication Systems (PACS) are the standard platforms used in clinical environments to store and transmit electronic images and the reading reports. Therefore, the integration of the automatic analysis tools with these systems is required to allow validation by physicians and the use in clinical and medical research. This paper presents a simple way of adding the use of machine learning models for the automatic analysis of medical images in the radiological workflow using DICOM services provided by open source tools. An implementation case study is also presented, in which a deep learning architecture was trained for classifying chest X-ray images as normal, bacterial pneumonia or viral pneumonia, including in the last case images of COVID-19 patients. © 2020, Springer Nature Switzerland AG.","Deep learning models; DICOM; Medical imaging; PACS integration","Clinical research; Computer aided diagnosis; Deep learning; Medical applications; Medical imaging; Medical problems; Picture archiving and communication systems; Automatic analysis; Automatic analysis tools; Clinical environments; Electronic images; Learning architectures; Machine learning models; Open source tools; Picture archiving and communication systems (PACS); Learning systems",Conference Paper,Scopus
"Putelli L., Gerevini A.E., Lavelli A., Olivato M., Serina I.","Deep learning for classification of radiology reports with a hierarchical schema",2020,"Procedia Computer Science",14,"10.1016/j.procs.2020.08.045","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093362189&doi=10.1016%2fj.procs.2020.08.045&partnerID=40&md5=d70bc15a247af01e3336a4b0e9ff26e9","Radiological reports are a valuable source of textual information, which can be exploited to improve clinical care and to support research. Such information can be extracted and put into a structured form using machine learning techniques. Some of them rely not only on the classification labels but also on the manual annotation of relevant snippets, which is a time consuming job and requires domain experts. In this paper, we apply deep learning techniques and in particular Long Short Term Memory (LSTM) networks to perform such a task relying only on the classification labels. We focus on the classification of chest computed tomography reports in Italian according to a classification schema proposed for this task by the radiologists of Spedali Civili di Brescia. Each report is classified according to such schema using a combination of neural network classifiers. The resulting system is a novel classification system, which we compare to a previous system based on standard machine learning techniques which used annotations of relevant snippets. © 2020 The Authors. Published by Elsevier B.V.","Deep learning; Radiology reports; Text classification","Clinical research; Computerized tomography; Knowledge based systems; Learning systems; Long short-term memory; Classification labels; Classification system; Combination of neural-network; Hierarchical schema; Learning techniques; Machine learning techniques; Standard machines; Textual information; Deep learning",Conference Paper,Scopus
"Schrempf P., Watson H., Mikhael S., Pajak M., Falis M., Lisowska A., Muir K.W., Harris-Birtill D., O’Neil A.Q.","Paying Per-Label Attention for Multi-label Extraction from Radiology Reports",2020,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",5,"10.1007/978-3-030-61166-8_29","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092889547&doi=10.1007%2f978-3-030-61166-8_29&partnerID=40&md5=5570c284a6367d915ab65ba4bf3ca081","Training medical image analysis models requires large amounts of expertly annotated data which is time-consuming and expensive to obtain. Images are often accompanied by free-text radiology reports which are a rich source of information. In this paper, we tackle the automated extraction of structured labels from head CT reports for imaging of suspected stroke patients, using deep learning. Firstly, we propose a set of 31 labels which correspond to radiographic findings (e.g. hyperdensity) and clinical impressions (e.g. haemorrhage) related to neurological abnormalities. Secondly, inspired by previous work, we extend existing state-of-the-art neural network models with a label-dependent attention mechanism. Using this mechanism and simple synthetic data augmentation, we are able to robustly extract many labels with a single model, classified according to the radiologist’s reporting (positive, uncertain, negative). This approach can be used in further research to effectively extract many labels from medical text. © 2020, Springer Nature Switzerland AG.","BERT; NLP; Radiology report labelling","Computer aided instruction; Computerized tomography; Deep learning; Extraction; Medical computing; Radiation; Radiology; Attention mechanisms; Automated extraction; Radiographic findings; Radiology reports; Single models; State of the art; Stroke patients; Synthetic data; Medical imaging",Conference Paper,Scopus
"Liu H., Xu Y., Zhang Z., Wang N., Huang Y., Hu Y., Yang Z., Jiang R., Chen H.","A Natural Language Processing Pipeline of Chinese Free-Text Radiology Reports for Liver Cancer Diagnosis",2020,"IEEE Access",16,"10.1109/ACCESS.2020.3020138","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091312603&doi=10.1109%2fACCESS.2020.3020138&partnerID=40&md5=146adbc4f450342a9a338b0816338a7f","Despite the rapid development of natural language processing (NLP) implementation in electronic medical records (EMRs), Chinese EMRs processing remains challenging due to the limited corpus and specific grammatical characteristics, especially for radiology reports. In this study, we designed an NLP pipeline for the direct extraction of clinically relevant features from Chinese radiology reports, which is the first key step in computer-aided radiologic diagnosis. The pipeline was comprised of named entity recognition, synonyms normalization, and relationship extraction to finally derive the radiological features composed of one or more terms. In named entity recognition, we incorporated lexicon into deep learning model bidirectional long short-term memory-conditional random field (BiLSTM-CRF), and the model finally achieved an F1 score of 93.00%. With the extracted radiological features, least absolute shrinkage and selection operator and machine learning methods (support vector machine, random forest, decision tree, and logistic regression) were used to build the classifiers for liver cancer prediction. For liver cancer diagnosis, random forest had the highest predictive performance in liver cancer diagnosis (F1 score 86.97%, precision 87.71%, and recall 86.25%). This work was a comprehensive NLP study focusing on Chinese radiology reports and the application of NLP in cancer risk prediction. The proposed NLP pipeline for the radiological feature extraction could be easily implemented in other kinds of Chinese clinical texts and other disease predictive tasks. © 2013 IEEE.","BiLSTM-CRF; computer-aided diagnosis; information extraction; Natural language processing; radiology reports","Computer aided diagnosis; Decision trees; Deep learning; Diseases; Extraction; Feature extraction; Learning systems; Logistic regression; Medical computing; Pipeline processing systems; Pipelines; Radiation; Radiology; Random forests; Random processes; Support vector machines; Support vector regression; Conditional random field; Electronic medical records (EMRs); Least absolute shrinkage and selection operators; Machine learning methods; Named entity recognition; NAtural language processing; Predictive performance; Relationship extraction; Natural language processing systems",Article,Scopus
"Senders J.T., Cho L.D., Calvachi P., McNulty J.J., Ashby J.L., Schulte I.S., Almekkawi A.K., Mehrtash A., Gormley W.B., Smith T.R., Broekman M.L.D., Arnaout O.","Automating clinical chart review: An Open-Source Natural Language Processing Pipeline Developed on Free-Text Radiology Reports from Patients with Glioblastoma",2020,"JCO Clinical Cancer Informatics",9,"10.1200/CCI.19.00060","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090748269&doi=10.1200%2fCCI.19.00060&partnerID=40&md5=f209ba5a3551fa4246d23fbeabb06f16","PURPOSE The aim of this study was to develop an open-source natural language processing (NLP) pipeline for text mining of medical information from clinical reports. We also aimed to provide insight into why certain variables or reports are more suitable for clinical text mining than others. MATERIALS AND METHODS Various NLP models were developed to extract 15 radiologic characteristics from free-text radiology reports for patients with glioblastoma. Ten-fold cross-validation was used to optimize the hyperparameter settings and estimate model performance. We examined how model performance was associated with quantitative attributes of the radiologic characteristics and reports. RESULTS In total, 562 unique brain magnetic resonance imaging reports were retrieved. NLP extracted 15 radiologic characteristics with high to excellent discrimination (area under the curve, 0.82 to 0.98) and accuracy (78.6% to 96.6%). Model performance was correlated with the inter-rater agreement of the manually provided labels (ρ = 0.904; P, .001) but not with the frequency distribution of the variables of interest (ρ = 0.179; P = .52). All variables labeled with a near perfect inter-rater agreement were classified with excellent performance (area under the curve . 0.95). Excellent performance could be achieved for variables with only 50 to 100 observations in the minority group and class imbalances up to a 9:1 ratio. Report-level classification accuracy was not associated with the number of words or the vocabulary size in the distinct text documents. CONCLUSION This study provides an open-source NLP pipeline that allows for text mining of narratively written clinical reports. Small sample sizes and class imbalance should not be considered as absolute contraindications for text mining in clinical research. However, future studies should report measures of inter-rater agreement whenever ground truth is based on a consensus label and use this measure to identify clinical variables eligible for text mining. © 2020 by American Society of Clinical Oncology",,"Article; automation; brain radiography; cancer patient; consensus; corpus callosum; cross validation; data accuracy; data mining; electronic medical record; frontal lobe; glioblastoma; human; major clinical study; medical information; medical record review; minority group; natural language processing; nuclear magnetic resonance imaging; occipital lobe; open source natural language processing; parietal lobe; priority journal; temporal lobe; automation; electronic medical record system; glioblastoma; neuroimaging; pathology; procedures; radiology; research; Automation; Data Mining; Glioblastoma; Humans; Medical Records Systems, Computerized; Natural Language Processing; Neuroimaging; Radiology; Research Report",Article,Scopus
"Belanova R., Sprlakova-Pukova A., Standara M., Janu E., Koukalova R., Kristek J., Burkon P., Kolouskova I., Prochazka T., Pospisil P., Chakravarti A., Slampa P., Slaby O., Kazda T.","In silico study of pseudoprogression in glioblastoma: Collaboration of radiologists and radiation oncologists in the estimation of extent of high dose RT region",2020,"Biomedical Papers",1,"10.5507/bp.2019.039","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088432092&doi=10.5507%2fbp.2019.039&partnerID=40&md5=595d8c31671bf099c89ae779b6a7399e","Background and Aim. Oncologists play a vital role in the interpretation of radiographic results in glioblastoma patients. Molecular pathology and information on radiation treatment protocols among others are all important for accurate interpretation of radiology images. One important issue that may arise in interpreting such images is the phenomenon of tumor “pseudoprogression”; oncologists need to be able to distinguish this effect from true disease progression. Exact knowledge about the location of high-dose radiotherapy region is needed for valid determination of pseudoprogression according to RANO (Response Assessment in Neuro-Oncology) criteria in neurooncology. The aim of the present study was to evaluate the radiologists’ understanding of a radiotherapy high-dose region in routine clinical practice since radiation oncologists do not always report 3-dimensional isodoses when ordering follow up imaging. Methods. Eight glioblastoma patients who underwent postresection radiotherapy were included in this study. Four radiologists worked with their pre-radiotherapy planning MR, however, they were blinded to RT target volumes which were defined by radiation oncologists according to current guidelines. The aim was to draw target volume for high dose RT fields (that is the region, where they would consider that there may be a pseudoprogression in future MRI scans). Many different indices describing structure differences were analyzed in comparison with original per-protocol RT target volumes. Results. The median volume for RT high dose field was 277 ccm (range 218 to 401 ccm) as defined per protocol by radiation oncologist and 87 ccm (range 32–338) as defined by radiologists (median difference of paired difference 31%, range 15–112%). The Median Dice index of similarity was 0.46 (range 0.14 – 0.78), the median Hausdorff distance 25 mm. Conclusion. Continuing effort to improve education on specific procedures in RT and in radiology as well as automatic tools for exporting RT targets is needed in order to increase specificity and sensitivity in response evaluation. © 2020 The Authors.","Glioblastoma; High-dose field; Pseudoprogression; Radiotherapy; RANO","adult; brain tumor; computer simulation; disease exacerbation; female; glioblastoma; human; intersectoral collaboration; male; middle aged; pathophysiology; radiation dose; radiation oncologist; radiation oncology; Adult; Brain Neoplasms; Computer Simulation; Disease Progression; Female; Glioblastoma; Humans; Intersectoral Collaboration; Male; Middle Aged; Radiation Dosage; Radiation Oncologists; Radiation Oncology",Article,Scopus
"Dercksen K., De Vries A.P.","First steps towards patient-friendly presentation of dutch radiology reports",2020,"CEUR Workshop Proceedings",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088228054&partnerID=40&md5=0b4fede0ffb513697bf211e65c19fd72","Nowadays, clinical patients are often free to access their own electronic health records (EHRs) online. Medical records are however not written with the patient in mind - the medical terminology necessary to ensure unambiguous communication between medical professionals on likelihood of pathology renders the EHRs less accessible to patients. By annotating these texts with links to external knowledge bases, the patients can be provided with additional reliable information to clarify terminology. In this paper, we present preliminary work on preparing Dutch radiology reports for named entity recognition and entity linking to provide additional information to patients. Additionally, we suggest a roadmap for further research into patient-friendly presentation of radiology reports. Copyright © 2020 for this paper by its authors.","Electronic health records; Information retrieval; Natural language processing","Indexing (of information); Information retrieval; Radiation; Radiology; Semantics; Terminology; Electronic health record (EHRs); External knowledge; Medical professionals; Medical record; Medical terminologies; Named entity recognition; Radiology reports; Roadmap; Electronic document exchange",Conference Paper,Scopus
"Hofmann P., Oesterle S., Rust P., Urbach N.","Machine learning approaches along the radiology value chain - Rethinking value propositions",2020,"27th European Conference on Information Systems - Information Systems for a Sharing Society, ECIS 2019",4,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087103474&partnerID=40&md5=e10635679fddd31e9502de528ef83669","Radiology is experiencing an increased interest in machine learning with its ability to use a large amount of available data. However, it remains unclear how and to what extent machine learning will affect radiology businesses. Conducting a systematic literature review and expert interviews, we compile the opportunities and challenges of machine learning along the radiology value chain to discuss their implications for the radiology business. Machine learning can improve diagnostic quality by reducing human errors, accurately analysing large amounts of data, quantifying reports, and integrating data. Hence, it strengthens radiology businesses seeking product or service leadership. Machine learning fosters efficiency by automating accompanying activities such as generating study protocols or reports, avoiding duplicate work due to low image quality, and supporting radiologists. These efficiency improvements advance the operational excellence strategy. By providing personnel and proactive medical solutions beyond the radiology silo, machine learning supports a customer intimacy strategy. However, the opportunities face challenges that are technical (i.e., lack of data, weak labelling, and generalisation), legal (i.e., regulatory approval and privacy laws), and persuasive (i.e., radiologists' resistance and patients' distrust). Our findings shed light on the strategic positioning of radiology businesses, contributing to academic discourse and practical decision-making. © 27th European Conference on Information Systems - Information Systems for a Sharing Society, ECIS 2019. All rights reserved.","Artificial Intelligence; Business Models; Health IT; Machine Learning; Radiology","Decision making; Diagnosis; Efficiency; Information systems; Information use; Radiation; Radiology; Diagnostic quality; Efficiency improvement; Large amounts of data; Machine learning approaches; Operational excellence; Regulatory approvals; Strategic positioning; Systematic literature review; Machine learning",Conference Paper,Scopus
"Kanjaria K., Pillai A., Shivade C., Bendersky M., Mukherjee V., Syeda-Mahmood T.","Receptivity of an AI cognitive assistant by the radiology community: A report on data collected at RSNA",2020,"HEALTHINF 2020 - 13th International Conference on Health Informatics, Proceedings; Part of 13th International Joint Conference on Biomedical Engineering Systems and Technologies, BIOSTEC 2020",1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083738571&partnerID=40&md5=1741957a459fe62a7ceb15d4043773cf","Due to advances in machine learning and artificial intelligence (AI), a new role is emerging for machines as intelligent assistants to radiologists in their clinical workflows. But what systematic clinical thought processes are these machines using? Are they similar enough to those of radiologists to be trusted as assistants? A live demonstration of such a technology was conducted at the 2016 Scientific Assembly and Annual Meeting of the Radiological Society of North America (RSNA). The demonstration was presented in the form of a question-answering system that took a radiology multiple choice question and a medical image as inputs. The AI system then demonstrated a cognitive workflow, involving text analysis, image analysis, and reasoning, to process the question and generate the most probable answer. A post demonstration survey was made available to the participants who experienced the demo and tested the question answering system. Of the reported 54,037 meeting registrants, 2,927 visited the demonstration booth, 1,991 experienced the demo, and 1,025 completed a post-demonstration survey. In this paper, the methodology of the survey is shown and a summary of its results are presented. The results of the survey show a very high level of receptiveness to cognitive computing technology and artificial intelligence among radiologists. © 2020 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.","Artificial intelligence; Cognitive computing; Decision support; Deep learning; Machine learning; Question answering; Radiology survey","Artificial intelligence; Biomedical engineering; Demonstrations; Medical imaging; Medical informatics; Radiation; Radiology; AI systems; Cognitive Computing; Intelligent assistants; Multiple choice questions; Question answering systems; Text analysis; Thought process; Work-flows; Surveys",Conference Paper,Scopus
"Krsnik I., Glavaš G., Krsnik M., Miletic D., Štajduhar I.","Automatic annotation of narrative radiology reports",2020,"Diagnostics",5,"10.3390/diagnostics10040196","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082838098&doi=10.3390%2fdiagnostics10040196&partnerID=40&md5=03ee72253f801d3632af96d4396f61b6","Narrative texts in electronic health records can be efficiently utilized for building decision support systems in the clinic, only if they are correctly interpreted automatically in accordance with a specified standard. This paper tackles the problem of developing an automated method of labeling free-form radiology reports, as a precursor for building query-capable report databases in hospitals. The analyzed dataset consists of 1295 radiology reports concerning the condition of a knee, retrospectively gathered at the Clinical Hospital Centre Rijeka, Croatia. Reports were manually labeled with one or more labels from a set of 10 most commonly occurring clinical conditions. After primary preprocessing of the texts, two sets of text classification methods were compared: (1) traditional classification models-Naive Bayes (NB), Logistic Regression (LR), Support Vector Machine (SVM), and Random Forests (RF)-coupled with Bag-of-Words (BoW) features (i.e., symbolic text representation) and (2) Convolutional Neural Network (CNN) coupled with dense word vectors (i.e., word embeddings as a semantic text representation) as input features. We resorted to nested 10-fold cross-validation to evaluate the performance of competing methods using accuracy, precision, recall, and F1 score. The CNN with semantic word representations as input yielded the overall best performance, having a micro-averaged F1 score of 86.7%. The CNN classifier yielded particularly encouraging results for the most represented conditions: degenerative disease (95.9%), arthrosis (93.3%), and injury (89.2%). As a data-hungry deep learning model, the CNN, however, performed notably worse than the competing models on underrepresented classes with fewer training instances such as multicausal disease or metabolic disease. LR, RF, and SVM performed comparably well, with the obtained micro-averaged F1 scores of 84.6%, 82.2%, and 82.1%, respectively. © 2020 by the authors.","Automatic labeling; Decision support system; Free-form radiology report; Machine learning; Natural language processing; Word embedding; knee","accuracy; anterior cruciate ligament injury; Article; autoimmune disease; Bayesian learning; classification algorithm; clinical outcome; convolutional neural network; Croatia; cross validation; data base; data processing; deep learning; degenerative disease; electronic health record; genetic disorder; human; idiopathic disease; inflammatory disease; injury; knee osteoarthritis; logistic regression analysis; metabolic disorder; neoplasm; nuclear magnetic resonance imaging; radiology; random forest; reporting and data system; retrospective study; support vector machine",Article,Scopus
"Martin-Carreras T., Chen P.-H.","From Data to Value: How Artificial Intelligence Augments the Radiology Business to Create Value",2020,"Seminars in Musculoskeletal Radiology",8,"10.1055/s-0039-3400269","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078687635&doi=10.1055%2fs-0039-3400269&partnerID=40&md5=09d06368a78024277ac3c97aa679399e","The radiology practice has access to a wealth of data in the radiologist information system, dictation reports, and electronic health records. Although many artificial intelligence applications in radiology have focused on computer vision and the interpretive use cases, many opportunities exist to enhance the radiologist's value proposition through business analytics. This article explores how AI lends an analytical lens to the radiology practice to create value. © 2020 by Thieme Medical Publishers, Inc.","artificial intelligence; business analytics; natural language processing","article; artificial intelligence; computer vision; electronic health record; human; information system; natural language processing; radiologist; radiology; artificial intelligence; computer assisted diagnosis; diagnostic imaging; economics; procedures; radiology; radiology information system; workflow; Artificial Intelligence; Diagnostic Imaging; Electronic Health Records; Humans; Image Interpretation, Computer-Assisted; Radiology; Radiology Information Systems; Workflow",Article,Scopus
"Do H.M., Spear L.G., Nikpanah M., Mirmomen S.M., Machado L.B., Toscano A.P., Turkbey B., Bagheri M.H., Gulley J.L., Folio L.R.","Augmented Radiologist Workflow Improves Report Value and Saves Time: A Potential Model for Implementation of Artificial Intelligence",2020,"Academic Radiology",36,"10.1016/j.acra.2019.09.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076001528&doi=10.1016%2fj.acra.2019.09.014&partnerID=40&md5=a608cb648aff518ec8b48f0a11b603d4","Rationale and Objectives: Our primary aim was to improve radiology reports by increasing concordance of target lesion measurements with oncology records using radiology preprocessors (RP). Faster notification of incidental actionable findings to referring clinicians and clinical radiologist exam interpretation time savings with RPs quantifying tumor burden were also assessed. Materials and Methods: In this prospective quality improvement initiative, RPs annotated lesions before radiologist interpretation of CT exams. Clinical radiologists then hyperlinked approved measurements into interactive reports during interpretations. RPs evaluated concordance with our tumor measurement radiologist, the determinant of tumor burden. Actionable finding detection and notification times were also deduced. Clinical radiologist interpretation times were calculated from established average CT chest, abdomen, and pelvis interpretation times. Results: RPs assessed 1287 body CT exams with 812 follow-up CT chest, abdomen, and pelvis studies; 95 (11.7%) of which had 241 verified target lesions. There was improved concordance (67.8% vs. 22.5%) of target lesion measurements. RPs detected 93.1% incidental actionable findings with faster clinician notification by a median time of 1 hour (range: 15 minutes–16 hours). Radiologist exam interpretation times decreased by 37%. Conclusions: This workflow resulted in three-fold improved target lesion measurement concordance with oncology records, earlier detection and faster notification of incidental actionable findings to referring clinicians, and decreased exam interpretation times for clinical radiologists. These findings demonstrate potential roles for automation (such as AI) to improve report value, worklist prioritization, and patient care. © 2019","Actionable findings; Artificial intelligence; Cancer clinical trials; Radiology preprocessors; Tumor quantification","abdomen; Article; artificial intelligence; computer assisted tomography; follow up; human; incidental finding; pelvis; priority journal; prospective study; radiologist; thorax; total quality management; tumor volume; workflow; radiologist; radiology; Artificial Intelligence; Humans; Prospective Studies; Radiologists; Radiology; Workflow",Article,Scopus
"Purkayastha S., Buddi S.B., Nuthakki S., Yadav B., Gichoya J.W.","Evaluating the Implementation of Deep Learning in LibreHealth Radiology on Chest X-Rays",2020,"Advances in Intelligent Systems and Computing",7,"10.1007/978-3-030-17795-9_47","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065488887&doi=10.1007%2f978-3-030-17795-9_47&partnerID=40&md5=ee6238dfb0f050a152a31394820a8936","Respiratory diseases are the dominant cause of deaths worldwide. In the US, the number of deaths due to chronic lung infections (mostly pneumonia and tuberculosis), lung cancer and chronic obstructive pulmonary disease has increased. Timely and accurate diagnosis of the disease is highly imperative to diminish the deaths. Chest X-ray is a vital diagnostic tool used for diagnosing lung diseases. Delay in X-Ray diagnosis is run-of-the-mill milieu and the reasons for the impediment are mostly because the X-ray reports are arduous to interpret, due to the complex visual contents of radiographs containing superimposed anatomical structures. A shortage of trained radiologists is another cause of increased workload and thus delay. We integrated CheXNet, a neural network algorithm into the LibreHealth Radiology Information System, which allows physicians to upload Chest X-rays and identify diagnosis probabilities. The uploaded images are evaluated from labels for 14 thoracic diseases. The turnaround time for each evaluation is about 30 s, which does not affect clinical workflow. A Python Flask application hosted web service is used to upload radiographs into a GPU server containing the algorithm. Thus, the use of this system is not limited to clients having their GPU server, but instead, we provide a web service. To evaluate the model, we randomly split the dataset into training (70%), validation (10%) and test (20%) sets. With over 86% accuracy and turnaround time under 30 s, the application demonstrates the feasibility of a web service for machine learning based diagnosis of 14-lung pathologies from Chest X-rays. © 2020, Springer Nature Switzerland AG.","Chest X-ray; CheXNet; Deep learning; LibreHealth; Radiology","Biological organs; Computer vision; Deep learning; Diagnosis; Pathology; Pulmonary diseases; Radiation; Radiography; Radiology; Statistical tests; Web services; Websites; Anatomical structures; Chest x-rays; CheXNet; Chronic obstructive pulmonary disease; Clinical workflow; LibreHealth; Neural network algorithm; Radiology information system; X rays",Conference Paper,Scopus
"Singh S., Karimi S., Ho-Shon K., Hamey L.","From Chest X-Rays to Radiology Reports: A Multimodal Machine Learning Approach",2019,"2019 Digital Image Computing: Techniques and Applications, DICTA 2019",13,"10.1109/DICTA47822.2019.8945819","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078697857&doi=10.1109%2fDICTA47822.2019.8945819&partnerID=40&md5=6df47b04f2288ba58732aeedefa2b082","Interpreting medical images and summarising them in the form of radiology reports is a challenging, tedious, and complex task. A radiologist provides a complete description of a medical image in the form of radiology report by describing normal or abnormal findings and providing a summary for decision making. Research shows that the radiology practice is error-prone due to the limited number of experts, increasing patient volumes, and the subjective nature of human perception. To reduce the number of diagnostic errors and to alleviate the task of radiologists, there is a need for a computer-aided report generation system that can automatically generate a radiology report for a given medical image. We propose an encoder-decoder based framework that can automatically generate radiology reports from medical images. Specifically, we use a Convolutional Neural Network as an encoder coupled with a multi-stage Stacked Long Short-Term Memory as a decoder to generate reports. We perform experiments on the Indiana University Chest X-ray collection, a publicly available dataset, to measure the effectiveness of our model. Experimental results show the effectiveness of our model in automatically generating radiology reports from medical images. © 2019 IEEE.","Artificial Intelligence; Computer Vision; Computer-aided Report Generation; Convolutional Neural Network; Medical Imaging; Natural Language Processing; Radiology; Recurrent Neural Network","Artificial intelligence; Computer vision; Convolution; Decision making; Decoding; Diagnosis; Learning algorithms; Machine learning; Natural language processing systems; Radiology; Recurrent neural networks; Signal encoding; X rays; Convolutional neural network; Diagnostic errors; Human perception; Indiana University; Machine learning approaches; NAtural language processing; Radiology reports; Report generation; Medical imaging",Conference Paper,Scopus
"Codari M., Melazzini L., Morozov S.P., van Kuijk C.C., Sconfienza L.M., Sardanelli F., European Society of Radiology (ESR)","Impact of artificial intelligence on radiology: a EuroAIM survey among members of the European Society of Radiology",2019,"Insights into Imaging",88,"10.1186/s13244-019-0798-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074294128&doi=10.1186%2fs13244-019-0798-3&partnerID=40&md5=94e15cf0364ebe3b8b5e493887ab4cde","We report the results of a survey conducted among ESR members in November and December 2018, asking for expectations about artificial intelligence (AI) in 5–10 years. Of 24,000 ESR members contacted, 675 (2.8%) completed the survey, 454 males (67%), 555 (82%) working at academic/public hospitals. AI impact was mostly expected (≥ 30% of responders) on breast, oncologic, thoracic, and neuro imaging, mainly involving mammography, computed tomography, and magnetic resonance. Responders foresee AI impact on: job opportunities (375/675, 56%), 218/375 (58%) expecting increase, 157/375 (42%) reduction; reporting workload (504/675, 75%), 256/504 (51%) expecting reduction, 248/504 (49%) increase; radiologist’s profile, becoming more clinical (364/675, 54%) and more subspecialised (283/675, 42%). For 374/675 responders (55%) AI-only reports would be not accepted by patients, for 79/675 (12%) accepted, for 222/675 (33%) it is too early to answer. For 275/675 responders (41%) AI will make the radiologist-patient relation more interactive, for 140/675 (21%) more impersonal, for 259/675 (38%) unchanged. If AI allows time saving, radiologists should interact more with clinicians (437/675, 65%) and/or patients (322/675, 48%). For all responders, involvement in AI-projects is welcome, with different roles: supervision (434/675, 64%), task definition (359/675, 53%), image labelling (197/675, 29%). Of 675 responders, 321 (48%) do not currently use AI, 138 (20%) use AI, 205 (30%) are planning to do it. According to 277/675 responders (41%), radiologists will take responsibility for AI outcome, while 277/675 (41%) suggest shared responsibility with other professionals. To summarise, responders showed a general favourable attitude towards AI. © 2019, The Author(s).","Artificial Intelligence; Machine Learning; Radiologists; Radiology; Surveys and Questionnaires",,Article,Scopus
"Goel A.K., DiLella D., Dotsikas G., Hilts M., Kwan D., Paxton L.","Unlocking Radiology Reporting Data: an Implementation of Synoptic Radiology Reporting in Low-Dose CT Cancer Screening",2019,"Journal of Digital Imaging",14,"10.1007/s10278-019-00214-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068868804&doi=10.1007%2fs10278-019-00214-2&partnerID=40&md5=f561639452740c38d3228b28f9ee10c0","Cancer Care Ontario (CCO) is the clinical advisor to the Ontario Ministry of Health and Long-Term Care for the funding and delivery of cancer services. Data contained in radiology reports are inaccessible for analysis without significant manual cost and effort. Synoptic reporting includes highly structured reporting and discrete data capture, which could unlock these data for clinical and evaluative purposes. To assess the feasibility of implementing synoptic radiology reporting, a trial implementation was conducted at one hospital within CCO’s Lung Cancer Screening Pilot for People at High Risk. This project determined that it is feasible to capture synoptic data with some barriers. Radiologists require increased awareness when reporting cases with a large number of nodules due to lack of automation within the system. These challenges may be mitigated by implementation of some report automation. Domains such as pathology and public health reporting have addressed some of these challenges with standardized reports based on interoperable standards, and radiology could borrow techniques from these domains to assist in implementing synoptic reporting. Data extraction from the reports could also be significantly automated to improve the process and reduce the workload in collecting the data. RadLex codes aided the difficult data extraction process, by helping label potential ambiguity with common terms and machine-readable identifiers. © 2019, Society for Imaging Informatics in Medicine.","RadLex; Structured Data capture; Structured Reporting; Synoptic Reporting","Automation; Diseases; Extraction; Radiation; Radiology; Risk assessment; Cancer screening; Lung cancer screening; Radiology reporting; Radiology reports; RadLex; Structured data; Structured reporting; Synoptic Reporting; Data mining; diagnostic imaging; human; lung; lung tumor; methodology; Ontario; procedures; radiation dose; radiology; research; x-ray computed tomography; Humans; Lung; Lung Neoplasms; Ontario; Radiation Dosage; Radiology; Research Design; Research Report; Tomography, X-Ray Computed",Article,Scopus
"Piotrkowicz A., Johnson O., Hall G.","Finding relevant free-text radiology reports at scale with IBM Watson Content Analytics: A feasibility study in the UK NHS",2019,"Journal of Biomedical Semantics",5,"10.1186/s13326-019-0213-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074857161&doi=10.1186%2fs13326-019-0213-5&partnerID=40&md5=f6656269daa3f8605e6cac413777c22c","Background: Significant amounts of health data are stored as free-text within clinical reports, letters, discharge summaries and notes. Busy clinicians have limited time to read such large amounts of free-text and are at risk of information overload and consequently missing information vital to patient care. Automatically identifying relevant information at the point of care has the potential to reduce these risks but represents a considerable research challenge. One software solution that has been proposed in industry is the IBM Watson analytics suite which includes rule-based analytics capable of processing large document collections at scale. Results: In this paper we present an overview of IBM Watson Content Analytics and a feasibility study using Content Analytics with a large-scale corpus of clinical free-text reports within a UK National Health Service (NHS) context. We created dictionaries and rules for identifying positive incidence of hydronephrosis and brain metastasis from 5.6 m radiology reports and were able to achieve 94% precision, 95% recall and 89% precision, 94% recall respectively on a sample of manually annotated reports. With minor changes for US English we applied the same rule set to an open access corpus of 0.5 m radiology reports from a US hospital and achieved 93% precision, 94% recall and 84% precision, 88% recall respectively. Conclusions: We were able to implement IBM Watson within a UK NHS context and demonstrate effective results that could provide clinicians with an automatic safety net which highlights clinically important information within free-text documents. Our results suggest that currently available technologies such as IBM Watson Content Analytics already have the potential to address information overload and improve clinical safety and that solutions developed in one hospital and country may be transportable to different hospitals and countries. Our study was limited to exploring technical aspects of the feasibility of one industry solution and we recognise that healthcare text analytics research is a fast-moving field. That said, we believe our study suggests that text analytics is sufficiently advanced to be implemented within industry solutions that can improve clinical safety. © 2019 The Author(s).","Feasibility study; Information retrieval; Natural language processing; Radiology; Rule-based system","brain tumor; data mining; diagnostic imaging; feasibility study; human; hydronephrosis; natural language processing; public health; radiology; research; United Kingdom; Brain Neoplasms; Data Mining; Feasibility Studies; Humans; Hydronephrosis; National Health Programs; Natural Language Processing; Radiology; Research Report; United Kingdom",Article,Scopus
"Tada T., Yamamoto K.","Effect of Preprocessing for Distributed Representations: Case Study of Japanese Radiology Reports",2019,"Proceedings of the 2019 International Conference on Asian Language Processing, IALP 2019",,"10.1109/IALP48816.2019.9037678","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083154366&doi=10.1109%2fIALP48816.2019.9037678&partnerID=40&md5=965ec4470ea1182b8a0d6e3fff466520","A radiology report is a medical document based on an examination image in a hospital. However, the preparation of this report is a burden on busy physicians. To support them, a retrieval system of past documents to prepare radiology reports is required. In recent years, distributed representation has been used in various NLP tasks and its usefulness has been demonstrated. However, there is not much research about Japanese medical documents that use distributed representations. In this study, we investigate preprocessing on a retrieval system with a distributed representation of the radiology report, as a first step. As a result, we confirmed that in word segmentation using Morphological analyzer and dictionaries, medical terms in radiology reports are not handled as long nouns, but are more effective as shorter nouns like subwords. We also confirmed that text segmentation by SentencePiece to obtain sentence distributed representation reflects more sentence characteristics. Furthermore, by removing some phrases from the radiology report based on frequency, we were able to reflect the characteristics of the document and avoid unnecessary high similarity between documents. It was confirmed that preprocessing was effective in this task. © 2019 IEEE.","Distributed representation; Japanese; Medical document; Pre-processing; Radiology report","Medical imaging; Natural language processing systems; Radiation; Radiology; Distributed representation; Medical documents; Medical terms; Morphological analyzer; Radiology reports; Retrieval systems; Text segmentation; Word segmentation; Information retrieval",Conference Paper,Scopus
"Kang S.K., Garry K., Chung R., Moore W.H., Iturrate E., Swartz J.L., Kim D.C., Horwitz L.I., Blecker S.","Natural Language Processing for Identification of Incidental Pulmonary Nodules in Radiology Reports",2019,"Journal of the American College of Radiology",25,"10.1016/j.jacr.2019.04.026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068390628&doi=10.1016%2fj.jacr.2019.04.026&partnerID=40&md5=0ac8649ff74186a391fb9a6d00f6bec1","Purpose: To develop natural language processing (NLP) to identify incidental lung nodules (ILNs) in radiology reports for assessment of management recommendations. Methods and Materials: We searched the electronic health records for patients who underwent chest CT during 2014 and 2017, before and after implementation of a department-wide dictation macro of the Fleischner Society recommendations. We randomly selected 950 unstructured chest CT reports and reviewed manually for ILNs. An NLP tool was trained and validated against the manually reviewed set, for the task of automated detection of ILNs with exclusion of previously known or definitively benign nodules. For ILNs found in the training and validation sets, we assessed whether reported management recommendations agreed with Fleischner Society guidelines. The guideline concordance of management recommendations was compared between 2014 and 2017. Results: The NLP tool identified ILNs with sensitivity and specificity of 91.1% and 82.2%, respectively, in the validation set. Positive and negative predictive values were 59.7% and 97.0%. In reports of ILNs in the training and validation sets before versus after introduction of a Fleischner reporting macro, there was no difference in the proportion of reports with ILNs (108 of 500 [21.6%] versus 101 of 450 [22.4%]; P = .8), or in the proportion of reports with ILNs containing follow-up recommendations (75 of 108 [69.4%] versus 80 of 101 [79.2%]; P = .2]. Rates of recommendation guideline concordance were not significantly different before and after implementation of the standardized macro (52 of 75 [69.3%] versus 60 of 80 [75.0%]; P = .43). Conclusion: NLP reliably automates identification of ILNs in unstructured reports, pertinent to quality improvement efforts for ILN management. © 2019 American College of Radiology","Incidental finding; natural language processing; pulmonary nodule; quality improvement","adult; aged; Article; female; follow up; human; incidental finding; lung nodule; major clinical study; male; natural language processing; predictive value; retrospective study; sensitivity and specificity; thorax radiography; total quality management; x-ray computed tomography; cohort analysis; diagnostic imaging; electronic health record; lung nodule; procedures; radiology; reproducibility; research; United States; Cohort Studies; Electronic Health Records; Female; Humans; Incidental Findings; Male; Natural Language Processing; Radiology; Reproducibility of Results; Research Report; Retrospective Studies; Solitary Pulmonary Nodule; Tomography, X-Ray Computed; United States",Article,Scopus
"Donnelly L.F., Grzeszczuk R., Guimaraes C.V., Zhang W., Bisset III G.S.","Using a Natural Language Processing and Machine Learning Algorithm Program to Analyze Inter-Radiologist Report Style Variation and Compare Variation Between Radiologists When Using Highly Structured Versus More Free Text Reporting",2019,"Current Problems in Diagnostic Radiology",6,"10.1067/j.cpradiol.2018.09.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055753981&doi=10.1067%2fj.cpradiol.2018.09.005&partnerID=40&md5=dd4b234ab2790d2fbceff8f0a6818fd1","Purpose: To use a natural language processing and machine learning algorithm to evaluate inter-radiologist report variation and compare variation between radiologists using highly structured versus more free text reporting. Materials and Methods: 28,615 radiology reports were analyzed for 4 metrics: verbosity, observational terms only, unwarranted negative findings, and repeated language in different sections. Radiology reports for two imaging examinations were analyzed and compared – one which was more templated (ultrasound – appendicitis) and one which relied on more free text (chest radiograph – single view). For each metric, the mean and standard deviation for defined outlier results for all dictations (individual and group mean) was calculated. The mean number of outlier metrics per reader per study was calculated and compared between radiologists and between the two report types. Wilcoxon rank test and paired Wilcoxon signed rank test were applied. The radiologists were also ranked based on the number of outlier metrics identified per study. Results: There was great variability in radiologist dictation styles – outlier metrics per report varied greatly between radiologists with the maximum 10 times higher than the minimum score. Metric values were greater (P < 0.0001) on the standardized reports using free text than the more structured reports. Conclusions: The algorithm successfully evaluated metrics showing variability in reporting profiles particularly when there is free text. This variability can be an obstacle to providing effective communication and reliability of care. © 2018 Elsevier Inc.",,"abdominal radiography; appendicitis; Article; artificial intelligence; clinical evaluation; clinical examination; controlled study; human; image enhancement; learning algorithm; medical practice; natural language processing; patient care; patient education; radiologist; scoring system; text messaging; thorax radiography; verbal communication; comparative study; machine learning; radiology information system; research; software; Humans; Machine Learning; Natural Language Processing; Radiology Information Systems; Research Report; Software",Article,Scopus
"Gu M., Huang X., Fang Y.","Automatic Generation of Pulmonary Radiology Reports with Semantic Tags",2019,"2019 IEEE 11th International Conference on Advanced Infocomm Technology, ICAIT 2019",7,"10.1109/ICAIT.2019.8935910","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078057822&doi=10.1109%2fICAIT.2019.8935910&partnerID=40&md5=58b26e27f470d3762699edcac5f9374c","The chest X-ray is widely used in clinical practice for diagnosis and treatment. Among all chest diseases, pulmonary disease accounts for the majority, and the description of the lungs in the radiology report is the most complicated. According to this situation, this paper proposes a pulmonary radiology report generation model (SRN+BC-LSTM) based on semantic tags of radiograph. Firstly, for the problem that the image features extracted by CNN do not contain obvious semantic information, this paper selects the high frequency words related to abnormalities in the pulmonary radiology report as semantic tags, and trains the multi-label classifier. Secondly, a binary classifier is combined to improve the BLEU of generated normal reports since the Chinese radiology reports have roughly the same description for the normal samples. The experiment results indicated that our model is 13% higher than the baseline model in BLUE4. © 2019 IEEE.","component; computer-aided detection; deep learning; radiology report; semantic tag","Classification (of information); Computer aided diagnosis; Computer aided instruction; Deep learning; Radiation; Radiology; Semantics; Automatic Generation; Binary classifiers; Clinical practices; component; Computer aided detection; High-frequency words; Radiology reports; Semantic information; Long short-term memory",Conference Paper,Scopus
"Kohli M., Alkasab T., Wang K., Heilbrun M.E., Flanders A.E., Dreyer K., Kahn C.E., Jr.","Bending the Artificial Intelligence Curve for Radiology: Informatics Tools From ACR and RSNA",2019,"Journal of the American College of Radiology",20,"10.1016/j.jacr.2019.06.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071398084&doi=10.1016%2fj.jacr.2019.06.009&partnerID=40&md5=0c8073e52a8ab84ce28d754882371b3d","Artificial intelligence (AI) will reshape radiology over the coming years. The radiology community has a strong history of embracing new technology for positive change, and AI is no exception. As with any new technology, rapid, successful implementation faces several challenges that will require creation and adoption of new integration technology. Use cases important to real-world application of AI are described, including clinical registries, AI research, AI product validation, and computer assistance for radiology reporting. Furthermore, the informatics technologies required for successful implementation of the use cases are described, including open Computer-Assisted Radiologist Decision Support, ACR Assist, ACR Data Science Institute use cases, common data elements (radelement.org), RadLex (radlex.org), LOINC/RSNA RadLex Playbook (loinc.org), and Radiology Report Templates (radreport.org). © 2019 American College of Radiology","Artificial intelligence; common data elements; interoperability; machine learning","adoption; article; artificial intelligence; common data elements; data science; decision support system; human; Logical Observation Identifiers Names and Codes; machine learning; radiologist; radiology; validation process; mass communication; medical informatics; medical society; practice guideline; register; Artificial Intelligence; Diffusion of Innovation; Humans; Medical Informatics Applications; Practice Guidelines as Topic; Radiology; Registries; Societies, Medical",Article,Scopus
"Kehl K.L., Elmarakeby H., Nishino M., Van Allen E.M., Lepisto E.M., Hassett M.J., Johnson B.E., Schrag D.","Assessment of Deep Natural Language Processing in Ascertaining Oncologic Outcomes from Radiology Reports",2019,"JAMA Oncology",76,"10.1001/jamaoncol.2019.1800","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069652818&doi=10.1001%2fjamaoncol.2019.1800&partnerID=40&md5=26a09244ccab833c4bbe69dec9e6a561","Importance: A rapid learning health care system for oncology will require scalable methods for extracting clinical end points from electronic health records (EHRs). Outside of clinical trials, end points such as cancer progression and response are not routinely encoded into structured data. Objective: To determine whether deep natural language processing can extract relevant cancer outcomes from radiologic reports, a ubiquitous but unstructured EHR data source. Design, Setting, and Participants: A retrospective cohort study evaluated 1112 patients who underwent tumor genotyping for a diagnosis of lung cancer and participated in the Dana-Farber Cancer Institute PROFILE study from June 26, 2013, to July 2, 2018. Exposures: Patients were divided into curation and reserve sets. Human abstractors applied a structured framework to radiologic reports for the curation set to ascertain the presence of cancer and changes in cancer status over time (ie, worsening/progressing vs improving/responding). Deep learning models were then trained to capture these outcomes from report text and subsequently evaluated in a 10% held-out test subset of curation patients. Cox proportional hazards regression models compared human and machine curations of disease-free survival, progression-free survival, and time to improvement/response in the curation set, and measured associations between report classification and overall survival in the curation and reserve sets. Main Outcomes and Measures: The primary outcome was area under the receiver operating characteristic curve (AUC) for deep learning models; secondary outcomes were time to improvement/response, disease-free survival, progression-free survival, and overall survival. Results: A total of 2406 patients were included (mean [SD] age, 66.5 [10.8] years; 1428 female [59.7%]; 2170 [90.2%] white). Radiologic reports (n = 14230) were manually reviewed for 1112 patients in the curation set. In the test subset (n = 109), deep learning models identified the presence of cancer, improvement/response, and worsening/progression with accurate discrimination (AUC >0.90). Machine and human curation yielded similar measurements of disease-free survival (hazard ratio [HR] for machine vs human curation, 1.18; 95% CI, 0.71-1.95); progression-free survival (HR, 1.11; 95% CI, 0.71-1.71); and time to improvement/response (HR, 1.03; 95% CI, 0.65-1.64). Among 15000 additional reports for 1294 reserve set patients, algorithm-detected cancer worsening/progression was associated with decreased overall survival (HR for mortality, 4.04; 95% CI, 2.78-5.85), and improvement/response was associated with increased overall survival (HR, 0.41; 95% CI, 0.22-0.77). Conclusions and Relevance: Deep natural language processing appears to speed curation of relevant cancer outcomes and facilitate rapid learning from EHR data. © 2019 American Medical Association. All rights reserved.",,"adult; aged; algorithm; Article; cancer classification; cancer growth; cancer mortality; cohort analysis; conceptual framework; deep learning; disease burden; disease free survival; female; genotype; human; lung cancer; major clinical study; male; middle aged; natural language processing; overall survival; progression free survival; radiology; retrospective study; treatment outcome",Article,Scopus
"Wheater E., Mair G., Sudlow C., Alex B., Grover C., Whiteley W.","A validated natural language processing algorithm for brain imaging phenotypes from radiology reports in UK electronic health records",2019,"BMC Medical Informatics and Decision Making",16,"10.1186/s12911-019-0908-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071983896&doi=10.1186%2fs12911-019-0908-7&partnerID=40&md5=fc0e5f59a4544ed07d8aa8ac25f4adda","Background: Manual coding of phenotypes in brain radiology reports is time consuming. We developed a natural language processing (NLP) algorithm to enable automatic identification of brain imaging in radiology reports performed in routine clinical practice in the UK National Health Service (NHS). Methods: We used anonymized text brain imaging reports from a cohort study of stroke/TIA patients and from a regional hospital to develop and test an NLP algorithm. Two experts marked up text in 1692 reports for 24 cerebrovascular and other neurological phenotypes. We developed and tested a rule-based NLP algorithm first within the cohort study, and further evaluated it in the reports from the regional hospital. Results: The agreement between expert readers was excellent (Cohen's κ =0.93) in both datasets. In the final test dataset (n = 700) in unseen regional hospital reports, the algorithm had very good performance for a report of any ischaemic stroke [sensitivity 89% (95% CI:81-94); positive predictive value (PPV) 85% (76-90); specificity 100% (95% CI:0.99-1.00)]; any haemorrhagic stroke [sensitivity 96% (95% CI: 80-99), PPV 72% (95% CI:55-84); specificity 100% (95% CI:0.99-1.00)]; brain tumours [sensitivity 96% (CI:87-99); PPV 84% (73-91); specificity: 100% (95% CI:0.99-1.00)] and cerebral small vessel disease and cerebral atrophy (sensitivity, PPV and specificity all > 97%). We obtained few reports of subarachnoid haemorrhage, microbleeds or subdural haematomas. In 110,695 reports from NHS Tayside, atrophy (n = 28,757, 26%), small vessel disease (15,015, 14%) and old, deep ischaemic strokes (10,636, 10%) were the commonest findings. Conclusions: An NLP algorithm can be developed in UK NHS radiology records to allow identification of cohorts of patients with important brain imaging phenotypes at a scale that would otherwise not be possible. © 2019 The Author(s).","Brain imaging; Natural language processing; Phenotyping; Radiology; Radiology reports; Stroke","adult; aged; algorithm; cerebrovascular accident; cohort analysis; diagnostic imaging; electronic health record; female; human; male; middle aged; national health service; natural language processing; neuroimaging; radiology; United Kingdom; young adult; Adult; Aged; Algorithms; Cohort Studies; Electronic Health Records; Female; Humans; Male; Middle Aged; Natural Language Processing; Neuroimaging; Radiology; State Medicine; Stroke; United Kingdom; Young Adult",Article,Scopus
"Hüsers J., Esdar M., WEIß J.-P., Hübner U.","Diffusion dynamics of radiology it – Systems in German hospitals – A Bayesian bass model",2019,"Studies in Health Technology and Informatics",1,"10.3233/SHTI190799","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071758267&doi=10.3233%2fSHTI190799&partnerID=40&md5=3b6a9399e7ee77a54fc7b8bbcf998539","Radiology has a reputation for having a high affinity to innovation – particularly with regard to information technologies. Designed for supporting the peculiarities of radiological diagnostic workflows, Radiology Information Systems (RIS) and Picture Archiving and Communication Systems (PACS) developed into widely used information systems in hospitals and form the basis for advancing the field towards automated image diagnostics. RIS and PACS can thus serve as meaningful indicators of how quickly IT innovations diffuse in secondary care settings – an issue that requires increased attention in research and health policy in the light of increasingly fast innovation cycles. We therefore conducted a retrospective longitudinal observational study to research the diffusion dynamics of RIS and PACS in German hospitals between 2005 and 2017. Based upon data points collected within the “IT Report Healthcare” and building on Rogers’ Diffusion of Innovation (DOI) theory, we applied a novel methodological technique by fitting Bayesian Bass Diffusion Models on past adoption rates. The Bass models showed acceptable goodness of fit to the data and the results indicated similar growth rates of RIS and PACS implementations and suggest that market saturation is almost reached. Adoption rates of PACS showed a slightly higher coefficient of imitation (q = 0.25) compared to RIS (q = 0.11). However, the diffusion process expands over approximately two decades for both systems which points at the need for further research into how innovation diffusion can be accelerated effectively. Furthermore, the Bayesian approach to Bass modelling showed to have several advantages over the classical frequentists approaches and should encourage adoption and diffusion research to adapt similar techniques. © 2019 The authors and IOS Press.","Bass diffusion model; Bayesian data analysis; Diffusion of innovation; Hospital information technology; PACS; RIS","Bayesian networks; Diagnosis; Diffusion; Hospitals; Image communication systems; Information systems; Information use; Interlocking signals; Medical applications; Medical informatics; Radiation; Radiology; Adoption and diffusion; Bass Diffusion Model; Bayesian data analysis; Diffusion of innovations; Hospital information; Innovation diffusion; Picture archiving and communication systems (PACS); Radiology information system; Picture archiving and communication systems; Bayes theorem; hospital; radiology; radiology information system; retrospective study; Bayes Theorem; Hospitals; Radiology; Radiology Information Systems; Retrospective Studies",Conference Paper,Scopus
"Steinkamp J.M., Chambers C.M., Lalevic D., Zafar H.M., Cook T.S.","Automated organ-level classification of free-text pathology reports to support a radiology follow-up tracking engine",2019,"Radiology: Artificial Intelligence",8,"10.1148/ryai.2019180052","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090996028&doi=10.1148%2fryai.2019180052&partnerID=40&md5=6ed4f596a654baad9357d7b06453ff60","Purpose: To evaluate the performance of machine learning algorithms on organ-level classification of semistructured pathology reports, to incorporate surgical pathology monitoring into an automated imaging recommendation follow-up engine. Materials and Methods: This retrospective study included 2013 pathology reports from patients who underwent abdominal imaging at a large tertiary care center between 2012 and 2018. The reports were labeled by two annotators as relevant to four abdominal organs: Liver, kidneys, pancreas and/or adrenal glands, or none. Automated classification methods were compared: Simple string matching, random forests, extreme gradient boosting, support vector machines, and two neural network architectures—convolutional neural networks and long short-term memory networks. Three methods from the literature were used to provide interpretability and qualitative validation of the learned network features. Results: The neural networks performed well on the four-organ classification task (F1 score: 96.3% for convolutional neural network and 96.7% for long short-term memory vs 89.9% for support vector machines, 93.9% for extreme gradient boosting, 82.8% for random forests, and 75.2% for simple string matching). Multiple methods were used to visualize the decision-making process of the network, verifying that the networks used similar heuristics to a human annotator. The neural networks were able to classify, with a high degree of accuracy, pathology reports written in unseen formats, suggesting the networks had learned a generalizable encoding of the salient features. Conclusion: Neural network-based approaches achieve high performance on organ-level pathology report classification, suggesting that it is feasible to use them within automated tracking systems. © RSNA, 2019.",,"abdominal viscera; adrenal gland; adult; article; convolutional neural network; female; follow up; heuristics; human; kidney; liver; long short term memory network; male; pancreas; radiology; random forest; retrospective study; support vector machine; tertiary care center; validation process",Article,Scopus
"Goldberg-Stein S., Chernyak V.","Adding Value in Radiology Reporting",2019,"Journal of the American College of Radiology",32,"10.1016/j.jacr.2019.05.042","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068797615&doi=10.1016%2fj.jacr.2019.05.042&partnerID=40&md5=1d2f2a4fcc29c5de6385603dccb2e428","The major goal of the radiology report is to deliver timely, accurate, and actionable information to the patient care team and the patient. Structured reporting offers multiple advantages over traditional free-text reporting, including reduction in diagnostic error, comprehensiveness, adherence to national consensus guidelines, revenue capture, data collection, and research. Various technological innovations enhance integration of structured reporting into everyday clinical practice. This review discusses the benefits of innovations in radiology reporting to the clinical decision process, the patient experience, the cost of imaging, and the overall contributions to the health of the population. Future directions, including the use of artificial intelligence, are reviewed. © 2019 American College of Radiology","Common data elements; radiology reporting; report quality; structured reporting","adult; article; artificial intelligence; common data elements; consensus; decision making; diagnostic error; human; patient care; practice guideline; radiology; diagnostic imaging; documentation; interdisciplinary communication; methodology; procedures; quality control; radiology; radiology information system; reproducibility; Artificial Intelligence; Diagnostic Imaging; Documentation; Humans; Interdisciplinary Communication; Quality Control; Radiology; Radiology Information Systems; Reproducibility of Results; Research Design",Article,Scopus
"Heilbrun M.E., Chapman B.E., Narasimhan E., Patel N., Mowery D.","Feasibility of Natural Language Processing–Assisted Auditing of Critical Findings in Chest Radiology",2019,"Journal of the American College of Radiology",19,"10.1016/j.jacr.2019.05.038","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068539387&doi=10.1016%2fj.jacr.2019.05.038&partnerID=40&md5=945d037f3dc6039efafebcebaede2afd","Objective: Time-sensitive communication of critical imaging findings like pneumothorax or pulmonary embolism to referring physicians is essential for patient safety. The definitive communication is the radiology free-text report. Quality assurance initiatives require that institutions audit these communications, a time-intensive manual task. We propose using a rule-based natural language processing system to improve the process for auditing critical findings communications. Methods: We present a pilot assessment of the feasibility of using an automated critical finding identification system to assist quality assurance teams’ evaluation of critical findings communication compliance. Our assessment is based on chest imaging reports. Critical findings are identified in radiology reports using pyConTextNLP, an open source Python implementation of the ConText algorithm. Results: In our test set, there were 75 reports with critical findings and 591 reports without critical findings. pyConTextNLP correctly identified 69 of the positive cases with 8 false-positives for a sensitivity of 0.92 and a specificity of 0.99. Discussion: Natural language processing can provide valuable assistance to auditing critical findings communications. © 2019 American College of Radiology","Critical findings; imaging informatics; natural language processing; quality assurance; the Joint Commission","aneurysm rupture; aortic dissection; Article; epiglottitis; false positive result; fracture; health care quality; human; lung embolism; malignant neoplasm; natural language processing; outpatient care; patient safety; pilot study; pneumomediastinum; pneumonia; pneumothorax; quality control; retropharyngeal abscess; spleen infarction; tension pneumothorax; thorax radiography; thrombosis; automation; feasibility study; female; machine learning; male; methodology; procedures; radiology information system; retrospective study; sensitivity and specificity; thorax radiography; total quality management; United States; university hospital; x-ray computed tomography; Academic Medical Centers; Automation; Feasibility Studies; Female; Humans; Machine Learning; Male; Natural Language Processing; Pilot Projects; Quality Improvement; Radiography, Thoracic; Radiology Information Systems; Research Design; Retrospective Studies; Sensitivity and Specificity; Tomography, X-Ray Computed; United States",Article,Scopus
"Filice R.W.","Radiology-Pathology Correlation to Facilitate Peer Learning: An Overview Including Recent Artificial Intelligence Methods",2019,"Journal of the American College of Radiology",16,"10.1016/j.jacr.2019.05.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068264027&doi=10.1016%2fj.jacr.2019.05.010&partnerID=40&md5=1676f1503cecbe9da9db491a6ce03016","Correlation of pathology reports with radiology examinations has long been of interest to radiologists and helps to facilitate peer learning. Such correlation also helps meet regulatory requirements, ensures quality, and supports multidisciplinary conferences and patient care. Additional offshoots of such correlation include evaluating for and ensuring concordance of pathology results with radiology interpretation and procedures as well as ensuring specimen adequacy after biopsy. For much of the history of radiology, this correlation has been done manually, which is time consuming and cumbersome and provides coverage of only a fraction of radiology examinations performed. Electronic storage and indexing of radiology and pathology information laid the foundation for easier access and for the development of automated artificial intelligence methods to match pathology information with radiology reports. More recent techniques have resulted in near comprehensive coverage of radiology examinations with methods to present results and solicit feedback from end users. Newer deep learning language modeling techniques will advance these methods by providing more robust automated and comprehensive radiology-pathology correlation with the ability to rapidly, flexibly, and iteratively tune models to site and user preference. © 2019 American College of Radiology","Artificial intelligence; deep learning; pathology; peer learning; quality","adult; article; artificial intelligence; biopsy; controlled study; deep learning; human; language; patient care; radiologist; radiology; storage; artificial intelligence; diagnostic imaging; female; immunohistochemistry; male; needle biopsy; nuclear magnetic resonance imaging; pathology; procedures; prostate tumor; radiology; total quality management; Artificial Intelligence; Biopsy, Needle; Deep Learning; Female; Humans; Immunohistochemistry; Magnetic Resonance Imaging; Male; Prostatic Neoplasms; Quality Improvement; Radiology",Article,Scopus
"Filice R.W.","Deep-Learning Language-Modeling Approach for Automated, Personalized, and Iterative Radiology-Pathology Correlation",2019,"Journal of the American College of Radiology",9,"10.1016/j.jacr.2019.05.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068250385&doi=10.1016%2fj.jacr.2019.05.007&partnerID=40&md5=832e2a4e009d1b2aef672147bbef788c","Purpose: Radiology-pathology correlation has long been foundational to continuing education, peer learning, quality assurance, and multidisciplinary patient care. The objective of this study was to determine whether modern deep-learning language-modeling techniques could reliably match pathology reports to pertinent radiology reports. Methods: The recently proposed Universal Language Model Fine-Tuning for Text Classification methodology was used. Two hundred thousand radiology and pathology reports were used for adaptation to the radiology-pathology space. One hundred thousand candidate radiology-pathology pairs, evenly split into match and no-match categories, were used for training the final binary classification model. Matches were defined by a previous-generation artificial intelligence anatomic concept radiology-pathology correlation system. Results: The language model rapidly adapted very closely to the prior anatomic concept-matching approach, with 100% specificity, 65.1% sensitivity, and 73.7% accuracy. For comparison, the previous methodology, which was intentionally designed to be specific at the expense of sensitivity, had 98.0% specificity, 65.1% sensitivity, and 73.2% accuracy. Conclusions: Modern deep-learning language-modeling approaches are promising for radiology-pathology correlation. Because of their rapid adaptation to underlying training labels, these models advance previous artificial intelligence work in that they can be continuously improved and tuned to improve performance and adjust to user and site-level preference. © 2019 American College of Radiology","artificial intelligence; deep learning; language modeling; pathology; Peer learning; quality","article; artificial intelligence; deep learning; human; human experiment; language; radiology; sensitivity and specificity; artificial intelligence; automation; factual database; forecasting; natural language processing; pathology; personalized medicine; procedures; radiology; radiology information system; total quality management; Artificial Intelligence; Automation; Databases, Factual; Deep Learning; Forecasting; Humans; Natural Language Processing; Pathology, Clinical; Precision Medicine; Quality Improvement; Radiology; Radiology Information Systems",Article,Scopus
"Krupinski E.A.","How Certain Are Your Radiology Reports And Are We Alone in Our Uncertainty?",2019,"Academic Radiology",,"10.1016/j.acra.2019.04.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067338276&doi=10.1016%2fj.acra.2019.04.019&partnerID=40&md5=f11c98c3ed4669c862d1074e5c16a8eb",[No abstract available],,"artificial intelligence; Editorial; human; nuclear magnetic resonance imaging; priority journal; radiology; uncertainty; multivariate analysis; radiologist; radiology information system; uncertainty; Humans; Multivariate Analysis; Radiologists; Radiology Information Systems; Uncertainty",Editorial,Scopus
"Trivedi G., Hong C., Dadashzadeh E.R., Handzel R.M., Hochheiser H., Visweswaran S.","Identifying incidental findings from radiology reports of trauma patients: An evaluation of automated feature representation methods",2019,"International Journal of Medical Informatics",12,"10.1016/j.ijmedinf.2019.05.021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066812585&doi=10.1016%2fj.ijmedinf.2019.05.021&partnerID=40&md5=b58bd23bfed2978f670639ce67f2561b","Background: Radiologic imaging of trauma patients often uncovers findings that are unrelated to the trauma. These are termed as incidental findings and identifying them in radiology examination reports is necessary for appropriate follow-up. We developed and evaluated an automated pipeline to identify incidental findings at sentence and section levels in radiology reports of trauma patients. Methods: We created an annotated dataset of 4,181 reports and investigated automated feature representations including traditional word and clinical concept (such as SNOMED CT) representations, as well as word and concept embeddings. We evaluated these representations by using them with traditional classifiers such as logistic regression and with deep learning methods such as convolutional neural networks (CNNs). Results: The best performance was observed using word embeddings with CNNs with F1 scores of 0.66 and 0.52 at section and sentence levels respectively. The F1 score was statistically significantly higher for sections compared to sentences (Wilcoxon; Z &lt; 0.001, p &lt; 0.05). Compared to using words alone, the addition of SNOMED CT concepts did not improve performance. At the sentence level, the F1 score improved significantly from 0.46 to 0.52 when using pre-trained embeddings (Wilcoxon; Z &lt; 0.001, p &lt; 0.05). Conclusion: The results show that the best performance was achieved by using embeddings with CNNs at both sentence and section levels. This provides evidence that such a pipeline is capable of accurately identifying incidental findings in radiology reports in an automated manner. © 2019 Elsevier B.V.","Automated feature representations; Convolutional neural networks; Incidental findings; Radiology reports; Word embeddings","Computerized tomography; Convolution; Deep learning; Embeddings; Neural networks; Pipelines; Radiation; Radiology; Automated features; Convolutional neural network; Improve performance; Incidental findings; Learning methods; Logistic regressions; Radiology examinations; Radiology reports; Automation; Article; artificial neural network; automation; clinical feature; comparative study; data base; deep learning; embedding; evaluation study; follow up; human; injury; logistic regression analysis; major clinical study; priority journal; radiology; scoring system; incidental finding; radiography; radiology; Humans; Incidental Findings; Neural Networks (Computer); Radiography; Radiology",Article,Scopus
"Shelmerdine S.C., Singh M., Norman W., Jones R., Sebire N.J., Arthurs O.J.","Automated data extraction and report analysis in computer-aided radiology audit: practice implications from post-mortem paediatric imaging",2019,"Clinical Radiology",9,"10.1016/j.crad.2019.04.021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066313307&doi=10.1016%2fj.crad.2019.04.021&partnerID=40&md5=7c9479e0f579ab5b327e094873589fee","AIM: To determine local departmental adherence to the paediatric post-mortem magnetic resonance imaging (MRI) protocols, using a customised automated computational approach. MATERIALS AND METHODS: A retrospective review of 460 whole-body post-mortem MRI examinations performed at Great Ormond Street Hospital for Children over a 5.5-year period was assessed for adherence to a full or abbreviated imaging sequence protocol. A simple computer program was developed to batch process DICOM (digital imaging and communications in medicine) files, extracting imaging sequence details, followed by natural language processing (NLP) of authorised reports to automate information extraction of diagnostic image quality. RESULTS: The program was able to extract study parameters from the entire dataset (approximately 80 GB of data) in a few hours, and retrieve information on diagnostic image quality using NLP with an overall diagnostic accuracy for data extraction of 96.7% (445/460, 95% confidence interval [CI]: 94.7–98%). The full imaging protocol was adhered to in 305/460 (66.3%) cases, and an abbreviated protocol in 140/460 (30.4%) cases. Overall, 423/460 (91.9%) of studies were of diagnostic quality. These included 298/305 (97.7%) of the full protocol, 111/140 (79.3%) of the abbreviated protocol. In only five cases were the examinations non-diagnostic for all body systems, all of whom weighed <100 g (24.7–72 g) and imaged using the abbreviated protocol. CONCLUSION: The present study demonstrated a successful application of an automated approach for data collection for audit and quality assessment purposes using paediatric post-mortem imaging as a specific example. Re-audit of these data following change implementation will be straightforward now that the automated workflow is clearly established. © 2019",,"article; child; clinical article; data extraction; diagnostic accuracy; diagnostic test accuracy study; human; image quality; natural language processing; quality control; radiology; retrospective study; workflow; automation; autopsy; clinical audit; England; fetus; infant; information retrieval; newborn; nuclear magnetic resonance imaging; preschool child; procedures; whole body imaging; Automation; Autopsy; Child; Child, Preschool; Clinical Audit; England; Fetus; Humans; Infant; Infant, Newborn; Information Storage and Retrieval; Magnetic Resonance Imaging; Retrospective Studies; Whole Body Imaging; Workflow",Article,Scopus
"Doshi A.M., Huang C., Melamud K., Shanbhogue K., Slywotsky C., Taffel M., Moore W., Recht M., Kim D.","Utility of an Automated Radiology-Pathology Feedback Tool",2019,"Journal of the American College of Radiology",13,"10.1016/j.jacr.2019.03.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065014770&doi=10.1016%2fj.jacr.2019.03.001&partnerID=40&md5=cf9f2a762ff7e7dcc91be53dcc640301","Purpose: To determine the utility of an automated radiology-pathology feedback tool. Methods: We previously developed a tool that automatically provides radiologists with pathology results related to imaging examinations they interpreted. The tool also allows radiologists to mark the results as concordant or discordant. Five abdominal radiologists prospectively scored their own discordant results related to their previously interpreted abdominal ultrasound, CT, and MR interpretations between August 2017 and June 2018. Radiologists recorded whether they would have followed up on the case if there was no automated alert, reason for the discordance, whether the result required further action, prompted imaging rereview, influenced future interpretations, enhanced teaching files, or inspired a research idea. Results: There were 234 total discordances (range 30-66 per radiologist), and 70.5% (165 of 234) of discordances would not have been manually followed up in the absence of the automated tool. Reasons for discordances included missed findings (10.7%; 25 of 234), misinterpreted findings (29.1%; 68 of 234), possible biopsy sampling error (13.3%; 31 of 234), and limitations of imaging techniques (32.1%; 75/234). In addition, 4.7% (11 of 234) required further radiologist action, including report addenda or discussion with referrer or pathologist, and 93.2% (218 of 234) prompted radiologists to rereview the images. Radiologists reported that they learned from 88% (206 of 234) of discordances, 38.6% (90 of 233) of discordances probably or definitely influenced future interpretations, 55.6% (130 of 234) of discordances prompted the radiologist to add the case to his or her teaching files, and 13.7% (32 of 233) inspired a research idea. Conclusion: Automated pathology feedback provides a valuable opportunity for radiologists across experience levels to learn, increase their skill, and improve patient care. © 2019 American College of Radiology","peer learning tools; Quality; radiology-pathology correlation; radiology-pathology discordance","adult; article; biopsy; female; human; learning; male; pathologist; patient care; radiologist; radiology; sampling error; skill; teaching; ultrasound; clinical competence; constructive feedback; diagnostic imaging; pathology; peer group; procedures; prospective study; radiology; Clinical Competence; Diagnostic Imaging; Formative Feedback; Humans; Pathology; Peer Group; Prospective Studies; Radiology",Article,Scopus
"Lacson R., Odigie E., Wang A., Kapoor N., Shinagare A., Boland G., Khorasani R.","Multivariate Analysis of Radiologists’ Usage of Phrases that Convey Diagnostic Certainty",2019,"Academic Radiology",10,"10.1016/j.acra.2018.10.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057287346&doi=10.1016%2fj.acra.2018.10.017&partnerID=40&md5=d678673634facdf8ea965b904b2a0421","Rationale and Objectives: To quantify the use of Diagnostic Certainty Phrases (DCP) in radiology reports, including DCPs with good agreement (including “diagnostic of,” “unlikely” and “represents”) in connoting degree of certainty between providers based on previous studies; and to assess whether modality, presence of a trainee, radiologic subspecialty, and individual radiologists are associated with the usage of DCPs with good agreement. Materials and Methods: This retrospective, IRB-approved study was conducted at an academic medical center. Radiology reports that contain DCPs were identified using information retrieval from all reports generated in 2016, excluding mammograms, obstetrical ultrasound, bone densitometry, and interventional studies. DCPs connoting good agreement were further noted. Of the reports that contained DCPs, a two-level hierarchical generalized linear model with attending as the level-two variable was performed comparing the use of DCP with good agreement while considering trainee involvement, modality, and subspecialty. Results: A total of 159,151 reports out of 370,881 were found to have at least one DCP (43%). Reports of CT scans had the most number of DCP (68% of all CT reports). Breast and abdomen subspecialties were associated with use of DCP with good agreement. There was significant variation in use of DCP with good agreement between physicians that could not be explained by modality, trainee presence, and subspecialty. Conclusion: Phrases to convey diagnostic certainty were commonly used in radiology reports. There is wide variation in usage of DCP with good agreement. Future interventions to reduce variation in use of DCPs may reduce ambiguity and improve quality of radiology reports. © 2018 The Association of University Radiologists","Diagnosis; Diagnostic Imaging; Radiology Reports; Uncertainty","abdomen; article; bone densitometry; breast; diagnostic imaging; human; information retrieval; intervention study; mammography; radiologist; radiology; student; ultrasound; uncertainty; university hospital; x-ray computed tomography; diagnostic imaging; medical record; multivariate analysis; nomenclature; radiography; retrospective study; Abdomen; Academic Medical Centers; Breast; Humans; Medical Records; Multivariate Analysis; Radiography; Radiology; Retrospective Studies; Terminology as Topic; Uncertainty",Article,Scopus
"Meng X., Heinz M.V., Ganoe C.H., Sieberg R.T., Cheung Y.Y., Hassanpour S.","Understanding urgency in radiology reporting: Identifying associations between clinical findings in radiology reports and their prompt communication to referring physicians",2019,"Studies in Health Technology and Informatics",3,"10.3233/SHTI190527","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071462035&doi=10.3233%2fSHTI190527&partnerID=40&md5=3e1246cc578012d280560512ee143a1f","In this study, we aim to develop an automatic pipeline to identify clinical findings in the unstructured text of radiology reports that necessitate communications between radiologists and referring physicians. Our approach identified 20 distinct clinical concepts and highlighted statistically significant concepts with strong associations to cases that require prompt communication. © 2019 International Medical Informatics Association (IMIA) and IOS Press. This article is published online with Open Access by IOS Press and distributed under the terms of the Creative Commons Attribution Non-Commercial License 4.0 (CC BY-NC 4.0).","Communication; Natural language processing; Radiology","Communication; Natural language processing systems; Radiation; Radiology; NAtural language processing; Radiology reporting; Radiology reports; Unstructured texts; Medical informatics; conference paper; human; natural language processing; pipeline; radiologist; radiology; comprehension; interpersonal communication; radiography; radiology; radiology information system; Communication; Comprehension; Radiography; Radiology; Radiology Information Systems",Conference Paper,Scopus
"Bozkurt S., Alkim E., Banerjee I., Rubin D.L.","Automated Detection of Measurements and Their Descriptors in Radiology Reports Using a Hybrid Natural Language Processing Algorithm",2019,"Journal of Digital Imaging",23,"10.1007/s10278-019-00237-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068108494&doi=10.1007%2fs10278-019-00237-9&partnerID=40&md5=4d27c4d31df903f1f4326ea285192a3d","Radiological measurements are reported in free text reports, and it is challenging to extract such measures for treatment planning such as lesion summarization and cancer response assessment. The purpose of this work is to develop and evaluate a natural language processing (NLP) pipeline that can extract measurements and their core descriptors, such as temporality, anatomical entity, imaging observation, RadLex descriptors, series number, image number, and segment from a wide variety of radiology reports (MR, CT, and mammogram). We created a hybrid NLP pipeline that integrates rule-based feature extraction modules and conditional random field (CRF) model for extraction of the measurements from the radiology reports and links them with clinically relevant features such as anatomical entities or imaging observations. The pipeline was trained on 1117 CT/MR reports, and performance of the system was evaluated on an independent set of 100 expert-annotated CT/MR reports and also tested on 25 mammography reports. The system detected 813 out of 806 measurements in the CT/MR reports; 784 were true positives, 29 were false positives, and 0 were false negatives. Similarly, from the mammography reports, 96% of the measurements with their modifiers were extracted correctly. Our approach could enable the development of computerized applications that can utilize summarized lesion measurements from radiology report of varying modalities and improve practice by tracking the same lesions along multiple radiologic encounters. © 2019, The Author(s).","Conditional random fields; Measurement extraction; Natural language processing; Radiology report","Computerized tomography; Extraction; Image segmentation; Pipeline processing systems; Pipelines; Radiation; Radiology; Random processes; Automated detection; Conditional random field; Measurement extractions; NAtural language processing; Radiological measurements; Radiology reports; Relevant features; Treatment planning; Natural language processing systems; algorithm; computer assisted diagnosis; electronic health record; human; mammography; natural language processing; nuclear magnetic resonance imaging; procedures; radiology information system; x-ray computed tomography; Algorithms; Electronic Health Records; Humans; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging; Mammography; Natural Language Processing; Radiology Information Systems; Tomography, X-Ray Computed",Article,Scopus
"Steinkamp J.M., Chambers C., Lalevic D., Zafar H.M., Cook T.S.","Toward Complete Structured Information Extraction from Radiology Reports Using Machine Learning",2019,"Journal of Digital Imaging",30,"10.1007/s10278-019-00234-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068092558&doi=10.1007%2fs10278-019-00234-y&partnerID=40&md5=67f0da62c77e989c258e2be12034ee02","Unstructured and semi-structured radiology reports represent an underutilized trove of information for machine learning (ML)-based clinical informatics applications, including abnormality tracking systems, research cohort identification, point-of-care summarization, semi-automated report writing, and as a source of weak data labels for training image processing systems. Clinical ML systems must be interpretable to ensure user trust. To create interpretable models applicable to all of these tasks, we can build general-purpose systems which extract all relevant human-level assertions or “facts” documented in reports; identifying these facts is an information extraction (IE) task. Previous IE work in radiology has focused on a limited set of information, and extracts isolated entities (i.e., single words such as “lesion” or “cyst”) rather than complete facts, which require the linking of multiple entities and modifiers. Here, we develop a prototype system to extract all useful information in abdominopelvic radiology reports (findings, recommendations, clinical history, procedures, imaging indications and limitations, etc.), in the form of complete, contextualized facts. We construct an information schema to capture the bulk of information in reports, develop real-time ML models to extract this information, and demonstrate the feasibility and performance of the system. © 2019, The Author(s).","Machine learning; Natural language processing; Radiology reports; Structured reporting","Clinical research; Data mining; Information retrieval; Information use; Learning algorithms; Learning systems; Machine learning; Natural language processing systems; Radiation; Radiology; Clinical informatics; General-purpose systems; Information schema; NAtural language processing; Prototype system; Radiology reports; Structured information; Structured reporting; Image processing; data mining; electronic health record; human; machine learning; natural language processing; radiology information system; Data Mining; Electronic Health Records; Humans; Machine Learning; Natural Language Processing; Radiology Information Systems",Article,Scopus
"Radha P., Meena Preethi B.","Machine learning approaches for disease prediction from radiology and pathology reports",2019,"Journal of Green Engineering",9,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073449995&partnerID=40&md5=1775c1ef72a3da826598b8c9dc0b588b","Nowadays disease can spread wider and easier which causes a serious issue to both living and non-living beings. In such situations, we will instantly go to a hospital to treat the patient on the hospital information system. The problem is, hospital with more than thousands of patients feels difficult to categorize the patients and to prioritize whom to give first preference to treat. The Manual reviews of patient’s health records to identify their issues are time consuming. For this purpose health and hospital information system text and data mining is used. Medical text mining is developed now days, but there are some negative effects in this field, that is few diseases and predictions are not found by using older technology. To defeat this, we are developing a method based on text mining systems to distinguish the radiology and pathology reports that classifies the prediction of disease in terms of positive and negative impact of the disease. So in this manuscript, the proposes to classify the radiology and pathology reports using Support Vector Machine(SVM), NaÏve Bayes(NB), and Modified Extreme Learning Machine(MELM) these three classifiers which provides accurate results. Our results see eye to eye fairly well with those obtained using manual reviews, and we therefore believe that it is possible to develop automatic tools for monitoring aspects of patient convenience and priorities. © 2019 the Author(s).","Modified extreme learning machine and radiology and pathology; NaÏve bayes; Support vector machine",,Article,Scopus
"Gupta E.K., Thammasudjarit R., Thakkinstian A.","A Hybrid Engine for Clinical Information Extraction from Radiology Reports",2019,"JCSSE 2019 - 16th International Joint Conference on Computer Science and Software Engineering: Knowledge Evolution Towards Singularity of Man-Machine Intelligence",1,"10.1109/JCSSE.2019.8864178","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074239572&doi=10.1109%2fJCSSE.2019.8864178&partnerID=40&md5=038e5055f636642ee4b81246b49b17f3","Clinical researches and practitioners require data extracted from CT scan reports but most of them are in unstructured data format, which are not ready to analysis. Furthermore, a lag of annotated data makes data extraction more difficult to apply natural language processing techniques to convert unstructured data to be structured data. This study is therefore conducted to apply an automated engine employing topic modeling combined with lexicon and syntactic rule-based approach to extract clinical information from CT scan reports. This prototype shows promising results for constructing clinical datasets for further clinical researches. © 2019 IEEE.","component; Information Extraction; Machine Learning; Natural Language Processing; Text Mining","Artificial intelligence; Clinical research; Computerized tomography; Data handling; Engines; Information retrieval; Learning algorithms; Learning systems; Natural language processing systems; Software engineering; Syntactics; Clinical information; component; NAtural language processing; Radiology reports; Structured data; Syntactic rules; Text mining; Unstructured data; Data mining",Conference Paper,Scopus
"Yan K., Peng Y., Sandfort V., Bagheri M., Lu Z., Summers R.M.","Holistic and comprehensive annotation of clinically significant findings on diverse CT images: Learning from radiology reports and label ontology",2019,"Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",38,"10.1109/CVPR.2019.00872","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073497735&doi=10.1109%2fCVPR.2019.00872&partnerID=40&md5=53fb20812e7d735886ee1df617305b60","In radiologists' routine work, one major task is to read a medical image, e.g., a CT scan, find significant lesions, and describe them in the radiology report. In this paper, we study the lesion description or annotation problem. Given a lesion image, our aim is to predict a comprehensive set of relevant labels, such as the lesion's body part, type, and attributes, which may assist downstream fine-grained diagnosis. To address this task, we first design a deep learning module to extract relevant semantic labels from the radiology reports associated with the lesion images. With the images and text-mined labels, we propose a lesion annotation network (LesaNet) based on a multilabel convolutional neural network (CNN) to learn all labels holistically. Hierarchical relations and mutually exclusive relations between the labels are leveraged to improve the label prediction accuracy. The relations are utilized in a label expansion strategy and a reliable hard example mining algorithm. We also attach a simple score propagation layer on LesaNet to enhance recall and explore implicit relation between labels. Multilabel metric learning is combined with classification to enable interpretable prediction. We evaluated LesaNet on the public DeepLesion dataset, which contains over 32K diverse lesion images. Experiments show that LesaNet can precisely annotate the lesions using an ontology of 171 fine-grained labels with an average AUC of 0.9344. © 2019 IEEE.","Biological and Cell Microscopy; Categorization; Datasets and Evaluation; Deep Learning; Medical; Recognition: Detection; Represen; Retrieval","Backpropagation; Computer vision; Convolutional neural networks; Deep learning; Diagnosis; Forecasting; Image annotation; Medical imaging; Ontology; Radiation; Radiology; Semantics; Categorization; Datasets and Evaluation; Medical; Represen; Retrieval; Computerized tomography",Conference Paper,Scopus
"Waymel Q., Badr S., Demondion X., Cotten A., Jacques T.","Impact of the rise of artificial intelligence in radiology: What do radiologists think?",2019,"Diagnostic and Interventional Imaging",87,"10.1016/j.diii.2019.03.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065058683&doi=10.1016%2fj.diii.2019.03.015&partnerID=40&md5=95325c8998b52335dd45ee5910309127","Purpose: The purpose of this study was to assess the perception, knowledge, wishes and expectations of a sample of French radiologists towards the rise of artificial intelligence (AI) in radiology. Material and method: A general data protection regulation-compliant electronic survey was sent by e-mail to the 617 radiologists registered in the French departments of Nord and Pas-de-Calais (93 radiology residents and 524 senior radiologists), from both public and private institutions. The survey included 42 questions focusing on AI in radiology, and data were collected between January 16th and January 31st, 2019. The answers were analyzed together by a senior radiologist and a radiology resident. Results: A total of 70 radiology residents and 200 senior radiologists participated to the survey, which corresponded to a response rate of 43.8% (270/617). One hundred ninety-eight radiologists (198/270; 73.3%) estimated they had received insufficient previous information on AI. Two hundred and fifty-five respondents (255/270; 94.4%) would consider attending a generic continuous medical education in this field and 187 (187/270; 69.3%) a technically advanced training on AI. Two hundred and fourteen respondents (214/270; 79.3%) thought that AI will have a positive impact on their future practice. The highest expectations were the lowering of imaging-related medical errors (219/270; 81%), followed by the lowering of the interpretation time of each examination (201/270; 74.4%) and the increase in the time spent with patients (141/270; 52.2%). Conclusion: While respondents had the feeling of receiving insufficient previous information on AI, they are willing to improve their knowledge and technical skills on this field. They share an optimistic view and think that AI will have a positive impact on their future practice. A lower risk of imaging-related medical errors and an increase in the time spent with patients are among their main expectations. © 2019 Société française de radiologie","Artificial intelligence (AI); Machine learning; Radiologists; Survey","adult; article; artificial intelligence; e-mail; expectation; female; human; machine learning; major clinical study; male; medical education; medical error; perception; radiologist; radiology; resident; skill; aged; attitude to health; France; health personnel attitude; middle aged; self report; young adult; Adult; Aged; Artificial Intelligence; Attitude of Health Personnel; Female; France; Health Knowledge, Attitudes, Practice; Humans; Male; Middle Aged; Radiology; Self Report; Young Adult",Article,Scopus
"Brown A.D., Kachura J.R.","Natural Language Processing of Radiology Reports in Patients With Hepatocellular Carcinoma to Predict Radiology Resource Utilization",2019,"Journal of the American College of Radiology",21,"10.1016/j.jacr.2018.12.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062230428&doi=10.1016%2fj.jacr.2018.12.004&partnerID=40&md5=5a1aca28111c4222726f80b618c90c3b","Objective: Radiology is a finite health care resource in high demand at most health centers. However, anticipating fluctuations in demand is a challenge because of the inherent uncertainty in disease prognosis. The aim of this study was to explore the potential of natural language processing (NLP)to predict downstream radiology resource utilization in patients undergoing surveillance for hepatocellular carcinoma (HCC). Materials and Methods: All HCC surveillance CT examinations performed at our institution from January 1, 2010, to October 31, 2017 were selected from our departmental radiology information system. We used open source NLP and machine learning software to parse radiology report text into bag-of-words and term frequency–inverse document frequency (TF-IDF)representations. Three machine learning models—logistic regression, support vector machine (SVM), and random forest—were used to predict future utilization of radiology department resources. A test data set was used to calculate accuracy, sensitivity, and specificity in addition to the area under the curve (AUC). Results: As a group, the bag-of-word models were slightly inferior to the TF-IDF feature extraction approach. The TF-IDF + SVM model outperformed all other models with an accuracy of 92%, a sensitivity of 83%, and a specificity of 96%, with an AUC of 0.971. Conclusions: NLP-based models can accurately predict downstream radiology resource utilization from narrative HCC surveillance reports and has potential for translation to health care management where it may improve decision making, reduce costs, and broaden access to care. © 2018 American College of Radiology","hepatocellular carcinoma; Natural language processing; practice management; radiology reports","accuracy; adult; age; algorithm; area under the curve; Article; cancer epidemiology; cancer patient; cancer prognosis; carcinoma; computer assisted tomography; diagnostic accuracy; diagnostic test accuracy study; disease exacerbation; electric potential; false negative result; female; follow up; health care utilization; human; liver cell carcinoma; logistic regression analysis; machine learning; major clinical study; male; narrative; natural language processing; nuclear magnetic resonance imaging; prediction; predictive value; radiology; radiology department; radiology information system; radiology resource utilization; random forest; receiver operating characteristic; retrospective study; sensitivity and specificity; sex; software; support vector machine; term frequency inverse document frequency; aged; diagnostic imaging; economics; factual database; health care planning; liver cell carcinoma; liver tumor; middle aged; Ontario; procedures; research; x-ray computed tomography; Aged; Area Under Curve; Carcinoma, Hepatocellular; Databases, Factual; Female; Health Resources; Humans; Liver Neoplasms; Machine Learning; Male; Middle Aged; Natural Language Processing; Ontario; Predictive Value of Tests; Radiology Department, Hospital; Radiology Information Systems; Research Report; Retrospective Studies; ROC Curve; Sensitivity and Specificity; Tomography, X-Ray Computed",Article,Scopus
"Banerjee I., Ling Y., Chen M.C., Hasan S.A., Langlotz C.P., Moradzadeh N., Chapman B., Amrhein T., Mong D., Rubin D.L., Farri O., Lungren M.P.","Comparative effectiveness of convolutional neural network (CNN) and recurrent neural network (RNN) architectures for radiology text report classification",2019,"Artificial Intelligence in Medicine",141,"10.1016/j.artmed.2018.11.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057000826&doi=10.1016%2fj.artmed.2018.11.004&partnerID=40&md5=c8bf0590b623597d3a06699a6f40abf4","This paper explores cutting-edge deep learning methods for information extraction from medical imaging free text reports at a multi-institutional scale and compares them to the state-of-the-art domain-specific rule-based system – PEFinder and traditional machine learning methods – SVM and Adaboost. We proposed two distinct deep learning models – (i) CNN Word – Glove, and (ii) Domain phrase attention-based hierarchical recurrent neural network (DPA-HNN), for synthesizing information on pulmonary emboli (PE) from over 7370 clinical thoracic computed tomography (CT) free-text radiology reports collected from four major healthcare centers. Our proposed DPA-HNN model encodes domain-dependent phrases into an attention mechanism and represents a radiology report through a hierarchical RNN structure composed of word-level, sentence-level and document-level representations. Experimental results suggest that the performance of the deep learning models that are trained on a single institutional dataset, are better than rule-based PEFinder on our multi-institutional test sets. The best F1 score for the presence of PE in an adult patient population was 0.99 (DPA-HNN) and for a pediatrics population was 0.99 (HNN) which shows that the deep learning models being trained on adult data, demonstrated generalizability to pediatrics population with comparable accuracy. Our work suggests feasibility of broader usage of neural network models in automated classification of multi-institutional imaging text reports for a variety of applications including evaluation of imaging utilization, imaging yield, clinical decision support tools, and as part of automated classification of large corpus for medical imaging deep learning work. © 2018 Elsevier B.V.","Convolutional neural network (CNN); Pulmonary embolism; Radiology report analysis; Recurrent neural network (RNN); Text report classification","Adaptive boosting; Computerized tomography; Convolution; Decision support systems; Medical imaging; Medical information systems; Pediatrics; Population statistics; Radiation; Radiology; Recurrent neural networks; Statistical tests; Text processing; Automated classification; Clinical decision support; Comparative effectiveness; Convolutional Neural Networks (CNN); Machine learning methods; Pulmonary embolism; Radiology reports; Recurrent neural network (RNN); Deep learning; adult; Article; artificial neural network; classification algorithm; computer assisted tomography; controlled study; convolutional neural network; deep learning; gold standard; human; lung embolism; priority journal; pulmonary artery; qualitative analysis; radiation attenuation; radiology; recurrent neural network; semantics; sensitivity analysis; support vector machine; Systematized Nomenclature of Medicine; comparative study; diagnostic imaging; information retrieval; thorax radiography; Deep Learning; Humans; Information Storage and Retrieval; Neural Networks, Computer; Pulmonary Embolism; Radiography, Thoracic",Article,Scopus
"Brown M., Browning P., Wahi-Anwar M.W., Murphy M., Delgado J., Greenspan H., Abtin F., Ghahremani S., Yaghmai N., da Costa I., Becker M., Goldin J.","Integration of Chest CT CAD into the Clinical Workflow and Impact on Radiologist Efficiency",2019,"Academic Radiology",18,"10.1016/j.acra.2018.07.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051076929&doi=10.1016%2fj.acra.2018.07.006&partnerID=40&md5=ee6a9f0b4bed37a11448c64ca7084184","Rationale and Objectives: The purpose of this paper is to describe the integration of a commercial chest CT computer-aided detection (CAD) system into the clinical radiology reporting workflow and perform an initial investigation of its impact on radiologist efficiency. It seeks to complement research into CAD sensitivity and specificity of stand-alone systems, by focusing on report generation time when the CAD is integrated into the clinical workflow. Materials and Methods: A commercial chest CT CAD software that provides automated detection and measurement of lung nodules, ascending and descending aorta, and pleural effusion was integrated with a commercial radiology report dictation application. The CAD system automatically prepopulated a radiology report template, thus offering the potential for increased efficiency. The integrated system was evaluated using 40 scans from a publicly available lung nodule database. Each scan was read using two methods: (1) without CAD analytics, i.e., manually populated report with measurements using electronic calipers, and (2) with CAD analytics to prepopulate the report for reader review and editing. Three radiologists participated as readers in this study. Results: CAD assistance reduced reading times by 7%–44%, relative to the conventional manual method, for the three radiologists from opening of the case to signing of the final report. Conclusion: This study provides an investigation of the impact of CAD and measurement on chest CTs within a clinical reporting workflow. Prepopulation of a report with automated nodule and aorta measurements yielded substantial time savings relative to manual measurement and entry. © 2018 The Association of University Radiologists","Computer-aided detection; Lung nodules","Article; ascending aorta; automation; cardiovascular parameters; clinical practice; computer aided design; descending aorta; digital imaging and communications in medicine; human; lung nodule; measurement accuracy; pleura effusion; priority journal; radiologist; sensitivity and specificity; thorax radiography; workflow; x-ray computed tomography; computer assisted diagnosis; diagnostic imaging; lung nodule; lung tumor; multiple pulmonary nodules; organization and management; productivity; radiology; software; thorax radiography; time factor; workflow; x-ray computed tomography; Efficiency; Humans; Lung Neoplasms; Multiple Pulmonary Nodules; Radiographic Image Interpretation, Computer-Assisted; Radiography, Thoracic; Radiology; Sensitivity and Specificity; Software; Solitary Pulmonary Nodule; Time Factors; Tomography, X-Ray Computed; Workflow",Article,Scopus
"Wang Y., Mehrabi S., Sohn S., Atkinson E.J., Amin S., Liu H.","Natural language processing of radiology reports for identification of skeletal site-specific fractures",2019,"BMC Medical Informatics and Decision Making",18,"10.1186/s12911-019-0780-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063931750&doi=10.1186%2fs12911-019-0780-5&partnerID=40&md5=343d6a91453de4790be235799ccae57c","Background: Osteoporosis has become an important public health issue. Most of the population, particularly elderly people, are at some degree of risk of osteoporosis-related fractures. Accurate identification and surveillance of patient populations with fractures has a significant impact on reduction of cost of care by preventing future fractures and its corresponding complications. Methods: In this study, we developed a rule-based natural language processing (NLP) algorithm for identification of twenty skeletal site-specific fractures from radiology reports. The rule-based NLP algorithm was based on regular expressions developed using MedTagger, an NLP tool of the Apache Unstructured Information Management Architecture (UIMA) pipeline to facilitate information extraction from clinical narratives. Radiology notes were retrieved from the Mayo Clinic electronic health records data warehouse. We developed rules for identifying each fracture type according to physicians' knowledge and experience, and refined these rules via verification with physicians. This study was approved by the institutional review board (IRB) for human subject research. Results: We validated the NLP algorithm using the radiology reports of a community-based cohort at Mayo Clinic with the gold standard constructed by medical experts. The micro-averaged results of sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and F1-score of the proposed NLP algorithm are 0.930, 1.0, 1.0, 0.941, 0.961, respectively. The F1-score is 1.0 for 8 fractures, and above 0.9 for a total of 17 out of 20 fractures (85%). Conclusions: The results verified the effectiveness of the proposed rule-based NLP algorithm in automatic identification of osteoporosis-related skeletal site-specific fractures from radiology reports. The NLP algorithm could be utilized to accurately identify the patients with fractures and those who are also at high risk of future fractures due to osteoporosis. Appropriate care interventions to those patients, not only the most at-risk patients but also those with emerging risk, would significantly reduce future fractures. © 2019 The Author(s).","Electronic health records; Fracture identification; Natural language processing; Radiology reports",,Article,Scopus
"Lim P.S., Schneider D., Sternlieb J., Taupin M., Sich N., Dian J., Jameson E., Frambes B., Taylor S.","Process improvement for follow-up radiology report recommendations of lung nodules",2019,"BMJ Open Quality",14,"10.1136/bmjoq-2018-000370","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076620372&doi=10.1136%2fbmjoq-2018-000370&partnerID=40&md5=e65fc14908efbe0ed50848c3ce18ab14","In the modern healthcare system, there are still wide gaps of communication of imaging results to physician and patient stakeholders and tracking of whether follow-up has occurred. Patients are also unaware of the significance of findings in radiology reports. With the increase in use of cross-sectional imaging such as CT, patients are not only being diagnosed with primary urgent findings but also with incidental findings such as lung nodules; however, they are not being told of their imaging findings nor what actions to take to mitigate their risks. In addition, patients at high risk for developing lung cancer often obtain serial CT scans, but tracking these patients is challenging for the clinician. In order to advance quality improvement goals and improve patient outcomes, we developed a custom application and business process for radiology practitioners that mines available healthcare data, identifies patients with lung nodules in need of follow-up imaging, notifies the patient and the primary care physician via mail, and measures process efficacy via executed follow-up screenings and captured patient condition. This integrated analytics and communication process increased our average rate of patient follow-ups for lung nodules from 26.50 in 2015 to 59.72% in 2017. 17.18% of these patients had new lung nodules or worsening severity of lung findings detected at follow-up. This new process has added missing quality and care coordination to an at-risk patient population. Problem Communication of imaging results and follow-up recommendations to patients and primary care providers (PCPs) is a challenge for healthcare systems. In addition, tracking whether a patient's follow-up has been completed is another significant gap in care coordination. Patients are often unaware of or cannot even understand the significance of radiology findings or follow-up recommendations reported after imaging procedures. In addition, patients may not have a primary physician listed at time of imaging if the first encounter is in the emergency room (ER) or if their primary care physician or specialist works in a different electronic health record platform. Communication of imaging results to different healthcare providers is challenging with the myriad of existing electronic health record systems that often lack interoperability with other clinical entities. Description of lung nodules in radiology reports can vary widely if a standardised lexicon is not used. Moreover, follow-up recommendations by radiologists can be varied for certain size lung nodules because an individual's risk factors to develop lung cancer may not be known at the time of dictation. Approximately 500 000 radiology imaging procedures are interpreted and performed annually by a single private group of 33 radiologists located at a 665-bed regional referral centre and at a 140-bed acute care community hospital, both located in the suburbs of a major metropolitan city. Management of this volume of patients in the health system can be overwhelming to nurse navigators, and there is usually no system in place for primary care physicians to follow-up lung nodules found unexpectedly on inpatient images. The goal of this project was to develop a better automated tracking method and communication tool to reduce the likelihood that needed follow-up studies are missed by patients and clinicians. © Author(s) (or their employer(s)) 2019. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.","continuous quality improvement; quality improvement; reminders; transitions in care","aftercare; diagnostic imaging; electronic health record; human; incidental finding; interdisciplinary communication; lung; lung tumor; pathophysiology; procedures; radiology; total quality management; Aftercare; Electronic Health Records; Humans; Incidental Findings; Interdisciplinary Communication; Lung; Lung Neoplasms; Process Assessment, Health Care; Quality Improvement; Radiology",Article,Scopus
"Gale W., Oakden-Rayner L., Carneiro G., Palmer L.J., Bradley A.P.","Producing radiologist-quality reports for interpretable deep learning.",2019,"Proceedings - International Symposium on Biomedical Imaging",21,"10.1109/ISBI.2019.8759236","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073910330&doi=10.1109%2fISBI.2019.8759236&partnerID=40&md5=fc2ce5d2c9e7e453df24936383b202da","Current approaches to explaining the decisions of deep learning systems for medical tasks have focused on visualising the elements that have contributed to each decision. We argue that such approaches are not enough to 'open the black box' of medical decision making systems because they are missing a key component that has been used as a standard communication tool between doctors for centuries: language. We propose a model-agnostic interpretability method that involves training a simple recurrent neural network model to produce descriptive sentences to clarify the decision of deep learning classifiers. We test our method on the task of detecting hip fractures from frontal pelvic x-rays. This process requires minimal additional labelling despite producing text containing elements that the original deep learning classification model was not specifically trained to detect. The experimental results show that: 1) the sentences produced by our method consistently contain the desired information, 2) the generated sentences are preferred by the cohort of doctors tested compared to current tools that create saliency maps, and 3) the combination of visualisations and generated text is better than either alone. © 2019 IEEE.","Bone; Fractures; Pattern recognition; Text generation; X-ray imaging","Bone; Character recognition; Decision making; Fracture; Medical imaging; Pattern recognition; Recurrent neural networks; Text processing; Classification models; Communication tools; Interpretability; Learning classifiers; Medical decision-making systems; Simple recurrent neural networks; Text generations; Xray imaging; Deep learning",Conference Paper,Scopus
"Lee C., Kim Y., Kim Y.S., Jang J.","Automatic disease annotation from radiology reports using artificial intelligence implemented by a recurrent neural network",2019,"American Journal of Roentgenology",21,"10.2214/AJR.18.19869","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063627732&doi=10.2214%2fAJR.18.19869&partnerID=40&md5=e117f73af3e209fa0b4c21e6608497fc","OBJECTIVE. Radiology reports are rich resources for biomedical researchers. Before utilization of radiology reports, experts must manually review these reports to identify the categories. In fact, automatically categorizing electronic medical record (EMR) text with key annotation is difficult because it has a free-text format. To address these problems, we developed an automated system for disease annotation. MATERIALS AND METHODS. Reports of musculoskeletal radiography examinations performed from January 1, 2016, through December 31, 2016, were exported from the database of Hanyang University Medical Center. After sentences not written in English and sentences containing typos were excluded, 3032 sentences were included. We built a system that uses a recurrent neural network (RNN) to automatically identify fracture and nonfracture cases as a preliminary study. We trained and tested the system using orthopedic surgeon–classified reports. We evaluated the system for the number of layers in the following two ways: the word error rate of the output sentences and performance as a binary classifier using standard evaluation metrics including accuracy, precision, recall, and F1 score. RESULTS. The word error rate using Levenshtein distance showed the best performance in the three-layer model at 1.03%. The three-layer model also showed the highest overall performance with the highest precision (0.967), recall (0.967), accuracy (0.982), and F1 score (0.967). CONCLUSION. Our results indicate that the RNN-based system has the ability to classify important findings in radiology reports with a high F1 score. We expect that our system can be used in cohort construction such as for retrospective studies because it is efficient for analyzing a large amount of data. © American Roentgen Ray Society.","Automatic annotation; Deep learning; Natural language processing; Radiology reports; Recurrent neural network","accuracy; Article; artificial intelligence; artificial neural network; automation; cohort analysis; controlled study; electronic medical record; human; machine learning; medical informatics; priority journal; radiology; retrospective study; scoring system; short term memory; support vector machine; thorax radiography; classification; diagnostic imaging; electronic health record; factual database; musculoskeletal disease; natural language processing; procedures; radiology; Artificial Intelligence; Databases, Factual; Electronic Health Records; Humans; Musculoskeletal Diseases; Natural Language Processing; Neural Networks, Computer; Radiology",Article,Scopus
"Carrodeguas E., Lacson R., Swanson W., Khorasani R.","Use of Machine Learning to Identify Follow-Up Recommendations in Radiology Reports",2019,"Journal of the American College of Radiology",47,"10.1016/j.jacr.2018.10.020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059132595&doi=10.1016%2fj.jacr.2018.10.020&partnerID=40&md5=4b2456d417f5f29c70f7caa53e6b7ccd","Purpose: The aims of this study were to assess follow-up recommendations in radiology reports, develop and assess traditional machine learning (TML) and deep learning (DL) models in identifying follow-up, and benchmark them against a natural language processing (NLP) system. Methods: This HIPAA-compliant, institutional review board–approved study was performed at an academic medical center generating >500,000 radiology reports annually. One thousand randomly selected ultrasound, radiography, CT, and MRI reports generated in 2016 were manually reviewed and annotated for follow-up recommendations. TML (support vector machines, random forest, logistic regression) and DL (recurrent neural nets) algorithms were constructed and trained on 850 reports (training data), with subsequent optimization of model architectures and parameters. Precision, recall, and F1 score were calculated on the remaining 150 reports (test data). A previously developed and validated NLP system (iSCOUT) was also applied to the test data, with equivalent metrics calculated. Results: Follow-up recommendations were present in 12.7% of reports. The TML algorithms achieved F1 scores of 0.75 (random forest), 0.83 (logistic regression), and 0.85 (support vector machine) on the test data. DL recurrent neural nets had an F1 score of 0.71; iSCOUT also had an F1 score of 0.71. Performance of both TML and DL methods by F1 scores appeared to plateau after 500 to 700 samples while training. Conclusions: TML and DL are feasible methods to identify follow-up recommendations. These methods have great potential for near real-time monitoring of follow-up recommendations in radiology reports. © 2018 American College of Radiology","deep learning; follow-up recommendations; Machine learning; natural language processing; radiology report","article; controlled study; follow up; human; institutional review; machine learning; major clinical study; monitoring; natural language processing; nuclear magnetic resonance imaging; radiography; radiology; random forest; randomized controlled trial; recall; support vector machine; ultrasound; university hospital; benchmarking; diagnostic imaging; natural language processing; patient care; protocol compliance; Benchmarking; Continuity of Patient Care; Diagnostic Imaging; Guideline Adherence; Humans; Machine Learning; Natural Language Processing",Article,Scopus
"Tahmasebi A.M., Zhu H., Mankovich G., Prinsen P., Klassen P., Pilato S., van Ommering R., Patel P., Gunn M.L., Chang P.","Automatic Normalization of Anatomical Phrases in Radiology Reports Using Unsupervised Learning",2019,"Journal of Digital Imaging",8,"10.1007/s10278-018-0116-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051630987&doi=10.1007%2fs10278-018-0116-5&partnerID=40&md5=2fab30223d30dace8909359b91f4ba1f","In today’s radiology workflow, free-text reporting is established as the most common medium to capture, store, and communicate clinical information. Radiologists routinely refer to prior radiology reports of a patient to recall critical information for new diagnosis, which is quite tedious, time consuming, and prone to human error. Automatic structuring of report content is desired to facilitate such inquiry of information. In this work, we propose an unsupervised machine learning approach to automatically structure radiology reports by detecting and normalizing anatomical phrases based on the Systematized Nomenclature of Medicine—Clinical Terms (SNOMED CT) ontology. The proposed approach combines word embedding-based semantic learning with ontology-based concept mapping to derive the desired concept normalization. The word embedding model was trained using a large corpus of unlabeled radiology reports. Fifty-six anatomical labels were extracted from SNOMED CT as class labels of the whole human anatomy. The proposed framework was compared against a number of state-of-the-art supervised and unsupervised approaches. Radiology reports from three different clinical sites were manually labeled for testing. The proposed approach outperformed other techniques yielding an average precision of 82.6%. The proposed framework boosts the coverage and performance of conventional approaches for concept normalization, by applying word embedding techniques in semantic learning, while avoiding the challenge of having access to a large amount of annotated data, which is typically required for training classifiers. © 2018, Society for Imaging Informatics in Medicine.","Anatomical classification; Concept normalization; Radiology reports; Semantic learning; SNOMED CT; word2vec","Diagnosis; Learning systems; Ontology; Radiology; Anatomical classification; Concept normalizations; Radiology reports; Semantic learning; SNOMED-CT; word2vec; Radiation; anatomy; article; classifier; concept mapping; embedding; human; ontology; radiology; Systematized Nomenclature of Medicine; unsupervised machine learning; electronic health record; nomenclature; procedures; radiology; workflow; Electronic Health Records; Humans; Radiology; Terminology as Topic; Unsupervised Machine Learning; Workflow",Article,Scopus
"Bendersky M., Wu J., Syeda-Mahmood T.","Classification of radiology reports by modality and anatomy: A comparative study",2019,"Proceedings - 2018 IEEE International Conference on Bioinformatics and Biomedicine, BIBM 2018",,"10.1109/BIBM.2018.8621320","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062496491&doi=10.1109%2fBIBM.2018.8621320&partnerID=40&md5=c4ce472ab0ed9800dd0eb23aa5eaf997","Data labeling is currently a time-consuming task that often requires expert knowledge. In research settings, the availability of correctly labeled data is crucial to ensure that model predictions are accurate and useful. We propose relatively simple machine learning-based models that achieve high performance metrics in the binary and multiclass classification of radiology reports. We compare the performance of these algorithms to that of a data-driven approach based on NLP, and find that the logistic regression classifier outperforms all other models, in both the binary and multiclass classification tasks. We then choose the logistic regression binary classifier to predict chest X-ray (CXR)/ non-chest X-ray non-CXR) labels in reports from different datasets, unseen during any training phase of any of the models. Even in unseen report collections, the binary logistic regression classifier achieves average precision values of above 0.9. Based on the regression coefficient values, we also identify frequent tokens in CXR and non-CXR reports that are features with possibly high predictive power. © 2018 IEEE.","logistic regression; machine learning; NLP; SVM; text classification","Bioinformatics; Learning systems; Machine learning; Machinery; Natural language processing systems; Radiation; Radiology; Regression analysis; Text processing; X rays; Binary logistic regression; Data-driven approach; Logistic regression classifier; Logistic regressions; Multi-class classification; Regression coefficient; Text classification; Time-consuming tasks; Classification (of information)",Conference Paper,Scopus
"Rayan J.C., Reddy N., Herman Kan J., Zhang W., Annapragada A.","Binomial classification of pediatric elbow fractures using a deep learning multiview approach emulating radiologist decision making",2019,"Radiology: Artificial Intelligence",52,"10.1148/ryai.2019180015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110176211&doi=10.1148%2fryai.2019180015&partnerID=40&md5=416b11cba1f8702444a916e98b5c6528","Purpose: To determine the feasibility of using deep learning with a multiview approach, similar to how a human radiologist reviews multiple images, for binomial classification of acute pediatric elbow radiographic abnormalities. Materials and Methods: A total of 21 456 radiographic studies containing 58 817 images of the elbow and associated radiology reports over the course of a 4-year period from January 2014 through December 2017 at a dedicated children’s hospital were retrospectively retrieved. Mean age was 7.2 years, and 43% were female patients. The studies were binomially classified, based on the reports, as either positive or negative for acute or subacute traumatic abnormality. The studies were randomly divided into a training set containing 20 350 studies and a validation set containing the remaining 1106 studies. A multiview approach was used for the model by combining both a convolutional neural network and recurrent neural network to interpret an entire series of three radiographs together. Sensitivity, specificity, positive predictive value, negative predictive value, area under the receiver operating characteristic curve (AUC), and their 95% confidence intervals were calculated. Results: AUC was 0.95, and accuracy was 88% for the model on the studied dataset. Sensitivity for the model was 91% (536 of 590), while the specificity for the model was 84% (434 of 516). Of 241 supracondylar fractures, one was missed. Of 88 lateral condylar fractures, one was missed. Of 77 elbow effusions without fracture, 15 were missed. Of 184 other abnormalities, 37 were missed. Conclusion: Deep learning can effectively classify acute and nonacute pediatric elbow abnormalities on radiographs in the setting of trauma. A recurrent neural network was used to classify an entire radiographic series, arrive at a decision based on all views, and identify fractures in pediatric patients with variable skeletal immaturity. © RSNA, 2019.",,"adolescent; adult; aged; algorithm; area under the curve; Article; artificial neural network; binomial distribution; child; cropping system; decision making; deep learning; diagnostic accuracy; diagnostic radiologist; diagnostic test accuracy study; distal humeral fracture; edema; elbow fracture; false negative result; female; femoral neck fracture; femur diaphysis; gated recurrent unit network; human; humeral supracondylar fracture; infant; joint effusion; major clinical study; male; newborn; osteochondroma; predictive value; preschool child; proximal radius fracture; proximal ulna; receiver operating characteristic; retrospective study; school child; scoring system; sensitivity and specificity; training; validation process; very elderly",Article,Scopus
"Senders J.T., Karhade A.V., Cote D.J., Mehrtash A., Lamba N., DiRisio A., Muskens I.S., Gormley W.B., Smith T.R., Broekman M.L.D., Arnaout O.","Natural language processing for automated quantification of brain metastases reported in free-text radiology reports",2019,"JCO Clinical Cancer Informatics",24,"10.1200/CCI.18.00138","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077483404&doi=10.1200%2fCCI.18.00138&partnerID=40&md5=224e50393339d6aa5c011108736292fa","PURPOSE Although the bulk of patient-generated health data are increasing exponentially, their use is impeded because most data come in unstructured format, namely as free-text clinical reports. A variety of natural language processing (NLP) methods have emerged to automate the processing of free text ranging from statistical to deep learning–based models; however, the optimal approach for medical text analysis remains to be determined. The aim of this study was to provide a head-to-head comparison of novel NLP techniques and inform future studies about their utility for automated medical text analysis. PATIENTS AND METHODS Magnetic resonance imaging reports of patients with brain metastases treated in two tertiary centers were retrieved and manually annotated using a binary classification (single metastasis v two or more metastases). Multiple bag-of-words and sequence-based NLP models were developed and compared after randomly splitting the annotated reports into training and test sets in an 80:20 ratio. RESULTS A total of 1,479 radiology reports of patients diagnosed with brain metastases were retrieved. The least absolute shrinkage and selection operator (LASSO) regression model demonstrated the best overall performance on the hold-out test set with an area under the receiver operating characteristic curve of 0.92 (95% CI, 0.89 to 0.94), accuracy of 83% (95% CI, 80% to 87%), calibration intercept of –0.06 (95% CI, –0.14 to 0.01), and calibration slope of 1.06 (95% CI, 0.95 to 1.17). CONCLUSION Among various NLP techniques, the bag-of-words approach combined with a LASSO regression model demonstrated the best overall performance in extracting binary outcomes from free-text clinical reports. This study provides a framework for the development of machine learning-based NLP models as well as a clinical vignette of patients diagnosed with brain metastases. © 2019 by American Society of Clinical Oncology.",,"Article; automation; brain metastasis; calibration; cancer classification; cancer patient; classification algorithm; controlled study; deep learning; diagnostic accuracy; diagnostic test accuracy study; human; image analysis; least absolute shrinkage and selection operator regression model; major clinical study; multicenter study; natural language processing; neuroimaging; nuclear magnetic resonance imaging; priority journal; receiver operating characteristic; regression analysis; signal processing; tertiary health care; algorithm; brain tumor; diagnostic imaging; electronic health record; medical informatics; nuclear magnetic resonance imaging; procedures; radiology; reproducibility; research; Algorithms; Brain Neoplasms; Electronic Health Records; Humans; Magnetic Resonance Imaging; Medical Informatics; Natural Language Processing; Radiology; Reproducibility of Results; Research Report; ROC Curve",Article,Scopus
"Yuan J., Liao H., Luo R., Luo J.","Automatic Radiology Report Generation Based on Multi-view Image Fusion and Medical Concept Enrichment",2019,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",88,"10.1007/978-3-030-32226-7_80","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075835176&doi=10.1007%2f978-3-030-32226-7_80&partnerID=40&md5=b005889dca1212522f350a4fb5907b3b","Generating radiology reports is time-consuming and requires extensive expertise in practice. Therefore, reliable automatic radiology report generation is highly desired to alleviate the workload. Although deep learning techniques have been successfully applied to image classification and image captioning tasks, radiology report generation remains challenging in regards to understanding and linking complicated medical visual contents with accurate natural language descriptions. In addition, the data scales of open-access datasets that contain paired medical images and reports remain very limited. To cope with these practical challenges, we propose a generative encoder-decoder model and focus on chest x-ray images and reports with the following improvements. First, we pretrain the encoder with a large number of chest x-ray images to accurately recognize 14 common radiographic observations, while taking advantage of the multi-view images by enforcing the cross-view consistency. Second, we synthesize multi-view visual features based on a sentence-level attention mechanism in a late fusion fashion. In addition, in order to enrich the decoder with descriptive semantics and enforce the correctness of the deterministic medical-related contents such as mentions of organs or diagnoses, we extract medical concepts based on the radiology reports in the training data and fine-tune the encoder to extract the most frequent medical concepts from the x-ray images. Such concepts are fused with each decoding step by a word-level attention model. The experimental results conducted on the Indiana University Chest X-Ray dataset demonstrate that the proposed model achieves the state-of-the-art performance compared with other baseline approaches. © 2019, Springer Nature Switzerland AG.",,"Decoding; Deep learning; Diagnosis; Image classification; Image enhancement; Image fusion; Medical computing; Radiation; Radiology; Semantics; Signal encoding; Visual languages; X ray radiography; Attention mechanisms; Chest X-ray image; Descriptive semantics; Indiana University; Learning techniques; Natural languages; Radiology reports; State-of-the-art performance; Medical imaging",Conference Paper,Scopus
"Nunes N., Martins B., André da Silva N., Leite F., J. Silva M.","A multi-modal deep learning method for classifying chest radiology exams",2019,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",7,"10.1007/978-3-030-30241-2_28","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072899138&doi=10.1007%2f978-3-030-30241-2_28&partnerID=40&md5=ec29420cdc60ec2afd4d077c88e91b56","Non-invasive medical imaging techniques, such as radiography or computed tomography, are extensively used in hospitals and clinics for the diagnosis of diverse injuries or diseases. However, the interpretation of these images, which often results in a free-text radiology report and/or a classification, requires specialized medical professionals, leading to high labor costs and waiting lists. Automatic inference of thoracic diseases from the results of chest radiography exams, e.g. for the purpose of indexing these documents, is still a challenging task, even if combining images with the free-text reports. Deep neural architectures can contribute to a more efficient indexing of radiology exams (e.g., associating the data to diagnostic codes), providing interpretable classification results that can guide the domain experts. This work proposes a novel multi-modal approach, combining a dual path convolutional neural network for processing images with a bidirectional recurrent neural network for processing text, enhanced with attention mechanisms and leveraging pre-trained clinical word embeddings. The experimental results show interesting patterns, e.g. validating the high performance of the individual components, and showing promising results for the multi-modal processing of radiology examination data, particularly when pre-training the components of the model with large pre-existing datasets (i.e., a 10% increase in terms of the average value for the areas under the receiver operating characteristic curves). © Springer Nature Switzerland AG 2019.","Classification of radiology exams; Deep learning; Learning from multi-modal data; Machine learning in medicine","Automatic indexing; Computerized tomography; Diagnosis; Image enhancement; Indexing (of information); Large dataset; Learning algorithms; Medical imaging; Modal analysis; Object recognition; Radiation; Radiography; Radiology; Recurrent neural networks; Text processing; Wages; Bidirectional recurrent neural networks; Classification results; Convolutional neural network; Individual components; Medical professionals; Multi-modal data; Radiology examinations; Receiver operating characteristic curves; Deep learning",Conference Paper,Scopus
"Xie Z., Yang Y., Wang M., Li M., Huang H., Zheng D., Shu R., Ling T.","Introducing Information Extraction to Radiology Information Systems to Improve the Efficiency on Reading Reports",2019,"Methods of Information in Medicine",5,"10.1055/s-0039-1694992","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072150066&doi=10.1055%2fs-0039-1694992&partnerID=40&md5=14003342175d949a8a8fbfd8e842897b","Background Radiology reports are a permanent record of patient's health information often used in clinical practice and research. Reading radiology reports is common for clinicians and radiologists. However, it is laborious and time-consuming when the amount of reports to be read is large. Assisting clinicians to locate and assimilate the key information of reports is of great significance for improving the efficiency of reading reports. There are few studies on information extraction from Chinese medical texts and its application in radiology information systems (RIS) for efficiency improvement. Objectives The purpose of this study was to explore methods for extracting, grouping, ranking, delivering, and displaying medical-named entities in radiology reports which can yield efficiency improvement in RISs. Methods A total of 5,000 reports were obtained from two medical institutions for this study. We proposed a neural network model called Multi-Embedding-BGRU-CRF (bidirectional gated recurrent unit-conditional random field) for medical-named entity recognition and rule-based methods for entity grouping and ranking. Furthermore, a methodology for delivering and displaying entities in RISs was presented. Results The proposed neural named entity recognition model has achieved a good F 1 score of 95.88%. Entity ranking achieved a very high accuracy of 99.23%. The weakness of the system is the entity grouping approach which yield accuracy of 91.03%. The effectiveness of the overall solution was proved by an evaluation task performed by two clinicians based on the setup of actual clinical practice. Conclusions The neural model shows great potential in extracting medical-named entities from radiology reports, especially for languages, that lack lexicons and natural language processing tools. The pipeline of extracting, grouping, ranking, delivering, and displaying medical-named entities could be a feasible solution to enhance RIS functionality by information extraction. The integration of information extraction and RIS has been demonstrated to be effective in improving the efficiency of reading radiology reports. © 2019 Georg Thieme Verlag KG Stuttgart New York.","information extraction; named-entity recognition; neural networks; radiology information systems; radiology reports","data mining; hospital; human; radiology information system; reading; research; theoretical model; Data Mining; Hospitals; Humans; Models, Theoretical; Radiology Information Systems; Reading; Research Report",Article,Scopus
"Trivedi G., Dadashzadeh E.R., Handzel R.M., Chapman W.W., Visweswaran S., Hochheiser H.","Interactive NLP in Clinical Care: Identifying Incidental Findings in Radiology Reports",2019,"Applied Clinical Informatics",19,"10.1055/s-0039-1695791","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071775626&doi=10.1055%2fs-0039-1695791&partnerID=40&md5=03c3f48f53957ac0dac4da5aa41b623b","Background: Despite advances in natural language processing (NLP), extracting information from clinical text is expensive. Interactive tools that are capable of easing the construction, review, and revision of NLP models can reduce this cost and improve the utility of clinical reports for clinical and secondary use. Objectives: We present the design and implementation of an interactive NLP tool for identifying incidental findings in radiology reports, along with a user study evaluating the performance and usability of the tool. Methods: Expert reviewers provided gold standard annotations for 130 patient encounters (694 reports) at sentence, section, and report levels. We performed a user study with 15 physicians to evaluate the accuracy and usability of our tool. Participants reviewed encounters split into intervention (with predictions) and control conditions (no predictions). We measured changes in model performance, the time spent, and the number of user actions needed. The System Usability Scale (SUS) and an open-ended questionnaire were used to assess usability. Results: Starting from bootstrapped models trained on 6 patient encounters, we observed an average increase in F1 score from 0.31 to 0.75 for reports, from 0.32 to 0.68 for sections, and from 0.22 to 0.60 for sentences on a held-out test data set, over an hour-long study session. We found that tool helped significantly reduce the time spent in reviewing encounters (134.30 vs. 148.44 seconds in intervention and control, respectively), while maintaining overall quality of labels as measured against the gold standard. The tool was well received by the study participants with a very good overall SUS score of 78.67. Conclusion: The user study demonstrated successful use of the tool by physicians for identifying incidental findings. These results support the viability of adopting interactive NLP tools in clinical care settings for a wider range of clinical applications. © 2019 Georg Thieme Verlag KG Stuttgart New York.","computerized; data display; data interpretation; medical records systems; statistical; workflow","computer interface; data mining; human; incidental finding; natural language processing; procedures; radiology; research; Data Mining; Humans; Incidental Findings; Natural Language Processing; Radiology; Research Report; User-Computer Interface",Article,Scopus
"Pillai A., Katouzian A., Kanjaria K., Shivade C., Jadhav A., Bendersky M., Mukherjee V., Syeda-Mahmood T.","A knowledge-based question answering system to provide cognitive assistance to radiologists",2019,"Progress in Biomedical Optics and Imaging - Proceedings of SPIE",1,"10.1117/12.2512000","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068548640&doi=10.1117%2f12.2512000&partnerID=40&md5=c6c2091e7e75d669c9151c6d6011d230","With the advent of computers and natural language processing, it is not surprising to see that humans are trying to use computers to answer questions. By the 1960s, there were systems implemented on the two major models of question answering, IR-based and knowledge-based, to answer questions about sport statistics and scientific facts. This paper reports on the development of a knowledge-based question answering system that is aimed at providing cognitive assistance to radiologists. Our system represents the question as a semantic query to a medical knowledge base. Evidence obtained from textual and imaging data associated with the question is then combined to arrive at an answer. This question answering system has 3 stages: i) question text and answer choices processing, ii) image processing, and iii) reasoning. Currently, the system can answer differential diagnosis and patient management questions, however, we can tackle a wider variety of question types by improving our medical knowledge coverage in the future. © 2019 SPIE.","Biomedical domain; Decision support system; Image processing; Question answering system; Reasoning","Artificial intelligence; Decision support systems; Diagnosis; Health care; Image processing; Knowledge based systems; Medical informatics; Natural language processing systems; Semantics; Biomedical domain; Cognitive assistance; Differential diagnosis; NAtural language processing; Patient management; Question Answering; Question answering systems; Reasoning; Medical imaging",Conference Paper,Scopus
"Han S., Tian J., Kelly M., Selvakumaran V., Henao R., Rubin G.D., Lo J.Y.","Classifying abnormalities in computed tomography radiology reports with rule-based and natural language processing models",2019,"Progress in Biomedical Optics and Imaging - Proceedings of SPIE",2,"10.1117/12.2513577","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068110752&doi=10.1117%2f12.2513577&partnerID=40&md5=e65306777cc3eaf3d6ebeb4dd33c138e","Purpose: When conducting machine learning algorithms on classification and detection of abnormalities for medical imaging, many researchers are faced with the problem that it is hard to get enough labeled data. This is especially difficult for modalities such as computed tomography (CT) with potentially 1000 or more slice images per case. To solve this problem, we plan to use machine learning algorithms to identify abnormalities within existing radiologist reports, thus creating case-level labels that may be used for weakly supervised training on the image data. We used a two-stage procedure to label the CT reports. In the first stage, a rule-based system labeled a smaller set of cases automatically with high accuracy. In the second stage, we developed machine learing algorithms using the labels from the rule-based system and word vectors learned without supervision from unlabeled CT reports. Method: In this study, we used approximately 24,000 CT reports from Duke University Health System. We initially focused on three organs, the lungs, liver/gallbladder, and kidneys. We first developed a rule-based system that can quickly identify certain types of abnormalities within CT reports with high accuracy. For each organ and disease combination, we produced several hundred cases with rule-based labels. These labels were combined with word vectors generated using word2vec from all the unlabeled reports to train two different machine learning algorithms: (a) average of word vectors merged by logistic regression, and (b) recurrent neural network (RNN). Result: Performance was evaluated by receiver operating characteristic (ROC) area under the curve (AUC) over an independent test set of 440 reports for which those organs were manually labeled as normal or abnormal by clinical experts. For lungs, the performance was 0.796 for average word vector and 0.827 for RNN. Liver performance was 0.683 for average word vector and 0.791 for RNN. For kidneys, it was 0.786 for average word vector and 0.928 for RNN. Conclusion: It is possible to label large numbers of cases automatically. These rule-based labels can then be used to build a classification model for large numbers of medical reports. With word2vec and other transfer learning techniques, we can get a good generalization performance. © 2019 SPIE.","Computed Tomography; Machine learning; Natural language processing; Transfer learning","Computer aided diagnosis; Learning algorithms; Learning systems; Machine learning; Medical imaging; Natural language processing systems; Recurrent neural networks; Vectors; Area under the curves; Classification models; Generalization performance; NAtural language processing; Receiver operating characteristics; Recurrent neural network (RNN); Transfer learning; Weakly supervised trainings; Computerized tomography",Conference Paper,Scopus
"Huang X., Fang Y., Lu M., Yao Y., Li M.","An Annotation Model on End-to-End Chest Radiology Reports",2019,"IEEE Access",5,"10.1109/ACCESS.2019.2917922","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067022699&doi=10.1109%2fACCESS.2019.2917922&partnerID=40&md5=c13bc0fe931b3ca5a375c68dd94188de","Annotating radiographic images with tags is an indispensable preliminary work in computer-aided medical research, which requires professional physician participated in and is quite time-consuming. Therefore, how to automatically annotate radiographic images has become the focus of researchers. However, image report texts, containing crucial radiologic information, have not to be given enough attention for images annotation. In this paper, we propose a neural sequence-to-sequence annotation model. Especially, in the decoding phase, a probability is first learned to copy existing words from report texts or generate new words. Second, to incorporate the patient's background information, 'indication' section of the report is encoded as a sentence embedding, and concatenated with the decoder neural unit input. What's more, we devise a more reasonable evaluation metric for this annotation task, aiming at assessing the importance of different words. On the Open-i dataset, our model outperforms existing non-neural and neural baselines under the BLEU-4 metrics. To our best knowledge, we are the first to use sequence-to-sequence model for radiographic image annotation. © 2013 IEEE.","Annotation; chest radiology report; deep learning; end-to-end model; indication","Decoding; Deep learning; Radiation; Radiology; Annotation; Background information; End-to-end models; Evaluation metrics; indication; Radiographic images; Radiology reports; Sequence modeling; Medical imaging",Article,Scopus
"Brodbeck D., Degen M., Lüthy R., Heye T.","Making the radiology workflow visible in order to inform optimization strategies",2019,"Studies in Health Technology and Informatics",1,"10.3233/978-1-61499-961-4-19","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064123923&doi=10.3233%2f978-1-61499-961-4-19&partnerID=40&md5=305a1f744877e138f0837f7ae2a79287","Medical imaging is undergoing rapid change, induced by the increasing amount of image data, and advances in fields such as artificial intelligence. In order for a radiology service provider to respond to these challenges, it needs to adapt its workflow. To inform optimization strategies, the way that processes and resources interact in the real world must be understood. We report on our experiences with an approach that consists of merging a variety of data sources into a data model that allows efficient interactive queries, and then providing highly interactive visualizations to explore the data. Two examples are discussed: animation of patient flow through the radiology workflow, and the use of energy consumption patterns to characterize operational modalities. © 2019 The authors and IOS Press.","Exploratory visualization; Process optimization; Radiology workflow","Energy utilization; Health care; Medical imaging; Optimization; Radiology; Visualization; Data-sources; Exploratory visualizations; Interactive queries; Interactive visualizations; Optimization strategy; Patient flow; Radiology workflow; Service provider; Radiation; adult; case report; clinical article; conference paper; energy consumption; female; human; male; process optimization; radiology; workflow; radiology information system; workflow; Humans; Radiology; Radiology Information Systems; Workflow",Conference Paper,Scopus
"Martin-Carreras T., Kahn C.E., Jr.","Coverage and Readability of Information Resources to Help Patients Understand Radiology Reports",2018,"Journal of the American College of Radiology",16,"10.1016/j.jacr.2017.11.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042316885&doi=10.1016%2fj.jacr.2017.11.019&partnerID=40&md5=12d549cbbabf57b9df651d2d466a9bc3","Background: Radiology reports can be difficult for a layperson to understand. MedlinePlus, a patient-oriented reference from the National Library of Medicine, may offer limited coverage of radiology report concepts. RadLex provides an extensive radiology vocabulary but may be ill suited to help patients understand radiology reports. We compared MedlinePlus, RadLex, and the PORTER (Patient-Oriented Radiology Reporter) lay-language radiology glossary for their coverage of radiology reports and for the readability of their definitions. Methods: We tallied how frequently terms from MedlinePlus (975 concepts), RadLex (46,433 concepts), and PORTER (3,734 concepts) were found in 10,000 radiology reports sampled randomly from a large academic health system. We also compared the readability of MedlinePlus, RadLex, and PORTER definitions. Results: The mean number of terms matched per radiology report was 3.8 for MedlinePlus, 40.7 for RadLex, and 42.0 for PORTER. RadLex and PORTER offered significantly greater coverage than MedlinePlus (P < .0001); there was no significant difference between RadLex and PORTER. Median readability score (grade level) of definitions was 10.1 for MedlinePlus, 12.6 for RadLex, and 4.1 for PORTER. Conclusions: The PORTER glossary matched significantly more terms in radiology reports than MedlinePlus and had similar performance to RadLex, even though RadLex had 12 times as many concepts. Only 8% of RadLex terms offered definitions, and most had readability above the 12th-grade reading level, making them incomprehensible to the average US adult. PORTER's glossary definitions were readable by a lay audience. A lay-language radiology glossary may help patients better understand their radiology reports. © 2017 American College of Radiology","patient experience; Patient-centered care; radiology reports; readability; vocabularies","adult; article; controlled study; human; language; Medline; patient care; radiology; reading; vocabulary; comparative study; comprehension; controlled vocabulary; diagnostic imaging; documentation; information retrieval; Comprehension; Diagnostic Imaging; Documentation; Humans; Information Storage and Retrieval; Vocabulary, Controlled",Article,Scopus
"Sánchez Y., Prabhakar A.M., Uppot R.N.","Adapting a Computerized Medical Dictation System to Prepare Academic Papers in Radiology",2018,"Current Problems in Diagnostic Radiology",,"10.1067/j.cpradiol.2017.09.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030860026&doi=10.1067%2fj.cpradiol.2017.09.002&partnerID=40&md5=04c739c596336418b2af0b8bf40e7359","Everyday radiologists use dictation software to compose clinical reports of imaging findings. The dictation software is tailored for medical use and to the speech pattern of each radiologist. Over the past 10 years we have used dictation software to compose academic manuscripts, correspondence letters, and texts of educational exhibits. The advantages of using voice dictation is faster composition of manuscripts. However, use of such software requires preparation. The purpose of this article is to review the steps of adapting a clinical dictation software for dictating academic manuscripts and detail the advantages and limitations of this technique. © 2018 Elsevier Inc.",,"human; publication; radiology; software; voice; writing; automatic speech recognition; computer interface; publication; task performance; Humans; Manuscripts, Medical as Topic; Radiology; Speech Recognition Software; User-Computer Interface; Work Simplification",Note,Scopus
"Paats A., Alumäe T., Meister E., Fridolin I.","Retrospective Analysis of Clinical Performance of an Estonian Speech Recognition System for Radiology: Effects of Different Acoustic and Language Models",2018,"Journal of Digital Imaging",7,"10.1007/s10278-018-0085-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053514701&doi=10.1007%2fs10278-018-0085-8&partnerID=40&md5=c94f97689a718899d1def53d6aac2d4e","The aim of this study was to analyze retrospectively the influence of different acoustic and language models in order to determine the most important effects to the clinical performance of an Estonian language-based non-commercial radiology-oriented automatic speech recognition (ASR) system. An ASR system was developed for Estonian language in radiology domain by utilizing open-source software components (Kaldi toolkit, Thrax). The ASR system was trained with the real radiology text reports and dictations collected during development phases. The final version of the ASR system was tested by 11 radiologists who dictated 219 reports in total, in spontaneous manner in a real clinical environment. The audio files collected in the final phase were used to measure the performance of different versions of the ASR system retrospectively. ASR system versions were evaluated by word error rate (WER) for each speaker and modality and by WER difference for the first and the last version of the ASR system. Total average WER for the final version throughout all material was improved from 18.4% of the first version (v1) to 5.8% of the last (v8) version which corresponds to relative improvement of 68.5%. WER improvement was strongly related to modality and radiologist. In summary, the performance of the final ASR system version was close to optimal, delivering similar results to all modalities and being independent on user, the complexity of the radiology reports, user experience, and speech characteristics. © 2018, The Author(s).","Automatic speech recognition; Estonian language; Radiology; Spontaneous dictation; Word error rate","Computational linguistics; Open source software; Open systems; Radiation; Radiology; User interfaces; Acoustic and language models; Automatic speech recognition; Automatic speech recognition system; Estonian language; Retrospective analysis; Speech recognition systems; Spontaneous dictation; Word error rate; Speech recognition; article; automatic speech recognition; human; human experiment; language; radiologist; radiology; retrospective study; automatic speech recognition; Estonia; reproducibility; retrospective study; Estonia; Humans; Language; Radiology; Reproducibility of Results; Retrospective Studies; Speech Recognition Software",Article,Scopus
"Hassanzadeh H., Nguyen A., Karimi S., Chu K.","Transferability of artificial neural networks for clinical document classification across hospitals: A case study on abnormality detection from radiology reports",2018,"Journal of Biomedical Informatics",15,"10.1016/j.jbi.2018.07.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050820681&doi=10.1016%2fj.jbi.2018.07.017&partnerID=40&md5=6e2a74ff22d8b9b89cca1496f2c3a0e3","Objective: Application of machine learning techniques for automatic and reliable classification of clinical documents have shown promising results. However, machine learning models require abundant training data specific to each target hospital and may not be able to benefit from available labeled data from each of the hospitals due to data variations. Such training data limitations have presented one of the major obstacles for maximising potential application of machine learning approaches in the healthcare domain. We investigated transferability of artificial neural network models across hospitals from different domains representing various age demographic groups (i.e., children, adults, and mixed) in order to cope with such limitations. Materials and methods: We explored the transferability of artificial neural networks for clinical document classification. Our case study was to detect abnormalities from limb X-ray reports obtained from the emergency department (ED) of three hospitals within different domains. Different transfer learning scenarios were investigated in order to employ a source hospital's trained model for addressing a target hospital's abnormality detection problem. Results: A Convolutional Neural Network (CNN) model exhibited the best effectiveness compared to other networks when employing an embedding model trained on a large corpus of clinical documents. Furthermore, CNN models derived from a source hospital outperformed a conventional machine learning approach based on Support Vector Machines (SVM) when applied to a different (target) hospital. These models were further improved by leveraging available training data in target hospitals and outperformed the models that used only the target hospital data with F1-Score of 0.92–0.96 across three hospitals. Discussion: Our transfer learning model used only simple vector representations of documents without any task-specific feature engineering. Transferring the CNN model significantly improved (approx.10% in F1-Score) the state-of-the-art approach for clinical document classification based on a trivial transferred model. In addition, the results showed that transfer learning techniques can further improve a CNN model that is trained only on either a source or target hospital's data. Conclusion: Transferring a pre-trained CNN model generated in one hospital to another facilitates application of machine learning approaches that alleviate both hospital-specific feature engineering and training data. © 2018 Elsevier Inc.","Clinical document classification; Deep learning; Machine learning; Radiology report; Transfer learning","Deep learning; Information retrieval systems; Learning algorithms; Learning systems; Neural networks; Radiation; Radiology; Support vector machines; Artificial neural network models; Convolutional Neural Networks (CNN); Document Classification; Machine learning approaches; Machine learning techniques; Radiology reports; State-of-the-art approach; Transfer learning; Hospitals; adult; age distribution; Article; artificial neural network; bone radiography; child; classification algorithm; clinical classification; clinical effectiveness; clinical practice; convolutional neural network; emergency care; hospital; human; learning algorithm; machine learning; medical documentation; practice guideline; priority journal; radiology; algorithm; biology; computer assisted diagnosis; factual database; radiography; support vector machine; Algorithms; Computational Biology; Databases, Factual; Deep Learning; Humans; Machine Learning; Neural Networks (Computer); Radiographic Image Interpretation, Computer-Assisted; Radiography; Support Vector Machine",Article,Scopus
"Dibble E.H., Binns E., Ellermeier A., March B.T., Baird G.L., Mayo-Smith W.W., Movson J.S.","Automated delivery of clinical follow-up to the radiologist via e-mail: Feasibility study of a new information technology algorithm",2018,"American Journal of Roentgenology",2,"10.2214/AJR.17.19375","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052388235&doi=10.2214%2fAJR.17.19375&partnerID=40&md5=3844f41c0f11b72d45ee8c83fe9b5d61","OBJECTIVE. The purposes of this study were to develop an automated process for radiologists to obtain clinical follow-up on radiology reports via HIPAA-compliant e-mail and to determine what follow-up data were collected and whether they were relevant to the radiology reports. CONCLUSION. The algorithm generated high-yield follow-up data for radiologists that may improve patient care by facilitating radiologist engagement and self-assessment. © American Roentgen Ray Society.","Clinical competence; Medical informatics; Quality assurance","adult; article; clinical competence; e-mail; feasibility study; follow up; human; medical informatics; patient care; quality control; radiologist; radiology; self evaluation; algorithm; clinical competence; computer interface; feasibility study; health care quality; patient care; total quality management; Algorithms; Clinical Competence; Continuity of Patient Care; Electronic Mail; Feasibility Studies; Humans; Quality Assurance, Health Care; Quality Improvement; Radiologists; User-Computer Interface",Article,Scopus
"Wang Y., Mehrabi S., Sohn S., Atkinson E., Amin S., Liu H.","Automatic Extraction of Major Osteoporotic Fractures from Radiology Reports using Natural Language Processing",2018,"Proceedings - 2018 IEEE International Conference on Healthcare Informatics Workshops, ICHI-W 2018",3,"10.1109/ICHI-W.2018.00021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051022287&doi=10.1109%2fICHI-W.2018.00021&partnerID=40&md5=f77aa7477b9ec9b79d9e1e34cef9c173","In this study, we developed a rule-based natural language processing (NLP) algorithm for automatic extraction of six major osteoporotic fractures from radiology reports. We validated the NLP algorithm using a dataset of radiology reports from Mayo Clinic with the gold standard constructed by medical experts. The micro-Averaged sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and F1-score of the proposed NLP algorithm are 0.796, 0.978, 0.972, 0.831, 0.874, respectively. The highest F1-score was achieved at 0.958 for the extraction of proximal femur fracture while the lowest was 0.821 for the hand and finger/wrists fracture. The experimental results verified the effectiveness of the proposed rule-based NLP algorithm in the automatic extraction of major osteoporotic fractures from radiology reports. © 2018 IEEE.","fracture; natural language processing; osteoporosis; radiology report","Bone; Extraction; Fracture; Health care; Radiation; Radiology; Automatic extraction; Medical experts; Negative predictive value; osteoporosis; Osteoporotic fractures; Positive predictive values; Proximal femur; Radiology reports; Natural language processing systems",Conference Paper,Scopus
"Pathak S., Van Rossen J., Vijlbrief O., Geerdink J., Seifert C., Van Keulen M.","Automatic structuring of breast cancer radiology reports for quality assurance",2018,"IEEE International Conference on Data Mining Workshops, ICDMW",3,"10.1109/ICDMW.2018.00111","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062876065&doi=10.1109%2fICDMW.2018.00111&partnerID=40&md5=10b21e48cca0aa966850f91f593aedd3","Hospitals often set protocols based on well defined standards to maintain quality of patient reports. To ensure that the clinicians conform to the protocols, quality assurance of these reports is needed. Patient reports are currently written in free-text format, which complicates the task of quality assurance. In this paper, we present a machine learning based natural language processing system for automatic quality assurance of radiology reports on breast cancer. This is achieved in three steps: We i) identify the top level structure of the report, ii) check whether the information under each section corresponds to the section heading, iii) convert the free-text detailed findings in the report to a semi-structured format. Top level structure and content of report were predicted with an F1 score of 0.97 and 0.94 respectively using Support Vector Machine (SVM). For automatic structuring, our proposed hierarchical Conditional Random Field (CRF) outperformed the baseline CRF with an F1 score of 0.78 vs 0.71. The third step generates a semi-structured XML format of the free-text report, which helps to easily visualize the conformance of the findings to the protocols. This format also allows easy extraction of specific information for other purposes such as search, evaluation and research. © 2018 IEEE.","Automatic Structuring; Conditional Random Field; Quality Assurance; Radiology Reports","Diseases; Learning algorithms; Natural language processing systems; Radiation; Radiology; Random processes; Support vector machines; Automatic structuring; Breast Cancer; Conditional random field; F1 scores; Free texts; Level structure; Radiology reports; Random fields; Semi-structured; Set protocols; Quality assurance",Conference Paper,Scopus
"Gill A.E., Wong P.K., Mullins M.E., Corey A.S., Little B.P.","Missed Case Feedback and Quality Assurance Conferences in Radiology Resident Education: A Survey of United States Radiology Program Directors",2018,"Current Problems in Diagnostic Radiology",3,"10.1067/j.cpradiol.2017.06.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021827163&doi=10.1067%2fj.cpradiol.2017.06.008&partnerID=40&md5=6a2a3584535793a4b3eff75e40b17b98","Rationale and Objectives: Diagnostic Radiology (DR) residents typically generate preliminary reports for imaging examinations, but few publications discuss feedback regarding missed or misinterpreted findings. Our goal was to determine the practices of United States DR residencies with respect to missed case feedback, including the role of Quality Assurance (QA) conferences. Materials and Methods: A 23-item survey containing multiple-choice questions and several free text fields was created and hosted on SurveyMonkeyR. An invitation to complete the survey was sent via email to all DR Program Directors (PDs) or representatives. Responses were tabulated and analyzed using SurveyMonkeyR analytic tools and Microsoft Excel. Results: 188 PDs or representatives were emailed, resulting in 45 survey responses. Common types of missed case feedback included resident QA case conferences (81%), resident self review of cases (72%), discussion during readout at the end of shift (70%), and faculty-resident meetings (67%). A minority of programs reported using automated methods of resident feedback, such as PACS integration or automated emails. Most resident QA conferences were held monthly (64%). Typical formats of conferences included informal discussion (43%), formal presentation (30%), or case conferences (30%). The majority (78%) of respondents rated resident missed case feedback mechanisms at their institution as at least “good”. Conclusion: DR residencies use a variety of mechanisms to provide feedback to residents regarding missed or misinterpreted cases, including QA conferences. Although several possibilities for improvement in feedback mechanisms were highlighted by survey responses, most respondents had a favorable view of their program's feedback processes. © 2018 Elsevier Inc.",,"case study; e-mail; feedback system; female; human; human experiment; male; multiple choice test; quality control; radiodiagnosis; resident; United States; university; diagnostic error; education; feedback system; health care quality; medical education; questionnaire; radiology; United States; Diagnostic Errors; Education, Medical, Graduate; Feedback; Humans; Internship and Residency; Quality Assurance, Health Care; Radiology; Surveys and Questionnaires; United States",Article,Scopus
"Percha B., Zhang Y., Bozkurt S., Rubin D., Altman R.B., Langlotz C.P.","Expanding a radiology lexicon using contextual patterns in radiology reports",2018,"Journal of the American Medical Informatics Association",15,"10.1093/jamia/ocx152","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048580148&doi=10.1093%2fjamia%2focx152&partnerID=40&md5=036b33d1da930fe9198017f9ad58448e","Objective: Distributional semantics algorithms, which learn vector space representations of words and phrases from large corpora, identify related terms based on contextual usage patterns. We hypothesize that distributional semantics can speed up lexicon expansion in a clinical domain, radiology, by unearthing synonyms from the corpus. Materials and Methods: We apply word2vec, a distributional semantics software package, to the text of radiology notes to identify synonyms for RadLex, a structured lexicon of radiology terms. We stratify performance by term category, term frequency, number of tokens in the term, vector magnitude, and the context window used in vector building. Results: Ranking candidates based on distributional similarity to a target term results in high curation efficiency: on a ranked list of 775 249 terms, > 50% of synonyms occurred within the first 25 terms. Synonyms are easier to find if the target term is a phrase rather than a single word, if it occurs at least 100× in the corpus, and if its vector magnitude is between 4 and 5. Some RadLex categories, such as anatomical substances, are easier to identify synonyms for than others. Discussion: The unstructured text of clinical notes contains a wealth of information about human diseases and treatment patterns. However, searching and retrieving information from clinical notes often suffer due to variations in how similar concepts are described in the text. Biomedical lexicons address this challenge, but are expensive to produce and maintain. Distributional semantics algorithms can assist lexicon curation, saving researchers time and money. © The Author(s) 2018. Published by Oxford University Press on behalf of the American Medical Informatics Association. All rights reserved.","Lexicons; Natural language processing; Ontologies; Radiology; Text mining","algorithm; Article; data mining; medical terminology; natural language processing; ontology; radiology; semantics; classification; controlled vocabulary; electronic health record; factual database; human; natural language processing; procedures; radiology; radiology information system; software; Algorithms; Data Mining; Databases, Factual; Electronic Health Records; Humans; Natural Language Processing; Radiology; Radiology Information Systems; Semantics; Software; Vocabulary, Controlled",Article,Scopus
"Zech J., Pain M., Titano J., Badgeley M., Schefflein J., Su A., Costa A., Bederson J., Lehar J., Oermann E.K.","Natural language-based machine learning models for the annotation of clinical radiology reports",2018,"Radiology",101,"10.1148/radiol.2018171093","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046006819&doi=10.1148%2fradiol.2018171093&partnerID=40&md5=c74ab7a20805bcf57725a185cf4e0729","Purpose: To compare different methods for generating features from radiology reports and to develop a method to automatically identify findings in these reports. Materials and Methods: In this study, 96 303 head computed tomography (CT) reports were obtained. The linguistic complexity of these reports was compared with that of alternative corpora. Head CT reports were preprocessed, and machine-analyzable features were constructed by using bag-of-words (BOW), word embedding, and Latent Dirichlet allocation-based approaches. Ultimately, 1004 head CT reports were manually labeled for findings of interest by physicians, and a subset of these were deemed critical findings. Lasso logistic regression was used to train models for physician-assigned labels on 602 of 1004 head CT reports (60%) using the constructed features, and the performance of these models was validated on a held-out 402 of 1004 reports (40%). Models were scored by area under the receiver operating characteristic curve (AUC), and aggregate AUC statistics were reported for (a) all labels, (b) critical labels, and (c) the presence of any critical finding in a report. Sensitivity, specificity, accuracy, and F1 score were reported for the best performing model's (a) predictions of all labels and (b) identification of reports containing critical findings. Results: The best-performing model (BOW with unigrams, bigrams, and trigrams plus average word embeddings vector) had a held-out AUC of 0.966 for identifying the presence of any critical head CT finding and an average 0.957 AUC across all head CT findings. Sensitivity and specificity for identifying the presence of any critical finding were 92.59% (175 of 189) and 89.67% (191 of 213), respectively. Average sensitivity and specificity across all findings were 90.25% (1898 of 2103) and 91.72% (18 351 of 20 007), respectively. Simpler BOW methods achieved results competitive with those of more sophisticated approaches, with an average AUC for presence of any critical finding of 0.951 for unigram BOW versus 0.966 for the best-performing model. The Yule I of the head CT corpus was 34, markedly lower than that of the Reuters corpus (at 103) or I2B2 discharge summaries (at 271), indicating lower linguistic complexity. Conclusion: Automated methods can be used to identify findings in radiology reports. The success of this approach benefits from the standardized language of these reports. With this method, a large labeled corpus can be generated for applications such as deep learning. © RSNA, 2018.",,"Article; computer assisted tomography; data processing; diagnostic value; electronic medical record; human; information processing; logistic regression analysis; machine learning; measurement accuracy; natural language processing; priority journal; receiver operating characteristic; sensitivity and specificity; validation study; area under the curve; electronic health record; factual database; procedures; radiology; x-ray computed tomography; Area Under Curve; Databases, Factual; Electronic Health Records; Humans; Machine Learning; Natural Language Processing; Radiology; Sensitivity and Specificity; Tomography, X-Ray Computed",Article,Scopus
"Dane B., Doshi A., Gfytopoulos S., Bhattacharji P., Recht M., Moore W.","Automated Radiology-Pathology Module Correlation Using a Novel Report Matching Algorithm by Organ System",2018,"Academic Radiology",15,"10.1016/j.acra.2017.11.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040622594&doi=10.1016%2fj.acra.2017.11.009&partnerID=40&md5=4571766691490593ab7362c42823ac81","Objectives and Rationale: Radiology-pathology correlation is time-consuming and is not feasible in most clinical settings, with the notable exception of breast imaging. The purpose of this study was to determine if an automated radiology-pathology report pairing system could accurately match radiology and pathology reports, thus creating a feedback loop allowing for more frequent and timely radiology-pathology correlation. Methods: An experienced radiologist created a matching matrix of radiology and pathology reports. These matching rules were then exported to a novel comprehensive radiology-pathology module. All distinct radiology-pathology pairings at our institution from January 1, 2016 to July 1, 2016 were included (n = 8999). The appropriateness of each radiology-pathology report pairing was scored as either “correlative” or “non-correlative.” Pathology reports relating to anatomy imaged in the specific imaging study were deemed correlative, whereas pathology reports describing anatomy not imaged with the particular study were denoted non-correlative. Results: Overall, there was 88.3% correlation (accuracy) of the radiology and pathology reports (n = 8999). Subset analysis demonstrated that computed tomography (CT) abdomen/pelvis, CT head/neck/face, CT chest, musculoskeletal CT (excluding spine), mammography, magnetic resonance imaging (MRI) abdomen/pelvis, MRI brain, musculoskeletal MRI (excluding spine), breast MRI, positron emission tomography (PET), breast ultrasound, and head/neck ultrasound all demonstrated greater than 91% correlation. When further stratified by imaging modality, CT, MRI, mammography, and PET demonstrated excellent correlation (greater than 96.3%). Ultrasound and non-PET nuclear medicine studies demonstrated poorer correlation (80%). Conclusion: There is excellent correlation of radiology imaging reports and appropriate pathology reports when matched by organ system. Rapid, appropriate radiology-pathology report pairings provide an excellent opportunity to close feedback loop to the interpreting radiologist. © 2018 The Association of University Radiologists","concordance; radiology education; Radiology pathology correlation","abdominal radiography; adult; algorithm; Article; automation; computer assisted tomography; controlled study; correlation function; echomammography; human; interventional radiology; mammography; normal human; nuclear magnetic resonance imaging; pathology; pelvis radiography; positron emission tomography; priority journal; radiology; retrospective study; thorax radiography; abdomen; brain; breast; diagnostic imaging; face; female; musculoskeletal system; neck; pathology; pelvis; procedures; radiology information system; scintiscanning; thorax; x-ray computed tomography; Abdomen; Algorithms; Brain; Breast; Diagnostic Imaging; Face; Female; Humans; Magnetic Resonance Imaging; Mammography; Musculoskeletal System; Neck; Pelvis; Positron-Emission Tomography; Radiology Information Systems; Radionuclide Imaging; Thorax; Tomography, X-Ray Computed; Ultrasonography, Mammary",Article,Scopus
"Goff D.J., Loehfelm T.W.","Automated Radiology Report Summarization Using an Open-Source Natural Language Processing Pipeline",2018,"Journal of Digital Imaging",27,"10.1007/s10278-017-0030-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032672275&doi=10.1007%2fs10278-017-0030-2&partnerID=40&md5=cb30ad8334e95bb3f0b2b6be3b274f39","Diagnostic radiologists are expected to review and assimilate findings from prior studies when constructing their overall assessment of the current study. Radiology information systems facilitate this process by presenting the radiologist with a subset of prior studies that are more likely to be relevant to the current study, usually by comparing anatomic coverage of both the current and prior studies. It is incumbent on the radiologist to review the full text report and/or images from those prior studies, a process that is time-consuming and confers substantial risk of overlooking a relevant prior study or finding. This risk is compounded when patients have dozens or even hundreds of prior imaging studies. Our goal is to assess the feasibility of natural language processing techniques to automatically extract asserted and negated disease entities from free-text radiology reports as a step towards automated report summarization. We compared automatically extracted disease mentions to a gold-standard set of manual annotations for 50 radiology reports from CT abdomen and pelvis examinations. The automated report summarization pipeline found perfect or overlapping partial matches for 86% of the manually annotated disease mentions (sensitivity 0.86, precision 0.66, accuracy 0.59, F1 score 0.74). The performance of the automated pipeline was good, and the overall accuracy was similar to the interobserver agreement between the two manual annotators. © 2017, Society for Imaging Informatics in Medicine.","Data extraction; NLP; Radiology report; Report summarization","Automation; Computerized tomography; Data reduction; Diagnosis; Pipeline processing systems; Pipelines; Radiation; Radiology; Data extraction; Interobserver agreement; Manual annotation; Natural languages; Overall accuracies; Radiology information system; Radiology reports; Report summarization; Natural language processing systems; abdomen; abdominal radiography; adolescent; adult; aged; child; diagnostic imaging; female; human; male; middle aged; natural language processing; pelvis; preschool child; procedures; radiology information system; retrospective study; very elderly; x-ray computed tomography; young adult; Abdomen; Adolescent; Adult; Aged; Aged, 80 and over; Child; Child, Preschool; Female; Humans; Male; Middle Aged; Natural Language Processing; Pelvis; Radiography, Abdominal; Radiology Information Systems; Retrospective Studies; Tomography, X-Ray Computed; Young Adult",Article,Scopus
"Chen P.-H., Zafar H., Galperin-Aizenberg M., Cook T.","Integrating Natural Language Processing and Machine Learning Algorithms to Categorize Oncologic Response in Radiology Reports",2018,"Journal of Digital Imaging",61,"10.1007/s10278-017-0027-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032491917&doi=10.1007%2fs10278-017-0027-x&partnerID=40&md5=6c53cf1c7f30e241d7efc0a4f1a46d57","A significant volume of medical data remains unstructured. Natural language processing (NLP) and machine learning (ML) techniques have shown to successfully extract insights from radiology reports. However, the codependent effects of NLP and ML in this context have not been well-studied. Between April 1, 2015 and November 1, 2016, 9418 cross-sectional abdomen/pelvis CT and MR examinations containing our internal structured reporting element for cancer were separated into four categories: Progression, Stable Disease, Improvement, or No Cancer. We combined each of three NLP techniques with five ML algorithms to predict the assigned label using the unstructured report text and compared the performance of each combination. The three NLP algorithms included term frequency-inverse document frequency (TF-IDF), term frequency weighting (TF), and 16-bit feature hashing. The ML algorithms included logistic regression (LR), random decision forest (RDF), one-vs-all support vector machine (SVM), one-vs-all Bayes point machine (BPM), and fully connected neural network (NN). The best-performing NLP model consisted of tokenized unigrams and bigrams with TF-IDF. Increasing N-gram length yielded little to no added benefit for most ML algorithms. With all parameters optimized, SVM had the best performance on the test dataset, with 90.6 average accuracy and F score of 0.813. The interplay between ML and NLP algorithms and their effect on interpretation accuracy is complex. The best accuracy is achieved when both algorithms are optimized concurrently. © 2017, Society for Imaging Informatics in Medicine.","Informatics; Machine learning; Natural language processing; Structured reporting","Artificial intelligence; Diseases; Learning algorithms; Learning systems; Nobelium; Radiation; Radiology; Statistical tests; Support vector machines; Text processing; Decision forest; Feature hashing; Fully connected neural network; Informatics; Logistic regressions; Radiology reports; Structured reporting; Term frequencyinverse document frequency (TF-IDF); Natural language processing systems; abdomen; abdominal tumor; algorithm; artificial intelligence; cross-sectional study; diagnostic imaging; human; machine learning; medical record; natural language processing; nuclear magnetic resonance imaging; pelvis; pelvis tumor; x-ray computed tomography; Abdomen; Abdominal Neoplasms; Algorithms; Artificial Intelligence; Cross-Sectional Studies; Humans; Machine Learning; Magnetic Resonance Imaging; Medical Records; Natural Language Processing; Pelvic Neoplasms; Pelvis; Tomography, X-Ray Computed",Article,Scopus
"Folio L.R., Machado L.B., Dwyer A.J.","Multimedia-enhanced radiology reports: Concept, components, and challenges",2018,"Radiographics",24,"10.1148/rg.2017170047","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043788201&doi=10.1148%2frg.2017170047&partnerID=40&md5=05ec2443d4ec0181589ae01d9c208be5","Multimedia-enhanced radiology report (MERR) development is defined and described from an informatics perspective, in which the MERR is seen as a superior information-communicating entity. Recent technical advances, such as the hyperlinking of report text directly to annotated images, improve MERR information content and accessibility compared with text-only reports. The MERR is analyzed by its components, which include hypertext, tables, graphs, embedded images, and their interconnections. The authors highlight the advantages of each component for improving the radiologist’s communication of report content information and the user’s ability to extract information. Requirements for MERR implementation (eg, integration of picture archiving and communication systems, radiology information systems, and electronic medical record systems) and the authors’ initial experiences and challenges in MERR implementation at the National Institutes of Health are reviewed. The transition to MERRs has provided advantages over use of traditional text-only radiology reports because of the capacity to include hyperlinked report text that directs clinicians to image annotations, images, tables, and graphs. A framework is provided for thinking about the MERR from the user’s perspective. Additional applications of emerging technologies (eg, artificial intelligence and machine learning) are described in the crafting of what the authors believe is the radiology report of the future. © RSNA, 2018.",,"artificial intelligence; electronic medical record system; human; machine learning; multimedia; radiology information system; Artificial Intelligence; Humans; Machine Learning; Medical Records Systems, Computerized; Multimedia; Radiology Information Systems",Article,Scopus
"Chen M.C., Ball R.L., Yang L., Moradzadeh N., Chapman B.E., Larson D.B., Langlotz C.P., Amrhein T.J., Lungren M.P.","Deep learning to classify radiology free-text reports",2018,"Radiology",141,"10.1148/radiol.2017171115","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042446924&doi=10.1148%2fradiol.2017171115&partnerID=40&md5=20f4a4ee145bab940fed486c64952a51","Purpose: To evaluate the performance of a deep learning convolutional neural network (CNN) model compared with a traditional natural language processing (NLP) model in extracting pulmonary embolism (PE) findings from thoracic computed tomography (CT) reports from two institutions. Materials and Contrast material-enhanced CT examinations of the Methods: chest performed between January 1, 1998, and January 1, 2016, were selected. Annotations by two human radiologists were made for three categories: the presence, chronicity, and location of PE. Classification of performance of a CNN model with an unsupervised learning algorithm for obtaining vector representations of words was compared with the open-source application PeFinder. Sensitivity, specificity, accuracy, and F1 scores for both the CNN model and PeFinder in the internal and external validation sets were determined. Results: The CNN model demonstrated an accuracy of 99% and an area under the curve value of 0.97. For internal validation report data, the CNN model had a statistically significant larger F1 score (0.938) than did PeFinder (0.867) when classifying findings as either PE positive or PE negative, but no significant difference in sensitivity, specificity, or accuracy was found. For external validation report data, no statistical difference between the performance of the CNN model and PeFinder was found. Conclusion: A deep learning CNN model can classify radiology free-text reports with accuracy equivalent to or beyond that of an existing traditional NLP model. © RSNA, 2017.",,"area under the curve; Article; artificial neural network; computer assisted tomography; contrast enhancement; controlled study; deep learning convolutional neural network; diagnostic accuracy; external validity; human; internal validity; interrater reliability; learning algorithm; lung embolism; measurement precision; natural language processing; priority journal; scoring system; sensitivity and specificity; unsupervised learning algorithm; algorithm; clinical trial; comparative study; diagnostic imaging; evaluation study; lung embolism; machine learning; multicenter study; procedures; receiver operating characteristic; reproducibility; thorax radiography; x-ray computed tomography; Algorithms; Humans; Machine Learning; Natural Language Processing; Neural Networks (Computer); Pulmonary Embolism; Radiography, Thoracic; Reproducibility of Results; ROC Curve; Sensitivity and Specificity; Tomography, X-Ray Computed",Article,Scopus
"Guimaraes C.V., Grzeszczuk R., Bisset G.S., III, Donnelly L.F.","Comparison Between Manual Auditing and a Natural Language Process With Machine Learning Algorithm to Evaluate Faculty Use of Standardized Reports in Radiology",2018,"Journal of the American College of Radiology",9,"10.1016/j.jacr.2017.10.042","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038349245&doi=10.1016%2fj.jacr.2017.10.042&partnerID=40&md5=24f440ea58fbd31766d614122197ea84","Purpose: When implementing or monitoring department-sanctioned standardized radiology reports, feedback about individual faculty performance has been shown to be a useful driver of faculty compliance. Most commonly, these data are derived from manual audit, which can be both time-consuming and subject to sampling error. The purpose of this study was to evaluate whether a software program using natural language processing and machine learning could accurately audit radiologist compliance with the use of standardized reports compared with performed manual audits. Methods: Radiology reports from a 1-month period were loaded into such a software program, and faculty compliance with use of standardized reports was calculated. For that same period, manual audits were performed (25 reports audited for each of 42 faculty members). The mean compliance rates calculated by automated auditing were then compared with the confidence interval of the mean rate by manual audit. Results: The mean compliance rate for use of standardized reports as determined by manual audit was 91.2% with a confidence interval between 89.3% and 92.8%. The mean compliance rate calculated by automated auditing was 92.0%, within that confidence interval. Conclusion: This study shows that by use of natural language processing and machine learning algorithms, an automated analysis can accurately define whether reports are compliant with use of standardized report templates and language, compared with manual audits. This may avoid significant labor costs related to conducting the manual auditing process. © 2017 American College of Radiology","compliance; machine learning; natural language processing; Standardized reports","human; human experiment; machine learning; natural language processing; radiologist; radiology; software; clinical audit; comparative study; documentation; medical school; radiology information system; standards; Documentation; Faculty, Medical; Humans; Machine Learning; Medical Audit; Natural Language Processing; Radiology Information Systems; Software",Article,Scopus
"McBee M.P., Laor T., Pryor R.M., Smith R., Hardin J., Ulland L., May S., Zhang B., Towbin A.J.","A Comprehensive Approach to Convert a Radiology Department From Coding Based on International Classification of Diseases, Ninth Revision, to Coding Based on International Classification of Diseases, Tenth Revision",2018,"Journal of the American College of Radiology",4,"10.1016/j.jacr.2017.09.046","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039758058&doi=10.1016%2fj.jacr.2017.09.046&partnerID=40&md5=7d8c4b01d3ffe1eac388a14f909cc331","Purpose: The purpose of this study was to adapt our radiology reports to provide the documentation required for specific International Classification of Diseases, tenth rev (ICD-10) diagnosis coding. Materials and Methods: Baseline data were analyzed to identify the reports with the greatest number of unspecified ICD-10 codes assigned by computer-assisted coding software. A two-part quality improvement initiative was subsequently implemented. The first component involved improving clinical histories by utilizing technologists to obtain information directly from the patients or caregivers, which was then imported into the radiologist's report within the speech recognition software. The second component involved standardization of report terminology and creation of four different structured report templates to determine which yielded the fewest reports with an unspecified ICD-10 code assigned by an automated coding engine. Results: In all, 12,077 reports were included in the baseline analysis. Of these, 5,151 (43%) had an unspecified ICD-10 code. The majority of deficient reports were for radiographs (n = 3,197; 62%). Inadequacies included insufficient clinical history provided and lack of detailed fracture descriptions. Therefore, the focus was standardizing terminology and testing different structured reports for radiographs obtained for fractures. At baseline, 58% of radiography reports contained a complete clinical history with improvement to >95% 8 months later. The total number of reports that contained an unspecified ICD-10 code improved from 43% at baseline to 27% at completion of this study (P <.0001). Conclusion: The number of radiology studies with a specific ICD-10 code can be improved through quality improvement methodology, specifically through the use of technologist-acquired clinical histories and structured reporting. © 2017 American College of Radiology","billing; clinical history; coding; ICD-10; quality improvement; Structured reporting","Article; automatic speech recognition; checklist; disease classification; human; ICD-10; medical documentation; nomenclature; radiodiagnosis; radiologist; radiology; radiology department; total quality management; coding; electronic health record; International Classification of Diseases; Ohio; organization and management; standards; Clinical Coding; Electronic Health Records; Humans; International Classification of Diseases; Ohio; Quality Improvement; Radiology Department, Hospital; Speech Recognition Software",Article,Scopus
"Moore W., Doshi A., Bhattacharji P., Gyftopoulos S., Ciavarra G., Kim D., Recht M.","Automated Radiology-Operative Note Communication Tool; Closing the Loop in Musculoskeletal Imaging",2018,"Academic Radiology",6,"10.1016/j.acra.2017.08.016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033212198&doi=10.1016%2fj.acra.2017.08.016&partnerID=40&md5=c47ec81dcf52229a49e0142126725be1","Rationale and Objectives: Correlation of imaging studies and reference standard outcomes is a significant challenge in radiology. This study evaluates the effectiveness of a new communication tool by assessing the ability of this system to correctly match the imaging studies to arthroscopy reports and qualitatively assessing radiologist behavior before and after the implementation of this system. Materials and Methods: Using a commercially available communication or educational tool and applying a novel matching rule algorithm, radiology and arthroscopy reports were matched from January 17, 2017 to March 1, 2017 based on anatomy. The interpreting radiologist was presented with email notifications containing the impression of the imaging report and the entire arthroscopy report. Total correlation rate of appropriate report pairings, modality-specific correlation rate, and the anatomy-specific correlation rate were calculated. Radiologists using the system were given a survey. Results: Overall correlation rate for all musculoskeletal imaging was 83.1% (433 or 508). Low correlation was found in fluoroscopic procedures at 74.4%, and the highest correlation was found with ultrasound at 88.4%. Anatomic location varied from 51.6% for spine to 98.8% for hips and pelvis studies. Survey results revealed 87.5% of the respondents reporting being either satisfied or very satisfied with the new communication tool. The survey also revealed that some radiologists reviewed more cases than before. Conclusions: Matching of radiology and arthroscopy reports by anatomy allows for excellent report correlation (83.1%). Automated correlation improves the quality and efficiency of feedback to radiologists, providing important opportunities for learning and improved accuracy. © 2018 The Association of University Radiologists",,"arthroscopy; Article; correlation analysis; echography; fluoroscopy; hip; human; image analysis; musculoskeletal system; pathological anatomy; pelvis; priority journal; radiology; radiology information system; spine; algorithm; arthroscopy; diagnostic imaging; health personnel attitude; interpersonal communication; musculoskeletal system; questionnaire; surgery; Algorithms; Arthroscopy; Attitude of Health Personnel; Communication; Fluoroscopy; Humans; Musculoskeletal System; Radiology Information Systems; Surveys and Questionnaires; Ultrasonography",Article,Scopus
"Huhdanpaa H.T., Tan W.K., Rundell S.D., Suri P., Chokshi F.H., Comstock B.A., Heagerty P.J., James K.T., Avins A.L., Nedeljkovic S.S., Nerenz D.R., Kallmes D.F., Luetmer P.H., Sherman K.J., Organ N.L., Griffith B., Langlotz C.P., Carrell D., Hassanpour S., Jarvik J.G.","Using Natural Language Processing of Free-Text Radiology Reports to Identify Type 1 Modic Endplate Changes",2018,"Journal of Digital Imaging",25,"10.1007/s10278-017-0013-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028527814&doi=10.1007%2fs10278-017-0013-3&partnerID=40&md5=9ad516287008760ed9f606dd9615db14","Electronic medical record (EMR) systems provide easy access to radiology reports and offer great potential to support quality improvement efforts and clinical research. Harnessing the full potential of the EMR requires scalable approaches such as natural language processing (NLP) to convert text into variables used for evaluation or analysis. Our goal was to determine the feasibility of using NLP to identify patients with Type 1 Modic endplate changes using clinical reports of magnetic resonance (MR) imaging examinations of the spine. Identifying patients with Type 1 Modic change who may be eligible for clinical trials is important as these findings may be important targets for intervention. Four annotators identified all reports that contained Type 1 Modic change, using N = 458 randomly selected lumbar spine MR reports. We then implemented a rule-based NLP algorithm in Java using regular expressions. The prevalence of Type 1 Modic change in the annotated dataset was 10%. Results were recall (sensitivity) 35/50 = 0.70 (95% confidence interval (C.I.) 0.52–0.82), specificity 404/408 = 0.99 (0.97–1.0), precision (positive predictive value) 35/39 = 0.90 (0.75–0.97), negative predictive value 404/419 = 0.96 (0.94–0.98), and F1-score 0.79 (0.43–1.0). Our evaluation shows the efficacy of rule-based NLP approach for identifying patients with Type 1 Modic change if the emphasis is on identifying only relevant cases with low concern regarding false negatives. As expected, our results show that specificity is higher than recall. This is due to the inherent difficulty of eliciting all possible keywords given the enormous variability of lumbar spine reporting, which decreases recall, while availability of good negation algorithms improves specificity. © 2017, Society for Imaging Informatics in Medicine.","Lumbar spine imaging; Modic classification; Natural language processing; Radiology reporting","Electronic document exchange; Magnetic resonance; Medical computing; Patient treatment; Radiation; Radiology; Confidence interval; Electronic medical record; Lumbar spines; Negation algorithms; Negative predictive value; Positive predictive values; Radiology reporting; Regular expressions; Natural language processing systems; diagnostic imaging; human; low back pain; lumbar vertebra; natural language processing; nuclear magnetic resonance imaging; pathology; procedures; prospective study; radiology; reproducibility; research; sensitivity and specificity; Humans; Low Back Pain; Lumbar Vertebrae; Magnetic Resonance Imaging; Natural Language Processing; Prospective Studies; Radiology; Reproducibility of Results; Research Report; Sensitivity and Specificity",Article,Scopus
"Zhang Y., Ding D.Y., Qian T., Manning C.D., Langlotz C.P.","Learning to Summarize Radiology Findings",2018,"EMNLP 2018 - 9th International Workshop on Health Text Mining and Information Analysis, LOUHI 2018 - Proceedings of the Workshop",55,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116426173&partnerID=40&md5=a4ec9c76997037e722e347e179917416","The Impression section of a radiology report summarizes crucial radiology findings in natural language and plays a central role in communicating these findings to physicians. However, the process of generating impressions by summarizing findings is time-consuming for radiologists and prone to errors. We propose to automate the generation of radiology impressions with neural sequence-to-sequence learning. We further propose a customized neural model for this task which learns to encode the study background information and use this information to guide the decoding process. On a large dataset of radiology reports collected from actual hospital studies, our model outperforms existing non-neural and neural baselines under the ROUGE metrics. In a blind experiment, a board-certified radiologist indicated that 67% of sampled system summaries are at least as good as the corresponding human-written summaries, suggesting significant clinical validity. To our knowledge our work represents the first attempt in this direction. © 2018 Association for Computational Linguistics.",,"Computational linguistics; Large dataset; Natural language processing systems; Radiation; Background information; Decoding process; Large datasets; Learn+; Natural languages; Neural modelling; Radiology reports; Sampled systems; Sequence learning; Radiology",Conference Paper,Scopus
"Xue Y., Xu T., Rodney Long L., Xue Z., Antani S., Thoma G.R., Huang X.","Multimodal recurrent model with attention for automated radiology report generation",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",91,"10.1007/978-3-030-00928-1_52","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054079960&doi=10.1007%2f978-3-030-00928-1_52&partnerID=40&md5=76acd9aff527cef47d2e359095d5eced","Radiologists routinely examine medical images such as X-Ray, CT, or MRI and write reports summarizing their descriptive findings and conclusive impressions. A computer-aided radiology report generation system can lighten the workload for radiologists considerably and assist them in decision making. Although the rapid development of deep learning technology makes the generation of a single conclusive sentence possible, results produced by existing methods are not sufficiently reliable due to the complexity of medical images. Furthermore, generating detailed paragraph descriptions for medical images remains a challenging problem. To tackle this problem, we propose a novel generative model which generates a complete radiology report automatically. The proposed model incorporates the Convolutional Neural Networks (CNNs) with the Long Short-Term Memory (LSTM) in a recurrent way. It is capable of not only generating high-level conclusive impressions, but also generating detailed descriptive findings sentence by sentence to support the conclusion. Furthermore, our multimodal model combines the encoding of the image and one generated sentence to construct an attention input to guide the generation of the next sentence, and henceforth maintains coherence among generated sentences. Experimental results on the publicly available Indiana U. Chest X-rays from the Open-i image collection show that our proposed recurrent attention model achieves significant improvements over baseline models according to multiple evaluation metrics. © Springer Nature Switzerland AG 2018.",,"Computerized tomography; Decision making; Deep learning; Image enhancement; Magnetic resonance imaging; Medical computing; Medical imaging; Radiation; Radiology; X rays; Computer-aided radiologies; Convolutional neural network; Evaluation metrics; Generative model; Image collections; Learning technology; Multimodal modeling; Radiology reports; Long short-term memory",Conference Paper,Scopus
"Han Z., Wei B., Leung S., Chung J., Li S.","Towards Automatic Report Generation in Spine Radiology Using Weakly Supervised Framework",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",25,"10.1007/978-3-030-00937-3_22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053852068&doi=10.1007%2f978-3-030-00937-3_22&partnerID=40&md5=b68e907f0f68fe163eeaff2ec1d5334e","The objective of this work is to automatically generate unified reports of lumbar spinal MRIs in the field of radiology, i.e., given an MRI of a lumbar spine, directly generate a radiologist-level report to support clinical decision making. We show that this can be achieved via a weakly supervised framework that combines deep learning and symbolic program synthesis theory to overcome four inevitable tasks: semantic segmentation, radiological classification, positional labeling, and structural captioning. The weakly supervised framework using object level annotations without requiring radiologist-level report annotations to generate unified reports. Each generated report covers almost type lumbar structures comprised of six intervertebral discs, six neural foramina, and five lumbar vertebrae. The contents of each report contain the exact locations and pathological correlations of these lumbar structures as well as their normalities in terms of three type relevant spinal diseases: intervertebral disc degeneration, neural foraminal stenosis, and lumbar vertebrae deformities. This framework is applied to a large corpus of T1/T2-weighted sagittal MRIs of 253 subjects acquired from multiple vendors. Extensive experiments demonstrate that the framework is able to generate unified radiological reports, which reveals its effectiveness and potential as a clinical tool to relieve spinal radiologists from laborious workloads to a certain extent, such that contributes to relevant time savings and expedites the initiation of many specific therapies. © 2018, Springer Nature Switzerland AG.",,"Computation theory; Decision making; Deep learning; Implants (surgical); Medical computing; Medical imaging; Radiation; Semantics; Clinical decision making; Inter-vertebral disc degeneration; Intervertebral discs; Lumbar vertebra; Multiple vendors; Program synthesis; Report generation; Semantic segmentation; Radiology",Conference Paper,Scopus
"Gordon M.N., Cha K.H., Hadjiiski L.M., Chan H.-P., Cohan R.H., Caoili E.M., Paramagul C., Alva A., Weizer A.Z.","Bladder cancer treatment response assessment with radiomic, clinical, and radiologist semantic features",2018,"Progress in Biomedical Optics and Imaging - Proceedings of SPIE",1,"10.1117/12.2294951","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046252747&doi=10.1117%2f12.2294951&partnerID=40&md5=93e058c5ba4dc051a20e426f1621a466","We are developing a decision support system for assisting clinicians in assessment of response to neoadjuvant chemotherapy for bladder cancer. Accurate treatment response assessment is crucial for identifying responders and improving quality of life for non-responders. An objective machine learning decision support system may help reduce variability and inaccuracy in treatment response assessment. We developed a predictive model to assess the likelihood that a patient will respond based on image and clinical features. With IRB approval, we retrospectively collected a data set of pre- A nd post-treatment CT scans along with clinical information from surgical pathology from 98 patients. A linear discriminant analysis (LDA) classifier was used to predict the likelihood that a patient would respond to treatment based on radiomic features extracted from CT urography (CTU), a radiologist's semantic feature, and a clinical feature extracted from surgical and pathology reports. The classification accuracy was evaluated using the area under the ROC curve (AUC) with a leave-one-case-out cross validation. The classification accuracy was compared for the systems based on radiomic features, clinical feature, and radiologist's semantic feature. For the system based on only radiomic features the AUC was 0.75. With the addition of clinical information from examination under anesthesia (EUA) the AUC was improved to 0.78. Our study demonstrated the potential of designing a decision support system to assist in treatment response assessment. The combination of clinical features, radiologist semantic features and CTU radiomic features improved the performance of the classifier and the accuracy of treatment response assessment. © 2018 SPIE.","Bladder; Classification; CT; Level Set; Radiomics; Treatment Response","Artificial intelligence; Chemotherapy; Classification (of information); Computer aided diagnosis; Decision support systems; Discriminant analysis; Diseases; Learning systems; Medical imaging; Pathology; Semantics; Surgery; Area under the ROC curve; Bladder; Classification accuracy; Level Set; Linear discriminant analyses (LDA); Neoadjuvant chemotherapies; Radiomics; Treatment response; Computerized tomography",Conference Paper,Scopus
"Banerjee I., Chen M.C., Lungren M.P., Rubin D.L.","Radiology report annotation using intelligent word embeddings: Applied to multi-institutional chest CT cohort",2018,"Journal of Biomedical Informatics",47,"10.1016/j.jbi.2017.11.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035789284&doi=10.1016%2fj.jbi.2017.11.012&partnerID=40&md5=78a029d14ee922a04a777c9598005806","We proposed an unsupervised hybrid method – Intelligent Word Embedding (IWE) that combines neural embedding method with a semantic dictionary mapping technique for creating a dense vector representation of unstructured radiology reports. We applied IWE to generate embedding of chest CT radiology reports from two healthcare organizations and utilized the vector representations to semi-automate report categorization based on clinically relevant categorization related to the diagnosis of pulmonary embolism (PE). We benchmark the performance against a state-of-the-art rule-based tool, PeFinder and out-of-the-box word2vec. On the Stanford test set, the IWE model achieved average F1 score 0.97, whereas the PeFinder scored 0.9 and the original word2vec scored 0.94. On UPMC dataset, the IWE model's average F1 score was 0.94, when the PeFinder scored 0.92 and word2vec scored 0.85. The IWE model had lowest generalization error with highest F1 scores. Of particular interest, the IWE model (trained on the Stanford dataset) outperformed PeFinder on the UPMC dataset which was used originally to tailor the PeFinder model. © 2017 Elsevier Inc.","Information extraction; Pulmonary embolism; Report annotation; Word embedding","Benchmarking; Diseases; Encoding (symbols); Information retrieval; Radiology; Semantics; Generalization Error; Healthcare organizations; Pulmonary embolism; Report annotation; Semantic dictionaries; Unstructured radiology reports; Vector representations; Word embedding; Radiation; Article; automation; benchmarking; classifier; cohort analysis; computer assisted tomography; diagnostic accuracy; diagnostic test accuracy study; disease classification; human; intelligent word embedding; learning algorithm; lung embolism; measurement precision; medical terminology; natural language processing; priority journal; receiver operating characteristic; semantics; thorax radiography; unsupervised machine learning; validation process; artificial neural network; computer assisted diagnosis; machine learning; predictive value; procedures; thorax radiography; trends; x-ray computed tomography; Humans; Machine Learning; Natural Language Processing; Neural Networks (Computer); Predictive Value of Tests; Pulmonary Embolism; Radiographic Image Interpretation, Computer-Assisted; Radiography, Thoracic; Semantics; Tomography, X-Ray Computed",Article,Scopus
"Qenam B., Kim T.Y., Carroll M.J., Hogarth M.","Text simplification using consumer health vocabulary to generate patient-centered radiology reporting: Translation and evaluation",2017,"Journal of Medical Internet Research",29,"10.2196/jmir.8536","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038947226&doi=10.2196%2fjmir.8536&partnerID=40&md5=53d9d015bee27e0eb00c5774274a0639","Background: Radiology reporting is a clinically oriented form of documentation that reflects critical information for patients about their health care processes. Realizing its importance, many medical institutions have started providing radiology reports in patient portals. The gain, however, can be limited because of medical language barriers, which require a way for customizing these reports for patients. The open-access, collaborative consumer health vocabulary (CHV) is a terminology system created for such purposes and can be the basis of lexical simplification processes for clinical notes. Objective: The aim of this study was to examine the comprehensibility and suitability of CHV in simplifying radiology reports for consumers. This was done by characterizing the content coverage and the lexical similarity between the terms in the reports and the CHV-preferred terms. Methods: The overall procedure was divided into the following two main stages: (1) translation and (2) evaluation. The translation process involved using MetaMap to link terms in the reports to CHV concepts. This is followed by replacing the terms with CHV-preferred terms using the concept names and sources table (MRCONSO) in the Unified Medical Language System (UMLS) Metathesaurus. In the second stage, medical terms in the reports and general terms that are used to describe medical phenomena were selected and evaluated by comparing the words in the original reports with the translated ones. The evaluation includes measuring the content coverage, investigating lexical similarity, and finding trends in missing concepts. Results: Of the 792 terms selected from the radiology reports, 695 of them could be mapped directly to CHV concepts, indicating a content coverage of 88.5%. A total of 51 of the concepts (53%, 51/97) that could not be mapped are names of human anatomical structures and regions, followed by 28 anatomical descriptions and pathological variations (29%, 28/97). In addition, 12 radiology techniques and projections represented 12% of the unmapped concepts, whereas the remaining six concepts (6%, 12/97) were physiological descriptions. The rate of lexical similarity between the CHV-preferred terms and the terms in the radiology reports was approximately 72.6%. Conclusions: The CHV covered a high percentage of concepts found in the radiology reports, but unmapped concepts are associated with areas that are commonly found in radiology reporting. CHV terms also showed a high percentage of lexical similarity with terms in the reports, which contain a myriad of medical jargon. This suggests that many CHV terms might not be suitable for lay consumers who would not be facile with radiology-specific vocabulary. Therefore, further patient-centered content changes are needed of the CHV to increase its usefulness and facilitate its integration into consumer-oriented applications. © 2017 Wenjing Pian, Christopher SG Khoo, Jianxing Chi.","Consumer Health Information; Electronic Health Records; Natural Language Processing; Radiology; Vocabulary","adult; anatomical concepts; consumer health information; electronic health record; female; human; linguistics; male; natural language processing; nomenclature; radiology; Unified Medical Language System; electronic health record; radiology; standards; Electronic Health Records; Humans; Radiology; Unified Medical Language System",Article,Scopus
"Chen W., Durkin C., Huang Y., Adler B., Rust S., Lin S.","Simplified Readability Metric Drives Improvement of Radiology Reports: an Experiment on Ultrasound Reports at a Pediatric Hospital",2017,"Journal of Digital Imaging",6,"10.1007/s10278-017-9972-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019023838&doi=10.1007%2fs10278-017-9972-7&partnerID=40&md5=7442c1f6de2d7c8612cbdcc47ba4adcc","Highly complex medical documents, including ultrasound reports, are greatly mismatched with patient literacy levels. While improving radiology reports for readability is a longstanding concern, few articles objectively measure the effectiveness of physician training for readability improvement. We hypothesized that writing styles may be evaluated using an objective two-dimensional measure and writing training could improve the writing styles of radiologists. To test it, a simplified “grade vs. length” readability metric is developed based on results from factor analysis of ten readability metrics applied to more than 500,000 radiology reports. To test the short-term effectiveness of a writing workshop, we measured the writing style improvement before and after the training. Statistically significant writing style improvement occurred as a result of the training. Although the degree of improvement varied for different measures, it is evident that targeted training could provide potential benefits to improve readability due to our statistically significant results. The simplified grade vs. length metric enables future clinical decision support systems to quantitatively guide physicians to improve writing styles through writing workshops. © 2017, Society for Imaging Informatics in Medicine.","Factor analysis; Radiology reports; Readability metrics; Ultrasound reports; Writing styles","Artificial intelligence; Decision support systems; Multivariant analysis; Radiation; Radiology; Ultrasonics; Clinical decision support systems; Medical documents; Potential benefits; Radiology reports; Readability metrics; Short term; Two-dimensional measure; Writing style; Factor analysis; comprehension; echography; education; hospital; human; medical education; medical record; physician; radiology; standards; total quality management; writing; Comprehension; Education, Medical; Hospitals, Pediatric; Humans; Medical Records; Physicians; Quality Improvement; Radiology; Ultrasonography; Writing",Article,Scopus
"Kelahan L.C., Kalaria A.D., Filice R.W.","PathBot: A Radiology-Pathology Correlation Dashboard",2017,"Journal of Digital Imaging",13,"10.1007/s10278-017-9969-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016943537&doi=10.1007%2fs10278-017-9969-2&partnerID=40&md5=2d73935b07c047cbe11ebe7e9bb2718d","Pathology is considered the “gold standard” of diagnostic medicine. The importance of radiology-pathology correlation is seen in interdepartmental patient conferences such as “tumor boards” and by the tradition of radiology resident immersion in a radiologic-pathology course at the American Institute of Radiologic Pathology. In practice, consistent pathology follow-up can be difficult due to time constraints and cumbersome electronic medical records. We present a radiology-pathology correlation dashboard that presents radiologists with pathology reports matched to their dictations, for both diagnostic imaging and image-guided procedures. In creating our dashboard, we utilized the RadLex ontology and National Center for Biomedical Ontology (NCBO) Annotator to identify anatomic concepts in pathology reports that could subsequently be mapped to relevant radiology reports, providing an automated method to match related radiology and pathology reports. Radiology-pathology matches are presented to the radiologist on a web-based dashboard. We found that our algorithm was highly specific in detecting matches. Our sensitivity was slightly lower than expected and could be attributed to missing anatomy concepts in the RadLex ontology, as well as limitations in our parent term hierarchical mapping and synonym recognition algorithms. By automating radiology-pathology correlation and presenting matches in a user-friendly dashboard format, we hope to encourage pathology follow-up in clinical radiology practice for purposes of self-education and to augment peer review. We also hope to provide a tool to facilitate the production of quality teaching files, lectures, and publications. Diagnostic images have a richer educational value when they are backed up by the gold standard of pathology. © 2017, Society for Imaging Informatics in Medicine.","Dashboard; Medical records systems; Radiology teaching files; Radiology workflow; Radiology-pathology correlation; RadLex","Diagnosis; Gold; Medical computing; Ontology; Pathology; Radiation; Radiology; Teaching; Dashboard; Medical records systems; Radiology teaching files; Radiology workflow; RadLex; Medicine; algorithm; computer interface; human; image guided biopsy; information retrieval; medical record; organization and management; pathology; procedures; radiology information system; workflow; Algorithms; Efficiency, Organizational; Health Records, Personal; Humans; Image-Guided Biopsy; Information Storage and Retrieval; Pathology; Radiology Information Systems; User-Computer Interface; Workflow",Article,Scopus
"Chen J.Y., Sippel Schmidt T.M., Carr C.D., Kahn C.E., Jr.","Enabling the next-generation radiology report: Description of two new system standards",2017,"Radiographics",11,"10.1148/rg.2017160106","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034600303&doi=10.1148%2frg.2017160106&partnerID=40&md5=8a6d40d654d1c434aa14490c50cbdc2a","Currently, most radiology reports are highly variable and consist of unconstrained narrative text. This variability limits the ability to extract information from the report to guide clinical care, populate a data registry, or support quality improvement. This article introduces two newly available standards that pertain to radiology reports. Management of Radiology Reporting Templates (MRRT) is an integration profile that defines the format and exchange mechanisms for radiology report templates. Digital Imaging and Communications in Medicine Part 20 defines how reports built using MRRT-based templates can be transmitted into an electronic health record (EHR). Together, these two standards enable new ways to improve report consistency and completeness, ensure proper clinical action, and improve the quality of patient care. Commercial and open-source developers are beginning to incorporate these standards into clinical systems. The authors use an example of a patient with an incidentally detected lung nodule to illustrate how these standards improve the exchange of information. The clinical scenario follows the use of the appropriate template through the completion of the radiology report, with the incidental finding structured and coded to enable automated follow-up in the EHR. © RSNA, 2017.",,"controlled vocabulary; diagnostic imaging; electronic health record; human; interpersonal communication; measurement accuracy; radiology information system; standards; Communication; Data Accuracy; Diagnostic Imaging; Electronic Health Records; Humans; Radiology Information Systems; Vocabulary, Controlled",Article,Scopus
"Yim W.-W., Kwan S.W., Yetisgen M.","Classifying tumor event attributes in radiology reports",2017,"Journal of the Association for Information Science and Technology",12,"10.1002/asi.23937","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029382177&doi=10.1002%2fasi.23937&partnerID=40&md5=8ce579ff92fb2157e1f9553d07f3cac2","Radiology reports contain vital diagnostic information that characterizes patient disease progression. However, information from reports is represented in free text, which is difficult to query against for secondary use. Automatic extraction of important information, such as tumor events using natural language processing, offers possibilities in improved clinical decision support, cohort identification, and retrospective evidence-based research for cancer patients. The goal of this work was to classify tumor event attributes: negation, temporality, and malignancy, using biomedical ontology and linguistically enriched features. We report our results on an annotated corpus of 101 hepatocellular carcinoma patient radiology reports, and show that the improved classification improves overall template structuring. Classification performances for negation identification, past temporality classification, and malignancy classification were at 0.94, 0.62, and 0.77 F1, respectively. Incorporating the attributes into full templates led to an improvement of 0.72 F1 for tumor-related events over a baseline of 0.65 F1. Improvement of negation, malignancy, and temporality classifications led to significant improvements in template extraction for the majority of categories. We present our machine-learning approach to identifying these several tumor event attributes from radiology reports, as well as highlight challenges and areas for improvement. © 2017 ASIS&T",,"Decision support systems; Extraction; Learning algorithms; Learning systems; Natural language processing systems; Radiation; Radiology; Tumors; Automatic extraction; Biomedical ontologies; Classification performance; Clinical decision support; Disease progression; Evidence based researches; Hepatocellular carcinoma; Machine learning approaches; Diagnosis",Article,Scopus
"Turkeli S., Gazioglu B.S.A., Kurt K.K., Atay H.T., Gorur Y.","Mining similar radiology reports using BoW and Fuzzy C-means clustering",2017,"IDAP 2017 - International Artificial Intelligence and Data Processing Symposium",1,"10.1109/IDAP.2017.8090213","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039900059&doi=10.1109%2fIDAP.2017.8090213&partnerID=40&md5=761b2a716100e9fcd8fdecdd02ca09eb","Finding similar diagnoses for the same region are vital for patients. In this paper, we aim to find the similarity radiology reports based on bag-of-words (BoW) and Fuzzy C-Means Clustering methods. A double-layer structure is applied. Firstly, extracting features from data BoW method is applied and then Fuzzy C-Means algorithm is performed to cluster the blocks into the similar cluster and the non-similar cluster. 457 radiology reports were examined which were collected from a research and education hospital in Istanbul. Data were tested according to the 23 regions and 137 diagnosis. By the opinion of the radiologist a vocabulary consists of these regions and diagnosis were created. Experimental results on data sets have shown that for the standard documents BoW and Fuzzy C-Means Clustering can be used to find similarity. © 2017 IEEE.","Bag of words; Fuzzy C means clustering; Radiology reports; Text mining","Artificial intelligence; Clustering algorithms; Copying; Data handling; Diagnosis; Fuzzy clustering; Fuzzy systems; Radiation; Radiology; Bag of words; Double layer structure; Extracting features; Fuzzy C means clustering; Fuzzy C-means algorithms; Fuzzy c-means clustering method; Radiology reports; Text mining; Data mining",Conference Paper,Scopus
"Gálvez J.A., Pappas J.M., Ahumada L., Martin J.N., Simpao A.F., Rehman M.A., Witmer C.","The use of natural language processing on pediatric diagnostic radiology reports in the electronic health record to identify deep venous thrombosis in children",2017,"Journal of Thrombosis and Thrombolysis",15,"10.1007/s11239-017-1532-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027520876&doi=10.1007%2fs11239-017-1532-y&partnerID=40&md5=54d85897b484b3f180a0f86656a63605","Venous thromboembolism (VTE) is a potentially life-threatening condition that includes both deep vein thrombosis (DVT) and pulmonary embolism. We sought to improve detection and reporting of children with a new diagnosis of VTE by applying natural language processing (NLP) tools to radiologists’ reports. We validated an NLP tool, Reveal NLP (Health Fidelity Inc, San Mateo, CA) and inference rules engine’s performance in identifying reports with deep venous thrombosis using a curated set of ultrasound reports. We then configured the NLP tool to scan all available radiology reports on a daily basis for studies that met criteria for VTE between July 1, 2015, and March 31, 2016. The NLP tool and inference rules engine correctly identified 140 out of 144 reports with positive DVT findings and 98 out of 106 negative reports in the validation set. The tool’s sensitivity was 97.2% (95% CI 93–99.2%), specificity was 92.5% (95% CI 85.7–96.7%). Subsequently, the NLP tool and inference rules engine processed 6373 radiology reports from 3371 hospital encounters. The NLP tool and inference rules engine identified 178 positive reports and 3193 negative reports with a sensitivity of 82.9% (95% CI 74.8–89.2) and specificity of 97.5% (95% CI 96.9–98). The system functions well as a safety net to screen patients for HA-VTE on a daily basis and offers value as an automated, redundant system. To our knowledge, this is the first pediatric study to apply NLP technology in a prospective manner for HA-VTE identification. © 2017, Springer Science+Business Media, LLC.","Epidemiology; Natural language processing; Pediatrics; Quality improvement; Venous thromboembolism; Venous thrombosis","Article; automation; child; clinical assessment tool; deep vein thrombosis; echography; electronic health record; human; lung embolism; mass screening; natural language processing; patient safety; priority journal; protocol compliance; sensitivity and specificity; validation process; venous thromboembolism; adolescent; preschool child; procedures; prospective study; radiology; vein thrombosis; Adolescent; Child; Child, Preschool; Electronic Health Records; Humans; Natural Language Processing; Prospective Studies; Radiology; Sensitivity and Specificity; Ultrasonography; Venous Thromboembolism; Venous Thrombosis",Article,Scopus
"Okawa G., Ching K., Qian H., Feng Y.","Automatic Release of Radiology Reports via an Online Patient Portal",2017,"Journal of the American College of Radiology",12,"10.1016/j.jacr.2017.04.037","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021155990&doi=10.1016%2fj.jacr.2017.04.037&partnerID=40&md5=418bd382dc5aabc1d38520aaff1c85d9",[No abstract available],,"Article; bone densitometry; computer assisted tomography; echography; electronic health record; fluoroscopy; human; medical information; nuclear magnetic resonance imaging; online system; physician; radiography; radiologist; shared decision making; access to information; diagnostic imaging; doctor patient relation; Hawaii; medical record; patient referral; patient right; patient satisfaction; radiology information system; Access to Information; Diagnostic Imaging; Electronic Health Records; Hawaii; Humans; Patient Portals; Patient Rights; Patient Satisfaction; Physician-Patient Relations; Radiology Information Systems; Referral and Consultation",Article,Scopus
"Alkasab T.K., Bizzo B.C., Berland L.L., Nair S., Pandharipande P.V., Harvey H.B.","Creation of an Open Framework for Point-of-Care Computer-Assisted Reporting and Decision Support Tools for Radiologists",2017,"Journal of the American College of Radiology",33,"10.1016/j.jacr.2017.04.031","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021126291&doi=10.1016%2fj.jacr.2017.04.031&partnerID=40&md5=c6a0b7e5cc1e1fdc4491e0ffc9f2c8a2","Decreasing unnecessary variation in radiology reporting and producing guideline-concordant reports is fundamental to radiology's success in value-based payment models and good for patient care. In this article, we present an open authoring system for point-of-care clinical decision support tools integrated into the radiologist reporting environment referred to as the computer-assisted reporting and decision support (CAR/DS) framework. The CAR/DS authoring system, described herein, includes: (1) a definition format for representing radiology clinical guidelines as structured, machine-readable Extensible Markup Language documents and (2) a user-friendly reference implementation to test the fidelity of the created definition files with the clinical guideline. The proposed definition format and reference implementation will enable content creators to develop CAR/DS tools that voice recognition software (VRS) vendors can use to extend the commercial tools currently in use. In making the definition format and reference implementation software freely available, we hope to empower individual radiologists, expert groups such as the ACR, and VRS vendors to develop a robust ecosystem of CAR/DS tools that can further improve the quality and efficiency of the patient care that our field provides. We hope that this initial effort can serve as the basis for a community-owned open standard for guideline definition that the imaging informatics and VRS vendor communities will embrace and strengthen. To this end, the ACR Assist™ initiative is intended to make the College's clinical content, including the Incidental Findings Committee White Papers, available for decision support tool creation based upon the herein described CAR/DS framework. © 2017 American College of Radiology","clinical decision support; guideline; quality; Radiology; reporting; standardized; structured; value","automatic speech recognition; college; decision support system; ecosystem; female; human; human experiment; imaging; incidental finding; information science; machine; male; markup language; patient care; practice guideline; radiologist; radiology; clinical decision support system; organization and management; point of care system; protocol compliance; software; Decision Support Systems, Clinical; Guideline Adherence; Humans; Point-of-Care Systems; Radiologists; Software",Article,Scopus
"Nandhakumar N., Sherkat E., Milios E.E., Gu H., Butler M.","Clinically significant information extraction from radiology reports",2017,"DocEng 2017 - Proceedings of the 2017 ACM Symposium on Document Engineering",8,"10.1145/3103010.3103023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030563405&doi=10.1145%2f3103010.3103023&partnerID=40&md5=2b59e3e50f158251fd233dbba2e3d1b7","Radiology reports are one of the most important medical documents that a diagnostician looks into, especially in the emergency context. .ey provide the emergency physicians with critical information regarding the condition of the patient and help the physicians take immediate action on urgent conditions. However, the reports are in the form of unstructured text, which makes them time consuming for humans to interpret. We have developed a machine learning system to (a) effciently extract the clinically signi.cant parts and their level of importance in radiology reports, and (b) toclassi.es the overall report into critical or non-critical categories which help doctors to identify potential high priority reports. As a starting point, the system uses anonymized chest X-RAY reports of adults and provides three levels of importance for medical phrases. We used the Conditional Random Field (CRF) model to identify clinically signi.cant phrases with an average f1-score of 0.75. .e proposed system includes a web-based interface which highlights the medical phrases, and their level of importance to the emergency physician. .e overall classi.cation of the report is performed using the phrases extracted from the CRF model as features for the classi.er. Average accuracy achieved is 85%. © 2017 ACM.","Classification; Information Extraction; Radiology Reports","Classification (of information); Information analysis; Information retrieval; Learning systems; Multimedia systems; Radiology; Random processes; Chest x-rays; Conditional random field; Emergency contexts; Medical documents; Radiology reports; System use; Unstructured texts; Web-based interface; Radiation",Conference Paper,Scopus
"Shin B., Chokshi F.H., Lee T., Choi J.D.","Classification of radiology reports using neural attention models",2017,"Proceedings of the International Joint Conference on Neural Networks",32,"10.1109/IJCNN.2017.7966408","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030987560&doi=10.1109%2fIJCNN.2017.7966408&partnerID=40&md5=0e27b0194cc626a388072639e480987e","The electronic health record (EHR) contains a large amount of multi-dimensional and unstructured clinical data of significant operational and research value. Distinguished from previous studies, our approach embraces a double-annotated dataset and strays away from obscure 'black-box' models to comprehensive deep learning models. In this paper, we present a novel neural attention mechanism that not only classifies clinically important findings. Specifically, convolutional neural networks (CNN) with attention analysis are used to classify radiology head computed tomography reports based on five categories that radiologists would account for in assessing acute and communicable findings in daily practice. The experiments show that our CNN attention models outperform non-neural models, especially when trained on a larger dataset. Our attention analysis demonstrates the intuition behind the classifier's decision by generating a heatmap that highlights attended terms used by the CNN model; this is valuable when potential downstream medical decisions are to be performed by human experts or the classifier information is to be used in cohort construction such as for epidemiological studies. © 2017 IEEE.",,"Computerized tomography; Neural networks; Radiation; Radiology; Attention mechanisms; Convolutional neural network; Electronic health record; Epidemiological studies; Learning models; Medical decision making; Multi dimensional; Radiology reports; Classification (of information)",Conference Paper,Scopus
"Rubin D.L., Kahn C.E., Jr.","Common data elements in radiology",2017,"Radiology",59,"10.1148/radiol.2016161553","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019841077&doi=10.1148%2fradiol.2016161553&partnerID=40&md5=d7446fe7d41a5007ef858953be11d94e","Diagnostic radiologists generally produce unstructured information in the form of images and narrative text reports. Although designed for human consumption, radiologic reports contain a wealth of information that could be valuable for clinical care, research, and quality improvement if that information could be extracted by automated systems. Unfortunately, the lack of structure in radiologic reports limits the ability of information systems to share information easily with other systems. A common data element (CDE) - a unit of information used in a shared, predefned fashion - can improve the ability to exchange information seamlessly among information systems. In this article, a model and a repository of radiologic CDEs is described, and three important applications are highlighted. CDEs can help advance radiologic practice, research, and performance improvement, and thus, it is crucial that CDEs be adopted widely in radiologic information systems. © RSNA, 2016.",,"Article; cerebrovascular accident; common data element; computer aided design; decision support system; emergency medicine; epilepsy; geometry; human; information system; malignant neoplasm; natural language processing; practice guideline; priority journal; process model; radiologist; rare disease; traumatic brain injury; common data elements; radiography; theoretical model; Common Data Elements; Models, Theoretical; Radiography",Article,Scopus
"Zucker E.J., Barth R.A.","Impact of California Computed Tomography Dose Legislation: Survey of Radiologists",2017,"Journal of Medical Imaging and Radiation Sciences",1,"10.1016/j.jmir.2017.02.072","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016744355&doi=10.1016%2fj.jmir.2017.02.072&partnerID=40&md5=54688a1154b8a80c310d8808ebf36bbd","Introduction Highly publicized accounts of radiation overdose from computed tomography (CT) in both children and adults prompted legislation in California regulating CT dose. The purpose of this study was to determine the impact of the law (codified in Senate Bill [SB] 1237) on California radiologist practice patterns and understanding of CT dose. Materials and Methods All radiologist members of the California Radiological Society were surveyed in August–September 2013. Questions gauged radiologists' familiarity with and attitudes toward the law, awareness of CT dose, and changes in practice following the law's enactment. Results Of 1,300 surveyed, 138 (11%) responded; 132 of 137 (96%) were familiar with SB 1237. Of 135 responding, 126 and 115 (93% and 85%, respectively) knew to report CT dose index volume and dose-length product. Sixty of 134 (45%) attributed dose reporting to an increased awareness of appropriate dose ranges. Twenty-nine of 133 (22%) had modified protocols in concert with SB 1237s enactment. Of 31 responding, 5 (16%), 23 (74%), and 3 (74%) had modified protocols in only children, both adults and children, and only adults, respectively. Twenty-four of 129 (19%) utilized automated dose reporting; 48 (37%) and 57 (44%) used dictation/transcription and template-assisted voice recognition, respectively. Forty of 134 (30%) noted delays finalizing CT reports. Conclusions Most radiologists who responded in our sample were familiar with SB 1237. Nearly half attributed dose reporting to an increased awareness of appropriate dose ranges. Almost one quarter indicated protocol modifications, the majority including children, occurring in conjunction with the law. Reporting inefficiency was a common concern. © 2017","California; CT; dose reporting; radiation dose; Senate Bill 1237","adult; Article; automatic speech recognition; awareness; California; clinical protocol; computer assisted tomography; health personnel attitude; human; information; law; major clinical study; practice guideline; priority journal; protocol compliance; radiation dose; radiologist",Article,Scopus
"Hassanpour S., Bay G., Langlotz C.P.","Characterization of Change and Significance for Clinical Findings in Radiology Reports Through Natural Language Processing",2017,"Journal of Digital Imaging",26,"10.1007/s10278-016-9931-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008224704&doi=10.1007%2fs10278-016-9931-8&partnerID=40&md5=9810c39b50dbc8a08b5bfc69b50ac2d7","We built a natural language processing (NLP) method to automatically extract clinical findings in radiology reports and characterize their level of change and significance according to a radiology-specific information model. We utilized a combination of machine learning and rule-based approaches for this purpose. Our method is unique in capturing different features and levels of abstractions at surface, entity, and discourse levels in text analysis. This combination has enabled us to recognize the underlying semantics of radiology report narratives for this task. We evaluated our method on radiology reports from four major healthcare organizations. Our evaluation showed the efficacy of our method in highlighting important changes (accuracy 99.2%, precision 96.3%, recall 93.5%, and F1 score 94.7%) and identifying significant observations (accuracy 75.8%, precision 75.2%, recall 75.7%, and F1 score 75.3%) to characterize radiology reports. This method can help clinicians quickly understand the key observations in radiology reports and facilitate clinical decision support, review prioritization, and disease surveillance. © 2016, Society for Imaging Informatics in Medicine.","Imaging informatics; Natural language processing; Radiology reports","Decision support systems; Learning algorithms; Learning systems; Radiation; Radiology; Semantics; Clinical decision support; Disease surveillance; Healthcare organizations; Imaging informatics; Levels of abstraction; NAtural language processing; Radiology reports; Specific information; Natural language processing systems; clinical decision making; human; machine learning; medical record; natural language processing; radiography; radiology; research; semantics; Clinical Decision-Making; Humans; Machine Learning; Medical Records; Natural Language Processing; Radiography; Radiology; Research Report; Semantics",Article,Scopus
"Castro S.M., Tseytlin E., Medvedeva O., Mitchell K., Visweswaran S., Bekhuis T., Jacobson R.S.","Automated annotation and classification of BI-RADS assessment from radiology reports",2017,"Journal of Biomedical Informatics",52,"10.1016/j.jbi.2017.04.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018487597&doi=10.1016%2fj.jbi.2017.04.011&partnerID=40&md5=bc8c06a7c358916dd3749cfeecfa7bd9","The Breast Imaging Reporting and Data System (BI-RADS) was developed to reduce variation in the descriptions of findings. Manual analysis of breast radiology report data is challenging but is necessary for clinical and healthcare quality assurance activities. The objective of this study is to develop a natural language processing (NLP) system for automated BI-RADS categories extraction from breast radiology reports. We evaluated an existing rule-based NLP algorithm, and then we developed and evaluated our own method using a supervised machine learning approach. We divided the BI-RADS category extraction task into two specific tasks: (1) annotation of all BI-RADS category values within a report, (2) classification of the laterality of each BI-RADS category value. We used one algorithm for task 1 and evaluated three algorithms for task 2. Across all evaluations and model training, we used a total of 2159 radiology reports from 18 hospitals, from 2003 to 2015. Performance with the existing rule-based algorithm was not satisfactory. Conditional random fields showed a high performance for task 1 with an F-1 measure of 0.95. Rules from partial decision trees (PART) algorithm showed the best performance across classes for task 2 with a weighted F-1 measure of 0.91 for BIRADS 0-6, and 0.93 for BIRADS 3-5. Classification performance by class showed that performance improved for all classes from Naïve Bayes to Support Vector Machine (SVM), and also from SVM to PART. Our system is able to annotate and classify all BI-RADS mentions present in a single radiology report and can serve as the foundation for future studies that will leverage automated BI-RADS annotation, to provide feedback to radiologists as part of a learning health system loop. © 2017","Breast Imaging Reporting and Data System (BI-RADS); Imaging informatics; Information extraction; Machine learning; Natural language processing","Artificial intelligence; Automation; Data mining; Decision trees; Information retrieval; Learning algorithms; Learning systems; Medical imaging; Quality assurance; Quality control; Radiation; Radiology; Supervised learning; Support vector machines; Trees (mathematics); BI-RADS; Breast imaging reporting and data systems; Classification performance; Conditional random field; Imaging informatics; NAtural language processing; Partial decision trees; Supervised machine learning; Natural language processing systems; Article; classification; classifier; computer assisted tomography; data processing; decision tree; echomammography; feedback system; image analysis; image processing; imaging software; information processing; intermethod comparison; mammography; natural language processing; nuclear magnetic resonance imaging; quality control; supervised machine learning; support vector machine; Bayes theorem; breast; breast tumor; diagnostic imaging; female; human; information processing; radiology information system; Bayes Theorem; Breast; Breast Neoplasms; Data Curation; Female; Humans; Mammography; Radiology Information Systems",Article,Scopus
"Hassanpour S., Langlotz C.P., Amrhein T.J., Befera N.T., Lungren M.P.","Performance of a machine learning classifier of knee mri reports in two large academic radiology practices: A tool to estimate diagnostic yield",2017,"American Journal of Roentgenology",31,"10.2214/AJR.16.16128","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016515607&doi=10.2214%2fAJR.16.16128&partnerID=40&md5=a4fa19652205551b549f67da02e6beac","OBJECTIVE. The purpose of this study is to evaluate the performance of a natural language processing (NLP) system in classifying a database of free-text knee MRI reports at two separate academic radiology practices. MATERIALS AND METHODS. An NLP system that uses terms and patterns in manually classified narrative knee MRI reports was constructed. The NLP system was trained and tested on expert-classified knee MRI reports from two major health care organizations. Radiology reports were modeled in the training set as vectors, and a support vector machine framework was used to train the classifier. A separate test set from each organization was used to evaluate the performance of the system. We evaluated the performance of the system both within and across organizations. Standard evaluation metrics, such as accuracy, precision, recall, and F1 score (i.e., the weighted average of the precision and recall), and their respective 95% CIs were used to measure the efficacy of our classification system. RESULTS. The accuracy for radiology reports that belonged to the model's clinically significant concept classes after training data from the same institution was good, yielding an F1 score greater than 90% (95% CI, 84.6-97.3%). Performance of the classifier on cross-institutional application without institution-specific training data yielded F1 scores of 77.6% (95% CI, 69.5-85.7%) and 90.2% (95% CI, 84.5-95.9%) at the two organizations studied. CONCLUSION. The results show excellent accuracy by the NLP machine learning classifier in classifying free-text knee MRI reports, supporting the institution-independent reproducibility of knee MRI report classification. Furthermore, the machine learning classifier performed well on free-text knee MRI reports from another institution. These data support the feasibility of multiinstitutional classification of radiologic imaging text reports with a single machine learning classifier without requiring institution-specific training data. © American Roentgen Ray Society.","Classification; Machine learning; MRI","accuracy; Article; bootstrapping; classification; classifier; diagnostic test accuracy study; diagnostic value; human; knee; machine learning; medical practice; natural language processing; nuclear magnetic resonance imaging; recall; retrospective study; software; support vector machine; automated pattern recognition; California; clinical trial; data mining; diagnostic imaging; image enhancement; knee; multicenter study; natural language processing; North Carolina; nuclear magnetic resonance imaging; organization and management; procedures; radiology department; radiology information system; reproducibility; sensitivity and specificity; statistics and numerical data; university hospital; workload; Academic Medical Centers; California; Data Mining; Humans; Image Enhancement; Knee; Machine Learning; Magnetic Resonance Imaging; Natural Language Processing; North Carolina; Pattern Recognition, Automated; Radiology Department, Hospital; Radiology Information Systems; Reproducibility of Results; Sensitivity and Specificity; Support Vector Machine; Workload",Article,Scopus
"Licurse M.Y., Lalevic D., Zafar H.M., Schnall M.D., Cook T.S.","Expanding the Scope of an Automated Radiology Recommendation-Tracking Engine: Initial Experiences and Lessons Learned",2017,"Journal of Digital Imaging",,"10.1007/s10278-016-9912-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994693959&doi=10.1007%2fs10278-016-9912-y&partnerID=40&md5=7923ed9cc335549e34181734a22c5f81","An automated radiology recommendation-tracking engine for incidental focal masses in the liver, pancreas, kidneys, and adrenal glands was launched within our institution in July 2013. For 2 years, the majority of CT, MR, and US examination reports generated within our health system were mined by the engine. However, the need to expand the system beyond the initial four organs was soon identified. In July 2015, the second phase of the system was implemented and expanded to include additional anatomic structures in the abdomen and pelvis, as well as to provide non-radiology and non-imaging options for follow-up. The most frequent organs with incidental findings, outside of the original four, included the ovaries and the endometrium, which also correlated to the most frequently ordered imaging follow-up study of pelvic ultrasound and non-imaging follow-up study of endometrial biopsies, respectively. The second phase expansion has demonstrated new venues for augmenting and improving radiologist roles in optimal communication and management of incidental findings. © 2016, Society for Imaging Informatics in Medicine.","Cancer detection; Communication; Data mining; Imaging informatics","Communication; Computerized tomography; Data mining; Engines; Radiation; Radiology; Ultrasonic applications; Adrenal gland; Anatomic structures; Cancer detection; Follow-up Studies; Health systems; Imaging informatics; Incidental findings; Optimal communication; Recommender systems; abdominal tumor; data mining; diagnostic imaging; echography; female; follow up; human; incidental finding; nuclear magnetic resonance imaging; pelvis tumor; procedures; search engine; x-ray computed tomography; Abdominal Neoplasms; Data Mining; Female; Follow-Up Studies; Humans; Incidental Findings; Magnetic Resonance Imaging; Pelvic Neoplasms; Search Engine; Tomography, X-Ray Computed; Ultrasonography",Article,Scopus
"Ringler M.D., Goss B.C., Bartholmai B.J.","Syntactic and semantic errors in radiology reports associated with speech recognition software",2017,"Health Informatics Journal",19,"10.1177/1460458215613614","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014868955&doi=10.1177%2f1460458215613614&partnerID=40&md5=71cfb21862857063d166a6b68f653c29","Speech recognition software can increase the frequency of errors in radiology reports, which may affect patient care. We retrieved 213,977 speech recognition software-generated reports from 147 different radiologists and proofread them for errors. Errors were classified as ""material"" if they were believed to alter interpretation of the report. ""Immaterial"" errors were subclassified as intrusion/omission or spelling errors. The proportion of errors and error type were compared among individual radiologists, imaging subspecialty, and time periods. In all, 20,759 reports (9.7%) contained errors, of which 3992 (1.9%) were material errors. Among immaterial errors, spelling errors were more common than intrusion/omission errors (p <.001). Proportion of errors and fraction of material errors varied significantly among radiologists and between imaging subspecialties (p <.001). Errors were more common in cross-sectional reports, reports reinterpreting results of outside examinations, and procedural studies (all p <.001). Error rate decreased over time (p <.001), which suggests that a quality control program with regular feedback may reduce errors. © SAGE Publications.","PowerScribe; quality control; radiology report; report errors; speech recognition","automatic speech recognition; controlled study; error; human; human experiment; imaging; patient care; quality control; radiologist; radiology; spelling; automatic speech recognition; cross-sectional study; documentation; methodology; procedures; radiology information system; research; retrospective study; semantics; standards; statistics and numerical data; utilization; Cross-Sectional Studies; Documentation; Humans; Radiologists; Radiology Information Systems; Research Design; Research Report; Retrospective Studies; Semantics; Speech Recognition Software",Article,Scopus
"Machado L.B., Apolo A.B., Steinberg S.M., Folio L.R.","Radiology reports with hyperlinks improve target lesion selection and measurement concordance in cancer trials",2017,"American Journal of Roentgenology",7,"10.2214/AJR.16.16845","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010930880&doi=10.2214%2fAJR.16.16845&partnerID=40&md5=5dccb087e11f12b41fa48bb7fb50fdc6","OBJECTIVE. Radiology reports often lack the measurements of target lesions that are needed for oncology clinical trials. When available, the measurements in the radiology reports often do not match those in the records used to calculate therapeutic response. This study assessed the clinical value of hyperlinked tumor measurements in multimedia-enhanced radiology reports in the PACS and the inclusion of a radiologist assistant in the process of assessing tumor burden. MATERIALS AND METHODS. We assessed 489 target lesions in 232 CT examinations of 71 patients with metastatic genitourinary cancer enrolled in two therapeutic trials. We analyzed target lesion selection and measurement concordance between oncology records (used to calculate therapeutic response) and two types of radiology reports in the PACS: multimedia-enhanced radiology reports and text-only reports. For statistical tests, we used the Wilcoxon signed rank, Wilcoxon rank sum test, and Fisher method to combine p values from the paired and unpaired results. The Fisher exact test was used to compare overall measurement concordance. RESULTS. Concordance on target lesion selection was greater for multimedia-enhanced radiology reports (78%) than the text-only reports (52%) (p = 0.0050). There was also improved overall measurement concordance with the multimedia-enhanced radiology reports (68%) compared with the text-only reports (38%) (p < 0.0001). CONCLUSION. Compared with text-only reports, hyperlinked multimedia-enhanced radiology reports improved concordance of target lesion selection and measurement with the measurements used to calculate therapeutic response. © American Roentgen Ray Society.","Hyperlinks; Multimedia; Radiology reports; Response Evaluation Criteria in Solid Tumors (RECIST) 1.1; Tumor assessment","Article; bladder cancer; bladder carcinoma; cohort analysis; germ cell tumor; human; image analysis; major clinical study; retrospective study; small cell carcinoma; squamous cell carcinoma; transitional cell carcinoma; tumor localization; tumor volume; urogenital tract cancer; x-ray computed tomography; clinical trial (topic); data mining; documentation; medical record; natural language processing; procedures; radiology information system; reproducibility; response evaluation criteria in solid tumors; sensitivity and specificity; Urogenital Neoplasms; utilization; x-ray computed tomography; Clinical Trials as Topic; Data Mining; Documentation; Humans; Medical Record Linkage; Natural Language Processing; Radiology Information Systems; Reproducibility of Results; Response Evaluation Criteria in Solid Tumors; Sensitivity and Specificity; Tomography, X-Ray Computed; Urogenital Neoplasms",Article,Scopus
"Kosik R.O., Lee K.K., Kang Y.S., Patel M.R.","Improved Radiologists’ Efficiency and Accuracy with the Application of Scripting Software for the Automated Reporting of Comparison Studies",2017,"Academic Radiology",,"10.1016/j.acra.2016.09.016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007040156&doi=10.1016%2fj.acra.2016.09.016&partnerID=40&md5=fb01e71ea1b62acd81dc56129f758a9c","Rationale and Objectives The American College of Radiology reporting guidelines state that “comparison with relevant examinations and reports should be part of the radiologic consultation and report when appropriate and available.“ Materials and Methods We evaluated the use of open-source Windows scripting software for the automated retrieval of the date and time of prior studies. Results and Conclusion The date and time of the comparative study are transferred automatically to the present report in a structured voice recognition dictation system with a “regular expression substitution pattern” construct. © 2017 The Association of University Radiologists","comparison studies; date retrieval; Scripting software","Article; automation; comparative study; controlled study; human; information retrieval; practice guideline; priority journal; productivity; radiologist; resident; software design; workflow; California; clinical competence; evaluation study; procedures; radiologist; radiology; radiology department; radiology information system; software; standards; California; Clinical Competence; Humans; Radiologists; Radiology; Radiology Department, Hospital; Radiology Information Systems; Software",Article,Scopus
"Karimi S., Dai X., Hassanzadeh H., Nguyen A.","Automatic Diagnosis Coding of Radiology Reports: A Comparison of Deep Learning and Conventional Classification Methods",2017,"BioNLP 2017 - SIGBioMed Workshop on Biomedical Natural Language Processing, Proceedings of the 16th BioNLP Workshop",36,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122954024&partnerID=40&md5=8b110acd2d2d779b46ef28af22b67a1f","Diagnosis autocoding is intended to both improve the productivity of clinical coders and the accuracy of the coding. We investigate the applicability of deep learning at autocoding of radiology reports using International Classification of Diseases (ICD). Deep learning methods are known to require large training data. Our goal is to explore how to use these methods when the training data is sparse, skewed and relatively small, and how their effectiveness compares to conventional methods. We identify optimal parameters for setting up a convolutional neural network for autocoding with comparable results to that of conventional methods. © 2017 Association for Computational Linguistics",,"Classification (of information); Computer aided diagnosis; Neural networks; Radiation; Radiology; Auto-coding; Automatic diagnosis; Conventional classification methods; Conventional methods; Convolutional neural network; International classification of disease; Learning methods; Optimal parameter; Radiology reports; Training data; Deep learning",Conference Paper,Scopus
"Chapman A.B., Mowery D.L., Swords D.S., Chapman W.W., Bucher B.T.","Detecting Evidence of Intra-abdominal Surgical Site Infections from Radiology Reports Using Natural Language Processing",2017,"AMIA ... Annual Symposium proceedings. AMIA Symposium",12,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058748609&partnerID=40&md5=e1b6479dc6c85ff60170347d34e46021","Free-text reports in electronic health records (EHRs) contain medically significant information - signs, symptoms, findings, diagnoses - recorded by clinicians during patient encounters. These reports contain rich clinical information which can be leveraged for surveillance of disease and occurrence of adverse events. In order to gain meaningful knowledge from these text reports to support surveillance efforts, information must first be converted into a structured, computable format. Traditional methods rely on manual review of charts, which can be costly and inefficient. Natural language processing (NLP) methods offer an efficient, alternative approach to extracting the information and can achieve a similar level of accuracy. We developed an NLP system to automatically identify mentions of surgical site infections in radiology reports and classify reports containing evidence of surgical site infections leveraging these mentions. We evaluated our system using a reference standard of reports annotated by domain experts, administrative data generated for each patient encounter, and a machine learning-based approach.",,"abdomen; controlled vocabulary; diagnostic imaging; electronic health record; evaluation study; human; information processing; machine learning; natural language processing; radiography; radiology information system; standard; surgery; surgical infection; Abdomen; Datasets as Topic; Electronic Health Records; Humans; Machine Learning; Natural Language Processing; Radiography; Radiology Information Systems; Reference Standards; Surgical Wound Infection; Vocabulary, Controlled",Article,Scopus
"Banerjee I., Madhavan S., Goldman R.E., Rubin D.L.","Intelligent Word Embeddings of Free-Text Radiology Reports",2017,"AMIA ... Annual Symposium proceedings. AMIA Symposium",21,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057020140&partnerID=40&md5=556e3a742f637e6b0c670e5cbf44d4de","Radiology reports are a rich resource for advancing deep learning applications in medicine by leveraging the large volume of data continuously being updated, integrated, and shared. However, there are significant challenges as well, largely due to the ambiguity and subtlety of natural language. We propose a hybrid strategy that combines semantic-dictionary mapping and word2vec modeling for creating dense vector embeddings of free-text radiology reports. Our method leverages the benefits of both semantic-dictionary mapping as well as unsupervised learning. Using the vector representation, we automatically classify the radiology reports into three classes denoting confidence in the diagnosis of intracranial hemorrhage by the interpreting radiologist. We performed experiments with varying hyperparameter settings of the word embeddings and a range of different classifiers. Best performance achieved was a weighted precision of 88% and weighted recall of 90%. Our work offers the potential to leverage unstructured electronic health record data by allowing direct analysis of narrative clinical notes.",,"brain hemorrhage; diagnostic imaging; electronic health record; human; information processing; machine learning; natural language processing; radiology information system; semantics; Datasets as Topic; Electronic Health Records; Humans; Intracranial Hemorrhages; Machine Learning; Natural Language Processing; Radiology Information Systems; Semantics",Article,Scopus
"Yim W.-W., Kwan S.W., Johnson G., Yetisgen M.","Classification of hepatocellular carcinoma stages from free-text clinical and radiology reports",2017,"AMIA ... Annual Symposium proceedings. AMIA Symposium",3,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056628176&partnerID=40&md5=c6b5847eb0c16c64a01953489d039cc2","Cancer stage information is important for clinical research. However, they are not always explicitly noted in electronic medical records. In this paper, we present our work on automatic classification of hepatocellular carcinoma (HCC) stages from free-text clinical and radiology notes. To accomplish this, we defined 11 stage parameters used in the three HCC staging systems, American Joint Committee on Cancer (AJCC), Barcelona Clinic Liver Cancer (BCLC), and Cancer of the Liver Italian Program (CLIP). After aggregating stage parameters to the patient-level, the final stage classifications were achieved using an expert-created decision logic. Each stage parameter relevant for staging was extracted using several classification methods, e.g. sentence classification and automatic information structuring, to identify and normalize text as cancer stage parameter values. Stage parameter extraction for the test set performed at 0.81 F1. Cancer stage prediction for AJCC, BCLC, and CLIP stage classifications were 0.55, 0.50, and 0.43 F1.",,"algorithm; cancer staging; classification; human; information processing; liver cell carcinoma; liver tumor; medical record; pathology; procedures; prognosis; radiology; Washington; Algorithms; Carcinoma, Hepatocellular; Datasets as Topic; Humans; Liver Neoplasms; Medical Records; Neoplasm Staging; Prognosis; Radiology; Washington",Article,Scopus
"Cotik V., Filippo D., Roller R., Uszkoreit H., Xu F.","Annotation of entities and relations in Spanish radiology reports",2017,"International Conference Recent Advances in Natural Language Processing, RANLP",18,"10.26615/978-954-452-049-6_025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045751535&doi=10.26615%2f978-954-452-049-6_025&partnerID=40&md5=cf6eda413798cb48ff84ce1877f6bf92","Radiology reports express the results of a radiology study and contain information about anatomical entities, findings, measures and impressions of the medical doctor. The use of information extraction techniques can help physicians to access this information in order to understand data and to infer further knowledge. Supervised machine learning methods are very popular to address information extraction, but are usually domain and language dependent. To train new classification models, annotated data is required. Moreover, annotated data is also required as an evaluation resource of information extraction algorithms. However, one major drawback of processing clinical data is the low availability of annotated datasets. For this reason we performed a manual annotation of radiology reports written in Spanish. This paper presents the corpus, the annotation schema, the annotation guidelines and further insight of the data. © 2018 Association for Computational Linguistics (ACL). All rights reserved.",,"Data handling; Data mining; Information retrieval; Information systems; Information use; Learning algorithms; Natural language processing systems; Radiation; Radiology; Supervised learning; Address informations; Classification models; Clinical data; Extraction algorithms; Information extraction techniques; Machine learning methods; Medical doctors; Radiology reports; Spanish Radiology; Supervised machine learning; Deep learning",Conference Paper,Scopus
"Kahn C.E., Jr.","An ontology-based approach to estimate the frequency of rare diseases in narrative-text radiology reports",2017,"Studies in Health Technology and Informatics",4,"10.3233/978-1-61499-830-3-896","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040534227&doi=10.3233%2f978-1-61499-830-3-896&partnerID=40&md5=9fece604813a7085886588aa71cdf83e","This study sought to use ontology-based knowledge to identify patients with rare diseases and to estimate the frequency of those diseases in a large database of radiology reports. Natural language processing methods were applied to 12, 377, 743 narrarive-text radiology reports of 7, 803, 811 patients at an academic health system. Using knowledge from the Orphanet Rare Disease Ontology and Radiology Gamuts Ontology, 1, 154 of 6, 794 rare diseases (17.0%) were observed in a total of 237, 840 patients (3.05%). Ninety of 2, 129 diseases (4%) with known prevalence less than 1 per 1, 000, 000 were observed in the database, whereas 100 of 173 diseases (58%) with prevalence greater than 1 per 10, 000 were observed; the difference was statistically significant (p<.00001). Automated ontology-based search of radiology reports can estimate the frequency of rare diseases, and those diseases with higher known prevalence were significantly more likely to appear in radiology reports. © 2017 International Medical Informatics Association (IMIA) and IOS Press.","Information storage and retrieval; Knowledge bases; Rare diseases","Health care; Natural language processing systems; Ontology; Radiation; Radiology; Health systems; Information storage and retrieval; Knowledge basis; Large database; Natural languages; Ontology-based searches; Radiology reports; Rare disease; Diseases; biological ontology; human; information retrieval; natural language processing; radiology; radiology information system; rare disease; verbal communication; Biological Ontologies; Humans; Information Storage and Retrieval; Narration; Natural Language Processing; Radiology; Radiology Information Systems; Rare Diseases",Conference Paper,Scopus
"Tian Z., Sun S., Eguale T., Rochefort C.M.","Automated extraction of vte events from narrative radiology reports in electronic health records: A validation study",2017,"Medical Care",25,"10.1097/MLR.0000000000000346","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030613686&doi=10.1097%2fMLR.0000000000000346&partnerID=40&md5=54beb515ab0b4048b43055cd3dbc36fb","Background: Surveillance of venous thromboembolisms (VTEs) is necessary for improving patient safety in acute care hospitals, but current detection methods are inaccurate and inefficient. With the growing availability of clinical narratives in an electronic format, automated surveillance using natural language processing (NLP) techniques may represent a better method. Objective: We assessed the accuracy of using symbolic NLP for identifying the 2 clinical manifestations of VTE, deep vein thrombosis (DVT) and pulmonary embolism (PE), from narrative radiology reports. Methods: A random sample of 4000 narrative reports was selected among imaging studies that could diagnose DVT or PE, and that were performed between 2008 and 2012 in a university health network of 5 adult-care hospitals in Montreal (Canada). The reports were coded by clinical experts to identify positive and negative cases of DVT and PE, which served as the reference standard. Using data from the largest hospital (n=2788), 2 symbolic NLP classifiers were trained; one for DVT, the other for PE. The accuracy of these classifiers was tested on data from the other 4 hospitals (n=1212). Results: On manual review, 663 DVT-positive and 272 PE-positive reports were identified. In the testing dataset, the DVT classifier achieved 94% sensitivity (95% CI, 88%-97%), 96% specificity (95% CI, 94%-97%), and 73% positive predictive value (95% CI, 65%-80%), whereas the PE classifier achieved 94% sensitivity (95% CI, 89%-97%), 96% specificity (95% CI, 95%-97%), and 80% positive predictive value (95% CI, 73%-85%). Conclusions: Symbolic NLP can accurately identify VTEs from narrative radiology reports. This method could facilitate VTE surveillance and the evaluation of preventive measures. © 2015 The Author(s). Published by Wolters Kluwer Health, Inc.","deep vein thrombosis; EHR; electronic health record; narrative radiology report; natural language processing; NLP; pulmonary embolism; VTE","aged; Article; automation; comorbidity; controlled study; deep vein thrombosis; diagnostic test accuracy study; electronic health record; female; human; ICD-9-CM; lung embolism; major clinical study; male; natural language processing; predictive value; priority journal; radiodiagnosis; random sample; sensitivity and specificity; validation study; Canada; complication; electronic health record; middle aged; Pulmonary Embolism; risk factor; statistics and numerical data; venous thromboembolism; Venous Thrombosis; very elderly; Aged; Aged, 80 and over; Canada; Electronic Health Records; Humans; Middle Aged; Natural Language Processing; Predictive Value of Tests; Pulmonary Embolism; Risk Factors; Venous Thromboembolism; Venous Thrombosis",Article,Scopus
"Shin H.-C., Lu L., Kim L., Seff A., Yao J., Summers R.","Interleaved text/image deep mining on a large-scale radiology image database",2017,"Advances in Computer Vision and Pattern Recognition",2,"10.1007/978-3-319-42999-1_17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024475514&doi=10.1007%2f978-3-319-42999-1_17&partnerID=40&md5=924c3f5eee4c3e7121339c8333d51eee","Exploiting and effective learning on very large-scale (>100K patients) medical image databases have been amajor challenge in spite of noteworthy progress in computer vision. This chapter suggests an interleaved text/image deep learning system to extract and mine the semantic interactions of radiologic images and reports, from a national research hospital’s Picture Archiving and Communication System. This chapter introduces a method to perform unsupervised learning (e.g., latent Dirichlet allocation, feedforward/recurrent neural net language models) on document- and sentence-level texts to generate semantic labels and supervised deep ConvNets with categorization and cross-entropy loss functions to map from images to label spaces.Keywords can be predicted for images in a retrievalmanner, and presence/ absence of some frequent types of disease can be predicted with probabilities. The large-scale datasets of extracted key images and their categorization, embedded vector labels, and sentence descriptions can be harnessed to alleviate deep learning’s “data-hungry” challenge in the medical domain. © Springer International Publishing Switzerland 2017.",,,Book Chapter,Scopus
"Segrelles Quilis J.D., Medina R., Blanquer I., Martí-Bonmatí L.","Increasing the efficiency on producing radiology reports for breast cancer diagnosis by means of structured reports: A comparative study",2017,"Methods of Information in Medicine",17,"10.3414/ME16-01-0091","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019953931&doi=10.3414%2fME16-01-0091&partnerID=40&md5=c2b178d8239a4dd33a0f2c68073e3f4b","Background: Radiology reports are commonly written on free-text using voice recognition devices. Structured reports (SR) have a high potential but they are usually considered more difficult to fill-in so their adoption in clinical practice leads to a lower efficiency. However, some studies have demonstrated that in some cases, producing SRs may require shorter time than plain-text ones. This work focuses on the definition and demonstration of a methodology to evaluate the productivity of software tools for producing radiology reports. A set of SRs for breast cancer diagnosis based on BI-RADS have been developed using this method. An analysis of their efficiency with respect to free-text reports has been performed. Material and Methods: The methodology proposed compares the Elapsed Time (ET) on a set of radiological reports. Free-text reports are produced with the speech recognition devices used in the clinical practice. Structured reports are generated using a web application generated with TRENCADIS framework. A team of six radiologists with three different levels of experience in the breast cancer diagnosis was recruited. These radiologists performed the evaluation, each one introducing 50 reports for mammography, 50 for ultrasound scan and 50 for MRI using both approaches. Also, the Relative Efficiency (REF) was computed for each report, dividing the ET of both methods. We applied the T-Student (T-S) test to compare the ETs and the ANOVA test to compare the REFs. Both tests were computed using the SPSS software. Results: The study produced three DICOM-SR templates for Breast Cancer Diagnosis on mammography, ultrasound and MRI, using RADLEX terms based on BIRADs 5th edition. The T-S test on radiologists with high or intermediate profile, showed that the difference between the ET was only statistically significant for mammography and ultrasound. The ANOVA test performed grouping the REF by modalities, indicated that there were no significant differences between mammograms and ultrasound scans, but both have significant statistical differences with MRI. The ANOVA test of the REF for each modality, indicated that there were only significant differences in Mammography (ANOVA p = 0.024) and Ultrasound (ANOVA p = 0.008). The ANOVA test for each radiologist profile, indicated that there were significant differences on the high profile (ANOVA p = 0.028) and medium (ANOVA p = 0.045). Conclusions: In this work, we have defined and demonstrated a methodology to evaluate the productivity of software tools for producing radiology reports in Breast Cancer. We have evaluated that adopting Structured Reporting in mammography and ultrasound studies in breast cancer diagnosis improves the performance in producing reports. © Schattauer 2017.","BI-RADS; Breast cancer; DICOM-SR; Structured reporting","automatic speech recognition; breast tumor; classification; comparative study; diagnostic imaging; electronic health record; evaluation study; human; information retrieval; organization and management; radiology; radiology information system; Spain; statistics and numerical data; task performance; workflow; workload; Breast Neoplasms; Diagnostic Imaging; Efficiency, Organizational; Electronic Health Records; Humans; Information Storage and Retrieval; Radiology; Radiology Information Systems; Spain; Speech Recognition Software; Time and Motion Studies; Workflow; Workload",Article,Scopus
"Yim W.-W., Kwan S.W., Yetisgen M.","Tumor reference resolution and characteristic extraction in radiology reports for liver cancer stage prediction",2016,"Journal of Biomedical Informatics",12,"10.1016/j.jbi.2016.10.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84993982062&doi=10.1016%2fj.jbi.2016.10.005&partnerID=40&md5=b2f4e40402b9341454c1cf0232b5fdb5","Background Anaphoric references occur ubiquitously in clinical narrative text. However, the problem, still very much an open challenge, is typically less aggressively focused on in clinical text domain applications. Furthermore, existing research on reference resolution is often conducted disjointly from real-world motivating tasks. Objective In this paper, we present our machine-learning system that automatically performs reference resolution and a rule-based system to extract tumor characteristics, with component-based and end-to-end evaluations. Specifically, our goal was to build an algorithm that takes in tumor templates and outputs tumor characteristic, e.g. tumor number and largest tumor sizes, necessary for identifying patient liver cancer stage phenotypes. Results Our reference resolution system reached a modest performance of 0.66 F1 for the averaged MUC, B-cubed, and CEAF scores for coreference resolution and 0.43 F1 for particularization relations. However, even this modest performance was helpful to increase the automatic tumor characteristics annotation substantially over no reference resolution. Conclusion Experiments revealed the benefit of reference resolution even for relatively simple tumor characteristics variables such as largest tumor size. However we found that different overall variables had different tolerances to reference resolution upstream errors, highlighting the need to characterize systems by end-to-end evaluations. © 2016 Elsevier Inc.","Cancer stages; Information extraction; Liver cancer; Natural language processing; Radiology report; Reference resolution","Artificial intelligence; Diseases; Information retrieval; Learning algorithms; Learning systems; Natural language processing systems; Radiation; Radiology; Anaphoric reference; Characteristic extraction; Co-reference resolutions; Liver cancers; NAtural language processing; Radiology reports; Reference resolution; Stage prediction; Tumors; algorithm; Article; autoanalysis; cancer staging; data analysis; data extraction; liver cancer; machine learning; natural language processing; phenotype; prediction; priority journal; radiology; tumor volume; classification; data mining; diagnostic imaging; electronic health record; human; liver tumor; natural language processing; semantics; Algorithms; Data Mining; Electronic Health Records; Humans; Liver Neoplasms; Natural Language Processing; Semantics",Article,Scopus
"Motyer R.E., Liddy S., Torreggiani W.C., Buckley O.","Frequency and analysis of non-clinical errors made in radiology reports using the National Integrated Medical Imaging System voice recognition dictation software",2016,"Irish Journal of Medical Science",11,"10.1007/s11845-016-1507-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989179803&doi=10.1007%2fs11845-016-1507-6&partnerID=40&md5=70fdf548e8b6b6022fa94b8129af95dc","Background: Voice recognition (VR) dictation of radiology reports has become the mainstay of reporting in many institutions worldwide. Despite benefit, such software is not without limitations, and transcription errors have been widely reported. Aim: Evaluate the frequency and nature of non-clinical transcription error using VR dictation software. Methods: Retrospective audit of 378 finalised radiology reports. Errors were counted and categorised by significance, error type and sub-type. Data regarding imaging modality, report length and dictation time was collected. Results: 67 (17.72 %) reports contained ≥1 errors, with 7 (1.85 %) containing ‘significant’ and 9 (2.38 %) containing ‘very significant’ errors. A total of 90 errors were identified from the 378 reports analysed, with 74 (82.22 %) classified as ‘insignificant’, 7 (7.78 %) as ‘significant’, 9 (10 %) as ‘very significant’. 68 (75.56 %) errors were ‘spelling and grammar’, 20 (22.22 %) ‘missense’ and 2 (2.22 %) ‘nonsense’. ‘Punctuation’ error was most common sub-type, accounting for 27 errors (30 %). Complex imaging modalities had higher error rates per report and sentence. Computed tomography contained 0.040 errors per sentence compared to plain film with 0.030. Longer reports had a higher error rate, with reports >25 sentences containing an average of 1.23 errors per report compared to 0–5 sentences containing 0.09. Conclusion: These findings highlight the limitations of VR dictation software. While most error was deemed insignificant, there were occurrences of error with potential to alter report interpretation and patient management. Longer reports and reports on more complex imaging had higher error rates and this should be taken into account by the reporting radiologist. © 2016, Royal Academy of Medicine in Ireland.","Productivity; Radiology; Report dictation; Reporting error; Voice recognition; Workflow","computer assisted tomography; diagnostic imaging; DNA transcription; error; human; human experiment; patient care; productivity; radiologist; radiology; recognition; software; voice; workflow; automatic speech recognition; evaluation study; medical record; radiography; radiology; radiology information system; retrospective study; standards; Humans; Medical Records; Radiography; Radiology; Radiology Information Systems; Retrospective Studies; Speech Recognition Software",Article,Scopus
"Gorniak R.J., Sevenster M., Flanders A.E., Deshmukh S.P., Ford R.W., Katzman G.L., Lo R., Mankovich G., Tellis R., Chang P.J.","A PACS-Integrated Tool to Automatically Extract Patient History From Prior Radiology Reports",2016,"Journal of the American College of Radiology",2,"10.1016/j.jacr.2016.06.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978880951&doi=10.1016%2fj.jacr.2016.06.004&partnerID=40&md5=dbb85fa5a8bf1b1f2466dc9baa45060b",[No abstract available],,"algorithm; anamnesis; Article; clinical indicator; computer assisted tomography; computer interface; data base; human; imaging software; information retrieval; major clinical study; medical information system; natural language processing; nuclear magnetic resonance imaging; radiologist; radiology; access to information; anamnesis; data mining; differential diagnosis; health care quality; organization and management; radiology information system; United States; Access to Information; Algorithms; Data Mining; Diagnosis, Differential; Humans; Medical History Taking; Quality Assurance, Health Care; Radiology Information Systems; United States",Article,Scopus
"Hanna T.N., Shekhani H., Maddu K., Zhang C., Chen Z., Johnson J.-O.","Structured report compliance: effect on audio dictation time, report length, and total radiologist study time",2016,"Emergency Radiology",18,"10.1007/s10140-016-1418-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976333374&doi=10.1007%2fs10140-016-1418-x&partnerID=40&md5=df9c72643ad7b13867f4ea115fa8f183","The purpose of this study was to examine structured template use among emergency radiologists, and if this influences audio dictation time, radiology report length, or total radiologist study time. Retrospective data collection of consecutive occurrences of seven common imaging examinations interpreted by a dedicated emergency radiology division over a 2-month period yielded 3449 reports. Templates had been in place for >3 years. For each examination, we documented the individual audio dictation time (ADT), total words, and total time the radiologist spent on a study from report creation until final signing. In 81.2 % (n = 2772) of all cases, a basic template was used. In 2.8 % (n = 78) of these template-use cases, the radiologist removed key elements from the structured template. Of the 3417 reports with complete data, mean ADT was 37.3 s, mean word length was 132.3 (of which, on average, 64 were dictated), and total radiologist time per study (TRT) was 349.7 s. Study type was significantly associated with ADT, total words, and TRT (p < 0.001). Template usage decreased ADT (p < 0.001) by 47 %, but did not affect total word length or TRT. Parameters varied by individual attending (p < 0.001): 20 % (2/10) of attendings had differences in report length when using versus not using templates (p < 0.001). With long-term template usage, compliance with structured templates is high, and few radiologists significantly alter the templates. Template use decreases ADT and for a small fraction of radiologists impacts total word length and has a mixed impact on TRT. © 2016, American Society of Emergency Radiology.","Informatics; Radiology; Speech recognition; Structured report; Template; Turnaround time","abdominal radiography; Article; audio dictation time; computer assisted tomography; emergency care; error; head; human; pelvis radiography; priority journal; protocol compliance; radiological parameters; radiologist; report length; retrospective study; speech discrimination; study time; thorax radiography; time; automatic speech recognition; organization and management; radiology department; radiology information system; standards; task performance; Humans; Radiology Department, Hospital; Radiology Information Systems; Retrospective Studies; Speech Recognition Software; Time and Motion Studies",Article,Scopus
"Chung J.H., MacMahon H., Montner S.M., Liu L., Paushter D.M., Chang P.J., Katzman G.L.","The Effect of an Electronic Peer-Review Auditing System on Faculty-Dictated Radiology Report Error Rates",2016,"Journal of the American College of Radiology",5,"10.1016/j.jacr.2016.04.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84970028891&doi=10.1016%2fj.jacr.2016.04.012&partnerID=40&md5=c61ef79f07859aa03521353af820d3b0",[No abstract available],,"Article; clinical assessment; clinical audit; electronic medical record system; human; medical error; medical school; outcomes research; peer review; radiologist; radiology department; automatic speech recognition; diagnostic error; radiology department; radiology information system; standards; statistics and numerical data; Diagnostic Errors; Humans; Medical Audit; Peer Review; Radiology Department, Hospital; Radiology Information Systems; Speech Recognition Software",Article,Scopus
"Di Grezia G., Somma F., Serra N., Reginelli A., Cappabianca S., Grassi R., Gatta G.","Reducing Costs of Breast Examination: Ultrasound Performance and Inter-Observer Variability of Expert Radiologists Versus Residents",2016,"Cancer Investigation",34,"10.1080/07357907.2016.1201097","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979036800&doi=10.1080%2f07357907.2016.1201097&partnerID=40&md5=50389e0e96ad568cd78f3a0799dee8db","Aim: To compare efficiency levels between radiologist and radiology resident and any significant or clinically relevant differences in breast ultrasound diagnosis, thus reducing extra costs. Material and methods: 100 patients attending for breast ultrasound were included. Each patient was examined by a radiologist, and subsequently by a resident of the radiology department. Both operators noted their findings and wrote a concluding report. Reports were compared for histological and biological analysis. Results: 100 female patients with a mean age about 49 years were examined. The proportions of correct diagnoses of lesions individuated by radiologist and resident were 26.90 > 13.71% (p-value = 10.7), i.e. the radiologist was more accurate in comparison to resident in the individuation of breast lesions. Conclusions: The radiologist was more accurate in comparison to radiology resident in the evaluation of breast pathology in ultrasonography diagnoses, and this could reduce cost and/or in-depth analysis. © 2016 Taylor & Francis Group, LLC.","Automated 3D ultrasonography; Breast ultrasound; Costs; Expert radiologist; Resident; Senology","adult; aged; Article; cost benefit analysis; cost control; echomammography; female; histology; histopathology; human; human tissue; major clinical study; priority journal; prospective study; residency education; resident; standardization; breast disease; clinical competence; diagnostic imaging; echography; economics; health care cost; middle aged; observer variation; physician; radiologist; standards; three dimensional imaging; very elderly; young adult; Adult; Aged; Aged, 80 and over; Breast Diseases; Clinical Competence; Direct Service Costs; Female; Humans; Imaging, Three-Dimensional; Middle Aged; Observer Variation; Physicians; Radiologists; Ultrasonography; Young Adult",Article,Scopus
"Allin S., Bleakney R., Zhang J., Munce S., Cheung A.M., Jaglal S.","Evaluation of Automated Fracture Risk Assessment Based on the Canadian Association of Radiologists and Osteoporosis Canada Assessment Tool",2016,"Journal of Clinical Densitometry",4,"10.1016/j.jocd.2016.02.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962695172&doi=10.1016%2fj.jocd.2016.02.001&partnerID=40&md5=e5ba4ae8d1601601d7364bd6857d6b11","Fracture risk assessments are not always clearly communicated on bone mineral density (BMD) reports; evidence suggests that structured reporting (SR) tools may improve report clarity. The aim of this study is to compare fracture risk assessments automatically assigned by SR software in accordance with Canadian Association of Radiologists and Osteoporosis Canada (CAROC) recommendations to assessments from experts on narrative BMD reports. Charts for 500 adult patients who recently received a BMD exam were sampled from across University of Toronto's Joint Department of Medical Imaging. BMD measures and clinical details were manually abstracted from charts and were used to create structured reports with assessments generated by a software implementation of CAROC recommendations. CAROC calculations were statistically compared to experts’ original assessments using percentage agreement (PA) and Krippendorff's alpha. Canadian FRAX calculations were also compared to experts’ where possible. A total of 25 (5.0%) reported assessments did not conform to categorizations recommended by Canadian guidelines. Across the remainder, the Krippendorff's alpha relating software assigned assessments to physicians was high at 0.918; PA was 94.3%. Lower agreement was associated with reports for patients with documented modifying factors (alpha = 0.860, PA = 90.2%). Similar patterns of agreement related expert assessments to FRAX calculations, although statistics of agreement were lower. Categories of disagreement were defined by (1) gray areas in current guidelines, (2) margins of assessment categorizations, (3) dictation/transcription errors, (4) patients on low doses of steroids, and (5) ambiguous documentation of modifying factors. Results suggest that SR software can produce fracture risk assessments that agree with experts on most routine, adult BMD exams. Results also highlight situations where experts tend to diverge from guidelines and illustrate the potential for SR software to (1) reduce variability in, (2) ameliorate errors in, and (3) improve clarity of routine adult BMD exam reports. © 2016 International Society for Clinical Densitometry","Dual-energy X-ray; guidelines; osteoporosis; radiology information systems; structured reporting","prednisone; adult; Article; automation; bone densitometry; bone density; Canada; clinical assessment tool; female; fracture; fragility fracture; high risk patient; hip fracture; human; low risk patient; major clinical study; male; medical documentation; medical history; medical specialist; osteoporosis; practice guideline; priority journal; radiologist; radiology information system; risk assessment; risk factor; software; spine fracture; steroid therapy; aged; automation; diagnostic imaging; fragility fracture; medical society; middle aged; osteoporosis; photon absorptiometry; radiology; risk assessment; software; Absorptiometry, Photon; Aged; Automation; Bone Density; Canada; Female; Humans; Male; Middle Aged; Osteoporosis; Osteoporotic Fractures; Radiology; Risk Assessment; Societies, Medical; Software",Article,Scopus
"Shin H.-C., Lu L., Kim L., Seff A., Yao J., Summers R.M.","Interleaved text/image deep mining on a large-scale radiology database for automated image interpretation",2016,"Journal of Machine Learning Research",47,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989187487&partnerID=40&md5=83764cf16c1f8dcf723acced65ee2054","Despite tremendous progress in computer vision, there has not been an attempt to apply machine learning on very large-scale medical image databases. We present an interleaved text/image deep learning system to extract and mine the semantic interactions of radiology images and reports from a national research hospital's Picture Archiving and Communication System. With natural language processing, we mine a collection of ∼216K representative two-dimensional images selected by clinicians for diagnostic reference and match the images with their descriptions in an automated manner. We then employ a weakly supervised approach using all of our available data to build models for generating approximate interpretations of patient images. Finally, we demonstrate a more strictly supervised approach to detect the presence and absence of a number of frequent disease types, providing more specific interpretations of patient scans. A relatively small amount of data is used for this part, due to the challenge in gathering quality labels from large raw text data. Our work shows the feasibility of large-scale learning and prediction in electronic patient records available in most modern clinical institutions. It also demonstrates the trade-offs to consider in designing machine learning systems for analyzing large medical data. © 2016, Microtome Publishing. All rights reserved.","Convolutional neural networks; Deep learning; Medical imaging; Natural language processing; Topic models","Artificial intelligence; Computer vision; Diagnosis; Economic and social effects; Learning algorithms; Learning systems; Medical imaging; Natural language processing systems; Neural networks; Picture archiving and communication systems; Radiation; Radiology; Semantics; Automated image interpretations; Convolutional neural network; Deep learning; Electronic patient record; Medical image database; NAtural language processing; Topic model; Two dimensional images; Image processing",Article,Scopus
"Kohli M., Schonlau D.","Radiology Quality Measure Compliance Reporting: an Automated Approach",2016,"Journal of Digital Imaging",4,"10.1007/s10278-015-9835-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945558999&doi=10.1007%2fs10278-015-9835-z&partnerID=40&md5=419c5e8ea28662e912a6f3bcad88e8f3","As part of its ongoing effort to improve healthcare quality, the Center of Medicare and Medicaid Services (CMS) has transitioned from monetary rewards to reimbursement penalties for noncompliance or nonparticipation with its quality measurement initiatives. More specifically, eligible providers who bill for CMS patient care, such as radiologists, will face a 2 % negative payment adjustment, if they fail to report adequate participation and compliance with sufficient CMS quality measures in 2015. Although several methods exist to report participation and compliance, each method requires the gathering of relevant studies and assessing the reports for compliance. To aid in this data gathering and to prevent reduced reimbursements, radiology groups should consider implementing automated processes to monitor compliance with these quality measure standards. This article describes one method of creating an automated report scanner, utilizing an open source interface engine called Mirth Connect, that may facilitate the data gathering and monitoring related to reporting compliance with CMS standard #195 Stenosis measurement in Ultrasound Carotid Imaging Reports. The process described in this article is currently utilized by a large multi-institutional radiology group to assess for report compliance and offers the user near real time surveillance of compliance with the quality measure. © 2015, Society for Imaging Informatics in Medicine.","Compliance; HL7; Mirth Connect; Pivot table; PQRS; Quality","Automation; Health insurance; Image quality; Radiation; Radiology; Compliance; HL7; Mirth Connect; Pivot-tables; PQRS; Regulatory compliance; economics; health care quality; human; medicaid; medicare; radiology; reimbursement; standards; total quality management; United States; Humans; Medicaid; Medicare; Quality Improvement; Quality of Health Care; Radiology; Reimbursement, Incentive; United States",Article,Scopus
"Bates J., Fodeh S.J., Brandt C.A., Womack J.A.","Classification of radiology reports for falls in an hiv study cohort",2016,"Journal of the American Medical Informatics Association",27,"10.1093/jamia/ocv155","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964959492&doi=10.1093%2fjamia%2focv155&partnerID=40&md5=1a684117baadb09fedf5ee7dd7fa277e","Objective: To identify patients in a human immunodeficiency virus (HIV) study cohort who have fallen by applying supervised machine learning methods to radiology reports of the cohort. Methods: We used the Veterans Aging Cohort Study Virtual Cohort (VACS-VC), an electronic health record-based cohort of 146 530 veterans for whom radiology reports were available (N 2 977 739). We created a reference standard of radiology reports, represented each report by a feature set of words and Unified Medical Language System concepts, and then developed several support vector machine (SVM) classifiers for falls. We compared mutual information (MI) ranking and embedded feature selection approaches. The SVM classifier with MI feature selection was chosen to classify all radiology reports in VACS-VC. Results: Our SVM classifier with MI feature selection achieved an area under the curve score of 97.04 on the test set. When applied to all the radiology reports in VACS-VC, 80 416 of these reports were classified as positive for a fall. Of these, 11 484 were associated with a fall-related external cause of injury code (E-code) and 68 932 were not, corresponding to 29 280 patients with potential fall-related injuries who could not have been found using E-codes. Discussion: Feature selection was crucial to improving the classifier's performance. Feature selection with MI allowed us to select the number of discriminative features to use for classification, in contrast to the embedded feature selection method, in which the number of features is chosen automatically. Conclusion Machine learning is an effective method of identifying patients who have suffered a fall. The development of this classifier supplements the clinical researcher's toolkit and reduces dependence on under-coded structured electronic health record data. © The Author 2015.","Aging; Falls; HIV; Information retrieval; Text mining","aging; Article; cohort analysis; data mining; falling; human; Human immunodeficiency virus infection; information retrieval; major clinical study; radiology; supervised machine learning; support vector machine; area under the curve; classification; electronic health record; government; Human immunodeficiency virus infection; radiology information system; support vector machine; Unified Medical Language System; United States; veteran; Accidental Falls; Area Under Curve; Cohort Studies; Electronic Health Records; HIV Infections; Humans; Radiology Information Systems; Support Vector Machine; Unified Medical Language System; United States; United States Department of Veterans Affairs; Veterans",Article,Scopus
"Omar A., Bujila R., Fransson A., Andreo P., Poludniowski G.","A framework for organ dose estimation in x-ray angiography and interventional radiology based on dose-related data in DICOM structured reports",2016,"Physics in Medicine and Biology",13,"10.1088/0031-9155/61/8/3063","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963669792&doi=10.1088%2f0031-9155%2f61%2f8%2f3063&partnerID=40&md5=082d93db2447fd6a521034df959eeba8","Although interventional x-ray angiography (XA) procedures involve relatively high radiation doses that can lead to deterministic tissue reactions in addition to stochastic effects, convenient and accurate estimation of absorbed organ doses has traditionally been out of reach. This has mainly been due to the absence of practical means to access dose-related data that describe the physical context of the numerous exposures during an XA procedure. The present work provides a comprehensive and general framework for the determination of absorbed organ dose, based on non-proprietary access to dose-related data by utilizing widely available DICOM radiation dose structured reports. The framework comprises a straightforward calculation workflow to determine the incident kerma and reconstruction of the geometrical relation between the projected x-ray beam and the patient's anatomy. The latter is difficult in practice, as the position of the patient on the table top is unknown. A novel patient-specific approach for reconstruction of the patient position on the table is presented. The proposed approach was evaluated for 150 patients by comparing the estimated position of the primary irradiated organs (the target organs) with their position in clinical DICOM images. The approach is shown to locate the target organ position with a mean (max) deviation of 1.3 (4.3), 1.8 (3.6) and 1.4 (2.9) cm for neurovascular, adult and paediatric cardiovascular procedures, respectively. To illustrate the utility of the framework for systematic and automated organ dose estimation in routine clinical practice, a prototype implementation of the framework with Monte Carlo simulations is included. © 2016 Institute of Physics and Engineering in Medicine.","DICOM structured report; interventional radiology; Monte Carlo; patient dosimetry; x-ray angiography","Angiography; Dosimetry; Intelligent systems; Monte Carlo methods; Pediatrics; Radiation effects; Radiology; Report generators; Stochastic systems; Accurate estimation; Clinical practices; Geometrical relations; Interventional radiology; Prototype implementations; Stochastic effects; Structured reports; X ray angiography; X rays; adolescent; adult; aged; angiography; cardiovascular disease; child; diagnostic imaging; female; human; infant; interventional radiology; male; middle aged; Monte Carlo method; neurologic disease; newborn; preschool child; procedures; radiation dose; vascular disease; X ray; young adult; Adolescent; Adult; Aged; Angiography; Cardiovascular Diseases; Child; Child, Preschool; Female; Humans; Infant; Infant, Newborn; Male; Middle Aged; Monte Carlo Method; Nervous System Diseases; Radiation Dosage; Radiology, Interventional; Vascular Diseases; X-Rays; Young Adult",Article,Scopus
"Demner-Fushman D., Kohli M.D., Rosenman M.B., Shooshan S.E., Rodriguez L., Antani S., Thoma G.R., McDonald C.J.","Preparing a collection of radiology examinations for distribution and retrieval",2016,"Journal of the American Medical Informatics Association",383,"10.1093/jamia/ocv080","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963729804&doi=10.1093%2fjamia%2focv080&partnerID=40&md5=c3f3afdc2b377d6eaf00fb28e6a7ec82","Objective Clinical documents made available for secondary use play an increasingly important role in discovery of clinical knowledge, development of research methods, and education. An important step in facilitating secondary use of clinical document collections is easy access to descriptions and samples that represent the content of the collections. This paper presents an approach to developing a collection of radiology examinations, including both the images and radiologist narrative reports, and making them publicly available in a searchable database. Materials and Methods The authors collected 3996 radiology reports from the Indiana Network for Patient Care and 8121 associated images from the hospitals' picture archiving systems. The images and reports were de-identified automatically and then the automatic de-identification was manually verified. The authors coded the key findings of the reports and empirically assessed the benefits of manual coding on retrieval. Results The automatic de-identification of the narrative was aggressive and achieved 100% precision at the cost of rendering a few findings uninterpretable. Automatic de-identification of images was not quite as perfect. Images for two of 3996 patients (0.05%) showed protected health information. Manual encoding of findings improved retrieval precision. Conclusion Stringent de-identification methods can remove all identifiers from text radiology reports. DICOM de-identification of images does not remove all identifying information and needs special attention to images scanned from film. Adding manual coding to the radiologist narrative reports significantly improved relevancy of the retrieved clinical documents. The de-identified Indiana chest X-ray collection is available for searching and downloading from the National Library of Medicine (http://openi.nlm.nih.gov/). © 2015 Published by Oxford University Press on behalf of the American Medical Informatics Association 2015. This work is written by US Government employees and is in the public domain in the US.","Abstracting and indexing; Biometric identification; Information storage and retrieval; Medical records; Radiography","attention; data base; digital imaging and communications in medicine; hospital; human; information retrieval; major clinical study; medical information; narrative; patient care; radiologist; radiology; thorax radiography; United States; anonymization; procedures; radiology information system; thorax radiography; Data Anonymization; Humans; Information Storage and Retrieval; Radiography, Thoracic; Radiology Information Systems",Article,Scopus
"Hwang T.J., Girard E., Shellikeri S., Setser R., Vossough A., Ho-Fung V., Cahill A.M.","Early experience with X-ray magnetic resonance fusion for low-flow vascular malformations in the pediatric interventional radiology suite",2016,"Pediatric Radiology",3,"10.1007/s00247-015-3485-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959158443&doi=10.1007%2fs00247-015-3485-7&partnerID=40&md5=f9ef2d920acd6438cd61a414b5458835","This technical innovation describes our experience using an X-ray magnetic resonance fusion (XMRF) software program to overlay 3-D MR images on real-time fluoroscopic images during sclerotherapy procedures for vascular malformations at a large pediatric institution. Five cases have been selected to illustrate the application and various clinical utilities of XMRF during sclerotherapy procedures as well as the technical limitations of this technique. The cases demonstrate how to use XMRF in the interventional suite to derive additional information to improve therapeutic confidence with regards to the extent of lesion filling and to guide clinical management in terms of intraprocedural interventional measures. © 2015, Springer-Verlag Berlin Heidelberg.","Children; Image fusion; Interventional radiology; Sclerotherapy; Vascular imaging; Vascular malformations","adolescent; Article; blood flow; clinical article; congenital blood vessel malformation; female; fluoroscopy; human; image analysis; imaging software; infant; interventional radiology; male; newborn; nuclear magnetic resonance imaging; pediatrics; priority journal; sclerotherapy; three dimensional imaging; x ray magnetic resonance fusion; automated pattern recognition; biological model; case report; child; computer assisted diagnosis; diagnostic imaging; image enhancement; image subtraction; interventional radiology; magnetic resonance angiography; multimodal imaging; pilot study; preschool child; procedures; reproducibility; sensitivity and specificity; statistical model; treatment outcome; Vascular Malformations; x-ray computed tomography; Adolescent; Child; Child, Preschool; Female; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Infant; Infant, Newborn; Magnetic Resonance Angiography; Male; Models, Biological; Models, Statistical; Multimodal Imaging; Pattern Recognition, Automated; Pilot Projects; Radiography, Interventional; Reproducibility of Results; Sclerotherapy; Sensitivity and Specificity; Subtraction Technique; Tomography, X-Ray Computed; Treatment Outcome; Vascular Malformations",Article,Scopus
"Duncan K.A., Drinkwater K.J., Dugar N., Howlett D.C., The Royal College of Radiologists' Clinical Radiology Audit Committee","Audit of radiology communication systems for critical, urgent, and unexpected significant findings",2016,"Clinical Radiology",10,"10.1016/j.crad.2015.11.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958155612&doi=10.1016%2fj.crad.2015.11.017&partnerID=40&md5=234741cbe1843b2b96907e66dfff7c50","Aim To determine the compliance of UK radiology departments and trusts/healthcare organisations with National Patient Safety Agency and Royal College of Radiologist's published guidance on the communication of critical, urgent, and unexpected significant radiological findings. Materials and methods A questionnaire was sent to all UK radiology department audit leads asking for details of their current departmental policy regarding the issuing of alerts; use of automated electronic alert systems; methods of notification of clinicians of critical, urgent, and unexpected significant radiological findings; monitoring of results receipt; and examples of the more common types of serious pathologies for which alerts were issued. Results One hundred and fifty-four of 229 departments (67%) responded. Eighty-eight percent indicated that they had a policy in place for the communication of critical, urgent, and unexpected significant radiological findings. Only 34% had an automated electronic alert system in place and only 17% had a facility for service-wide electronic tracking of radiology reports. In only 11 departments with an electronic acknowledgement system was someone regularly monitoring the read rate. Conclusion There is wide variation in practice across the UK with regard to the communication and monitoring of reports with many departments/trusts not fully compliant with published UK guidance. Despite the widespread use of electronic systems, only a minority of departments/trusts have and use electronic tracking to ensure reports have been read and acted upon. © 2015 The Royal College of Radiologists.",,"Article; budget; health care policy; hospital policy; human; interpersonal communication; medical audit; patient safety; priority journal; radiology; radiology department; risk management; United Kingdom; clinical decision support system; clinical practice; Great Britain; organization and management; policy; questionnaire; radiology information system; reminder system; system analysis; Communication; Decision Support Systems, Clinical; Great Britain; Humans; Organizational Policy; Practice Patterns, Physicians'; Radiology Department, Hospital; Radiology Information Systems; Reminder Systems; Surveys and Questionnaires; Systems Integration",Article,Scopus
"Hassanpour S., Langlotz C.P.","Unsupervised Topic Modeling in a Large Free Text Radiology Report Repository",2016,"Journal of Digital Imaging",26,"10.1007/s10278-015-9823-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955368738&doi=10.1007%2fs10278-015-9823-3&partnerID=40&md5=f93952c559adff3bc95f08eac3b5be7a","Radiology report narrative contains a large amount of information about the patient’s health and the radiologist’s interpretation of medical findings. Most of this critical information is entered in free text format, even when structured radiology report templates are used. The radiology report narrative varies in use of terminology and language among different radiologists and organizations. The free text format and the subtlety and variations of natural language hinder the extraction of reusable information from radiology reports for decision support, quality improvement, and biomedical research. Therefore, as the first step to organize and extract the information content in a large multi-institutional free text radiology report repository, we have designed and developed an unsupervised machine learning approach to capture the main concepts in a radiology report repository and partition the reports based on their main foci. In this approach, radiology reports are modeled in a vector space and compared to each other through a cosine similarity measure. This similarity is used to cluster radiology reports and identify the repository’s underlying topics. We applied our approach on a repository of 1,899,482 radiology reports from three major healthcare organizations. Our method identified 19 major radiology report topics in the repository and clustered the reports accordingly to these topics. Our results are verified by a domain expert radiologist and successfully explain the repository’s primary topics and extract the corresponding reports. The results of our system provide a target-based corpus and framework for information extraction and retrieval systems for radiology reports. © 2015, Society for Imaging Informatics in Medicine.","Clustering; Natural language processing; Radiology report narrative; Text mining; Topic modeling","Artificial intelligence; Computational linguistics; Decision support systems; Information retrieval; Learning algorithms; Learning systems; Modeling languages; Natural language processing systems; Radiation; Radiology; Search engines; Societies and institutions; Vector spaces; Clustering; NAtural language processing; Radiology reports; Text mining; Topic Modeling; Data mining; algorithm; cluster analysis; human; machine learning; natural language processing; radiology information system; theoretical model; Algorithms; Cluster Analysis; Humans; Machine Learning; Models, Theoretical; Natural Language Processing; Radiology Information Systems",Article,Scopus
"Oberkampf H., Zillner S., Overton J.A., Bauer B., Cavallaro A., Uder M., Hammon M.","Semantic representation of reported measurements in radiology",2016,"BMC Medical Informatics and Decision Making",6,"10.1186/s12911-016-0248-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955741148&doi=10.1186%2fs12911-016-0248-9&partnerID=40&md5=6939e334213f3f446ecfa8ba63493373","Background: In radiology, a vast amount of diverse data is generated, and unstructured reporting is standard. Hence, much useful information is trapped in free-text form, and often lost in translation and transmission. One relevant source of free-text data consists of reports covering the assessment of changes in tumor burden, which are needed for the evaluation of cancer treatment success. Any change of lesion size is a critical factor in follow-up examinations. It is difficult to retrieve specific information from unstructured reports and to compare them over time. Therefore, a prototype was implemented that demonstrates the structured representation of findings, allowing selective review in consecutive examinations and thus more efficient comparison over time. Methods: We developed a semantic Model for Clinical Information (MCI) based on existing ontologies from the Open Biological and Biomedical Ontologies (OBO) library. MCI is used for the integrated representation of measured image findings and medical knowledge about the normal size of anatomical entities. An integrated view of the radiology findings is realized by a prototype implementation of a ReportViewer. Further, RECIST (Response Evaluation Criteria In Solid Tumors) guidelines are implemented by SPARQL queries on MCI. The evaluation is based on two data sets of German radiology reports: An oncologic data set consisting of 2584 reports on 377 lymphoma patients and a mixed data set consisting of 6007 reports on diverse medical and surgical patients. All measurement findings were automatically classified as abnormal/normal using formalized medical background knowledge, i.e., knowledge that has been encoded into an ontology. A radiologist evaluated 813 classifications as correct or incorrect. All unclassified findings were evaluated as incorrect. Results: The proposed approach allows the automatic classification of findings with an accuracy of 96.4 % for oncologic reports and 92.9 % for mixed reports. The ReportViewer permits efficient comparison of measured findings from consecutive examinations. The implementation of RECIST guidelines with SPARQL enhances the quality of the selection and comparison of target lesions as well as the corresponding treatment response evaluation. Conclusions: The developed MCI enables an accurate integrated representation of reported measurements and medical knowledge. Thus, measurements can be automatically classified and integrated in different decision processes. The structured representation is suitable for improved integration of clinical findings during decision-making. The proposed ReportViewer provides a longitudinal overview of the measurements. © 2016 Oberkampf et al.","Classification; Follow-up; Measurement; OBO; Ontology; Open Biological and Biomedical Ontologies; Radiology; RECIST","biological ontology; human; image processing; medical informatics; procedures; radiology; semantics; theoretical model; Biological Ontologies; Humans; Image Processing, Computer-Assisted; Medical Informatics Applications; Models, Theoretical; Radiology; Semantics",Article,Scopus
"Cotik V., Stricker V., Vivaldi J., Rodriguez H.","Syntactic methods for negation detection in radiology reports in spanish",2016,"BioNLP 2016 - Proceedings of the 15th Workshop on Biomedical Natural Language Processing",13,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044784916&partnerID=40&md5=3fa614c7c512183888cf97ca6d2963d8","Identification of the certainty of events is an important text mining problem. In particular, biomedical texts report medical conditions or findings that might be factual, hedged or negated. Identification of negation and its scope over a term of interest determines whether a finding is reported and is a challenging task. Not much work has been performed for Spanish in this domain. In this work we introduce different algorithms developed to determine if a term of interest is under the scope of negation in radiology reports written in Spanish. The methods include syntactic techniques based in rules derived from PoS tagging patterns, constituent tree patterns and dependency tree patterns, and an adaption of NegEx, a well known rule-based negation detection algorithm (Chapman et al., 2001a). All methods outperform a simple dictionary lookup algorithm developed as baseline. NegEx and the PoS tagging pattern method obtain the best results with 0.92 F1. © BioNLP 2016. All rights reserved.",,"Computational linguistics; Forestry; Natural language processing systems; Radiation; Radiology; Trees (mathematics); Biomedical text; Dependency trees; Medical conditions; Mining problems; Pattern trees; PoS tagging; Radiology reports; Rule based; Text-mining; Tree pattern; Syntactics",Conference Paper,Scopus
"Chapman B.E., Mowery D.L., Narasimhan E., Patel N., Chapman W.W., Heilbrun M.E.","Assessing the feasibility of an automated suggestion system for communicating critical findings from chest radiology reports to referring physicians",2016,"BioNLP 2016 - Proceedings of the 15th Workshop on Biomedical Natural Language Processing",5,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032387828&partnerID=40&md5=6192a16966a2c6b37a932b3e88904d48","Time-sensitive communication of critical imaging findings like pneumothorax or pulmonary embolism to referring physicians is important for patient safety. However, radiology findings are recorded in free-text format, relying on verbal communication that is not always successful. Natural language processing can provide automated suggestions to radiologists that new critical findings be added to a followup list. We present a pilot assessment of the feasibility of an automated critical finding suggestion system for radiology reporting by assessing suggestions made by the pyConTextNLP algorithm. Our evaluation focused on the false alarm rate to determine feasibility of deployment without increasing alert fatigue. py- ConTextNLP identified 77 critical findings from 1,370 chest exams. Review of the suggested findings demonstrated a 7.8% false alarm rate. We discuss the errors, which would be challenging to address, and compare pyConTextNLP's false alarm rate to false alarm rates of similar systems from the literature. © BioNLP 2016. All rights reserved.",,"Alarm systems; Automation; Errors; Natural language processing systems; Radiation; Radiology; False alarm rate; Free texts; Patient safety; Pulmonary embolism; Radiology reporting; Radiology reports; Text format; Verbal communications; Image resolution",Conference Paper,Scopus
"Masino A.J., Grundmeier R.W., Pennington J.W., Germiller J.A., Bryan Crenshaw E., III","Temporal bone radiology report classification using open source machine learning and natural langue processing libraries",2016,"BMC Medical Informatics and Decision Making",16,"10.1186/s12911-016-0306-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007531074&doi=10.1186%2fs12911-016-0306-3&partnerID=40&md5=287508e836634f30f05e9c5e619bb8dc","Background: Radiology reports are a rich resource for biomedical research. Prior to utilization, trained experts must manually review reports to identify discrete outcomes. The Audiological and Genetic Database (AudGenDB) is a public, de-identified research database that contains over 16,000 radiology reports. Because the reports are unlabeled, it is difficult to select those with specific abnormalities. We implemented a classification pipeline using a human-in-the-loop machine learning approach and open source libraries to label the reports with one or more of four abnormality region labels: inner, middle, outer, and mastoid, indicating the presence of an abnormality in the specified ear region. Methods: Trained abstractors labeled radiology reports taken from AudGenDB to form a gold standard. These were split into training (80 %) and test (20 %) sets. We applied open source libraries to normalize and convert every report to an n-gram feature vector. We trained logistic regression, support vector machine (linear and Gaussian), decision tree, random forest, and native Bayes models for each ear region. The models were evaluated on the hold-out test set. Results: Our gold-standard data set contained 726 reports. The best classifiers were linear support vector machine for inner and outer ear, logistic regression for middle ear, and decision tree for mastoid. Classifier test set accuracy was 90 %, 90 %, 93 %, and 82 % for the inner, middle, outer and mastoid regions, respectively. The logistic regression method was very consistent, achieving accuracy scores within 2.75 % of the best classifier across regions and a receiver operator characteristic area under the curve of 0.92 or greater across all regions. Conclusions: Our results indicate that the applied methods achieve accuracy scores sufficient to support our objective of extracting discrete features from radiology reports to enhance cohort identification in AudGenDB. The models described here are available in several free, open source libraries that make them more accessible and simplify their utilization as demonstrated in this work. We additionally implemented the models as a web service that accepts radiology report text in an HTTP request and provides the predicted region labels. This service has been used to label the reports in AudGenDB and is freely available. © 2016 The Author(s).","Audiology; Human-in-the-loop; Machine learning; Natural language processing; Radiology","audiology; classification; data base; diagnostic imaging; human; machine learning; natural language processing; radiology; temporal bone; Audiology; Databases as Topic; Humans; Machine Learning; Natural Language Processing; Radiology; Temporal Bone",Article,Scopus
"Grundmeier R.W., Masino A.J., Charles Casper T., Dean J.M., Bell J., Enriquez R., Deakyne S., Chamberlain J.M., Alpern E.R.","Identification of long bone fractures in radiology reports using natural language processing to support healthcare quality improvement",2016,"Applied Clinical Informatics",28,"10.4338/ACI-2016-08-RA-0129","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995428307&doi=10.4338%2fACI-2016-08-RA-0129&partnerID=40&md5=a401038664311c91d05da09cf20a85f0","Background: Important information to support healthcare quality improvement is often recorded in free text documents such as radiology reports. Natural language processing (NLP) methods may help extract this information, but these methods have rarely been applied outside the research laboratories where they were developed. Objective: To implement and validate NLP tools to identify long bone fractures for pediatric emergency medicine quality improvement. Methods: Using freely available statistical software packages, we implemented NLP methods to identify long bone fractures from radiology reports. A sample of 1,000 radiology reports was used to construct three candidate classification models. A test set of 500 reports was used to validate the model performance. Blinded manual review of radiology reports by two independent physicians provided the reference standard. Each radiology report was segmented and word stem and bigram features were constructed. Common English “stop words” and rare features were excluded. We used 10-fold cross-validation to select optimal configuration parameters for each model. Accuracy, recall, precision and the F1 score were calculated. The final model was compared to the use of diagnosis codes for the identification of patients with long bone fractures. Results: There were 329 unique word stems and 344 bigrams in the training documents. A support vector machine classifier with Gaussian kernel performed best on the test set with accuracy=0.958, recall=0.969, precision=0.940, and F1 score=0.954. Optimal parameters for this model were cost=4 and gamma=0.005. The three classification models that we tested all performed better than diagnosis codes in terms of accuracy, precision, and F1 score (diagnosis code accuracy=0.932, recall= 0.960, precision=0.896, and F1 score=0.927). Conclusions: NLP methods using a corpus of 1,000 training documents accurately identified acute long bone fractures from radiology reports. Strategic use of straightforward NLP methods, implemented with freely available software, offers quality improvement teams new opportunities to extract information from narrative documents. © Schattauer 2016.","Emergency medicine; Machine learning; Natural language processing; Pediatrics; Quality improvement","child; clinical decision making; diagnostic imaging; documentation; emergency medicine; fracture; human; natural language processing; radiology; research; total quality management; Child; Clinical Decision-Making; Documentation; Emergency Medicine; Fractures, Bone; Humans; Natural Language Processing; Quality Improvement; Radiology; Research Report",Article,Scopus
"Barbosa F., Traina A.J., Muglia V.F.","Meta-generalis: A novel method for structuring information from radiology reports",2016,"Applied Clinical Informatics",4,"10.4338/ACI-2016-03-RA-0037","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988699136&doi=10.4338%2fACI-2016-03-RA-0037&partnerID=40&md5=66039da0ee3ae15cd9ee7605b0dddc7d","Background: A structured report for imaging exams aims at increasing the precision in information retrieval and communication between physicians. However, it is more concise than free text and may limit specialists’ descriptions of important findings not covered by pre-defined structures. A computational ontological structure derived from free texts designed by specialists may be a solution for this problem. Therefore, the goal of our study was to develop a methodology for structuring information in radiology reports covering specifications required for the Brazilian Portuguese language, including the terminology to be used. Methods: We gathered 1,701 radiological reports of magnetic resonance imaging (MRI) studies of the lumbosacral spine from three different institutions. Techniques of text mining and ontological conceptualization of lexical units extracted were used to structure information. Ten radiologists, specialists in lumbosacral MRI, evaluated the textual superstructure and terminology extracted using an electronic questionnaire. Results: The established methodology consists of six steps: 1) collection of radiology reports of a specific MRI examination; 2) textual decomposition; 3) normalization of lexical units; 4) identification of textual superstructures; 5) conceptualization of candidate-terms; and 6) evaluation of superstructures and extracted terminology by experts using an electronic questionnaire. Three different textual superstructures were identified, with terminological variations in the names of their textual categories. The number of candidate-terms conceptualized was 4,183, yielding 727 concepts. There were a total of 13,963 relationships between candidate-terms and concepts and 789 relationships among concepts. Conclusions: The proposed methodology allowed structuring information in a more intuitive and practical way. Indications of three textual superstructures, extraction of lexicon units and the normalization and ontologically conceptualization were achieved while maintaining references to their respective categories and free text radiology reports. © Schattauer 2016.","Free-text; Ontology; Radiological report; Structured report; Terminology","controlled vocabulary; data mining; human; natural language processing; nomenclature; nuclear magnetic resonance imaging; questionnaire; radiology; research; Data Mining; Humans; Magnetic Resonance Imaging; Natural Language Processing; Radiology; Research Report; Surveys and Questionnaires; Terminology as Topic; Vocabulary, Controlled",Article,Scopus
"Lee H., Weerasinghe A., Barnes J., Oakden-Rayner L., Gale W., Carneiro G.","CRISTAL: Adapting workplace training to the real world context with an intelligent simulator for radiology trainees",2016,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",2,"10.1007/978-3-319-39583-8_52","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976621529&doi=10.1007%2f978-3-319-39583-8_52&partnerID=40&md5=cdcbe1806146eb5c1fbda27e9a53ba50","Intelligent learning environments based on interactions within the digital world are increasingly popular as they provide mechanisms for interactive and adaptive learning, but learners find it difficult to transfer this to real world tasks. We present the initial development stages of CRISTAL, an intelligent simulator targeted at trainee radiologists which enhances the learning experience by enabling the virtual environment to adapt according to their real world experiences. Our system design has been influenced by feedback from trainees, and allows them to practice their reporting skills by writing freeform reports in natural language. This has the potential to be expanded to other areas such as short-form journalism and legal document drafting. © Springer International Publishing Switzerland 2016.","Adult learning; Natural language processing; Radiology training; Self-regulated learning; Simulated environments for learning","Computational linguistics; Computer aided instruction; Intelligent vehicle highway systems; Natural language processing systems; Radiation; Radiology; Virtual reality; Adult learning; NAtural language processing; Radiology trainings; Self-regulated learning; Simulated environment; Personnel training",Conference Paper,Scopus
"Shi L., Ling T., Zhang J.","Semantic information extracting system for classification of radiological reports in radiology information system (RIS)",2016,"Progress in Biomedical Optics and Imaging - Proceedings of SPIE",3,"10.1117/12.2216183","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976271899&doi=10.1117%2f12.2216183&partnerID=40&md5=23440eaf2699e6b189868734b180c8a0","Radiologists currently use a variety of terminologies and standards in most hospitals in China, and even there are multiple terminologies being used for different sections in one department. In this presentation, we introduce a medical semantic comprehension system (MedSCS) to extract semantic information about clinical findings and conclusion from free text radiology reports so that the reports can be classified correctly based on medical terms indexing standards such as Radlex or SONMED-CT. Our system (MedSCS) is based on both rule-based methods and statistics-based methods which improve the performance and the scalability of MedSCS. In order to evaluate the over all of the system and measure the accuracy of the outcomes, we developed computation methods to calculate the parameters of precision rate, recall rate, F-score and exact confidence interval. © 2016 SPIE.","Hidden Markov Model; Natural Language Processing; Non-Definite Finite Automata; Radiology Information System; Sematic Information Extracting","Classification (of information); Computerized tomography; Hidden Markov models; Information science; Information systems; Markov processes; Medical applications; Medical imaging; Natural language processing systems; Radiation; Radiology; Semantics; Speech processing; Terminology; Computation methods; Exact confidence interval; Information extracting; NAtural language processing; Radiology information system; Radiology reports; Semantic comprehension; Semantic information; Medical information systems",Conference Paper,Scopus
"Ramos J., Kockelkorn T.T.J.P., Ramos I., Ramos R., Grutters J., Viergever M.A., Van Ginneken B., Campilho A.","Content-based image retrieval by metric learning from radiology reports: Application to interstitial lung diseases",2016,"IEEE Journal of Biomedical and Health Informatics",34,"10.1109/JBHI.2014.2375491","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973370388&doi=10.1109%2fJBHI.2014.2375491&partnerID=40&md5=4c21b919468c8c798a9548de821dad1a","Content-based image retrieval (CBIR) is a search technology that could aid medical diagnosis by retrieving and presenting earlier reported cases that are related to the one being diagnosed. To retrieve relevant cases, CBIR systems depend on supervised learning to map low-level image contents to high-level diagnostic concepts. However, the annotation by medical doctors for training and evaluation purposes is a difficult and time-consuming task, which restricts the supervised learning phase to specific CBIR problems of well-defined clinical applications. This paper proposes a new technique that automatically learns the similarity between the several exams from textual distances extracted from radiology reports, thereby successfully reducing the number of annotations needed. Our method first infers the relation between patients by using information retrieval techniques to determine the textual distances between patient radiology reports. These distances are subsequently used to supervise a metric learning algorithm, that transforms the image space accordingly to textual distances. CBIR systems with different image descriptions and different levels of medical annotations were evaluated, with and without supervision from textual distances, using a database of computer tomography scans of patients with interstitial lung diseases. The proposed method consistently improves CBIR mean average precision, with improvements that can reach 38%, and more marked gains for small annotation sets. Given the overall availability of radiology reports in picture archiving and communication systems, the proposed approach can be broadly applied to CBIR systems in different medical problems, and may facilitate the introduction of CBIR in clinical practice. © 2014 IEEE.","Computed tomography; Computer-aided diagnosis (CAD); Content-based image retrieval (CBIR); Interstitial lung diseases (ILD); Metric learning","Biological organs; Computer aided diagnosis; Computer aided instruction; Computerized tomography; Content based retrieval; Medical computing; Medical imaging; Medical problems; Petroleum reservoir evaluation; Picture archiving and communication systems; Radiation; Radiology; Supervised learning; Clinical application; Computer Aided Diagnosis(CAD); Content-Based Image Retrieval; Image descriptions; Interstitial lung disease; Medical annotation; Metric learning; Time-consuming tasks; Learning algorithms; algorithm; computer assisted diagnosis; computer assisted tomography; human; interstitial lung disease; procedures; radiography; Algorithms; Humans; Image Interpretation, Computer-Assisted; Lung Diseases, Interstitial; Tomography, X-Ray Computed",Article,Scopus
"Monteiro E., Sernadela P., Matos S., Costa C., Oliveira J.L.","Semantic knowledge base construction from radiology reports",2016,"HEALTHINF 2016 - 9th International Conference on Health Informatics, Proceedings; Part of 9th International Joint Conference on Biomedical Engineering Systems and Technologies, BIOSTEC 2016",1,"10.5220/0005709503450352","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969263661&doi=10.5220%2f0005709503450352&partnerID=40&md5=1d08309885b0cd9cb2e595fd3a477499","The tremendous quantity of data stored daily in healthcare institutions demands the development of new methods to summarize and reuse available information in clinical practice. In order to leverage modern healthcare information systems, new strategies must be developed that address challenges such as extraction of relevant information, data redundancy, and the lack of associations within the data. This article proposes a pipeline to overcome these challenges in the context of medical imaging reports, by automatically extracting and linking information, and summarizing natural language reports into an ontology model. Using data from the Physionet MIMIC II database, we created a semantic knowledge base with more than 6.5 millions of triples obtained from a collection of 16,000 radiology reports. Copyright © 2016 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.","Clinical reports; Healthcare information management; Radiology; Semantic web; Text-mining","Biomedical engineering; Health care; Information management; Information use; Knowledge based systems; Medical computing; Medical imaging; Medical informatics; Natural language processing systems; Radiation; Radiology; Semantic Web; Clinical practices; Clinical reports; Health care information system; Healthcare institutions; Natural languages; Radiology reports; Semantic knowledge; Text mining; Data mining",Conference Paper,Scopus
"Hassanpour S., Langlotz C.P.","Information extraction from multi-institutional radiology reports",2016,"Artificial Intelligence in Medicine",108,"10.1016/j.artmed.2015.09.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958115528&doi=10.1016%2fj.artmed.2015.09.007&partnerID=40&md5=dd80f1c067f6b2a6eecb2139eabb8d28","Objectives: The radiology report is the most important source of clinical imaging information. It documents critical information about the patient's health and the radiologist's interpretation of medical findings. It also communicates information to the referring physicians and records that information for future clinical and research use. Although efforts to structure some radiology report information through predefined templates are beginning to bear fruit, a large portion of radiology report information is entered in free text. The free text format is a major obstacle for rapid extraction and subsequent use of information by clinicians, researchers, and healthcare information systems. This difficulty is due to the ambiguity and subtlety of natural language, complexity of described images, and variations among different radiologists and healthcare organizations. As a result, radiology reports are used only once by the clinician who ordered the study and rarely are used again for research and data mining. In this work, machine learning techniques and a large multi-institutional radiology report repository are used to extract the semantics of the radiology report and overcome the barriers to the re-use of radiology report information in clinical research and other healthcare applications. Material and methods: We describe a machine learning system to annotate radiology reports and extract report contents according to an information model. This information model covers the majority of clinically significant contents in radiology reports and is applicable to a wide variety of radiology study types. Our automated approach uses discriminative sequence classifiers for named-entity recognition to extract and organize clinically significant terms and phrases consistent with the information model. We evaluated our information extraction system on 150 radiology reports from three major healthcare organizations and compared its results to a commonly used non-machine learning information extraction method. We also evaluated the generalizability of our approach across different organizations by training and testing our system on data from different organizations. Results: Our results show the efficacy of our machine learning approach in extracting the information model's elements (10-fold cross-validation average performance: precision: 87%, recall: 84%, F1 score: 85%) and its superiority and generalizability compared to the common non-machine learning approach (p-value < 0.05). Conclusions: Our machine learning information extraction approach provides an effective automatic method to annotate and extract clinically significant information from a large collection of free text radiology reports. This information extraction system can help clinicians better understand the radiology reports and prioritize their review process. In addition, the extracted information can be used by researchers to link radiology reports to information from other data sources such as electronic health records and the patient's genome. Extracted information also can facilitate disease surveillance, real-time clinical decision support for the radiologist, and content-based image retrieval. © 2015 Elsevier B.V..","Discriminative sequence classifier; Information extraction; Natural language processing; Radiology report narrative","Artificial intelligence; Computational linguistics; Content based retrieval; Data mining; Decision support systems; Health care; Image retrieval; Information analysis; Information retrieval; Information retrieval systems; Information systems; Information theory; Information use; Learning algorithms; Learning systems; Medical computing; Medical imaging; Natural language processing systems; Radiation; Radiology; Semantics; Societies and institutions; Content based image retrieval; Health care information system; Information extraction methods; Information extraction systems; Machine learning approaches; Machine learning techniques; NAtural language processing; Radiology reports; Classification (of information); Article; clinical data repository; clinical research; conditional markov model; conditional random field model; data extraction; documentation; health care organization; human; information model; information retrieval; machine learning; measurement precision; medical documentation; medical illustration; medical information; named entity recognition; natural language processing; priority journal; radiology report; semantics; automated pattern recognition; clinical trial; computer assisted diagnosis; data mining; discriminant analysis; electronic health record; factual database; medical record; multicenter study; observer variation; predictive value; procedures; radiology information system; reproducibility; semantics; theoretical model; United States; Data Mining; Databases, Factual; Discriminant Analysis; Electronic Health Records; Humans; Information Storage and Retrieval; Machine Learning; Medical Record Linkage; Models, Theoretical; Natural Language Processing; Observer Variation; Pattern Recognition, Automated; Predictive Value of Tests; Radiographic Image Interpretation, Computer-Assisted; Radiology Information Systems; Reproducibility of Results; Semantics; United States",Article,Scopus
"Cai T., Giannopoulos A.A., Yu S., Kelil T., Ripley B., Kumamaru K.K., Rybicki F.J., Mitsouras D.","Natural language processing technologies in radiology research and clinical applications",2016,"Radiographics",140,"10.1148/rg.2016150080","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955464993&doi=10.1148%2frg.2016150080&partnerID=40&md5=e39648a33d2dde81b53631e54a6471f4","The migration of imaging reports to electronic medical record systems holds great potential in terms of advancing radiology research and practice by leveraging the large volume of data continuously being updated, integrated, and shared. However, there are significant challenges as well, largely due to the heterogeneity of how these data are formatted. Indeed, although there is movement toward structured reporting in radiology (ie, hierarchically itemized reporting with use of standardized terminology), the majority of radiology reports remain unstructured and use free-form language. To effectively “mine” these large datasets for hypothesis testing, a robust strategy for extracting the necessary information is needed. Manual extraction of information is a time-consuming and often unmanageable task. “Intelligent” search engines that instead rely on natural language processing (NLP), a computer-based approach to analyzing free-form text or speech, can be used to automate this data mining task. The overall goal of NLP is to translate natural human language into a structured format (ie, a fixed collection of elements), each with a standardized set of choices for its value, that is easily manipulated by computer programs to (among other things) order into subcategories or query for the presence or absence of a finding. The authors review the fundamentals of NLP and describe various techniques that constitute NLP in radiology, along with some key applications. © RSNA, 2016.",,"computer program; data mining; electronic medical record; extraction; human; human experiment; imaging; natural language processing; nomenclature; radiology; search engine; speech; automated pattern recognition; controlled vocabulary; electronic health record; machine learning; medical research; organization and management; procedures; radiology; Biomedical Research; Data Mining; Electronic Health Records; Humans; Machine Learning; Natural Language Processing; Pattern Recognition, Automated; Radiology; Vocabulary, Controlled",Article,Scopus
"Hassanpour S., Langlotz C.P.","Predicting High Imaging Utilization Based on Initial Radiology Reports: A Feasibility Study of Machine Learning",2016,"Academic Radiology",11,"10.1016/j.acra.2015.09.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949655484&doi=10.1016%2fj.acra.2015.09.014&partnerID=40&md5=6b66fd74d9ab69afa3fc67e9482afe7b","Rationale and Objectives: Imaging utilization has significantly increased over the last two decades, and is only recently showing signs of moderating. To help healthcare providers identify patients at risk for high imaging utilization, we developed a prediction model to recognize high imaging utilizers based on their initial imaging reports. Materials and Methods: The prediction model uses a machine learning text classification framework. In this study, we used radiology reports from 18,384 patients with at least one abdomen computed tomography study in their imaging record at Stanford Health Care as the training set. We modeled the radiology reports in a vector space and trained a support vector machine classifier for this prediction task. We evaluated our model on a separate test set of 4791 patients. In addition to high prediction accuracy, in our method, we aimed at achieving high specificity to identify patients at high risk for high imaging utilization. Results: Our results (accuracy: 94.0%, sensitivity: 74.4%, specificity: 97.9%, positive predictive value: 87.3%, negative predictive value: 95.1%) show that a prediction model can enable healthcare providers to identify in advance patients who are likely to be high utilizers of imaging services. Conclusions: Machine learning classifiers developed from narrative radiology reports are feasible methods to predict imaging utilization. Such systems can be used to identify high utilizers, inform future image ordering behavior, and encourage judicious use of imaging. © 2016 The Association of University Radiologists.","Imaging utilization; Natural language processing; Prediction modeling; Radiology report narrative","abdominal radiography; Article; classification; classifier; computer assisted tomography; diagnostic imaging; echography; feasibility study; health care personnel; health care utilization; high risk patient; human; machine learning; major clinical study; model; natural language processing; pelvis radiography; prediction; predictive value; priority journal; radiodiagnosis; sensitivity and specificity; support vector machine; thorax radiography; adult; evaluation study; male; research; unnecessary procedure; utilization; x-ray computed tomography; Adult; Feasibility Studies; Humans; Machine Learning; Male; Radiography, Abdominal; Research Report; Sensitivity and Specificity; Support Vector Machine; Tomography, X-Ray Computed; Unnecessary Procedures",Article,Scopus
"Arnold C.W., Wallace W.D., Chen S., Oh A., Abtin F., Genshaft S., Binder S., Aberle D., Enzmann D.","RadPath: A Web-based System for Integrating and Correlating Radiology and Pathology Findings During Cancer Diagnosis",2016,"Academic Radiology",21,"10.1016/j.acra.2015.09.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949654317&doi=10.1016%2fj.acra.2015.09.009&partnerID=40&md5=26330033ae6f31a831f6822a1bc2a539","Rationale and Objectives: The current paradigm of cancer diagnosis involves uncoordinated communication of findings from radiology and pathology to downstream physicians. Discordance between these findings can require additional time from downstream users to resolve, or given incorrect resolution, may adversely impact treatment decisions. To mitigate this problem, we developed a web-based system, called RadPath, for correlating and integrating radiology and pathology reporting. Materials and Methods: RadPath includes interfaces to our institution's clinical information systems, which are used to retrieve reports, images, and test results that are structured into an interactive compendium for a diagnostic patient case. The system includes an editing interface for physicians, allowing for the inclusion of additional clinical data, as well as the ability to retrospectively correlate and contextualize imaging findings following pathology diagnosis. Results: During pilot deployment and testing over the course of 1 year, physicians at our institution have completed 60 RadPath cases, requiring an average of 128 seconds from a radiologist and an average of 93 seconds from a pathologist per case. Several technical and workflow challenges were encountered during development, including interfacing with diverse clinical information systems, automatically structuring report contents, and determining the appropriate physicians to create RadPath summaries. Reaction to RadPath has been positive, with users valuing the system's ability to consolidate diagnostic information. Conclusions: With the increasing complexity of medicine and the movement toward team-based disease management, there is a need for improved clinical communication and information exchange. RadPath provides a platform for generating coherent and correlated diagnostic summaries in cancer diagnosis with minimal additional effort from physicians. © 2016 The Association of University Radiologists.","Cancer diagnosis; Clinical workflow; Integrated reporting","Article; cancer diagnosis; computer system; correlation analysis; Internet; medical information system; pathology; priority journal; radiology; diagnostic imaging; electronic health record; human; information retrieval; neoplasm; organization and management; pathology; radiologist; radiology information system; workflow; Electronic Health Records; Humans; Information Storage and Retrieval; Internet; Neoplasms; Radiologists; Radiology Information Systems; Workflow",Article,Scopus
"Johnson E., Baughman W.C., Ozsoyoglu G.","A method for imputation of semantic class in diagnostic radiology text",2015,"Proceedings - 2015 IEEE International Conference on Bioinformatics and Biomedicine, BIBM 2015",1,"10.1109/BIBM.2015.7359780","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962440852&doi=10.1109%2fBIBM.2015.7359780&partnerID=40&md5=00d1926dec854bbf659e139c30ef5913","Diagnostic medicine produces large volumes of free-text reports used primarily for communication between medical professionals. Secondary use of these reports requires extraction of structured information from the free text. State-of-the-art computational natural language processing techniques can make partial identification of semantics in text, but the diverse terminology used in medical settings makes training classifiers for every lexicon a laborious task. We present statistics of semantics from a large-scale machine-annotated corpus of 83,452 chest x-ray reports. We show that the distribution of semantics is consistent with Zipfian distributions observed in other natural language corpora, and we quantify the semantic focus imparted by limiting a study by body area and modality. We demonstrate that within our semantically focused corpus, pairwise co-occurrence statistics can be used to accurately impute the semantic class for frequently occurring unknown entities, thereby reducing the number of semantically unclassified phrases by up to 25%. Finally, we show that our imputation approach is consistent across multiple reconstructions of the underlying text data. © 2015 IEEE.",,"Bioinformatics; Computational linguistics; Diagnosis; Diagnostic radiography; Linguistics; Natural language processing systems; Co-occurrence statistics; Diagnostic radiology; Medical professionals; Medical settings; NAtural language processing; Natural languages; Partial identification; Structured information; Semantics",Conference Paper,Scopus
"Lalithsena S., Tari L., Von Reden A., Wilson B., Kolowitz B.J., Kalafut J., Gustafson S., Sheth A.","Feedback-driven radiology exam report retrieval with semantics",2015,"Proceedings - 2015 IEEE International Conference on Healthcare Informatics, ICHI 2015",1,"10.1109/ICHI.2015.35","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966340132&doi=10.1109%2fICHI.2015.35&partnerID=40&md5=4e220b411610da0fe4b8969a56c2d184","Clinical documents are vital resources for radiologists to have a better understanding of patient history. The use of clinical documents can complement the often brief reasons for exams that are provided by physicians in order to perform more informed diagnoses. With the large number of study exams that radiologists have to perform on a daily basis, it becomes too time-consuming for radiologists to sift through each patient's clinical documents. It is therefore important to provide a capability that can present contextually relevant clinical documents, and at the same time satisfy the diverse information needs among radiologists from different specialties. In this work, we propose a knowledge-based semantic similarity approach that uses domain-specific relationships such as part-of along with taxonomic relationships such as is-a to identify relevant radiology exam records. Our approach also incorporates explicit relevance feedback to personalize radiologists information needs. We evaluated our approach on a corpus of 6,265 radiology exam reports through study sessions with radiologists and demonstrated that the retrieval performance of our approach yields an improvement of 5% over the baseline. We further performed intra-class and inter-class similarities using a subset of 2,384 reports spanning across 10 exam codes. Our result shows that intra-class similarities are always higher than the inter-class similarities and our approach was able to obtain 6% percent improvement in intra-class similarities against the baseline. Our results suggest that the use of domain-specific relationships together with relevance feedback provides a significant value to improve the accuracy of the retrieval of radiology exam reports. © 2015 IEEE.",,"Health care; Information science; Knowledge based systems; Natural language processing systems; Radiation; Radiology; Semantics; Domain specific; Inter class; Intra class; Knowledge based; Patient history; Relevance feedback; Retrieval performance; Semantic similarity approaches; Feedback",Conference Paper,Scopus
"Linaker K.L.","Radiologists as Educators: A Narrative Review of the Literature",2015,"Journal of Chiropractic Humanities",6,"10.1016/j.echu.2015.09.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951821431&doi=10.1016%2fj.echu.2015.09.003&partnerID=40&md5=cd824af8f18031ce534671232b842c3e","Objective: The purpose of this study was to examine literature on how radiologists are trained to be effective educators for both residents and undergraduates in the health professions. Methods: A review of the literature was performed using relevant key words. Articles were retrieved through from 1990 through December 2012 using PubMed, ScienceDirect, ERIC, Proquest, and ICL databases along with a manual review of references. Results: Of the 4716 unique abstracts reviewed by the author, 51 were found to be relevant to the purpose of this study. Faculty teaching skills seem to be solidified during residency. This may be due to a failure to include scholarship of teaching and learning in education and faculty development. Preliminary research shows that creating opportunity for faculty development is beneficial with much of this literature focused on explaining educational concepts to radiologists. Conclusion: The literature examining faculty training in the area of radiology education is sparse. Several articles address the need for more academic radiologists and the need for better training of academic radiologists. The few articles aimed at providing insight to radiologists in this area introduce basic educational concepts such as lecture creation, examination writing, and learning styles or simply delineating what makes an effective educator. © 2015 National University of Health Sciences.","Chiropractic; Diagnostic imaging; Education; Medical radiology teaching","abstract report; Article; faculty practice; health educator; human; information retrieval; learning style; medical education; medical profession; narrative; priority journal; professional competence; radiologist; radiology; reference database; residency education; teaching",Article,Scopus
"Bodile A., Kshirsagar M.","Text mining in radiology reports by statistical machine translation approach",2015,"Global Conference on Communication Technologies, GCCT 2015",2,"10.1109/GCCT.2015.7342797","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960105796&doi=10.1109%2fGCCT.2015.7342797&partnerID=40&md5=89dcb8f796ea3e1042bcb20ae919a893","Medical text mining has gained increasing popularity in recent years. Now a days, large amount of medical text data are daily generated in health institutions, but never refer again as it is very time consuming task. In Radiology domain, most of the reports are in free text format and usually unprocessed, hence it is difficult to access the valuable information for medical professional unless proper text mining is not applied. There are some systems existing for radiology report information retrieval like MedLEE, NeuRadIR, CBIR but very few of them make use of text associated with image. This paper proposes a text mining system to deals with this problem by using statistical machine translation approach. The System stores the text and image features to find the match report. The SVM classifier is use in SMT approach to check whether entered report present in database or not. The system will return the similar report match with the entered report from the database. © 2015 IEEE.","Image feature extractor; Radiology report; report retriever; Text mining","Classification (of information); Computational linguistics; Computer aided language translation; Linguistics; Radiation; Radiology; Search engines; Translation (languages); Image features; Medical professionals; Radiology reports; report retriever; Statistical machine translation; SVM classifiers; Text mining; Time-consuming tasks; Data mining",Conference Paper,Scopus
"Scott J.A., Palmer E.L.","Radiology reports: A quantifiable and objective textual approach",2015,"Clinical Radiology",7,"10.1016/j.crad.2015.06.080","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942986020&doi=10.1016%2fj.crad.2015.06.080&partnerID=40&md5=f6af5a610586c60dce8b69e450e43667","Aim To examine the feasibility of using automated lexical analysis in conjunction with machine learning to create a means of objectively characterising radiology reports for quality improvement. Materials and methods Twelve lexical parameters were quantified from the collected reports of four radiologists. These included the number of different words used, number of sentences, reading grade, readability, usage of the passive voice, and lexical metrics of concreteness, ambivalence, complexity, passivity, embellishment, communication and cognition. Each radiologist was statistically compared to the mean of the group for each parameter to determine outlying report characteristics. The reproducibility of these parameters in a given radiologist's reporting style was tested by using only these 12 parameters as input to a neural network designed to establish the authorship of 60 unknown reports. Results Significant differences in report characteristics were observed between radiologists, quantifying and characterising deviations of individuals from the group reporting style. The 12 metrics employed in a neural network correctly identified the author in each of 60 unknown reports tested, indicating a robust parametric signature. Conclusion Automated and quantifiable methods can be used to analyse reporting style and provide impartial and objective feedback as well as to detect and characterise significant differences from the group. The parameters examined are sufficiently specific to identify the authors of reports and can potentially be useful in quality improvement and residency training. © 2015 The Royal College of Radiologists. Published by Elsevier Ltd. All rights reserved.",,"ambivalence; Article; autoanalysis; automated lexical analysis; bone scintiscanning; cognition; comparative study; health care management; human; information processing; interpersonal communication; language processing; machine learning; medical education; normal human; priority journal; radiologist; radiology; radiology report; reproducibility; total quality management; bone; clinical competence; clinical trial; comprehension; electronic medical record; evaluation study; feasibility study; language; methodology; multicenter study; observer variation; radiology; scintiscanning; standards; total quality management; Bone and Bones; Clinical Competence; Comprehension; Feasibility Studies; Humans; Language; Medical Records Systems, Computerized; Observer Variation; Quality Improvement; Radiology; Research Design",Article,Scopus
"Kahn C.E., Jr., Genereaux B., Langlotz C.P.","Conversion of Radiology Reporting Templates to the MRRT Standard",2015,"Journal of Digital Imaging",20,"10.1007/s10278-015-9787-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941994793&doi=10.1007%2fs10278-015-9787-3&partnerID=40&md5=e114baeb95d9c3be052c0102459a0909","In 2013, the Integrating the Healthcare Enterprise (IHE) Radiology workgroup developed the Management of Radiology Report Templates (MRRT) profile, which defines both the format of radiology reporting templates using an extension of Hypertext Markup Language version 5 (HTML5), and the transportation mechanism to query, retrieve, and store these templates. Of 200 English-language report templates published by the Radiological Society of North America (RSNA), initially encoded as text and in an XML schema language, 168 have been converted successfully into MRRT using a combination of automated processes and manual editing; conversion of the remaining 32 templates is in progress. The automated conversion process applied Extensible Stylesheet Language Transformation (XSLT) scripts, an XML parsing engine, and a Java servlet. The templates were validated for proper HTML5 and MRRT syntax using web-based services. The MRRT templates allow radiologists to share best-practice templates across organizations and have been uploaded to the template library to supersede the prior XML-format templates. By using MRRT transactions and MRRT-format templates, radiologists will be able to directly import and apply templates from the RSNA Report Template Library in their own MRRT-compatible vendor systems. The availability of MRRT-format reporting templates will stimulate adoption of the MRRT standard and is expected to advance the sharing and use of templates to improve the quality of radiology reports. © 2015, Society for Imaging Informatics in Medicine.","Infrastructure; Integrating the Healthcare Enterprise (IHE); MRRT; Radiology reporting; Reporting; Standards; Structured reporting","Automation; Computational linguistics; Health care; HTML; Hypertext systems; Java programming language; Radiology; Social networking (online); Standards; Syntactics; XML; Infrastructure; Integrating the healthcare enterprise; MRRT; Radiology reporting; Reporting; Structured reporting; Radiation; computer language; controlled vocabulary; human; radiology information system; software; Humans; Programming Languages; Radiology Information Systems; Software; Vocabulary, Controlled",Article,Scopus
"Shin H.-C., Lu L., Kim L., Seff A., Yao J., Summers R.M.","Interleaved text/image Deep Mining on a large-scale radiology database",2015,"Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",79,"10.1109/CVPR.2015.7298712","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959244105&doi=10.1109%2fCVPR.2015.7298712&partnerID=40&md5=33617e5f0df1699a54cfd9bf47af7966","Despite tremendous progress in computer vision, effective learning on very large-scale (> 100K patients) medical image databases has been vastly hindered. We present an interleaved text/image deep learning system to extract and mine the semantic interactions of radiology images and reports from a national research hospital's picture archiving and communication system. Instead of using full 3D medical volumes, we focus on a collection of representative ∼216K 2D key images/slices (selected by clinicians for diagnostic reference) with text-driven scalar and vector labels. Our system interleaves between unsupervised learning (e.g., latent Dirichlet allocation, recurrent neural net language models) on document- and sentence-level texts to generate semantic labels and supervised learning via deep convolutional neural networks (CNNs) to map from images to label spaces. Disease-related key words can be predicted for radiology images in a retrieval manner. We have demonstrated promising quantitative and qualitative results. The large-scale datasets of extracted key images and their categorization, embedded vector labels and sentence descriptions can be harnessed to alleviate the deep learning 'data-hungry' obstacle in the medical domain. © 2015 IEEE.",,"Computer vision; Diagnosis; Medical computing; Medical imaging; Neural networks; Pattern recognition; Picture archiving and communication systems; Radiation; Radiology; Recurrent neural networks; Semantics; Statistics; Convolutional neural network; Effective learning; Large-scale datasets; Latent Dirichlet allocation; Medical domains; Medical image database; Semantic interactions; Sentence-level texts; Image processing",Conference Paper,Scopus
"Schmitt J.E., Scanlon M.H., Servaes S., Levin D., Cook T.S.","Milestones on a Shoestring: A Cost-Effective, Semi-automated Implementation of the New ACGME Requirements for Radiology",2015,"Academic Radiology",15,"10.1016/j.acra.2015.02.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941183516&doi=10.1016%2fj.acra.2015.02.013&partnerID=40&md5=9497dffd6e7a68ae9fc85e21fec0ba8d","Rationale and Objectives: The advent of the ACGME's Next Accreditation System represents a significant new challenge for residencies and fellowships, owing to its requirements for more complex and detailed information. Material and Methods: We developed a system of online assessment tools to provide comprehensive coverage of the twelve ACGME Milestones and digitized them using freely available cloud-based productivity tools. These tools include a combination of point-of-care procedural assessments, electronic quizzes, online modules, and other data entry forms. Using free statistical analytic tools, we also developed an automated system for management, processing, and data reporting. Results: After one year of use, our Milestones project has resulted in the submission of over 20,000 individual data points. The use of automated statistical methods to generate resident-specific profiles has allowed for dynamic reports of individual residents' progress. These profiles both summarize data and also allow program directors access to more granular information as needed. Conclusion: Informatics-driven strategies for data assessment and processing represent feasible solutions to Milestones assessment and analysis, reducing the potential administrative burden for program directors, residents, and staff. © 2015 AUR.","ACGME; Informatics; Milestones","accreditation; Article; automation; data processing; human; medical informatics; online system; priority journal; radiology; residency education; statistical analysis; clinical competence; cost benefit analysis; education; medical education; point of care system; radiology; Accreditation; Clinical Competence; Cost-Benefit Analysis; Humans; Internship and Residency; Point-of-Care Systems; Radiology",Article,Scopus
"Markonis D., Holzer M., Baroz F., De Castaneda R.L.R., Boyer C., Langs G., Müller H.","User-oriented evaluation of a medical image retrieval system for radiologists",2015,"International Journal of Medical Informatics",19,"10.1016/j.ijmedinf.2015.04.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940893422&doi=10.1016%2fj.ijmedinf.2015.04.003&partnerID=40&md5=d6eebb33a155a79cdb0dd70e35334827","Purpose: This article reports the user-oriented evaluation of a text- and content-based medical image retrieval system. User tests with radiologists using a search system for images in the medical literature are presented. The goal of the tests is to assess the usability of the system, identify system and interface aspects that need improvement and useful additions. Another objective is to investigate the system's added value to radiology information retrieval. The study provides an insight into required specifications and potential shortcomings of medical image retrieval systems through a concrete methodology for conducting user tests. Methods: User tests with a working image retrieval system of images from the biomedical literature were performed in an iterative manner, where each iteration had the participants perform radiology information seeking tasks and then refining the system as well as the user study design itself. During these tasks the interaction of the users with the system was monitored, usability aspects were measured, retrieval success rates recorded and feedback was collected through survey forms. Results: In total, 16 radiologists participated in the user tests. The success rates in finding relevant information were on average 87% and 78% for image and case retrieval tasks, respectively. The average time for a successful search was below 3. min in both cases. Users felt quickly comfortable with the novel techniques and tools (after 5 to 15. min), such as content-based image retrieval and relevance feedback. User satisfaction measures show a very positive attitude toward the system's functionalities while the user feedback helped identifying the system's weak points. The participants proposed several potentially useful new functionalities, such as filtering by imaging modality and search for articles using image examples. Conclusion: The iterative character of the evaluation helped to obtain diverse and detailed feedback on all system aspects. Radiologists are quickly familiar with the functionalities but have several comments on desired functionalities. The analysis of the results can potentially assist system refinement for future medical information retrieval systems. Moreover, the methodology presented as well as the discussion on the limitations and challenges of such studies can be useful for user-oriented medical image retrieval evaluation, as user-oriented evaluation of interactive system is still only rarely performed. Such interactive evaluations can be limited in effort if done iteratively and can give many insights for developing better systems. © 2015.","Content-based image retrieval; Medical informatics applications; Usability tests; User-centered design","Content based retrieval; Feedback; Human computer interaction; Image retrieval; Information retrieval; Information retrieval systems; Information science; Iterative methods; Medical imaging; Medical information systems; Radiation; Radiology; User centered design; Biomedical literature; Content based image retrieval; Content-based medical image retrieval system; Evaluation of interactive systems; Image retrieval systems; Medical informatics applications; Medical literatures; Usability tests; Search engines; adult; Article; attitude; computer interface; controlled study; feedback system; female; human; image retrieval; information retrieval; information seeking; male; methodology; normal human; priority journal; radiologist; satisfaction; attitude to computers; Austria; computer interface; computer program; consumer attitude; data mining; health personnel attitude; human computer interaction; medical record; physician; procedures; radiology information system; statistics and numerical data; Switzerland; utilization; utilization review; workload; young adult; Adult; Attitude of Health Personnel; Attitude to Computers; Austria; Computer Literacy; Consumer Behavior; Data Mining; Female; Humans; Male; Medical Record Linkage; Physicians; Radiology Information Systems; Software; Switzerland; User-Computer Interface; Utilization Review; Workload; Young Adult",Article,Scopus
"Minn M.J., Zandieh A.R., Filice R.W.","Improving Radiology Report Quality by Rapidly Notifying Radiologist of Report Errors",2015,"Journal of Digital Imaging",16,"10.1007/s10278-015-9781-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937978540&doi=10.1007%2fs10278-015-9781-9&partnerID=40&md5=5ae30571ea0d73db83ab8e31325fe3b3","Radiology report errors occur for many reasons including the use of pre-filled report templates, wrong-word substitution, nonsensical phrases, and missing words. Reports may also contain clinical errors that are not specific to the speech recognition including wrong laterality and gender-specific discrepancies. Our goal was to create a custom algorithm to detect potential gender and laterality mismatch errors and to notify the interpreting radiologists for rapid correction. A JavaScript algorithm was devised to flag gender and laterality mismatch errors by searching the text of the report for keywords and comparing them to parameters within the study’s HL7 metadata (i.e., procedure type, patient sex). The error detection algorithm was retrospectively applied to 82,353 reports 4 months prior to its development and then prospectively to 309,304 reports 15 months after implementation. Flagged reports were reviewed individually by two radiologists for a true gender or laterality error and to determine if the errors were ultimately corrected. There was significant improvement in the number of flagged reports (pre, 198/82,353 [0.24 %]; post, 628/309,304 [0.20 %]; P = 0.04) and reports containing confirmed gender or laterality errors (pre, 116/82,353 [0.014 %]; post, 285/309,304 [0.09 %]; P < 0.0001) after implementing our error notification system. The number of flagged reports containing an error that were ultimately corrected improved dramatically after implementing the notification system (pre, 17/116 [15 %]; post, 239/285 [84 %]; P < 0.0001). We developed a successful automated tool for detecting and notifying radiologists of potential gender and laterality errors, allowing for rapid report correction and reducing the overall rate of report errors. © 2015, Society for Imaging Informatics in Medicine.","Gender mismatch; Health Level 7 (HL7); Laterality; Patient safety; Quality control; Radiology reporting; Software design","Errors; Quality control; Radiation; Radiology; Social sciences; Software design; Gender mismatch; Health Level 7 (HL7); Laterality; Patient safety; Radiology reporting; Speech recognition; algorithm; automatic speech recognition; electronic medical record system; female; human; male; medical error; prevention and control; radiology; radiology information system; reproducibility; retrospective study; standards; total quality management; Algorithms; Female; Humans; Male; Medical Errors; Medical Records Systems, Computerized; Quality Improvement; Radiology; Radiology Information Systems; Reproducibility of Results; Retrospective Studies; Speech Recognition Software",Article,Scopus
"Sevenster M., Buurman J., Liu P., Peters J.F., Chang P.J.","Natural language processing techniques for extracting and categorizing finding measurements in narrative radiology reports",2015,"Applied Clinical Informatics",35,"10.4338/ACI-2014-11-RA-0110","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982682353&doi=10.4338%2fACI-2014-11-RA-0110&partnerID=40&md5=682ecfc388e138b0f42e73a4d67a8e08","Background: Accumulating quantitative outcome parameters may contribute to constructing a healthcare organization in which outcomes of clinical procedures are reproducible and predictable. In imaging studies, measurements are the principal category of quantitative para meters. Objectives: The purpose of this work is to develop and evaluate two natural language processing engines that extract finding and organ measurements from narrative radiology reports and to categorize extracted measurements by their “temporality“. Methods: The measurement extraction engine is developed as a set of regular expressions. The engine was evaluated against a manually created ground truth. Automated categorization of measurement temporality is defined as a machine learning problem. A ground truth was manually developed based on a corpus of radiology reports. A maximum entropy model was created using features that characterize the measurement itself and its narrative context. The model was evaluated in a ten-fold cross validation protocol. Results: The measurement extraction engine has precision 0.994 and recall 0.991. Accuracy of the measurement classification engine is 0.960. Conclusions: The work contributes to machine understanding of radiology reports and may find application in software applications that process medical data. © Schattauer 2015.","Maximum entropy; Measurement; Natural language processing; Quantitative imaging; Radiology report","data mining; natural language processing; procedures; radiology; research; software; Data Mining; Natural Language Processing; Radiology; Research Report; Software",Article,Scopus
"Henshaw D., Okawa G., Ching K., Garrido T., Qian H., Tsai J.","Access to radiology reports via an online patient portal: Experiences of referring physicians and patients",2015,"Journal of the American College of Radiology",67,"10.1016/j.jacr.2015.01.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930893302&doi=10.1016%2fj.jacr.2015.01.015&partnerID=40&md5=3d2bb1b3226ec5e9f4f4ba85e8607c1b","Purpose Few organizations have reported providing radiology reports to patients via an electronic health record patient portal. The authors describe the process of manual release of reports made by referring physicians, and patients' and referring physicians' experiences during the first year that release through the portal was available. Methods A survey of 508 patients assessed perceived accessibility and importance of portal-released radiology reports, and communications with referring physicians before and after the release. A survey of 48 referring physicians and a group interview assessed the utility of releasing reports, preferences regarding automatic release, and workload impact. Data were analyzed using descriptive statistics and qualitative methods. Results A total of 74% (377) of patients found reports easy to access, and 88% (446) reported that the ability to do so was important. In all, 49% (250) of patients were contacted by their referring physician before report release, and 25% (156) contacted their physician for more information after viewing a report. Of the referring physicians, 88% (42) found that releasing reports to patients was useful. Auto-release of x-ray reports, with a 1-week delay, was preferred by 58% (28), but they were more reluctant to auto-release CT and MRI reports. A total of 86% (41) of referring physicians reported that follow-up emails, telephone calls, and office visits were unchanged or had decreased. Conclusions Referring-physician release of radiology reports via the online portal is important to patients, useful to referring physicians, and does not affect referring-physician workloads. A delay between reporting results to referring physicians and releasing them to patients allows time for needed physician-patient communication. © 2015 American College of Radiology.","electronic health record; patient-centered care; qualitative research; Radiology","Article; computer assisted tomography; doctor patient relation; electronic medical record; human; major clinical study; nuclear magnetic resonance imaging; online system; patient preference; physician; radiography; radiology; workload; access to information; electronic health record; Hawaii; interpersonal communication; interview; patient referral; patient right; patient satisfaction; questionnaire; radiology information system; statistics and numerical data; Access to Information; Communication; Electronic Health Records; Hawaii; Humans; Interviews as Topic; Patient Rights; Patient Satisfaction; Physician-Patient Relations; Radiology Information Systems; Referral and Consultation; Surveys and Questionnaires; Workload",Article,Scopus
"Sadigh G., Hertweck T., Kao C., Wood P., Hughes D., Henry T.S., Duszak R., Jr.","Traditional text-only versus multimedia-enhanced radiology reporting: Referring physicians' perceptions of value",2015,"Journal of the American College of Radiology",36,"10.1016/j.jacr.2014.11.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929030811&doi=10.1016%2fj.jacr.2014.11.009&partnerID=40&md5=d3b90a79444c2eb4e8f8f968afb48e10","Purpose The aim of this study was to evaluate referring physicians' perceptions of multimedia-enhanced radiology reporting (MERR) as an alternative to traditional text-only radiology reporting. MERR supplements text-only reports by embedding user-friendly interactive hyperlinks to key images and graphically plotting target lesion size longitudinally over time. Methods Of 402 physicians responding to a web-based survey, 200 (50 each medical oncologists, radiation oncologists, neurosurgeons, and pulmonologists) practicing in the United States fulfilled criteria to complete an online survey with questions focusing on satisfaction with current text-only reports and the perceived value of image- and data-enriched reporting. Results The mean respondent age was 46 years, with a mean of 15 years in posttraining clinical practice (85% men; 47% from academic medical centers). Although 80% were satisfied with the format of their current text-only radiology reports, 80% believed that MERR would represent an improvement. The most commonly reported advantages of MERR were ""improved understanding of radiology findings by correlating images to text reports"" (86%) and ""easier access to images while monitoring progression of a disease/condition"" (79%). Of the 28% of physicians with concerns about MERR implementation, the most common were that it was ""too time intensive"" (53%) and ""the clinic workflow does not allow itself to view reports in such a fashion"" (42%). Physicians indicated a strong increased likelihood of preferentially referring patients to (80%) and recommending peers to (79%) facilities that offer MERR. Conclusion Most specialist referring physicians believe that interactive image- and data-embedded MERR represents an improvement over current text-only radiology reporting. Compared with current report formatting, most would preferentially refer patients and peers to facilities offering more meaningful image- and graphically enriched reporting platforms. © 2015 American College of Radiology.","Multimedia-enhanced radiology reporting; perceived value; radiology communication; referring physician","adult; Article; automatic speech recognition; clinical practice; electronic medical record; female; follow up; health survey; human; male; medical oncologist; multimedia; multimedia enhanced radiology reporting; neurosurgeon; normal human; oncologist; outcome assessment; patient referral; physician attitude; pulmonologist; radiation oncologist; satisfaction; teleradiology; text only radiology reporting; time; workflow; comparative study; documentation; health personnel attitude; hospital information system; middle aged; multimedia; physician; procedures; statistics and numerical data; total quality management; United States; writing; Attitude of Health Personnel; Documentation; Electronic Health Records; Female; Humans; Male; Middle Aged; Multimedia; Physicians; Quality Improvement; Radiology Information Systems; United States; Writing",Article,Scopus
"Zucker E.J., Larson D.B., Newman B., Barth R.A.","Radiologist compliance with california CT dose reporting requirements: A single-center review of pediatric chest CT",2015,"American Journal of Roentgenology",3,"10.2214/AJR.14.13693","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929650483&doi=10.2214%2fAJR.14.13693&partnerID=40&md5=e58811854059fcf6a9c967f4b7122ac7","Objective. Effective July 1, 2012, CT dose reporting became mandatory in California. We sought to assess radiologist compliance with this legislation and to determine areas for improvement. MATERIALS AND METHODS. We retrospectively reviewed reports from all chest CT examinations performed at our institution from July 1, 2012, through June 30, 2013, for errors in documentation of volume CT dose index (CTDIvol), dose-length product (DLP), and phantom size. Reports were considered as legally compliant if both CTDIvol and DLP were documented accurately and as institutionally compliant if phantom size was also documented accurately. Additionally, we tracked reports that did not document dose in our standard format (phantom size, CTDIvol for each series, and total DLP). Results. Radiologists omitted CTDIvol, DLP, or both in nine of 664 examinations (1.4%) and inaccurately reported one or both of them in 56 of the remaining 655 examinations (8.5%). Radiologists omitted phantom size in 11 of 664 examinations (1.7%) and inaccurately documented it in 20 of the remaining 653 examinations (3.1%). Of 664 examinations, 599 (90.2%) met legal reporting requirements, and 583 (87.8%) met institutional requirements. In reporting dose, radiologists variably used less decimal precision than available, summed CTDIvol, included only series-level DLP, and specified dose information from the scout topogram or a nonchest series for combination examinations. Conclusion. Our institutional processes, which primarily rely on correct human performance, do not ensure accurate dose reporting and are prone to variation in dose reporting format. In view of this finding, we are exploring higher-reliability processes, including better-defined standards and automated dose reporting systems, to improve compliance. © American Roentgen Ray Society.","California; Chest; CT; Dose reporting; Pediatric","Article; computer assisted tomography; human; measurement accuracy; medical documentation; medical error; pediatrics; priority journal; protocol compliance; radiation dose; radiation exposure; radiologist; radiology phantom; retrospective study; thorax examination; United States; image quality; legislation and jurisprudence; mandatory reporting; practice guideline; reproducibility; thorax radiography; California; Guideline Adherence; Humans; Mandatory Reporting; Pediatrics; Phantoms, Imaging; Radiation Dosage; Radiography, Thoracic; Reproducibility of Results; Retrospective Studies; Tomography, X-Ray Computed",Article,Scopus
"du Toit J., Hattingh R., Pitcher R.","The accuracy of radiology speech recognition reports in a multilingual South African teaching hospital",2015,"BMC Medical Imaging",11,"10.1186/s12880-015-0048-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84931049809&doi=10.1186%2fs12880-015-0048-1&partnerID=40&md5=2caad6af0e35575b72b1ba69ffb79e44","Background: Speech recognition (SR) technology, the process whereby spoken words are converted to digital text, has been used in radiology reporting since 1981. It was initially anticipated that SR would dominate radiology reporting, with claims of up to 99% accuracy, reduced turnaround times and significant cost savings. However, expectations have not yet been realised. The limited data available suggest SR reports have significantly higher levels of inaccuracy than traditional dictation transcription (DT) reports, as well as incurring greater aggregate costs. Methods: The aim of the study was to compare the accuracy of SR and DT reports in a resource-limited setting. The first 300 SR and the first 300 DT reports generated during March 2010 were retrieved from the hospital's PACS, and reviewed by a single observer. Text errors were identified, and then classified as either clinically significant or insignificant based on their potential impact on patient management. In addition, a follow-up analysis was conducted exactly 4 years later. Results: Of the original 300 SR reports analysed, 25.6% contained errors, with 9.6% being clinically significant. Only 9.3% of the DT reports contained errors, 2.3% having potential clinical impact. Both the overall difference in SR and DT error rates, and the difference in 'clinically significant' error rates (9.6% vs. 2.3%) were statistically significant. In the follow-up study, the overall SR error rate was strikingly similar at 24.3%, 6% being clinically significant. Conclusion: SR technology consistently increased inaccuracies in Tygerberg Hospital (TBH) radiology reports, thereby potentially compromising patient care. Awareness of increased error rates in SR reports, particularly amongst those transcribing in a second-language, is important for effective implementation of SR in a multilingual healthcare environment. © 2015 du Toit et al.; licensee BioMed Central.","Error rate; Radiology reporting; Speech recognition; Transcriptionist","automatic speech recognition; electronic medical record system; meaningful use criteria; radiology information system; reproducibility; sensitivity and specificity; South Africa; statistics and numerical data; teaching hospital; translating (language); utilization; Hospitals, Teaching; Meaningful Use; Medical Records Systems, Computerized; Radiology Information Systems; Reproducibility of Results; Sensitivity and Specificity; South Africa; Speech Recognition Software; Translating",Article,Scopus
"Tublin M.E., Deible C.R., Shrestha R.B.","The radiology report version 2.0",2015,"Journal of the American College of Radiology",4,"10.1016/j.jacr.2014.04.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924527885&doi=10.1016%2fj.jacr.2014.04.014&partnerID=40&md5=1a9bd211af9066d430a660aada518cb6",[No abstract available],,"algorithm; automatic speech recognition; automation; comprehension; computer program; human; human computer interaction; mammography; natural language processing; Note; nuclear magnetic resonance imaging; radiology; randomized controlled trial (topic); semantics; turnaround time; documentation; electronic health record; international cooperation; practice guideline; radiology; radiology information system; standards; writing; Documentation; Electronic Health Records; Internationality; Practice Guidelines as Topic; Radiology; Radiology Information Systems; Writing",Note,Scopus
"Nunes M., Rowland B., Schlachter M., Ken S., Matkovic K., Laprie A., Buhler K.","An integrated visual analysis system for fusing MR spectroscopy and multi-modal radiology imaging",2015,"2014 IEEE Conference on Visual Analytics Science and Technology, VAST 2014 - Proceedings",13,"10.1109/VAST.2014.7042481","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929458489&doi=10.1109%2fVAST.2014.7042481&partnerID=40&md5=176cffbe43d291f025ce3d7dcb50f206","For cancers such as glioblastoma multiforme, there is an increasing interest in defining 'biological target volumes' (BTV), high tumour-burden regions which may be targeted with dose boosts in radiotherapy. The definition of a BTV requires insight into tumour characteristics going beyond conventionally defined radiological abnormalities and anatomical features. Molecular and biochemical imaging techniques, like positron emission tomography, the use of Magnetic Resonance (MR) Imaging contrast agents or MR Spectroscopy deliver this information and support BTV delineation. MR Spectroscopy Imaging (MRSI) is the only non-invasive technique in this list. Studies with MRSI have shown that voxels with certain metabolic signatures are more susceptible to predict the site of relapse. Nevertheless, the discovery of complex relationships between a high number of different metabolites, anatomical, molecular and functional features is an ongoing topic of research - still lacking appropriate tools supporting a smooth workflow by providing data integration and fusion of MRSI data with other imaging modalities. We present a solution bridging this gap which gives fast and flexible access to all data at once. By integrating a customized visualization of the multi-modal and multi-variate image data with a highly flexible visual analytics (VA) framework, it is for the first time possible to interactively fuse, visualize and explore user defined metabolite relations derived from MRSI in combination with markers delivered by other imaging modalities. Real-world medical cases demonstrate the utility of our solution. By making MRSI data available both in a VA tool and in a multi-modal visualization renderer we can combine insights from each side to arrive at a superior BTV delineation. We also report feedback from domain experts indicating significant positive impact in how this work can improve the understanding of MRSI data and its integration into radiotherapy planning. © 2014 IEEE.","brain; cancer; medical decision support systems; MR spectroscopy; multi-modality data; radiotherapy planning; visualization","Artificial intelligence; Brain; Data visualization; Decision support systems; Diseases; Flow visualization; Graphical user interfaces; Magnetic resonance; Magnetic resonance spectroscopy; Metabolites; Molecular imaging; Positron emission tomography; Radiotherapy; Tumors; Visualization; cancer; Medical decision support system; MR spectroscopy; Multi modality; Radiotherapy planning; Data integration",Conference Paper,Scopus
"Yetisgen M., Klassen P., McCarthy L.H., Pellicer E., Payne T.H., Gunn M.L.","Annotation of Clinically Important Follow-up Recommendations in Radiology Reports",2015,"EMNLP 2015 - 6th International Workshop on Health Text Mining and Information Analysis, LOUHI 2015 - Proceedings of the Workshop",1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072039454&partnerID=40&md5=610a3ee6fe7b0a42e47aadc1fec138d0","Communication of follow-up recommendations when abnormalities are identified on imaging studies is prone to error. The absence of an automated system to identify and track radiology recommendations is an important barrier to ensuring timely follow-up of patients especially with non-acute incidental findings on imaging studies. We are in the process of building a natural language processing (NLP) system to identify follow-up recommendations in free-text radiology reports. In this paper, we describe our efforts in creating a multi-institutional radiology report corpus annotated for follow-up recommendation information. The annotated corpus will be used to train and test the NLP system. © 2015 Association for Computational Linguistics.",,"Automation; Radiation; Radiology; Automated systems; Follow up; Free texts; Incidental findings; Radiology reports; Natural language processing systems",Conference Paper,Scopus
"Cocos A., Masino A.J., Qian T., Pavlick E., Callison-Burch C.","Effectively Crowdsourcing Radiology Report Annotations",2015,"EMNLP 2015 - 6th International Workshop on Health Text Mining and Information Analysis, LOUHI 2015 - Proceedings of the Workshop",8,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040610826&partnerID=40&md5=dd16c27b5be6b54e9ba12ed178752389","Crowdsourcing platforms are a popular choice for researchers to gather text annotations quickly at scale. We investigate whether crowdsourced annotations are useful when the labeling task requires medical domain knowledge. Comparing a sentence classification model trained with expert-annotated sentences to the same model trained on crowd-labeled sentences, we find the crowdsourced training data to be just as effective as the manually produced dataset. We can improve the accuracy of the crowd-fueled model without collecting further labels by filtering out worker labels applied with low confidence. © 2015 Association for Computational Linguistics.",,"Classification (of information); Computational linguistics; Domain Knowledge; Natural language processing systems; Classification models; Crowdsourcing platforms; Domain knowledge; Labelings; Medical domains; Radiology reports; Sentence classifications; Text annotations; Training data; Workers'; Crowdsourcing",Conference Paper,Scopus
"Koopman B., Zuccon G., Wagholikar A., Chu K., O'Dwyer J., Nguyen A., Keijzers G.","Automated Reconciliation of Radiology Reports and Discharge Summaries",2015,"AMIA ... Annual Symposium proceedings. AMIA Symposium",9,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034838506&partnerID=40&md5=c3071d91e2bd61744c3766fe71da2c78","We study machine learning techniques to automatically identify limb abnormalities (including fractures, dislocations and foreign bodies) from radiology reports. For patients presenting to the Emergency Room (ER) with suspected limb abnormalities (e.g., fractures) there is often a multi-day delay before the radiology report is available to ER staff, by which time the patient may have been discharged home with the possibility of undiagnosed fractures. ER staff, currently, have to manually review and reconcile radiology reports with the ER discharge diagnosis; this is a laborious and error-prone manual process. Using radiology reports from three different hospitals, we show that extracting detailed features from the reports to train Support Vector Machines can effectively automate the identification of limb fractures, dislocations and foreign bodies. These can be automatically reconciled with a patient's discharge diagnosis from the ER to identify a number of cases where limb abnormalities went undiagnosed.",,"diagnostic error; diagnostic imaging; hospital emergency service; human; injuries; injury; limb; machine learning; medical record; natural language processing; prevention and control; radiology; radiology information system; software; support vector machine; Diagnostic Errors; Emergency Service, Hospital; Extremities; Humans; Machine Learning; Natural Language Processing; Patient Discharge Summaries; Radiology; Radiology Information Systems; Software; Support Vector Machine; Wounds and Injuries",Article,Scopus
"Hwang D.H., Ma K., Yepes F., Nadamuni M., Nayyar M., Liu B., Duddalwar V., Lepore N.","Multidimensional Interactive Radiology Report and Analysis: Standardization of workflow and reporting for renal mass tracking and quantification",2015,"Proceedings of SPIE - The International Society for Optical Engineering",1,"10.1117/12.2211526","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958230918&doi=10.1117%2f12.2211526&partnerID=40&md5=8f7f693b14e7b4aee4d79a3256b3efab","A conventional radiology report primarily consists of a large amount of unstructured text, and lacks clear, concise, consistent and content-rich information. Hence, an area of unmet clinical need consists of developing better ways to communicate radiology findings and information specific to each patient. Here, we design a new workflow and reporting system that combines and integrates advances in engineering technology with those from the medical sciences, the Multidimensional Interactive Radiology Report and Analysis (MIRRA). Until recently, clinical standards have primarily relied on 2D images for the purpose of measurement, but with the advent of 3D processing, many of the manually measured metrics can be automated, leading to better reproducibility and less subjective measurement placement. Hence, we make use this newly available 3D processing in our workflow. Our pipeline is used here to standardize the labeling, tracking, and quantifying of metrics for renal masses. © 2015 SPIE.","DICOM; image processing; renal masses; reporting; tumor","Bioinformatics; Information science; Radiation; Radiology; Tumors; DICOM; Radiology reports; renal masses; reporting; Reporting systems; Reproducibilities; Subjective measurements; Unstructured texts; Image processing",Conference Paper,Scopus
"Demner-Fushman D., Shooshan S.E., Rodriguez L., Antani S., Thoma G.R.","Annotation of chest radiology reports for indexing and retrieval",2015,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",9,"10.1007/978-3-319-24471-6_9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84952783827&doi=10.1007%2f978-3-319-24471-6_9&partnerID=40&md5=8a3a485e2236737a5ceb97bfff24b52a","Annotation of MEDLINE citations with controlled vocabulary terms improves the quality of retrieval results. Due to variety in descriptions of similar clinical phenomena and abundance of negation and uncertainty, annotation of clinical radiology reports for subsequent indexing and retrieval with a search engine is even more important. Provided with an opportunity to add about 4,000 radiology reports to collections indexed with NLM image retrieval engine Open-i, we needed to assure good retrieval quality. To accomplish this, we explored automatic and manual approaches to annotation, as well as developed a small controlled vocabulary of chest x-ray indexing terms and guidelines for manual annotation. Manual annotation captured the most salient findings in the reports and normalized the sparse distinct descriptions of similar findings to one controlled vocabulary term. This paper presents the vocabulary and the manual annotation process, as well as an evaluation of the automatic annotation of the reports. © Springer International Publishing Switzerland 2015.","Information storage and retrieval; Radiolog; Vocabulary, controlled","Indexing (of information); Quality control; Radiation; Radiology; Vocabulary control; Automatic annotation; Clinical radiology; Controlled vocabulary terms; Image retrieval engines; Indexing and retrieval; Information storage and retrieval; Radiolog; Vocabulary , controlled; Search engines",Conference Paper,Scopus
"Cotik V., Filippo D., Castaño J.","An Approach for Automatic Classification of Radiology Reports in Spanish",2015,"Studies in Health Technology and Informatics",10,"10.3233/978-1-61499-564-7-634","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84952020428&doi=10.3233%2f978-1-61499-564-7-634&partnerID=40&md5=a729658a749426d016877158be5ef6cd","Automatic detection of relevant terms in medical reports is useful for educational purposes and for clinical research. Natural language processing (NLP) techniques can be applied in order to identify them. In this work we present an approach to classify radiology reports written in Spanish into two sets: the ones that indicate pathological findings and the ones that do not. In addition, the entities corresponding to pathological findings are identified in the reports. We use RadLex, a lexicon of English radiology terms, and NLP techniques to identify the occurrence of pathological findings. Reports are classified using a simple algorithm based on the presence of pathological findings, negation and hedge terms. The implemented algorithms were tested with a test set of 248 reports annotated by an expert, obtaining a best result of 0.72 F1 measure. The output of the classification task can be used to look for specific occurrences of pathological findings. © 2015 IMIA and IOS Press.","Natural language processing; Negation detection; Pathological findings; Radiology reports; Text classification","Bioinformatics; Classification (of information); Clinical research; Radiation; Radiology; Text processing; Automatic classification; Automatic Detection; Classification tasks; Nlp techniques; Pathological findings; Radiology reports; SIMPLE algorithm; Text classification; Natural language processing systems; classification; human; human experiment; natural language processing; radiology; algorithm; computer assisted diagnosis; controlled vocabulary; data mining; machine learning; natural language processing; nomenclature; procedures; radiology information system; semantics; Spain; translating (language); Algorithms; Data Mining; Machine Learning; Natural Language Processing; Radiographic Image Interpretation, Computer-Assisted; Radiology Information Systems; Semantics; Spain; Terminology as Topic; Translating; Vocabulary, Controlled",Conference Paper,Scopus
"Ringler M.D., Goss B.C., Bartholmai B.J.","Syntactic and Semantic Errors in Radiology Reports Associated with Speech Recognition Software",2015,"Studies in Health Technology and Informatics",7,"10.3233/978-1-61499-564-7-922","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951986596&doi=10.3233%2f978-1-61499-564-7-922&partnerID=40&md5=8d4bc5a06a25766bcba0fe4fbbd73dc6","Speech recognition software (SRS) has many benefits, but also increases the frequency of errors in radiology reports, which could impact patient care. As part of a quality control project, 13 trained medical transcriptionists proofread 213,977 SRS-generated signed reports from 147 different radiologists over a 40 month time interval. Errors were classified as 'material' if they were believed to alter interpretation of the report. 'Immaterial' errors were subclassified as intrusion/omission or spelling errors. The proportion of errors and error type were compared among individual radiologists, imaging subspecialty, and time periods using.2 analysis and multiple logistic regression, as appropriate. 20,759 (9.7%) reports contained errors; 3,992 (1.9%) contained material errors. Among immaterial errors, spelling errors were more common than intrusion/omission errors (P<.001). Error proportion varied significantly among radiologists and between imaging subspecialties (P<.001). Errors were more common in cross-sectional reports (vs. plain radiography) (OR, 3.72), reports reinterpreting results of outside examinations (vs. in-house) (OR, 1.55), and procedural studies (vs. diagnostic) (OR, 1.91) (all P<.001). Dictation microphone upgrade did not affect error rate (P=.06). Error rate decreased over time (P<.001). © 2015 IMIA and IOS Press.","PowerScribe; quality control; radiology report; report errors; speech recognition","Bioinformatics; Diagnosis; Quality control; Radiation; Radiology; Semantics; Speech recognition; Frequency of error; Multiple logistic regression; Plain radiography; PowerScribe; Radiology reports; Semantic errors; Speech recognition softwares; Spelling errors; Errors; automatic speech recognition; human; procedures; radiography; radiology information system; semantics; standards; Humans; Radiography; Radiology Information Systems; Semantics; Speech Recognition Software",Conference Paper,Scopus
"Oliveira L., Tellis R., Qian Y., Trovato K., Mankovich G.","Follow-up Recommendation Detection on Radiology Reports with Incidental Pulmonary Nodules",2015,"Studies in Health Technology and Informatics",6,"10.3233/978-1-61499-564-7-1028","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951971582&doi=10.3233%2f978-1-61499-564-7-1028&partnerID=40&md5=76d0c1eaf8da109b9ca25036b1a9fec8","The management of follow-up recommendations is fundamental for the appropriate care of patients with incidental pulmonary findings. The lack of communication of these important findings can result in important actionable information being lost in healthcare provider electronic documents. This study aims to analyze follow-up recommendations in radiology reports containing pulmonary incidental findings by using Natural Language Processing and Regular Expressions. Our evaluation highlights the different follow-up recommendation rates for oncology and non-oncology patient cohorts. The results reveal the need for a context-sensitive approach to tracking different patient cohorts in an enterprise-wide assessment. © 2015 IMIA and IOS Press.","Follow-up Recommendation; Incidental Findings; Natural Language Processing; Patient Care; Radiology","Bioinformatics; Computer programming languages; Oncology; Radiation; Radiology; Word processing; Context sensitive; Electronic document; Follow up; Health care providers; Incidental findings; Patient care; Pulmonary nodules; Regular expressions; Natural language processing systems; abdominal radiography; classification; clinical decision support system; computer assisted diagnosis; controlled vocabulary; data mining; epidemiology; human; Illinois; incidental finding; machine learning; natural language processing; nomenclature; organization and management; patient referral; pilot study; procedures; radiology information system; reproducibility; sensitivity and specificity; statistics and numerical data; supply and distribution; Data Mining; Decision Support Systems, Clinical; Diagnosis, Computer-Assisted; Humans; Illinois; Incidental Findings; Machine Learning; Natural Language Processing; Pilot Projects; Radiography, Abdominal; Radiology Information Systems; Referral and Consultation; Reproducibility of Results; Sensitivity and Specificity; Terminology as Topic; Vocabulary, Controlled",Conference Paper,Scopus
"Oliveira L., Tellis R., Qian Y., Trovato K., Mankovich G.","Identification of Incidental Pulmonary Nodules in Free-text Radiology Reports: An Initial Investigation",2015,"Studies in Health Technology and Informatics",9,"10.3233/978-1-61499-564-7-1027","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951967014&doi=10.3233%2f978-1-61499-564-7-1027&partnerID=40&md5=db660884658d04f7e24df52655029e9b","Advances in image quality produced by computed tomography (CT) and the growth in the number of image studies currently performed has made the management of incidental pulmonary nodules (IPNs) a challenging task. This research aims to identify IPNs in radiology reports of chest and abdominal CT by Natural Language Processing techiniques to recognize IPN in sentences of radiology reports. Our preliminary analysis indicates vastly different pulmonary incidental findings rates for two different patient groups. © 2015 IMIA and IOS Press.","Algorithms; Incidental Findings; Natural Language Processing; Patient Care; Radiology","Algorithms; Bioinformatics; Natural language processing systems; Radiation; Radiology; Free texts; Image study; Incidental findings; Patient care; Preliminary analysis; Pulmonary nodules; Radiology reports; Computerized tomography; abdominal radiography; classification; clinical decision support system; computer assisted diagnosis; controlled vocabulary; data mining; epidemiology; human; Illinois; incidental finding; machine learning; natural language processing; nomenclature; organization and management; pilot study; procedures; radiology information system; reproducibility; sensitivity and specificity; statistics and numerical data; supply and distribution; Data Mining; Decision Support Systems, Clinical; Diagnosis, Computer-Assisted; Humans; Illinois; Incidental Findings; Machine Learning; Natural Language Processing; Pilot Projects; Radiography, Abdominal; Radiology Information Systems; Reproducibility of Results; Sensitivity and Specificity; Terminology as Topic; Vocabulary, Controlled",Conference Paper,Scopus
"Hong Y., Zhang J., Zhu Y., Zhou X.","A Statistical Analysis of Term Occurrences in Radiology Reporting",2015,"Studies in Health Technology and Informatics",,"10.3233/978-1-61499-564-7-1085","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951931250&doi=10.3233%2f978-1-61499-564-7-1085&partnerID=40&md5=cc727c9d2e1759b72382e20541ad0b5d","To compare term occurrences in free-text radiology reports and RSNA reporting templates, we selected five templates from an RSNA reporting template library and their corresponding free-text reports as a test set, and employed the Wilcoxon signed-rank test to find out whether the terms in RSNA reporting templates match those terms appearing in corresponding free-text radiology reports. The results show that most terms in free-text radiology reports are covered by RSNA reporting templates. By assessing the terminology coverage of existing templates, this study may benefit the growth of the RSNA reporting template library. © 2015 IMIA and IOS Press.","Radiology reports; Reporting templates; Term occurrences; Wilcoxon signed-rank test","Bioinformatics; Radiology; Free texts; Radiology reporting; Radiology reports; Reporting templates; Template libraries; Term occurrences; Test sets; Wilcoxon signed rank test; Radiation; nomenclature; radiology; statistical analysis; Wilcoxon signed ranks test; automated pattern recognition; classification; data mining; electronic medical record; hospital information system; natural language processing; nomenclature; North America; procedures; statistical analysis; statistics and numerical data; Data Interpretation, Statistical; Data Mining; Electronic Health Records; Natural Language Processing; North America; Pattern Recognition, Automated; Radiology Information Systems; Terminology as Topic",Conference Paper,Scopus
"Rafeh R., Ahmadi M.","A new approach for classifying radiology reports",2015,"Journal of Medical Imaging and Health Informatics",,"10.1166/jmihi.2015.1383","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921787122&doi=10.1166%2fjmihi.2015.1383&partnerID=40&md5=cda2391a192f1ca8f941e66b687b4a70","Usually, physicians need radiology reports to diagnose their patients' illness. Radiology reports are mostly stored as unstructured text from which information retrieval is difficult. As a consequence, interpreting unstructured radiology reports automatically needs sophisticated text mining algorithms. In this paper, we propose a new approach for structuring textual radiology reports. In the proposed approach radiology experts provide a set of patterns each of which consists of items with specific properties. Using the patterns as class labels, a radiology report is then classified based on the items found in its sentences. In the proposed approach, the given radiology report is first classified by a Naïve Bayes classifier to support uncertainty. Then, a Boolean classifier is applied to the report which uses exact matching to achieve high precision. Finally, a Case-Based Reasoning classifier is used to learn new patterns from the report if there is any. The experimental results show that the proposed approach can dynamically classify radiology reports with high precision. Copyright © 2015 American Scientific Publishers","Boolean classifier; Case-based reasoning classifier; Naïve bayes classifier; Radiology report","Article; artificial intelligence; Bayesian learning; classifier; decision making; diagnostic accuracy; human; radiologist; radiology; thorax radiography",Article,Scopus
"Baccei S.J., Hoimes M., Shin H., Karam A.R.","Reducing radiology report addenda using provisionally signed status",2015,"Journal of the American College of Radiology",2,"10.1016/j.jacr.2014.08.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84920380617&doi=10.1016%2fj.jacr.2014.08.012&partnerID=40&md5=337d0599a4d5017d41f6d23b6073bf70",[No abstract available],,"Article; automatic speech recognition; cardiology; clinical evaluation; comparative study; follow up; health care policy; human; image analysis; information system; interpersonal communication; mammography; nuclear magnetic resonance imaging; outcome assessment; patient care; patient compliance; postgraduate student; radiology; radiology department; total quality management; documentation; electronic medical record; hospital information system; information retrieval; medical record; procedures; radiology; statistics and numerical data; United States; workload; Documentation; Health Records, Personal; Information Storage and Retrieval; Massachusetts; Medical Records Systems, Computerized; Radiology; Radiology Information Systems; Workload",Article,Scopus
"Paats A., Alumäe T., Meister E., Fridolin I.","Evaluation of automatic speech recognition prototype for estonian language in radiology domain: A pilot study",2015,"IFMBE Proceedings",6,"10.1007/978-3-319-12967-9_26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84910668003&doi=10.1007%2f978-3-319-12967-9_26&partnerID=40&md5=cdbe5a256b4d4404672301ec9f0b684f","The aim of this study was to determine the dictation error rates in finalized radiology reports generated with a new automatic speech recognition (ASR) technology prototype for the Estonian language.For training a language model, 177 659 real radiology reports from different imaging modalities were used. Manually normalized versions of 1299 randomly selected reports were created to standardize the report corpus. The ASR prototype, incorporating the trained language and acoustic models, was tested in Radiology Department, North Estonia Medical Centre, Tallinn, Estonia, by 17 radiologists (11 female and 6 male). In total, 424 reports were dictated, including 77 067 x-ray, 30 929 ultrasound, 28 825 computed tomography, 14 815 mammography, 12 082 endoscopic, 8 792 magnetic resonance tomography, 3 950 radiology consultation and 1 199 angiographic reports. Word error rates (WER) and report error rates (RER) were calculated for each speaker and modality.Total WER over all material was 18.4% and total RER 93.1%. WER and RER were lowest for mammography dictations (7.7%; 70.3%), and highest for angiography (34.4%; 100%), followed by endoscopy (30.9%; 100%). 3D modalities had higher RER and WER compared to planar x-ray correlating with the complexity of the radiology reports. Live experiments with the ASR prototype showed differences between the users depending on their experience and speech characteristics.In summary, the ASR prototype for Estonian language in radiology domain was the first time successfully applied and assessed in routine clinical practice. Improvements of the ASR prototype performance are planned in the future. © Springer International Publishing Switzerland 2015.","Automatic speech recognition; Estonian language; Radiology; Reporting; Word error rate","Biomedical engineering; Computational linguistics; Computerized tomography; Diagnostic radiography; Endoscopy; Magnetic resonance; Radiation; Radiology; Tomography; Automatic speech recognition; Clinical practices; Estonian language; Magnetic resonance tomography; Radiology departments; Radiology reports; Reporting; Word error rate; Speech recognition",Conference Paper,Scopus
"Weiss D.L., Kim W., Branstetter B.F., IV, Prevedello L.M.","Radiology reporting: A closed-loop cycle from order entry to results communication",2014,"Journal of the American College of Radiology",16,"10.1016/j.jacr.2014.09.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928096661&doi=10.1016%2fj.jacr.2014.09.009&partnerID=40&md5=3a713fc1019888230f496eaca73477a9","With the increasing prevalence of PACS over the past decade, face-to-face image review among health care providers has become a rarity. This change has resulted in increasing dependence on fast and accurate communication in radiology. Turnaround time expectations are now conveyed in minutes rather than hours or even days. Ideal modern radiology communication is a closed-loop cycle with multiple interoperable applications contributing to the final product. The cycle starts with physician order entry, now often performed through the electronic medical record, with clinical decision support to ensure that the most effective imaging study is ordered. Radiology reports are now almost all in electronic format. The majority are produced using speech recognition systems. Optimization of this software use can alleviate some, if not all, of the inherent user inefficiencies in this type of reporting. Integrated third-party software applications that provide data mining capability are extremely helpful in both academic and clinical settings. The closed-loop ends with automated communication of imaging results. Software products for this purpose should facilitate use of levels of alert, automated escalation to providers, and recording of audit trails of reports received. The multiple components of reporting should be completely interoperable with each other, as well as with the PACS, the RIS, and the electronic medical record. This integration will maximize radiologist efficiency and minimize the possibility of communication error. © 2014 Published by Elsevier on behalf of American College of Radiology.","computerized physician order entry (CPOE); data mining; decision support; Reporting; results communication; speech recognition","accuracy; Article; automatic speech recognition; automation; computer interface; computer program; computerized provider order entry; data mining; decision support system; electronic medical record; expectation; health care personnel; hospital information system; human; intermethod comparison; interpersonal communication; medical audit; medical error; microphone; natural language processing; picture archiving and communication system; problem solving; speech discrimination; turnaround time; documentation; information dissemination; meaningful use criteria; nonbiological model; organization and management; procedures; United States; workflow; Documentation; Efficiency, Organizational; Electronic Health Records; Information Dissemination; Meaningful Use; Medical Order Entry Systems; Models, Organizational; Radiology Information Systems; United States; Workflow",Article,Scopus
"Midgley S.M.","Capture and analysis of radiation dose reports for radiology",2014,"Australasian Physical and Engineering Sciences in Medicine",6,"10.1007/s13246-014-0304-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921028269&doi=10.1007%2fs13246-014-0304-7&partnerID=40&md5=b6e9d36104d746e156173ef7b1673382","Radiographic imaging systems can produce records of exposure and dose parameters for each patient. A variety of file formats are in use including plain text, bit map images showing pictures of written text and radiation dose structured reports as text or extended markup language files. Whilst some of this information is available with image data on the hospital picture archive and communication system, access is restricted to individual patient records, thereby making it difficult to locate multiple records for the same scan protocol. This study considers the exposure records and dose reports from four modalities. Exposure records for mammography and general radiography are utilized for repeat analysis. Dose reports for fluoroscopy and computed tomography (CT) are utilized to study the distribution of patient doses for each protocol. Results for dosimetric quantities measured by General Radiography, Fluoroscopy and CT equipment are summarised and presented in the Appendix. Projection imaging uses the dose (in air) area product and derived quantities including the dose to the reference point as a measure of the air kerma reaching the skin, ignoring movement of the beam for fluoroscopy. CT uses the dose indices CTDIvol and dose length product as a measure of the dose per axial slice, and to the scanned volume. Suitable conversion factors are identified and used to estimate the effective dose to an average size patient (for CT and fluoroscopy) and the entrance skin dose for fluoroscopy. © 2014, Australasian College of Physical Scientists and Engineers in Medicine.","CT dose indices; Diagnostic reference levels; Fluoroscopy entrance skin dose; Radiology dose reports; Radiology effective dose; Radiology exposure records; Reject analysis","Diagnostic radiography; Dosimetry; Fluorescent screens; Markup languages; Radiation; Radiology; Diagnostic reference levels; Dose-length products; Effective dose; Picture archive and communication systems; Radiographic imaging; Reject analysis; Skin dose; Structured reports; Computerized tomography; Article; computer assisted tomography; fluoroscopy; human; major clinical study; mammography; priority journal; radiation dose; radiation exposure; radiation response; radiography; radiology; comparative study; data base; factual database; hospital information system; image quality; information retrieval; organization and management; procedures; radiometry; Database Management Systems; Databases, Factual; Humans; Information Storage and Retrieval; Radiation Dosage; Radiographic Image Enhancement; Radiology Information Systems; Radiometry",Article,Scopus
"Sloan C.E., Chadalavada S.C., Cook T.S., Langlotz C.P., Schnall M.D., Zafar H.M.","Assessment of follow-up completeness and notification preferences for imaging findings of possible cancer: What happens after radiologists submit their reports?",2014,"Academic Radiology",26,"10.1016/j.acra.2014.07.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908539479&doi=10.1016%2fj.acra.2014.07.006&partnerID=40&md5=70bdee22365aaf178177949a3dc72cd0","Rationale and Objectives: To understand the reasons leading to potentially inappropriate management of imaging findings concerning for malignancy and identify optimal methods for communicating these findings to providers. Materials and Methods: We identified all abdominal imaging examinations with findings of possible cancer performed on six randomly selected days in August to December 2013. Electronic medical records (EMR) of one patient group were reviewed 3 months after the index examination to determine whether management was appropriate (completed follow-up or documented reason for no follow-up) or potentially inappropriate (no follow-up or no documented reason). Providers of a second patient group were contacted 5-6days after imaging examinations to determine notification preferences. Results: Among 43 patients in the first group, five (12%) received potentially inappropriate management. Reasons included patient loss to follow-up and provider failure to review imaging results, document known imaging findings, or communicate findings to providers outside the health system. Among 16 providers caring for patients in the second group, 33% were unaware of the findings, 75% preferred to be notified of abnormal findings via e-mail or EMR, 56% wanted an embedded hyperlink enabling immediate follow-up order entry, and only 25% had a system to monitor whether patients had completed ordered testing. Conclusions: One in eight patients did not receive potentially necessary follow-up care within 3 months of imaging findings of possible cancer. Automated notification of imaging findings and follow-up monitoring not only is desired by providers but can also address many of the reasons we found for inappropriate management. © 2014 AUR.","Communication; Continuity of patient care; Follow-up; Physician practice patterns","antineoplastic agent; abdominal radiography; adrenal cancer; adult; aged; Article; cancer chemotherapy; cancer diagnosis; cancer patient; cancer surgery; clinical article; diagnostic imaging; e-mail; electronic medical record; female; follow up; health care; human; interpersonal communication; kidney cancer; liver cancer; male; neoplasm; pancreas cancer; patient care; patient monitoring; pilot study; tumor biopsy; clinical practice; diagnostic imaging; interdisciplinary communication; Neoplasms; patient care; standards; Continuity of Patient Care; Diagnostic Imaging; Humans; Interdisciplinary Communication; Medical Records Systems, Computerized; Neoplasms; Physician's Practice Patterns",Article,Scopus
"Zhou Y., Amundson P.K., Yu F., Kessler M.M., Benzinger T.L.S., Wippold F.J.","Automated Classification of Radiology Reports to Facilitate Retrospective Study in Radiology",2014,"Journal of Digital Imaging",15,"10.1007/s10278-014-9708-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84911970862&doi=10.1007%2fs10278-014-9708-x&partnerID=40&md5=2dd44bc8a79cdac5e28753d4c742cbe1","Retrospective research is an import tool in radiology. Identifying imaging examinations appropriate for a given research question from the unstructured radiology reports is extremely useful, but labor-intensive. Using the machine learning text-mining methods implemented in LingPipe [1], we evaluated the performance of the dynamic language model (DLM) and the Naïve Bayesian (NB) classifiers in classifying radiology reports to facilitate identification of radiological examinations for research projects. The training dataset consisted of 14,325 sentences from 11,432 radiology reports randomly selected from a database of 5,104,594 reports in all disciplines of radiology. The training sentences were categorized manually into six categories (Positive, Differential, Post Treatment, Negative, Normal, and History). A 10-fold cross-validation [2] was used to evaluate the performance of the models, which were tested in classification of radiology reports for cases of sellar or suprasellar masses and colloid cysts. The average accuracies for the DLM and NB classifiers were 88.5 % with 95 % confidence interval (CI) of 1.9 % and 85.9 % with 95 % CI of 2.0 %, respectively. The DLM performed slightly better and was used to classify 1,397 radiology reports containing the keywords “sellar or suprasellar mass”, or “colloid cyst”. The DLM model produced an accuracy of 88.2 % with 95 % CI of 2.1 % for 959 reports that contain “sellar or suprasellar mass” and an accuracy of 86.3 % with 95 % CI of 2.5 % for 437 reports of “colloid cyst”. We conclude that automated classification of radiology reports using machine learning techniques can effectively facilitate the identification of cases suitable for retrospective research. © 2014, Society for Imaging Informatics in Medicine.","Computer analysis; Machine learning; Natural language processing; Radiology Information Systems (RIS); Radiology report classification; Radiology reporting; Retrospective studies","Classification (of information); Lagrange multipliers; Learning systems; Machine learning; Natural language processing systems; Radiation; Sodium compounds; Text mining; Computer analysis; NAtural language processing; Radiology information system; Radiology reporting; Radiology reports; Retrospective studies; Radiology; classification; factual database; hospital information system; human; information processing; natural language processing; radiology; reproducibility; research; retrospective study; sensitivity and specificity; standards; Databases, Factual; Datasets as Topic; Humans; Natural Language Processing; Radiology; Radiology Information Systems; Reproducibility of Results; Research Report; Retrospective Studies; Sensitivity and Specificity",Article,Scopus
"Bosmans J.M.L., Schrans D., Avonts D., De Maeseneer J.M.","Communication between general practitioners and radiologists: Opinions, experience, promises, pitfalls",2014,"JBR-BTR",6,"10.5334/jbr-btr.127","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928699871&doi=10.5334%2fjbr-btr.127&partnerID=40&md5=8987442f492abdd8acc3ece1ab04fc12","Purpose: Studies encompassing the views and aspirations of general practitioners (GPs) concerning the radiology report are rare. We present the results of a large-scale survey among GPs in Flanders, Belgium, and examine its implications for the communication between radiologists and GPs. Materials and methods: GPs were invited by e-mail to participate in a survey on the radiology report. Respondents could state their degree of agreement with 46 statements. Besides that, they could freely make suggestions to improve the report. Quantitative results were examined to determine majority convictions. Free text suggestions were searched for motives and convictions. Results: Of 1323 GPs invited, 282 completed forms were prepared for analysis. 96.8% considered the report an indispensable tool. 85.5% were satisfied with it. Itemized reporting of complex examinations was favoured by a very large majority. 83 GPs (29.4%) made suggestions for improvement. Much emphasis was put upon the clinical role of the radiologist. The need to mark key images, to mention meaningful normal findings, to structure the report and to facilitate communication was also frequently mentioned. Conclusion: GPs expect the radiologist to think as a clinician and offer clinical answers. An automated electronic information chain may contribute to realize this objective but direct communication should always remain possible.","Radiology and radiologists","adult; aged; Article; Belgium; clinical practice; e-mail; female; general practitioner; human; interpersonal communication; male; priority journal; quantitative analysis; questionnaire; radiologist; interpersonal communication; middle aged; radiology; Adult; Aged; Communication; Female; General Practitioners; Humans; Male; Middle Aged; Radiology",Article,Scopus
"Hawkins C.M., Hall S., Zhang B., Towbin A.J.","Creation and Implementation of Department-Wide Structured Reports: An Analysis of the Impact on Error Rate in Radiology Reports",2014,"Journal of Digital Imaging",51,"10.1007/s10278-014-9699-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925839987&doi=10.1007%2fs10278-014-9699-7&partnerID=40&md5=0668063bd054ffb983e0cc7f63237cc2","The purpose of this study was to evaluate and compare textual error rates and subtypes in radiology reports before and after implementation of department-wide structured reports. Randomly selected radiology reports that were generated following the implementation of department-wide structured reports were evaluated for textual errors by two radiologists. For each report, the text was compared to the corresponding audio file. Errors in each report were tabulated and classified. Error rates were compared to results from a prior study performed prior to implementation of structured reports. Calculated error rates included the average number of errors per report, average number of nongrammatical errors per report, the percentage of reports with an error, and the percentage of reports with a nongrammatical error. Identical versions of voice-recognition software were used for both studies. A total of 644 radiology reports were randomly evaluated as part of this study. There was a statistically significant reduction in the percentage of reports with nongrammatical errors (33 to 26 %; p = 0.024). The likelihood of at least one missense omission error (omission errors that changed the meaning of a phrase or sentence) occurring in a report was significantly reduced from 3.5 to 1.2 % (p = 0.0175). A statistically significant reduction in the likelihood of at least one comission error (retained statements from a standardized report that contradict the dictated findings or impression) occurring in a report was also observed (3.9 to 0.8 %; p = 0.0007). Carefully constructed structured reports can help to reduce certain error types in radiology reports. © 2014, Society for Imaging Informatics in Medicine.","Errors; Radiology; Structured reports","Radiation; Radiology; Audio files; Average numbers; Error rate; Error types; Omission errors; Radiology reports; Structured reports; Voice recognition software; Errors; automatic speech recognition; electronic medical record; hospital information system; human; organization and management; procedures; radiology; radiology department; reproducibility; standards; Humans; Medical Records Systems, Computerized; Radiology; Radiology Department, Hospital; Radiology Information Systems; Reproducibility of Results; Speech Recognition Software",Article,Scopus
"Maehara C.K., Silverman S.G., Lacson R., Khorasani R.","Renal masses detected at abdominal CT: Radiologists' adherence to guidelines regarding management recommendations and communication of critical results",2014,"American Journal of Roentgenology",12,"10.2214/AJR.13.11497","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84910143860&doi=10.2214%2fAJR.13.11497&partnerID=40&md5=b0aefce9d9904f6605787b4d532c0aaf","OBJECTIVE. The purpose of this study was to assess radiologists' adherence to published guidelines for managing renal masses detected at abdominal CT at one institution and to a critical results communication policy. MATERIALS AND METHODS. A validated natural language processing tool supplemented by manual review was used to randomly assemble a cohort of 97 radiology reports from all abdominal CT reports (n = 11,952) generated from July 2010 to June 2011. Critical renal mass findings warranted consideration for surgery, intervention, or imaging follow-up and required direct, separate, and timely communication to the referrer in addition to the radiology report. Primary outcomes were adherence to guidelines and institutional policy for communicating critical results. Sample size allowed a 95% CI ± 5% for primary outcome. Pearson chi-square test was performed to assess whether radiology subspecialization was predictive of the primary outcome. RESULTS. Of all abdominal CT reports, 35.6% contained at least one renal mass finding (4.3% critical). Guideline adherence was lower for patients with critical than for those with noncritical findings (48/57 [84.2%] vs 40/40 [100%]; p = 0.01). Adherence to critical result communication policy was 73.7% (42/57). For critical findings, abdominal radiologists had higher guideline adherence (40/43 [93.0%] vs 8/14 [57.1%]; p = 0.001) and critical result communication policy adherence (36/43 [83.7%] vs 6/14 [42.9%]; p = 0.002) than non-abdominal radiologists. CONCLUSION. In reporting renal masses detected at abdominal CT, radiologists largely adhered to management guidelines but did not adhere to the critical results communication policy in one of four reports. Subspecialization improved adherence to both management guidelines and the institution's critical result communication policy. © American Roentgen Ray Society.","Abdominal Ct; American Urological Association guidelines; Critical test results; Evidence-based practice; Renal cyst; Renal mass","abdominal radiologist; Article; cancer diagnosis; cohort analysis; computer assisted tomography; controlled study; human; kidney tumor; major clinical study; policy; practice guideline; priority journal; protocol compliance; radiologist; tertiary health care; abdominal CT; abdominal radiography; adult; aged; American Urological Association guidelines; article; critical test results; documentation; electronic medical record; evidence based practice; female; kidney cyst; kidney tumor; male; middle aged; radiography; radiology; reproducibility; sensitivity and specificity; standard; statistics; United States; very elderly; young adult; abdominal CT; American Urological Association guidelines; critical test results; evidence-based practice; renal cyst; renal mass; Adult; Aged; Aged, 80 and over; Boston; Documentation; Electronic Health Records; Female; Guideline Adherence; Humans; Kidney Neoplasms; Male; Middle Aged; Practice Guidelines as Topic; Radiography, Abdominal; Radiology; Reproducibility of Results; Sensitivity and Specificity; Tomography, X-Ray Computed; Young Adult",Article,Scopus
"Pham A.-D., Névéol A., Lavergne T., Yasunaga D., Clément O., Meyer G., Morello R., Burgun A.","Natural language processing of radiology reports for the detection of thromboembolic diseases and clinically relevant incidental findings",2014,"BMC Bioinformatics",64,"10.1186/1471-2105-15-266","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905971052&doi=10.1186%2f1471-2105-15-266&partnerID=40&md5=7bf6d5ba420a4fc58091b1735131b6d3","Background: Natural Language Processing (NLP) has been shown effective to analyze the content of radiology reports and identify diagnosis or patient characteristics. We evaluate the combination of NLP and machine learning to detect thromboembolic disease diagnosis and incidental clinically relevant findings from angiography and venography reports written in French. We model thromboembolic diagnosis and incidental findings as a set of concepts, modalities and relations between concepts that can be used as features by a supervised machine learning algorithm. A corpus of 573 radiology reports was de-identified and manually annotated with the support of NLP tools by a physician for relevant concepts, modalities and relations. A machine learning classifier was trained on the dataset interpreted by a physician for diagnosis of deep-vein thrombosis, pulmonary embolism and clinically relevant incidental findings. Decision models accounted for the imbalanced nature of the data and exploited the structure of the reports. Results: The best model achieved an F measure of 0.98 for pulmonary embolism identification, 1.00 for deep vein thrombosis, and 0.80 for incidental clinically relevant findings. The use of concepts, modalities and relations improved performances in all cases. Conclusions: This study demonstrates the benefits of developing an automated method to identify medical concepts, modality and relations from radiology reports in French. An end-to-end automatic system for annotation and classification which could be applied to other radiology reports databases would be valuable for epidemiological surveillance, performance monitoring, and accreditation in French hospitals. © 2014 Pham et al.; licensee BioMed Central Ltd.","Embolism and thrombosis/diagnosis; Human; Incidental findings; Medical informatics; Natural language processing; Phlebography","Angiography; Artificial intelligence; Blood vessels; Classification (of information); Diseases; Learning algorithms; Radiation; Radiology; Supervised learning; Embolism and thrombosis/diagnosis; Human; Incidental findings; Medical informatics; Phlebography; Natural language processing systems; algorithm; article; biology; computer assisted tomography; human; incidental finding; lung embolism; methodology; natural language processing; radiography; radiology; research; Algorithms; Computational Biology; Humans; Incidental Findings; Natural Language Processing; Pulmonary Embolism; Radiology; Research Report; Tomography, X-Ray Computed",Article,Scopus
"Powell D.K., Lin E., Silberzweig J.E., Kagetsu N.J.","Introducing radiology report checklists among residents: Adherence rates when suggesting versus requiring their use and early experience in improving accuracy",2014,"Academic Radiology",11,"10.1016/j.acra.2013.12.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893461614&doi=10.1016%2fj.acra.2013.12.004&partnerID=40&md5=64925670f0db11521903a843f4fb7f7c","Rationale and Objectives: To retrospectively compare resident adherence to checklist-style structured reporting for maxillofacial computed tomography (CT) from the emergency department (when required vs. suggested between two programs). To compare radiology resident reporting accuracy before and after introduction of the structured report and assess its ability to decrease the rate of undetected pathology. Materials and Methods: We introduced a reporting checklist for maxillofacial CT into our dictation software without specific training, requiring it at one program and suggesting it at another. We quantified usage among residents and compared reporting accuracy, before and after counting and categorizing faculty addenda. Results: There was no significant change in resident accuracy in the first few months, with residents acting as their own controls (directly comparing performance with and without the checklist). Adherence to the checklist at program A (where it originated and was required) was 85% of reports compared to 9% of reports at program B (where it was suggested). When using program B as a secondary control, there was no significant difference in resident accuracy with or without using the checklist (comparing different residents using the checklist to those not using the checklist). Conclusions: Our results suggest that there is no automatic value of checklists for improving radiology resident reporting accuracy. They also suggest the importance of focused training, checklist flexibility, and a period of adjustment to a new reporting style. Mandatory checklists were readily adopted by residents but not when simply suggested. © 2014 AUR.","Checklists; Quality improvement; Radiology reporting; Resident accuracy; Resident education; Safety; Structured reporting","article; checklist; computer assisted tomography; human; incidental finding; maxilla; maxillofacial disorder; patient safety; practice guideline; priority journal; protocol compliance; residency education; resident; checklists; quality improvement; radiology reporting; resident accuracy; resident education; safety; Structured reporting; Checklist; Clinical Competence; Documentation; Guideline Adherence; Humans; Internship and Residency; Maxillofacial Injuries; New York; Observer Variation; Radiology; Reproducibility of Results; Sensitivity and Specificity",Article,Scopus
"Markonis D., Donner R., Holzer M., Schlegl T., Dungs S., Kriewel S., Langs G., Müller H.","A visual information retrieval system for radiology reports and the medical literature",2014,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",2,"10.1007/978-3-319-04117-9_43","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893487688&doi=10.1007%2f978-3-319-04117-9_43&partnerID=40&md5=5e345131b26ce19abd85e5638f52442f","The enormous amount of visual data in Picture Archival and Communication Systems (PACS) and in the medical literature is growing exponentially. In the proposed demo, the medical image search of the KHRESMOI project is presented to solve some of the challenges of medical data management and retrieval. The system allows searching for visual information by combining content-based image retrieval (CBIR) and text retrieval in several languages using semantic concepts. 3D visual retrieval in internal hospital sources is supported by marking volumes of interest (VOI) in the data and connection to the medical literature are established to allow further investigating interesting cases. The system is demonstrated on 5TB of radiology reports with associated images and articles of the biomedical literature with over 1.7M images. © 2014 Springer International Publishing.",,"Biomedical literature; Content-Based Image Retrieval; Medical data management; Medical literatures; Picture archival and communication systems; Visual information; Visual information retrieval; Volumes of interests; Content based retrieval; Information management; Medical applications; Radiation; Radiology; Semantics; Search engines",Conference Paper,Scopus
"Mabotuwana T., Qian Y., Sevenster M.","A Context-Sensitive Image Annotation Recommendation Engine for Radiology",2014,"Studies in Health Technology and Informatics",,"10.3233/978-1-61499-432-9-1143","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929505730&doi=10.3233%2f978-1-61499-432-9-1143&partnerID=40&md5=f7d74123767415bafb19605e39a17384","In the typical radiology reading workflow, a radiologist would go through an imaging study and annotate specific regions of interest. The radiologist has the option to select a suitable description (e.g., 'calcification') from a list of predefined descriptions, or input the description directly as free-text. However, this process is time-consuming and the descriptions are not standardized over time, even for the same patient or the same general finding. In this paper, we describe an approach that presents finding descriptions based on textual information extracted from a patient's prior reports. Using 133 finding descriptions obtained in routine oncology workflow, we demonstrate how the system can be used to reduce keystrokes by up to 86% in about 38% of the instances. We have integrated our solution into a PACS and discuss how the system can be used in a clinical setting to improve the image annotation workflow efficiency and promote standardization of finding descriptions. © 2014 European Federation for Medical Informatics and IOS Press.","autocompletion; context-driven autocompletion; image markup; Natural language processing; pacs radiology; radiology finding descriptions; radiology information system; typing assistant","Biomineralization; Image analysis; Image enhancement; Medical applications; Natural language processing systems; Radiation; Radiology; autocompletion; context-driven autocompletion; image markup; Radiology information system; typing assistant; Image annotation; human; oncology; standardization; workflow; artificial intelligence; automation; computer assisted diagnosis; computer interface; computer program; controlled vocabulary; documentation; hospital information system; natural language processing; procedures; writing; Artificial Intelligence; Documentation; Image Interpretation, Computer-Assisted; Natural Language Processing; Radiology Information Systems; Software; User-Computer Interface; Vocabulary, Controlled; Word Processing; Writing",Conference Paper,Scopus
"Sonntag D., Zillner S., Ernst P., Schulz C., Sintek M., Dankerl P.","Mobile Radiology Interaction and Decision Support Systems of the Future",2014,"Cognitive Technologies",2,"10.1007/978-3-319-06755-1_28","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907333447&doi=10.1007%2f978-3-319-06755-1_28&partnerID=40&md5=5d5e900b6a3a6f517578c660d2988bc3","Clinical care and research increasingly rely on digitized patient information. There is a growing need to store and organize all patient data, including health records, laboratory reports, and medical images. Medical images have become indispensable for detecting and differentiating pathologies, planning interventions, and monitoring treatments. The effective retrieval of images builds on the semantic annotation of image contents and intelligent interaction with the image material. The semantic annotation of image contents has an automatic and a manual component. In our work, we heavily rely on automatic organ, tissue, and disease detection, which represents one of the main technical research questions in Medico. In this article, however, we will focus on intelligent interaction with the image material, i.e., what mobile radiology interaction and decision support systems of the future, based on automatic detectors, may look like. © Springer International Publishing Switzerland 2014.",,"Decision support systems; Hospital data processing; Radiation; Radiology; Semantics; Automatic detector; Digitized patients; Disease detection; Health records; Image materials; Intelligent interactions; Semantic annotations; Technical research; Artificial intelligence",Article,Scopus
"Kvist M., Velupillai S.","SCAN: A Swedish clinical abbreviation normalizer - Further development and adaptation to radiology",2014,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",6,"10.1007/978-3-319-11382-1_7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906776807&doi=10.1007%2f978-3-319-11382-1_7&partnerID=40&md5=23416ddd27679dc75c2153d0d1e54c53","Abbreviations pose a challenge for information extraction systems. In clinical text, abbreviations are abundant, as this type of documentation is written under time-pressure. We report work on characterizing abbreviations in Swedish clinical text and the development of SCAN: a Swedish Clinical Abbreviation Normalizer, which is built for the purpose of improving information access systems in the clinical domain. The clinical domain includes several subdomains with differing vocabularies depending on the nature of the specialist work, and adaption of NLP-tools may consequently be necessary. We extend and adapt SCAN, and evaluate on two different clinical subdomains: emergency department (ED) and radiology (X-ray). Overall final results are 85% (ED) and 83% (X-ray) F1-measure on the task of abbreviation identification. We also evaluate coverage of abbreviation expansion candidates in existing lexical resources, and create two new, freely available, lexicons with abbreviations and their possible expansions for the two clinical subdomains. © 2014 Springer International Publishing.",,"Information retrieval systems; Radiology; Abbreviation expansion; Emergency departments; Information access systems; Information extraction systems; Lexical resources; Sub-domains; Swedishs; Radiation",Conference Paper,Scopus
"Nguyen D.H.M., Patrick J.D.","Supervised machine learning and active learning in classification of radiology reports",2014,"Journal of the American Medical Informatics Association",40,"10.1136/amiajnl-2013-002516","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906313707&doi=10.1136%2famiajnl-2013-002516&partnerID=40&md5=d8096dfbd1c73def0c0b8da9d5dc4d5c","Objective: This paper presents an automated system for classifying the results of imaging examinations (CT, MRI, positron emission tomography) into reportable and non-reportable cancer cases. This system is part of an industrial-strength processing pipeline built to extract content from radiology reports for use in the Victorian Cancer Registry. Materials and methods: In addition to traditional supervised learning methods such as conditional random fields and support vector machines, active learning (AL) approaches were investigated to optimize training production and further improve classification performance. The project involved two pilot sites in Victoria, Australia (Lake Imaging (Ballarat) and Peter MacCallum Cancer Centre (Melbourne)) and, in collaboration with the NSW Central Registry, one pilot site at Westmead Hospital (Sydney). Results: The reportability classifier performance achieved 98.25% sensitivity and 96.14% specificity on the cancer registry's held-out test set. Up to 92% of training data needed for supervised machine learning can be saved by AL. Discussion: AL is a promising method for optimizing the supervised training production used in classification of radiology reports. When an AL strategy is applied during the data selection process, the cost of manual classification can be reduced significantly. Conclusions: The most important practical application of the reportability classifier is that it can dramatically reduce human effort in identifying relevant reports from the large imaging pool for further investigation of cancer. The classifier is built on a large real-world dataset and can achieve high performance in filtering relevant reports to support cancer registries.",,"article; cancer registry; classification; computer assisted tomography; human; machine learning; nuclear magnetic resonance imaging; positron emission tomography; radiology; radiology report; sensitivity and specificity; support vector machine; active learning; Classification; machine learning; Radiology Information Systems; Algorithms; Artificial Intelligence; Diagnostic Imaging; Humans; Magnetic Resonance Imaging; Neoplasms; Positron-Emission Tomography; Radiology Information Systems; Sensitivity and Specificity; Support Vector Machines; Tomography, X-Ray Computed; Vocabulary, Controlled",Article,Scopus
"Haider J., Hölzl K., Toth H., Duftschmid G.","Generation of ELGA-compatible radiology reports from the vienna hospital association's EHR system",2014,"Studies in Health Technology and Informatics",1,"10.3233/978-1-61499-397-1-226","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903710485&doi=10.3233%2f978-1-61499-397-1-226&partnerID=40&md5=92170998cf285329008fc130ad5f9408","In the course of setting up the upcoming Austrian national shared EHR system ELGA, adaptors will have to be implemented for the local EHR systems of all participating healthcare providers. These adaptors must be able to transform EHR data from the internal format of the particular local EHR system to the specified format of the ELGA document types and vice versa. In the course of an ongoing diploma thesis we are currently developing a transformation application that shall allow the generation of ELGA-compatible radiology reports from the local EHR system of the Vienna Hospital Association. Up to now a first prototype has been developed that was tested with six radiology reports. It generates technically valid ELGA radiology reports apart from two errors yielded by the ELGA online validator that rather seem to be bugs of the validator. A medical validation of the reports remains to be done. © 2014 The authors and IOS Press.","Electronic Health Records; Medical Informatics; Radiology Information Systems","Curricula; Hospitals; Radiation; Radiology; EHR systems; Electronic health record; Health care providers; Medical informatics; Radiology information system; Radiology reports; Medical information systems; Austria; controlled vocabulary; electronic medical record; hospital information system; hospital management; information retrieval; medical record; natural language processing; organization and management; procedures; public health; system analysis; Austria; Electronic Health Records; Hospital Administration; Information Storage and Retrieval; Medical Record Linkage; National Health Programs; Natural Language Processing; Radiology Information Systems; Systems Integration; Vocabulary, Controlled",Conference Paper,Scopus
"Travis A.R., Sevenster M., Ganesh R., Peters J.F., Chang P.J.","Preferences for Structured Reporting of Measurement Data. An Institutional Survey of Medical Oncologists, Oncology Registrars, and Radiologists",2014,"Academic Radiology",38,"10.1016/j.acra.2014.02.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899789167&doi=10.1016%2fj.acra.2014.02.008&partnerID=40&md5=9c6ae622b3f337969ce7b3533206e80c","Rationale and Objectives: The aim of this study was to determine whether key radiology report ""consumers"" in our institution prefer structured measurement reporting in a dedicated report section over the current practice of embedding measurements throughout the ""Findings"" section, given the availability of new tools for quantitative imaging interpretation that enable automated structured reporting of measurement data. Materials and Methods: Oncologic clinicians and radiologists at our institution were surveyed regarding their preferences for a standard report versus three reports each having uniquely formatted dedicated ""Measurements"" sections and regarding their impressions of various characteristics of report quality demonstrated by these reports. The online survey was completed by 25 radiologists, 16 oncologists, and 17 oncology nurses and research assistants (registrars). Results: Aggregation of respondents' preferences by group into single orderings using the Kemeny-Young method revealed that both oncology groups preferred all proposed reports to the standard report but that radiologists only preferred two of the proposed reports to the standard report. All preferences for proposed reports in the two oncology groups were statistically significant based on Wilcoxon tests, but the preference for only one of the proposed reports was significant for radiologists. Additional results suggest that these preferences are driven by respondent favor for the readability of and confidence conveyed by the proposed reports compared to the standard report. Conclusions: Oncologic clinicians responding to our survey preferred communication of lesion measurements in a separate report section to the current practice of embedding measurements throughout the ""Findings"" section, based on their assessments of reports containing simulated measurement sections assembled from a single sample report using standardized formatting. © 2014 AUR.","AIM; Annotation and Image Markup; Quantitative imaging; RECIST; Structured reporting","article; computer interface; data processing; health care survey; human; medical oncologist; nurse; priority journal; professional standard; quantitative analysis; radiologist; structured reporting of measurement data; health personnel attitude; information dissemination; interdisciplinary communication; medical staff; nonparametric test; oncology; procedures; questionnaire; radiology; radiology department; radiology information system; statistics and numerical data; Attitude of Health Personnel; Humans; Information Dissemination; Interdisciplinary Communication; Medical Oncology; Medical Staff, Hospital; Radiology; Radiology Department, Hospital; Radiology Information Systems; Statistics, Nonparametric; Surveys and Questionnaires",Article,Scopus
"Prevedello L.M., Ledbetter S., Farkas C., Khorasani R.","Implementation of speech recognition in a community-based radiology practice: Effect on report turnaround times",2014,"Journal of the American College of Radiology",19,"10.1016/j.jacr.2013.07.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84898596990&doi=10.1016%2fj.jacr.2013.07.008&partnerID=40&md5=b45a1f75b44f4a4665f2efb9b5286d7a","Purpose Large academic practices have reported important benefits with the implementation of speech recognition software (SRS). However, the applicability of these results has been questioned in the community hospital setting because of major differences in workflow. The aim of this study was to evaluate the impact of SRS on radiology report turnaround times (TATs) at a community-based hospital practice with no radiology training program. The secondary goal was to evaluate the impact of SRS on radiologist productivity. Methods SRS was implemented at a 150-bed community hospital between May 2011 and July 2011. Radiology report TATs and normalized radiologist productivity were determined during 5 months before and after SRS implementation. Median and 80th and 95th percentile report TATs were compared between the preimplementation and postimplementation periods. The trend in productivity was also assessed. Results Median and 80th and 95th percentile report TATs decreased multiple-fold between the preimplementation and postimplementation periods (median, from 24 to 1 hour; 80th percentile, from 60 to 10 hours; 95th percentile, from 165 to 33 hours; P <.0001). No significant trend in report TATs was appreciated beyond the initial implementation of the software, a sustained effect on TATs. Normalized radiologist productivity was stable throughout the study period. Conclusions The implementation of SRS was associated with 24-fold improvement in the median radiology report TAT in a community hospital setting with no radiology trainees. Improvements were obtained without affecting normalized radiologist productivity. © 2014 American College of Radiology.","community hospital; report turnaround time; Speech recognition","article; automatic speech recognition; community care; community hospital; controlled study; diagnostic imaging; health care planning; human; medical education; medical practice; normal human; productivity; radiologist; radiology; speech discrimination; total quality management; turnaround time; automatic speech recognition; community care; electronic medical record; hospital information system; medical record; organization and management; radiology; statistics and numerical data; United States; writing; Boston; Community Networks; Efficiency, Organizational; Health Records, Personal; Medical Records Systems, Computerized; Radiology; Radiology Information Systems; Speech Recognition Software; Writing",Article,Scopus
"Hawkins C.M., Anton C.G., Bankes W.M., Leach A.D., Zeno M.J., Pryor R.M., Larson D.B.","Improving the availability of clinical history accompanying radiographic examinations in a large pediatric radiology department",2014,"American Journal of Roentgenology",25,"10.2214/AJR.13.11273","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84896970796&doi=10.2214%2fAJR.13.11273&partnerID=40&md5=de179fdf72711c538eb4a910b6556af4","OBJECTIVE. The purpose of this quality improvement initiative was to improve the consistency with which radiologists are provided a complete clinical history when interpreting radiography examinations performed in the outpatient and emergency department settings. MATERIALS AND METHODS. The clinical history was considered complete if it contained three elements: nature of the symptoms, description of injury, or cause for clinical concern; duration of symptoms or time of injury; and focal site of pain or abnormality, if applicable. This was reduced to three elements: ""what-when-where."" A goal was established that 95% of the clinical histories should contain all three elements. To achieve this goal, technologists supplemented referring clinicians' history. The project was divided into four phases: launch, support, transition to sustainability, and maintenance. During the support phase, results of automated weekly audits automatically populated group-level performance reports. During the transition to the sustainability phase, audit results populated individual-level performance reports. During the maintenance phase, quarterly audit results were incorporated into technologists' employee performance goals. RESULTS. Before initiation of the project, 38% (76/200) of radiography examinations were accompanied by a complete clinical history. This increased to 95% (928/1006) by the end of the 15-week improvement phase. Performance was sustained at 92% (1168/1213) 7 months later. CONCLUSION. By clearly defining expectations for an appropriate clinical history and establishing system and organizational mechanisms to facilitate verifiable compliance, we were able to successfully and sustainably improve the consistency with which radiography examinations were accompanied by a complete clinical history. © American Roentgen Ray Society.","Clinical history; Quality improvement; Radiography","article; automation; child; communication skill; controlled study; disease duration; electronic medical record; emergency ward; health care availability; human; medical history; medical information; outcome assessment; patient assessment; physician attitude; priority journal; professional competence; professional knowledge; radiodiagnosis; radiology department; total quality management; Documentation; Humans; Medical History Taking; Pediatrics; Quality Improvement; Radiology Department, Hospital; Radiology Information Systems",Article,Scopus
"Petkov V.I., Penberthy L.T., Dahman B.A., Poklepovic A., Gillam C.W., McDermott J.H.","Automated determination of metastases in unstructured radiology reports for eligibility screening in oncology clinical trials",2013,"Experimental Biology and Medicine",13,"10.1177/1535370213508172","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84888403368&doi=10.1177%2f1535370213508172&partnerID=40&md5=087683906d84d6cc9552eb4607e5df04","Enrolling adequate numbers of patients that meet protocol eligibility criteria in a timely manner is critical, yet clinical trial accrual continues to be problematic. One approach to meet these accrual challenges is to utilize technology to automatically screen patients for clinical trial eligibility. This manuscript reports on the evaluation of different automated approaches to determine the metastatic status from unstructured radiology reports using the Clinical Trials Eligibility Database Integrated System (CTED). The study sample included all patients (N = 5,523) with radiologic diagnostic studies (N = 10,492) completed in a two-week period. Eight search algorithms (queries) within CTED were developed and applied to radiology reports. The performance of each algorithm was compared to a reference standard which consisted of a physician's review of the radiology reports. Sensitivity, specificity, positive, and negative predicted values were calculated for each algorithm. The number of patients identified by each algorithm varied from 187 to 330 and the number of true positive cases confirmed by physician review ranged from 171 to 199 across the algorithms. The best performing algorithm had sensitivity 94%, specificity 100%, positive predictive value 90%, negative predictive value 100%, and accuracy of 99%. Our evaluation process identified the optimal method for rapid identification of patients with metastatic disease through automated screening of unstructured radiology reports. The methods developed using the CTED system could be readily implemented at other institutions to enhance the efficiency of research staff in the clinical trials eligibility screening process. © 2013 by the Society for Experimental Biology and Medicine.","automation; Clinical trials; eligibility screening; information extraction; metastases; radiology reports","algorithm; article; cancer diagnosis; clinical trial (topic); diagnostic test accuracy study; electronic medical record; human; ICD-9; major clinical study; metastasis; performance; physician; predictive value; radiology; screening; sensitivity and specificity; automation; Clinical trials; eligibility screening; information extraction; metastases; radiology reports; Algorithms; Automation; Clinical Trials as Topic; Databases, Factual; Humans; Medical Oncology; Neoplasms; Radiographic Image Interpretation, Computer-Assisted; Sensitivity and Specificity",Article,Scopus
"Nayak L., Beaulieu C.F., Rubin D.L., Lipson J.A.","A Picture Is Worth A Thousand Words. Needs Assessment for Multimedia Radiology Reports in a Large Tertiary Care Medical Center",2013,"Academic Radiology",23,"10.1016/j.acra.2013.09.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887202691&doi=10.1016%2fj.acra.2013.09.002&partnerID=40&md5=e4c54c6596f06ee82374fd52480e4789","Rationale and Objectives: Radiology reports are the major, and often only, means of communication between radiologists and their referring clinicians. The purposes of this study are to identify referring physicians' preferences about radiology reports and to quantify their perceived value of multimedia reports (with embedded images) compared with narrative text reports. Materials and Methods: We contacted 1800 attending physicians from a range of specialties at large tertiary care medical center via e-mail and a hospital newsletter linking to a 24-question electronic survey between July and November 2012. One hundred sixty physicians responded, yielding a response rate of 8.9%. Survey results were analyzed using Statistical Analysis Software (SAS Institute Inc, Cary, NC). Results: Of the 160 referring physicians respondents, 142 (89%) indicated a general interest in reports with embedded images and completed the remainder of the survey questions. Of 142 respondents, 103 (73%) agreed or strongly agreed that reports with embedded images could improve the quality of interactions with radiologists; 129 respondents (91%) agreed or strongly agreed that having access to significant images enhances understanding of a text-based report; 110 respondents (77%) agreed or strongly agreed that multimedia reports would significantly improve referring physician satisfaction; and 85 respondents (60%) felt strongly or very strongly that multimedia reports would significantly improve patient care and outcomes. Conclusions: Creating accessible, readable, and automatic multimedia reports should be a high priority to enhance the practice and satisfaction of referring physicians, improve patient care, and emphasize the critical role radiology plays in current medical care. © 2013 AUR.","Communication; Digital images; Multimedia reports; Radiology practice; Radiology reporting","article; computer program; e-mail; health care management; health survey; human; image quality; multimedia; needs assessment; physician; priority journal; radiography; satisfaction; tertiary health care; communication; digital images; Multimedia reports; radiology practice; radiology reporting; Attitude of Health Personnel; Humans; Interdisciplinary Communication; Medical Records; Multimedia; Needs Assessment; Physicians; Questionnaires; Radiology; Radiology Information Systems; Referral and Consultation; Tertiary Care Centers",Article,Scopus
"Gorniak R.J.T., Flanders A.E., Sharpe Jr. R.E.","Trainee report dashboard: Tool for enhancing feedback to radiology trainees about their reports",2013,"Radiographics",20,"10.1148/rg.337135705","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887520125&doi=10.1148%2frg.337135705&partnerID=40&md5=dca7aa9fa93d5899063c8f55f05dab7f","During their radiology residency, trainees must learn multiple facets of radiology practice, including the writing of radiology reports. An important factor in the trainee's development of reporting skills is feedback from the attending radiologist on the trainee's preliminary reports. The quality and quantity of feedback may vary and are not typically documented. As radiology department workloads have increased and stricter limitations have been imposed on trainee work hours, less time is available for attending radiologists and trainees to perform a joint retrospective review of radiology reports. To compensate, the authors have developed a Web-based dashboard that provides trainees with case-specific feedback about their reports. Components include an attending radiologist-trainee report discrepancy logging and communication system that is integrated with the institutional picture archiving and communication system, an automated preliminary report-final report comparator, modules showing statistics related to the discrepancy logger and report comparator components, and a Web page that unifies these components with image and report display capabilities. Both the actual report feedback and the trainee's use of the system are documented, and the resultant data may be used for evaluating trainee competence in written communication, as mandated by the Accreditation Council for Graduate Medical Education. With these tools, trainees can obtain near-real-time feedback, which may pinpoint issues that can be corrected to improve the quality of their radiology reporting. This system, although it does not supplant face-to-face training sessions with attending radiologists, can augment traditional methods of learning. © RSNA, 2013.",,"adaptive behavior; article; computer interface; computer program; documentation; education; Internet; interpersonal communication; medical record; methodology; radiology; teaching; United States; Communication; Computer-Assisted Instruction; Documentation; Educational Measurement; Feedback, Psychological; Health Records, Personal; Internet; Pennsylvania; Radiology; Software; Teaching; User-Computer Interface",Article,Scopus
"Arnold C.W., McNamara M., El-Saden S., Chen S., Taira R.K., Bui A.A.T.","Imaging informatics for consumer health: Towards a radiology patient portal",2013,"Journal of the American Medical Informatics Association",26,"10.1136/amiajnl-2012-001457","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84886236145&doi=10.1136%2famiajnl-2012-001457&partnerID=40&md5=2501456ae3002e53528f8a700a706cd6","Objective With the increased routine use of advanced imaging in clinical diagnosis and treatment, it has become imperative to provide patients with a means to view and understand their imaging studies. We illustrate the feasibility of a patient portal that automatically structures and integrates radiology reports with corresponding imaging studies according to several information orientations tailored for the layperson. Methods The imaging patient portal is composed of an image processing module for the creation of a timeline that illustrates the progression of disease, a natural language processing module to extract salient concepts from radiology reports (73% accuracy, F1 score of 0.67), and an interactive user interface navigable by an imaging findings list. The portal was developed as a Java-based web application and is demonstrated for patients with brain cancer. Results and discussion The system was exhibited at an international radiology conference to solicit feedback from a diverse group of healthcare professionals. There was wide support for educating patients about their imaging studies, and an appreciation for the informatics tools used to simplify images and reports for consumer interpretation. Primary concerns included the possibility of patients misunderstanding their results, as well as worries regarding accidental improper disclosure of medical information. Conclusions Radiologic imaging composes a significant amount of the evidence used to make diagnostic and treatment decisions, yet there are few tools for explaining this information to patients. The proposed radiology patient portal provides a framework for organizing radiologic results into several information orientations to support patient education.",,"article; brain cancer; consumer health information; diagnostic accuracy; diagnostic test accuracy study; disease course; glioma; health care personnel; human; image processing; imaging; interpersonal communication; medical informatics; medical information; meningioma; natural language processing; patient education; computer assisted image processing; natural language processing; patient education; radiology; Brain Neoplasms; Humans; Internet; Natural Language Processing; Patient Access to Records; Patient Education as Topic; Radiology Information Systems; United States",Article,Scopus
"Cowan I.A., MacDonald S.L.S., Floyd R.A.","Measuring and managing radiologist workload: Measuring radiologist reporting times using data from a Radiology Information System",2013,"Journal of Medical Imaging and Radiation Oncology",27,"10.1111/1754-9485.12092","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885959299&doi=10.1111%2f1754-9485.12092&partnerID=40&md5=25b5b6863b06da13afdfe1dde31c25df","Introduction Historically, there has been no objective method of measuring the time required for radiologists to produce reports during normal work. We have created a technique for semi-automated measurement of radiologist reporting time, and through it produced a robust set of absolute time requirements and relative value units for consultant reporting of diagnostic examinations in our hospital. Methods A large sample of reporting times, recorded automatically by the Radiology Information System (COMRAD, Software Innovations, Christchurch, New Zealand) along with the description of each examination being reported, was placed in a database. Analysis was confined to diagnostic reporting by consultant radiologists. A spreadsheet was produced, listing the total number and the frequency of reporting times of each distinct examination. Outliers with exceptionally long report times (more than 10 min for plain radiography, 30 min for ultrasound, or 60 min for CT or MRI with some exceptions) were culled; this removed 9.5% of the total. Complex CTs requiring separate workstation time were assigned times by consensus. The median time for the remainder of each sample was the assigned absolute reporting time in minutes and seconds. Relative value units were calculated using the reporting time for a single view department chest X-ray of 1 min 38 s including verifying a report made using speech recognition software. Results A schedule of absolute and relative values, based on over 179 000 reports, forms Table 2 of this paper. Conclusions The technique provides a schedule of reporting times with reduced subjective input, which is more robust than existing systems for measuring reporting time. © 2013 The Royal Australian and New Zealand College of Radiologists.","productivity; radiologist; reporting; time; workload","article; automatic speech recognition; consultation; data base; hospital information system; human; major clinical study; medical information system; nuclear magnetic resonance imaging; priority journal; productivity; radiologist; retrospective study; thorax radiography; ultrasound; workload; productivity; radiologist; reporting; time; workload; Diagnostic Imaging; Efficiency, Organizational; Employee Performance Appraisal; Health Planning; Health Records, Personal; New Zealand; Physician's Practice Patterns; Radiology Department, Hospital; Radiology Information Systems; Relative Value Scales; Workflow; Workload",Article,Scopus
"Sevenster M., Qian Y., Abe H., Buurman J.","Cross-sectional relatedness between sentences in breast radiology reports: Development of an SVM classifier and evaluation against annotations of five breast radiologists",2013,"Journal of Digital Imaging",2,"10.1007/s10278-013-9612-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885420468&doi=10.1007%2fs10278-013-9612-9&partnerID=40&md5=b3d4aeb022b24491174dc0681dbe9645","Introduce the notion of cross-sectional relatedness as an informational dependence relation between sentences in the conclusion section of a breast radiology report and sentences in the findings section of the same report. Assess inter-rater agreement of breast radiologists. Develop and evaluate a support vector machine (SVM) classifier for automatically detecting cross-sectional relatedness. A standard reference is manually created from 444 breast radiology reports by the first author. A subset of 37 reports is annotated by five breast radiologists. Inter-rater agreement is computed among their annotations and standard reference. Thirteen numerical features are developed to characterize pairs of sentences; the optimal feature set is sought through forward selection. Inter-rater agreement is F-measure 0.623. SVM classifier has F-measure of 0.699 in the 12-fold cross-validation protocol against standard reference. Report length does not correlate with the classifier's performance (correlation coefficient = -0.073). SVM classifier has average F-measure of 0.505 against annotations by breast radiologists. Mediocre inter-rater agreement is possibly caused by: (1) definition is insufficiently actionable, (2) fine-grained nature of cross-sectional relatedness on sentence level, instead of, for instance, on paragraph level, and (3) higher-than-average complexity of 37-report sample. SVM classifier performs better against standard reference than against breast radiologists's annotations. This is supportive of (3). SVM's performance on standard reference is satisfactory. Since optimal feature set is not breast specific, results may transfer to non-breast anatomies. Applications include a smart report viewing environment and data mining. © 2013 Society for Imaging Informatics in Medicine.","Information retrieval; Inter-rater agreement; Radiology reports; Support vector machine; Text mining; Textual entailment","Classifier's performance; Correlation coefficient; Dependence relation; Inter-rater agreements; Optimal feature sets; Radiology reports; Text mining; Textual entailment; Data mining; Information retrieval; Optimization; Support vector machines; Breast Neoplasms; echomammography; female; hospital information system; human; information retrieval; mammography; medical record; nuclear magnetic resonance imaging; observer variation; statistics and numerical data; support vector machine; article; breast tumor; echomammography; hospital information system; information retrieval; mammography; medical record; statistics; Breast Neoplasms; Female; Humans; Information Storage and Retrieval; Magnetic Resonance Imaging; Mammography; Medical Records; Observer Variation; Radiology Information Systems; Support Vector Machines; Ultrasonography, Mammary; Breast Neoplasms; Female; Humans; Information Storage and Retrieval; Magnetic Resonance Imaging; Mammography; Medical Records; Observer Variation; Radiology Information Systems; Support Vector Machines; Ultrasonography, Mammary",Article,Scopus
"Mabotuwana T., Lee M.C., Cohen-Solal E.V.","An ontology-based similarity measure for biomedical data - Application to radiology reports",2013,"Journal of Biomedical Informatics",37,"10.1016/j.jbi.2013.06.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883809158&doi=10.1016%2fj.jbi.2013.06.013&partnerID=40&md5=93918c953068ea889c64bb0e264956a4","Background: Determining similarity between two individual concepts or two sets of concepts extracted from a free text document is important for various aspects of biomedicine, for instance, to find prior clinical reports for a patient that are relevant to the current clinical context. Using simple concept matching techniques, such as lexicon based comparisons, is typically not sufficient to determine an accurate measure of similarity. Methods: In this study, we tested an enhancement to the standard document vector cosine similarity model in which ontological parent-child ( is-a) relationships are exploited. For a given concept, we define a semantic vector consisting of all parent concepts and their corresponding weights as determined by the shortest distance between the concept and parent after accounting for all possible paths. Similarity between the two concepts is then determined by taking the cosine angle between the two corresponding vectors. To test the improvement over the non-semantic document vector cosine similarity model, we measured the similarity between groups of reports arising from similar clinical contexts, including anatomy and imaging procedure. We further applied the similarity metrics within a k-nearest-neighbor ( k-NN) algorithm to classify reports based on their anatomical and procedure based groups. 2150 production CT radiology reports (952 abdomen reports and 1128 neuro reports) were used in testing with SNOMED CT, restricted to Body structure, Clinical finding and Procedure branches, as the reference ontology. Results: The semantic algorithm preferentially increased the intra-class similarity over the inter-class similarity, with a 0.07 and 0.08 mean increase in the neuro-neuro and abdomen-abdomen pairs versus a 0.04 mean increase in the neuro-abdomen pairs. Using leave-one-out cross-validation in which each document was iteratively used as a test sample while excluding it from the training data, the k-NN based classification accuracy was shown in all cases to be consistently higher with the semantics based measure compared with the non-semantic case. Moreover, the accuracy remained steady even as k value was increased - for the two anatomy related classes accuracy for k= 41 was 93.1% with semantics compared to 86.7% without semantics. Similarly, for the eight imaging procedures related classes, accuracy (for k= 41) with semantics was 63.8% compared to 60.2% without semantics. At the same k, accuracy improved significantly to 82.8% and 77.4% respectively when procedures were logically grouped together into four classes (such as ignoring contrast information in the imaging procedure description). Similar results were seen at other k-values. Conclusions: The addition of semantic context into the document vector space model improves the ability of the cosine similarity to differentiate between radiology reports of different anatomical and image procedure-based classes. This effect can be leveraged for document classification tasks, which suggests its potential applicability for biomedical information retrieval. © 2013 Elsevier Inc.","Document similarity comparison; Radiology informatics; Semantic similarity","Biomedical information retrieval; Classification accuracy; Document Classification; Document similarity; Leave-one-out cross validations; Measure of similarities; Radiology informatics; Semantic similarity; Algorithms; Classification (of information); Image matching; Information retrieval systems; Iterative methods; Ontology; Radiation; Radiology; Statistical methods; Vector spaces; Vectors; Semantics; abdomen; algorithm; anatomy; article; bioinformatics; book; child parent relation; classification; computer assisted tomography; data mining; human; imaging; information retrieval; measurement accuracy; priority journal; radiology; semantics; support vector machine; Document similarity comparison; Natural Language Processing; Radiology informatics; Radiology information systems; Semantic similarity; Semantics; Systematized Nomenclature of Medicine; Algorithms; Natural Language Processing; Radiology; Semantics",Article,Scopus
"Nguyen D.H.M., Patrick J.D.","Information extraction from radiology reports for a population based cancer registry",2013,"Proceedings of the IASTED International Conference on Biomedical Engineering, BioMed 2013",,"10.2316/P.2013.791-046","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883884594&doi=10.2316%2fP.2013.791-046&partnerID=40&md5=3877dd4c3739bec2a4d04393e68cbe81","A complete system of Cancer Information Extraction for a population based Cancer Registry is introduced. The analysis involves the classification and annotation of radiology imaging reports to identify the components needed to complete cancer staging and recurrence extraction. Besides traditional supervised learning methods such as Conditional Random Fields and Support Vector Machines, active learning approaches are investigated to bring further improvement to the information extraction system performance. A reportability classifier, separating cancer from non-cancer reports, has achieved a performance of 97.74% sensitivity and 96.00% specificity on the held-out test set. The accuracies of Report Purpose classifier and Tumour Stream classifier are approximately 80% on 10-fold cross-validation (CV) experiments. The overall F-score of the tagging system is over 93% on 5-fold CV with approximately 487000 instances from more than 3000 reports manually annotated.","Active learning; Cancer; Clinical assessment and patient diagnosis; Clinical engineering; Information extraction","10-fold cross-validation; Active Learning; Cancer; Clinical assessment and patient diagnosis; Clinical engineering; Conditional random field; Information extraction systems; Supervised learning methods; Biomedical engineering; Classification (of information); Diagnosis; Information retrieval; Information retrieval systems; Radiation; Radiology; Diseases",Conference Paper,Scopus
"Dublin S., Baldwin E., Walker R.L., Christensen L.M., Haug P.J., Jackson M.L., Nelson J.C., Ferraro J., Carrell D., Chapman W.W.","Natural language processing to identify pneumonia from radiology reports",2013,"Pharmacoepidemiology and Drug Safety",54,"10.1002/pds.3418","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880739886&doi=10.1002%2fpds.3418&partnerID=40&md5=2c9a5afde9b0c2ce06bd93bd3c52d3dd","Purpose: This study aimed to develop Natural Language Processing (NLP) approaches to supplement manual outcome validation, specifically to validate pneumonia cases from chest radiograph reports. Methods: We trained one NLP system, ONYX, using radiograph reports from children and adults that were previously manually reviewed. We then assessed its validity on a test set of 5000 reports. We aimed to substantially decrease manual review, not replace it entirely, and so, we classified reports as follows: (1) consistent with pneumonia; (2) inconsistent with pneumonia; or (3) requiring manual review because of complex features. We developed processes tailored either to optimize accuracy or to minimize manual review. Using logistic regression, we jointly modeled sensitivity and specificity of ONYX in relation to patient age, comorbidity, and care setting. We estimated positive and negative predictive value (PPV and NPV) assuming pneumonia prevalence in the source data. Results: Tailored for accuracy, ONYX identified 25% of reports as requiring manual review (34% of true pneumonias and 18% of non-pneumonias). For the remainder, ONYX's sensitivity was 92% (95% CI 90-93%), specificity 87% (86-88%), PPV 74% (72-76%), and NPV 96% (96-97%). Tailored to minimize manual review, ONYX classified 12% as needing manual review. For the remainder, ONYX had sensitivity 75% (72-77%), specificity 95% (94-96%), PPV 86% (83-88%), and NPV 91% (90-91%). Conclusions: For pneumonia validation, ONYX can replace almost 90% of manual review while maintaining low to moderate misclassification rates. It can be tailored for different outcomes and study needs and thus warrants exploration in other settings. © 2013 John Wiley & Sons, Ltd.","Natural Language Processing; Pharmacoepidemiology; Pneumonia; Sensitivity; Specificity; Validity","accuracy; article; classification; comorbidity; data analysis software; human; logistic regression analysis; natural language processing; pneumonia; predictive value; prevalence; priority journal; sensitivity and specificity; thorax radiography; validity; Natural Language Processing; pharmacoepidemiology; pneumonia; sensitivity; specificity; validity; Adolescent; Adult; Age Factors; Aged; Aged, 80 and over; Child; Child, Preschool; Humans; Infant; Logistic Models; Middle Aged; Natural Language Processing; Pharmacoepidemiology; Pneumonia; Predictive Value of Tests; Prevalence; Young Adult",Article,Scopus
"Dutta S., Long W.J., Brown D.F.M., Reisner A.T.","Automated detection using natural language processing of radiologists recommendations for additional imaging of incidental findings",2013,"Annals of Emergency Medicine",67,"10.1016/j.annemergmed.2013.02.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880569580&doi=10.1016%2fj.annemergmed.2013.02.001&partnerID=40&md5=077fdcce7b4139689b7cc3acf7676157","Study objective: As use of radiology studies increases, there is a concurrent increase in incidental findings (eg, lung nodules) for which the radiologist issues recommendations for additional imaging for follow-up. Busy emergency physicians may be challenged to carefully communicate recommendations for additional imaging not relevant to the patient's primary evaluation. The emergence of electronic health records and natural language processing algorithms may help address this quality gap. We seek to describe recommendations for additional imaging from our institution and develop and validate an automated natural language processing algorithm to reliably identify recommendations for additional imaging. Methods: We developed a natural language processing algorithm to detect recommendations for additional imaging, using 3 iterative cycles of training and validation. The third cycle used 3,235 radiology reports (1,600 for algorithm training and 1,635 for validation) of discharged emergency department (ED) patients from which we determined the incidence of discharge-relevant recommendations for additional imaging and the frequency of appropriate discharge documentation. The test characteristics of the 3 natural language processing algorithm iterations were compared, using blinded chart review as the criterion standard. Results: Discharge-relevant recommendations for additional imaging were found in 4.5% (95% confidence interval [CI] 3.5% to 5.5%) of ED radiology reports, but 51% (95% CI 43% to 59%) of discharge instructions failed to note those findings. The final natural language processing algorithm had 89% (95% CI 82% to 94%) sensitivity and 98% (95% CI 97% to 98%) specificity for detecting recommendations for additional imaging. For discharge-relevant recommendations for additional imaging, sensitivity improved to 97% (95% CI 89% to 100%). Conclusion: Recommendations for additional imaging are common, and failure to document relevant recommendations for additional imaging in ED discharge instructions occurs frequently. The natural language processing algorithm's performance improved with each iteration and offers a promising error-prevention tool. © 2013 American College of Emergency Physicians.",,"algorithm; article; automation; computer program; diagnostic imaging; electronic medical record; emergency patient; emergency physician; emergency ward; follow up; hospital discharge; human; incidental finding; major clinical study; medical documentation; medical record review; natural language processing; predictive value; priority journal; sensitivity and specificity; algorithm; electronic medical record; emergency health service; evaluation study; hospital discharge; radiology department; reproducibility; single blind procedure; Algorithms; Electronic Health Records; Emergency Service, Hospital; Humans; Incidental Findings; Natural Language Processing; Patient Discharge; Radiology Department, Hospital; Reproducibility of Results; Single-Blind Method",Article,Scopus
"Surrey D., Sharpe Jr. R.E., Gorniak R.J.T., Nazarian L.N., Rao V.M., Flanders A.E.","QRSE: A novel metric for the evaluation of trainee radiologist reporting skills",2013,"Journal of Digital Imaging",5,"10.1007/s10278-013-9574-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880174011&doi=10.1007%2fs10278-013-9574-y&partnerID=40&md5=b4b88cb080d2355a82b4ebe4b0f5797d","Diagnostic radiology training programs must produce highly skilled diagnostic radiologists capable of interpreting radiological examinations and communicating results to clinicians. Established training performance tools evaluate interpretive skills, but trainees' competency in reporting skills is also essential. Our semi-automated passive electronic tool entitled the Quantitative Reporting Skills Evaluation (QRSE) allows radiology training programs to evaluate the quantity of edits made to trainee preliminary reports by attending physicians as a metric to evaluate trainee reporting performance. Consecutive report pairs and metadata extracted from the radiology information system were anonymized and exported to a MySQL database. To perform the QRSE, for each report pair, open source software was first utilized to calculate the Levenshtein Percent (LP), the percent of character changes required to convert each preliminary report to its corresponding final report. The average LP (ALP), ALP for each trainee, and standard deviations were calculated. Eighty-four trainees and 56 attending radiologists interpreted 228,543 radiological examinations during the study period. The overall ALP was 6.38 %. Trainee-specific ALPs ranged from 1.1 to 15.3 %. Among trainee-specific ALPs, the standard deviation was 3.7 %. Our analysis identified five trainees with trainee-specific ALPs above 2 standard deviations from the mean and 14 trainees with trainee-specific ALPs less than 1 standard deviation below the mean. The QRSE methodology allows for the passive, quantitative, and longitudinal evaluation of the reporting skills of trainees during diagnostic radiology residency training. The QRSE identifies trainees with high and low levels of edits to their preliminary reports, as a marker for trainee overall reporting skills, and thus represents a novel performance metric for radiology training programs. © 2013 Society for Imaging Informatics in Medicine.","Electronic medical records; Internship and residency; Medical Education; Open source; Radiology information systems; Radiology reporting; Radiology teaching files; Reporting","Electronic medical record; Internship and residency; Open sources; Radiology information system; Radiology reporting; Radiology teaching files; Reporting; Diagnostic radiography; Information systems; Medical computing; Medical education; Radiation; Radiology; Software engineering; Statistics; Tools; Personnel training; clinical competence; education; electronic medical record; hospital information system; human; medical education; medical staff; organization and management; procedures; radiology; standards; article; clinical competence; education; electronic medical record; hospital information system; medical education; methodology; organization and management; radiology; standard; Clinical Competence; Education, Medical, Graduate; Electronic Health Records; Humans; Internship and Residency; Medical Staff, Hospital; Radiology; Radiology Information Systems; Clinical Competence; Education, Medical, Graduate; Electronic Health Records; Humans; Internship and Residency; Medical Staff, Hospital; Radiology; Radiology Information Systems",Conference Paper,Scopus
"Prevedello L.M., Farkas C., Dufault A., Damiano M., Doubilet P., Khorasani R.","Using informatics-enabled quality improvement techniques to meet health record documentation requirements in radiology reports",2013,"Academic Radiology",4,"10.1016/j.acra.2013.04.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880028910&doi=10.1016%2fj.acra.2013.04.007&partnerID=40&md5=6a5e331760c59b347f48022970d4fc83","Purpose: Medicare requires documented teaching physician involvement (attestation) in trainee-generated radiology reports. Automated attestation statement insertion in reports expedites the process but does not comply with requirements for active attestation. We evaluated an informatics-enabled quality improvement (QI) intervention to improve health record documentation requirements for active attestation. Materials and Methods: Institutional review board approval was not needed for this QI project performed in a 776-bed tertiary/quaternary teaching hospital. The intervention consisted of (1) policy requiring staff radiologists to actively attest to trainee-generated reports by personally activating a ""macro"" in the reporting system and (2) a semiautomated process to detect reports missing attestation; radiologistsreceived daily e-mail reminders until the attestation statement was inserted. A random sample of 600 of 123,561 trainee-generated radiology reports created 17 months after the intervention (May 2011) was manually reviewed to determine attestation policy adherence. The number of attestation statements added in response to reminders throughout the entire study period was also evaluated. Trend analysis of the number of report addenda containing solely the attestation statement (proxy for missing initial attestation) was performed. Results: Of 600 reports, 594 (99%) contained the attestation statement. Monthly attestations in response to email notifications decreased from 585 to 227 by the sixth month, a 2.6-fold reduction (P < .01). No significant trend was observed the following year, indicating asustained effect. Conclusion: Informatics-enabled QI techniques resulted in 99% adherence to our teaching physician attestation policy with sustained results. Similar approaches may help improve adherence to other mandated performance measures in radiology reports. © 2013 AUR.","Attestation; Health record documentation; Quality improvement","article; e-mail; follow up; human; information science; institutional review; intervention study; medical documentation; priority journal; protocol compliance; radiologist; random sample; teaching hospital; total quality management; Attestation; health record documentation; quality improvement; Boston; Forms and Records Control; Guideline Adherence; Health Records, Personal; Medical Informatics Applications; Medical Records Systems, Computerized; Practice Guidelines as Topic; Quality Improvement; Radiology",Article,Scopus
"Baccianella S., Esuli A., Sebastiani F.","Variable-constraint classification and quantification of radiology reports under the ACR Index",2013,"Expert Systems with Applications",5,"10.1016/j.eswa.2012.12.052","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84874662693&doi=10.1016%2fj.eswa.2012.12.052&partnerID=40&md5=4f7de0dda79e6716932776f888436318","We apply hierarchical supervised learning technology to the problem of assigning codes from the well-known ACR Index (a ""double-hierarchy"" classification scheme from the American College of Radiology) to radiology reports. This task is actually two classification tasks in one: the former uses a first hierarchy of codes describing anatomic locations, and the latter uses a second hierarchy of codes describing pathologies, where the two hierarchies are closely intertwined. A requirement of each such classification task is that the document be placed in exactly one node of depth ≥2 of the ""anatomic location"" hierarchy and in exactly one node of depth ≥3 of the ""pathology"" hierarchy; this makes our task a (fairly uncommon) variable-constraint classification task, since at the first levels of the hierarchy (2 for anatomic location, 3 for pathology) we need to use a standard ""exactly 1 class per document"" constraint, while at the lower levels we need to use an ""at most 1 class per document"" constraint. We have used a large dataset of about 250,000 radiology reports written in Italian and an adaptation of our TreeBoost.MH learning algorithm to variable-constraint classification. Notwithstanding the extreme difficulty of the task (given by the fact that the two codes had to be picked out of a pool of 719 codes for anatomic location and 5269 codes for pathology, respectively) our system displayed good accuracy, indicating that it may represent a viable tool for semi-automated classification of medical reports. We also analyzed the quantification accuracy of our system (i.e.; the ability of the system at correctly estimating the frequency of the individual codes), a concern of special interest in epidemiology; the results show that our system has excellent quantification accuracy, making this system a valuable tool for the fully automated coding of radiology reports for epidemiological purposes. © 2012 Elsevier Ltd. All rights reserved.","Automatic classification; Medical reports; Text classification","American college of radiologies; Automatic classification; Classification scheme; Classification tasks; Fully automated; Large dataset; Medical reports; Radiology reports; Semi-automated; Text classification; Two classification; Two-hierarchy; Classification (of information); Learning algorithms; Pathology; Radiation; Radiology; Information retrieval systems",Article,Scopus
"Wagholikar A., Zuccon G., Nguyen A., Chu K., Martin S., Lai K., Greenslade J.","Automated classification of limb fractures from free-text radiology reports using a clinician-informed gazetteer methodology",2013,"Australasian Medical Journal",10,"10.4066/AMJ.2013.1651","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878650397&doi=10.4066%2fAMJ.2013.1651&partnerID=40&md5=f3f1dca0c78c4ab0e6353b97ac4785db","Background Timely diagnosis and reporting of patient symptoms in hospital emergency departments (ED) is a critical component of health services delivery. However, due to dispersed information resources and a vast amount of manual processing of unstructured information, accurate point-of-care diagnosis is often difficult. Aims The aim of this research is to report initial experimental evaluation of a clinician-informed automated method for the issue of initial misdiagnoses associated with delayed receipt of unstructured radiology reports. Method A method was developed that resembles clinical reasoning for identifying limb abnormalities. The method consists of a gazetteer of keywords related to radiological findings; the method classifies an X-ray report as abnormal if it contains evidence contained in the gazetteer. A set of 99 narrative reports of radiological findings was sourced from a tertiary hospital. Reports were manually assessed by two clinicians and discrepancies were validated by a third expert ED clinician; the final manual classification generated by the expert ED clinician was used as ground truth to empirically evaluate the approach. Results The automated method that attempts to individuate limb abnormalities by searching for keywords expressed by clinicians achieved an F-measure of 0.80 and an accuracy of 0.80. Conclusion While the automated clinician-driven method achieved promising performances, a number of avenues for improvement were identified using advanced natural language processing (NLP) and machine learning techniques.","Classification; Emergency department; Limb fractures; Machine learning; Radiology reports; Rule-based method","article; classifier; diagnostic error; disease classification; follow up; human; limb fracture; measurement accuracy; natural language processing; radiology; X ray",Article,Scopus
"Berlin L.","Medicolegal: Malpractice and ethical issues in radiology proofreading radiology reports",2013,"American Journal of Roentgenology",1,"10.2214/AJR.12.10073","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880940234&doi=10.2214%2fAJR.12.10073&partnerID=40&md5=050a6b17b62fa9b0f0f6ba468f21105f",[No abstract available],,"human; law suit; letter; malpractice; medical documentation; medical ethics; negligence; physician; practice guideline; priority journal; radiologist; radiology; automatic speech recognition; diagnostic error; legal aspect; reading; Diagnostic Errors; Humans; Malpractice; Radiology; Reading; Speech Recognition Software",Letter,Scopus
"Esuli A., Marcheggiani D., Sebastiani F.","An enhanced CRFs-based system for information extraction from radiology reports",2013,"Journal of Biomedical Informatics",40,"10.1016/j.jbi.2013.01.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878166593&doi=10.1016%2fj.jbi.2013.01.006&partnerID=40&md5=2adc43eb8f07f59d39d08f4cab886e63","We discuss the problem of performing information extraction from free-text radiology reports via supervised learning. In this task, segments of text (not necessarily coinciding with entire sentences, and possibly crossing sentence boundaries) need to be annotated with tags representing concepts of interest in the radiological domain. In this paper we present two novel approaches to IE for radiology reports: (i) a cascaded, two-stage method based on pipelining two taggers generated via the well known linear-chain conditional random fields (LC-CRFs) learner and (ii) a confidence-weighted ensemble method that combines standard LC-CRFs and the proposed two-stage method. We also report on the use of "" positional features"" , a novel type of feature intended to aid in the automatic annotation of texts in which the instances of a given concept may be hypothesized to systematically occur in specific areas of the text. We present experiments on a dataset of mammography reports in which the proposed ensemble is shown to outperform a traditional, single-stage CRFs system in two different, applicatively interesting scenarios. © 2013 Elsevier Inc.","Clinical narratives; Concept extraction; Conditional random fields; Information extraction; Machine learning; Medical reports; Radiology reports","Clinical narratives; Concept extraction; Conditional random field; Information Extraction; Medical reports; Radiology reports; Information retrieval; Learning systems; Radiation; Random processes; Radiology; article; automation; data extraction; information extraction; linear chain conditional random field; mammography; priority journal; process design; radiology; Computer Simulation; Data Mining; Radiology",Article,Scopus
"Yetisgen-Yildiz M., Gunn M.L., Xia F., Payne T.H.","A text processing pipeline to extract recommendations from radiology reports",2013,"Journal of Biomedical Informatics",59,"10.1016/j.jbi.2012.12.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875621214&doi=10.1016%2fj.jbi.2012.12.005&partnerID=40&md5=5b777fc5ac808686e9ee1b4b9e3bb4d4","Communication of follow-up recommendations when abnormalities are identified on imaging studies is prone to error. The absence of an automated system to identify and track radiology recommendations is an important barrier to ensuring timely follow-up of patients especially with non-acute incidental findings on imaging examinations. In this paper, we present a text processing pipeline to automatically identify clinically important recommendation sentences in radiology reports. Our extraction pipeline is based on natural language processing (NLP) and supervised text classification methods. To develop and test the pipeline, we created a corpus of 800 radiology reports double annotated for recommendation sentences by a radiologist and an internist. We ran several experiments to measure the impact of different feature types and the data imbalance between positive and negative recommendation sentences. Our fully statistical approach achieved the best f-score 0.758 in identifying the critical recommendation sentences in radiology reports. © 2013 Elsevier Inc.","Natural language processing; Recommendation identification; Section segmentation","Automated systems; Data imbalance; Feature types; Incidental findings; NAtural language processing; Radiology reports; Statistical approach; Text classification methods; Automation; Classification (of information); Natural language processing systems; Pipelines; Radiology; Text processing; Radiation; article; computer assisted tomography; extraction; human; internist; medical information; natural language processing; nuclear magnetic resonance imaging; priority journal; radiologist; radiology; Algorithms; Databases, Factual; Humans; Medical Informatics; Natural Language Processing; Radiographic Image Interpretation, Computer-Assisted; Radiology Information Systems",Article,Scopus
"Larson D.B., Towbin A.J., Pryor R.M., Donnelly L.F.","Improving consistency in radiology reporting through the use of department-wide standardized structured reporting",2013,"Radiology",161,"10.1148/radiol.12121502","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875439389&doi=10.1148%2fradiol.12121502&partnerID=40&md5=53c8ff892bdcc5ea53532c4faaf30c14","Purpose: To successfully develop a department-wide standardized structured reporting program and achieve widespread adoption throughout the radiology department. Materials and Methods: A structured reporting work group was formed in February 2010 to oversee development of standardized structured reports for a radiology department of 36 radiologists at a tertiary care children's hospital. The committee reached consensus on report organization and provided written guidelines and checklists for division representatives to aid in creation of the structured reports. Report drafts were reviewed by a subcommittee and revised until agreement was reached with the report author. Each report was vetted by all radiologists who would be using the report, and further revisions were made, as appropriate. Reports were then entered into the speech recognition system so that each report was associated with a procedure code or a group of codes from the radiology information system. This enabled automatic report population within the speech recognition system. The initiative was completed by September 2011. Quarterly audits were performed to evaluate for adherence to the standard report format and use of the normal report in cases in which the radiologist believed the study was normal. In August 2012, radiologists were surveyed as to their impressions of the structured reporting program. Results: A total of 228 standardized structured reports were created within 2 years after initiation of the project, corresponding to 199 000 (94%) of 212 000 departmental studies by volume. By the end of the implementation period in September 2011, all 223 (100%) audited reports adhered to the standard report format and 80 (99%) of 81 reports adhered to the normal report. Radiologist feedback was largely favorable. Conclusion: Standardized department-wide structured reporting can be implemented in a radiology department, with a high rate of adoption by the radiologists. © 2013 RSNA.",,"article; automatic speech recognition; consensus development; human; medical information system; pediatric hospital; priority journal; radiologist; radiology department; standardization; structured reporting; tertiary health care; voluntary reporting; Attitude of Health Personnel; Documentation; Humans; Information Dissemination; Process Assessment (Health Care); Radiology Department, Hospital; Radiology Information Systems; Total Quality Management",Article,Scopus
"Bretschneider C., Zillner S., Hammon M.","Identifying pathological findings in german radiology reports using a syntacto-semantic parsing approach",2013,"Proceedings of the Annual Meeting of the Association for Computational Linguistics",17,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84968934647&partnerID=40&md5=f9c381c562464e4bdb394ccc55c747e8","In order to integrate heterogeneous clinical information sources, semantically correlating information entities have to be linked. Our discussions with radiologists revealed that anatomical entities with pathological findings are of particular interest when linking radiology text and images. Previous research to identify pathological findings focused on simplistic approaches that recognize diseases or negated findings, but failed to establish a holistic approach. In this paper, we introduce our syntacto-semantic parsing approach to classify sentences in radiology reports as either pathological or non-pathological based on the findings they describe. Although we operate with an incomplete, RadLex-based linguistic resource, the obtained results show the effectiveness of our approach by identifying a recall value of 74.3% for the classification task. © 2013 Association for Computational Linguistics",,"Classification (of information); Natural language processing systems; Radiation; Semantics; Syntactics; Classification tasks; Clinical information; Holistic approach; Information sources; Linguistic resources; Radiology reports; Semantic parsing; Radiology",Conference Paper,Scopus
"Khorasani R.","Can health IT tools enable improved documentation of quality, safety measures, and regulatory requirements in radiology reports?",2013,"Journal of the American College of Radiology",5,"10.1016/j.jacr.2013.02.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928099473&doi=10.1016%2fj.jacr.2013.02.003&partnerID=40&md5=a765f584b11ffb11708211e9097469d5",[No abstract available],,"automatic speech recognition; decision support system; health care policy; human; medical documentation; medical informatics; natural language processing; note; patient safety; radiologist; radiology; total quality management",Article,Scopus
"Prevedello L.M., Khorasani R.","Can health IT tools enable improved documentation of quality, safety measures, and regulatory requirements in radiology reports? Part 2",2013,"Journal of the American College of Radiology",,"10.1016/j.jacr.2013.05.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928097106&doi=10.1016%2fj.jacr.2013.05.007&partnerID=40&md5=1bd157799cec1da9c17a0df796928cc6",[No abstract available],,"article; computerized provider order entry; decision support system; human; medical documentation; medical informatics; medical information system; medical record; natural language processing; patient safety; radiology; standard; total quality management",Article,Scopus
"Luetmer M.T., Hunt C.H., McDonald R.J., Bartholmai B.J., Kallmes D.F.","Laterality errors in radiology reports generated with and without voice recognition software: Frequency and clinical significance",2013,"Journal of the American College of Radiology",8,"10.1016/j.jacr.2013.02.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928096615&doi=10.1016%2fj.jacr.2013.02.017&partnerID=40&md5=5bfe54bcc5586464b78fffc020867f21","Purpose: The aim of this study was to determine the incidence, types, and clinical implications of laterality errors and the effect of voice recognition software on the frequency of laterality errors. Methods: All radiology reports generated between January 2007 and April 2011 were retrospectively evaluated to identify revised reports containing laterality errors. Type of error was catalogued with regard to modality, body part, type of discrepancy (major or minor, with discrepancies considered major if the potential existed to affect patient management), duration of time between report finalization and corrected report, clinical significance, and use of voice recognition. The rate of errors causing major and minor discrepancies between voice recognition-generated reports and nonvoice recognition-generated reports was compared. Results: Among 2,923,094 reports, 1,607 (0.055%) contained corrected laterality errors, and 56 (0.0019% of the total report volume) were major. A total of 584,878 (20%) were generated using voice recognition. The rate of laterality errors leading to major discrepancies in voice recognition-generated reports was 0.00188%, compared with 0.00192% in nonvoice recognition-generated reports (P =.9436). None of the errors led to wrong-sided surgery. However, there were potential adverse effects due to laterality errors in 3 patients with major discrepancies (0.000103% of the total report volume). Conclusions: Rates of laterality errors were low and, in our population, did not result in wrong-sided surgeries. Rates of laterality errors in reports with major discrepancies were unaffected by voice recognition software, but voice recognition was associated with a significant reduction in the duration of time between report finalization and the issuing of a corrected report. © 2013 American College of Radiology.","Laterality errors; quality; voice recognition","adverse outcome; article; automatic speech recognition; body regions; computer assisted tomography; digital radiography; echography; hemispheric dominance; human; major clinical study; mammography; nuclear magnetic resonance imaging; radiologist; radiology",Article,Scopus
"Mabotuwana T., Qian Y., Sevenster M.","Using image references in radiology reports to support enhanced report-to-image navigation.",2013,"AMIA ... Annual Symposium proceedings / AMIA Symposium. AMIA Symposium",4,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901283138&partnerID=40&md5=8db743e66f9b72ec9de605d32e44da3d","Radiology reports frequently contain references to image slices that are illustrative of described findings, for instance, ""Neurofibroma in superior right extraconal space (series 5, image 104)"". In the current workflow, if a report consumer wants to view a referenced image, he or she needs to (1) open prior study, (2) open the series of interest (series 5 in this example), and (3) navigate to the corresponding image slice (image 104). This research aims to improve this report-to-image navigation process by providing hyperlinks to images. We develop and evaluate a regular expressions-based algorithm that recognizes image references at a sentence level. Validation on 314 image references from general radiology reports shows precision of 99.35%, recall of 98.08% and F-measure of 98.71%, suggesting this is a viable approach for image reference extraction. We demonstrate how recognized image references can be hyperlinked in a PACS report viewer allowing one-click access to the images.",,"algorithm; article; automated pattern recognition; hospital information system; human; information retrieval; methodology; organization and management; workflow; Algorithms; Humans; Information Storage and Retrieval; Pattern Recognition, Automated; Radiology Information Systems; Workflow",Article,Scopus
"Patrick J., Asgari P., Li M., Nguyen D.","Using NLP to identify cancer cases in imaging reports drawn from radiology information systems",2013,"Studies in Health Technology and Informatics",1,"10.3233/978-1-61499-266-0-91","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84894268494&doi=10.3233%2f978-1-61499-266-0-91&partnerID=40&md5=b11b8f4630071106b73b09ab33332a59","A Natural Language processing (NLP) classifier has been developed for the Victorian and NSW Cancer Registries with the purpose of automatically identifying cancer reports from imaging services, transmitting them to the Registries and then extracting pertinent cancer information. Large scale trials conducted on over 40,000 reports show the sensitivity for identifying reportable cancer reports is above 98% with a specificity above 96%. Detection of tumour stream, report purpose, and a variety of extracted content is generally above 90% specificity. The differences between report layout and authoring strategies across imaging services appear to require different classifiers to retain this high level of accuracy. Linkage of the imaging data with existing registry records (hospital and pathology reports) to derive stage and recurrence of cancer has commenced and shown very promising results. © 2013 The authors and IOS Press. All rights reserved.","cancer registry; classifier; NLP; radiology reports","Classification (of information); Classifiers; Health care; Hybrid integrated circuits; Natural language processing systems; Radiation; Radiology; Cancer registries; Imaging data; Imaging services; Radiology information system; Radiology reports; Diseases; Australia; conference paper; diagnostic imaging; electronic medical record; hospital information system; human; information retrieval; methodology; natural language processing; neoplasm; register; sensitivity and specificity; Diagnostic Imaging; Humans; Information Storage and Retrieval; Medical Records Systems, Computerized; Natural Language Processing; Neoplasms; New South Wales; Radiology Information Systems; Registries; Sensitivity and Specificity; Victoria",Conference Paper,Scopus
"Bretschneider C., Zillner S., Hammon M.","Grammar-based lexicon extension for aligning German radiology text and images",2013,"International Conference Recent Advances in Natural Language Processing, RANLP",4,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84890497307&partnerID=40&md5=4eebca80875391bae8712312f5c6578e","For efficient diagnosis processes, the multitude of heterogeneous medical data requires seamless integration. In order to automatically align radiology reports and images based on the pathological anatomical entities they describe, a preceding sentence classification is necessary. However, the lexical resource used has to contain semantic information about the pathological classification of each entity. We introduce an approach to extend medical lexical resources with pathology classification information and, at the same time, with new classified vocabulary. Our algorithm is based on a semi-supervised learning algorithm and incorporates a semantic context-free grammar combined with a RadLex-based lexicon.",,"Context free grammars; Diagnosis; Learning algorithms; Natural language processing systems; Radiation; Radiology; Semantics; Semi-supervised learning; Classification informations; Lexical resources; Medical data; Radiology reports; Seamless integration; Semantic context; Semantic information; Sentence classifications; Classification (of information)",Conference Paper,Scopus
"Uberoi R., Tapping C.R., Chalmers N., Allgar V.","British society of interventional radiology (BSIR) inferior vena cava (IVC) filter registry",2013,"CardioVascular and Interventional Radiology",77,"10.1007/s00270-013-0606-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84888203806&doi=10.1007%2fs00270-013-0606-2&partnerID=40&md5=b3f5fdf23a201dd4971d28cb6f0a48a6","Purpose: The British Society of Interventional Radiology (BSIR) Inferior Vena Cava (IVC) Filter Registry was produced to provide an audit of current United Kingdom (UK) practice regarding placement and retrieval of IVC filters to address concerns regarding their safety. Methods: The IVC filter registry is a web-based registry, launched by the BSIR on behalf of its membership in October 2007. This report is based on prospectively collected data from October 2007 to March 2011. This report contains analysis of data on 1,434 IVC filter placements and 400 attempted retrievals performed at 68 UK centers. Data collected included patient demographics, insertion and retrieval data, and patient follow-up. Results: IVC filter use in the majority of patients in the UK follows accepted CIRSE guidelines. Filter placement is usually a low-risk procedure, with a low major complication rate (<0.5 %). Cook Gunther Tulip (560 filters: 39 %) and Celect (359 filters: 25 %) filters constituted the majority of IVC filters inserted, with Bard G2, Recovery filters, Cordis Trapease, and OptEase constituting most of the remainder (445 filters: 31 %). More than 96 % of IVC filters deployed as intended. Operator inexperience (<25 procedure) was significantly associated with complications (p < 0.001). Of the IVC filters initially intended for temporary placement, retrieval was attempted in 78 %. Of these retrieval was technically successful in 83 %. Successful retrieval was significantly reduced for implants left in situ for >9 weeks versus those with a shorter dwell time. New lower limb deep vein thrombosis (DVT) and/or IVC thrombosis was reported in 88 patients following filter placement, there was no significant difference of incidence between filter types. Conclusions: This registry report provides interventional radiologists and clinicians with an improved understanding of the technical aspects of IVC filter placement to help improve practice, and the potential consequences of IVC filter placement so that we are better able to advise patients. There is a significant learning curve associated with IVC filter insertion, and when a filter is placed with the intention of removal, procedures should be in place to avoid the patient being lost to follow-up. © 2013 Springer Science+Business Media New York and the Cardiovascular and Interventional Radiological Society of Europe (CIRSE).","Deep vein thrombosis; Inferior vena cava filter; Pulmonary embolus; Venous thromboembolism","adult; article; clinical competence; deep vein thrombosis; demography; device removal; dwell time; female; follow up; human; inferior cava vein; interventional radiology; male; medical device complication; practice guideline; priority journal; prospective study; register; time; United Kingdom; vena cava filter; Adult; Age Distribution; Aged; Aged, 80 and over; Device Removal; Female; Great Britain; Humans; Male; Middle Aged; Practice Guidelines as Topic; Pulmonary Embolism; Radiology, Interventional; Registries; Societies, Medical; Time Factors; Treatment Outcome; Vena Cava Filters; Vena Cava, Inferior; Venous Thromboembolism; Young Adult",Article,Scopus
"Sevenster M.","Classifying measurements in dictated, free-text radiology reports",2013,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",2,"10.1007/978-3-642-38326-7_43","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887315733&doi=10.1007%2f978-3-642-38326-7_43&partnerID=40&md5=3bd71ba84f3f7eb8c35aa737c640db21","Radiological measurements (e.g., '3.2 x 1.4 cm') are the predominant type of quantitative data in free-text radiology reports. We report on the development and evaluation of a classifier that labels measurement descriptors with the exam they refer to: current and/or prior exam. Our classifier aggregates regular expressions as binary features in a maximum entropy model. It has average F-measure 0.942 on 2,000 annotated instances; the rule-based baseline algorithm has F-measure 0.795. Potential applications and routes for future are discussed. © 2013 Springer-Verlag.","measurements; natural language processing; Radiology report","Artificial intelligence; Measurements; Natural language processing systems; Pattern matching; Radiation; Binary features; Descriptors; Maximum entropy modeling; NAtural language processing; Quantitative data; Radiological measurements; Radiology reports; Regular expressions; Radiology",Conference Paper,Scopus
"Sippo D.A., Warden G.I., Andriole K.P., Lacson R., Ikuta I., Birdwell R.L., Khorasani R.","Automated extraction of BI-RADS final assessment categories from radiology reports with natural language processing",2013,"Journal of Digital Imaging",50,"10.1007/s10278-013-9616-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885419690&doi=10.1007%2fs10278-013-9616-5&partnerID=40&md5=c4c36affb0d4478f65d26a9335fc4704","The objective of this study is to evaluate a natural language processing (NLP) algorithm that determines American College of Radiology Breast Imaging Reporting and Data System (BI-RADS) final assessment categories from radiology reports. This HIPAA-compliant study was granted institutional review board approval with waiver of informed consent. This cross-sectional study involved 1,165 breast imaging reports in the electronic medical record (EMR) from a tertiary care academic breast imaging center from 2009. Reports included screening mammography, diagnostic mammography, breast ultrasound, combined diagnostic mammography and breast ultrasound, and breast magnetic resonance imaging studies. Over 220 reports were included from each study type. The recall (sensitivity) and precision (positive predictive value) of a NLP algorithm to collect BI-RADS final assessment categories stated in the report final text was evaluated against a manual human review standard reference. For all breast imaging reports, the NLP algorithm demonstrated a recall of 100.0 % (95 % confidence interval (CI), 99.7, 100.0 %) and a precision of 96.6 % (95 % CI, 95.4, 97.5 %) for correct identification of BI-RADS final assessment categories. The NLP algorithm demonstrated high recall and precision for extraction of BI-RADS final assessment categories from the free text of breast imaging reports. NLP may provide an accurate, scalable data extraction mechanism from reports within EMRs to create databases to track breast imaging performance measures and facilitate optimal breast cancer population management strategies. © 2013 Society for Imaging Informatics in Medicine.","Breast; Breast Imaging Reporting and Data System (BI-RADS); Imaging informatics; Natural language processing","Diagnosis; Extraction; Magnetic resonance imaging; Medical computing; Medical imaging; Population statistics; Radiation; Radiology; Telemedicine; Ultrasonics; American college of radiologies; BI-RADS; Breast; Breast imaging reporting and data systems; Breast magnetic-resonance imaging; Imaging informatics; Institutional review boards; NAtural language processing; Natural language processing systems; Breast Neoplasms; cross-sectional study; echomammography; factual database; female; hospital information system; human; mammography; natural language processing; nuclear magnetic resonance imaging; sensitivity and specificity; statistics and numerical data; article; breast tumor; echomammography; hospital information system; mammography; statistics; Breast Neoplasms; Cross-Sectional Studies; Databases, Factual; Female; Humans; Magnetic Resonance Imaging; Mammography; Natural Language Processing; Radiology Information Systems; Sensitivity and Specificity; Ultrasonography, Mammary; Breast Neoplasms; Cross-Sectional Studies; Databases, Factual; Female; Humans; Magnetic Resonance Imaging; Mammography; Natural Language Processing; Radiology Information Systems; Sensitivity and Specificity; Ultrasonography, Mammary",Article,Scopus
"Newsom E., Jones J.F.","Data reduction for continuum of care: An exploratory study using the predicate-argument structure to pre-process radiology sentences for measurement of semantic similarity",2013,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"10.1007/978-3-642-39194-1_60","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880710263&doi=10.1007%2f978-3-642-39194-1_60&partnerID=40&md5=6f83b6937fa62e822e4b71c5ad08bb51","In the clinical setting, continuum of care depends on integrated information services to assure a smooth progression for patient centered care, and these integrated information services must understand past events and personal circumstances to make care relevant. Clinicians face a problem that the amount of information produced in disparate electronic clinical notes is increasing to levels incapable of being processed by humans. Clinicians need a function in information services that can reduce the free text data to a message useful at time of care. Information extraction (IE) is a sub-field of natural language processing with the goal of data reduction of unstructured free text. Pertinent to IE is an annotated corpus that frames how IE methods should create a logical expression necessary for processing meaning of text. This study explores and reports on the requirements to using the predicate-argument statement (PAS) as the framework. A convenient sample from a prior study with ten synsets of 100 unique sentences from radiology reports deemed by domain experts to mean the same thing will be the text from which PAS structures are formed. Through content analysis of pattern recognition, findings show PAS is a feasible framework to structure sentences for semantic similarity measurement. © 2013 Springer-Verlag Berlin Heidelberg.","Information Extraction; Predicate-Argument Structure; Semantic Similarity","Human computer interaction; Information retrieval; Information services; Natural language processing systems; Pattern recognition; Radiation; Radiology; Semantics; Amount of information; Argument structures; Exploratory studies; Integrated information services; NAtural language processing; Patient-centered care; Semantic similarity; Semantic similarity measurement; Data reduction",Conference Paper,Scopus
"Hadimli K., Yöndem M.T.","Two alternate methods for information retrieval from turkish radiology reports",2012,"Computer and Information Sciences II - 26th International Symposium on Computer and Information Sciences, ISCIS 2011",2,"10.1007/978-1-4471-2155-8-67","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887842861&doi=10.1007%2f978-1-4471-2155-8-67&partnerID=40&md5=9809819a49ec473895e1856c43fcf1d0","Turkish is an highly agglutinative language and this poses problems in information retrieval from Turkish free-texts. In this paper one rule based and one data driven alternate methods for information retrieval from Turkish radiology reports are presented. Both methods do not utilize any medical lexicon or ontology, although inherent medical information within the training reports exist. Performance is measured and evaluated as a retrieval problem. © 2012 Springer-Verlag London Limited.",,"Agglutinative language; Alternate method; Data driven; Medical information; One-rule; Radiology reports; Turkishs; Information science; Radiation; Radiology; Information retrieval",Conference Paper,Scopus
"Gerstmair A., Daumke P., Simon K., Langer M., Kotter E.","Intelligent image retrieval based on radiology reports",2012,"European Radiology",26,"10.1007/s00330-012-2608-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870312742&doi=10.1007%2fs00330-012-2608-x&partnerID=40&md5=98b98c172287481ddc2329dc494f3ea6","Objectives: To create an advanced image retrieval and datamining system based on in-house radiology reports. Methods: Radiology reports are semantically analysed using natural language processing (NLP) techniques and stored in a state-of-the-art search engine. Images referenced by sequence and image number in the reports are retrieved from the picture archiving and communication system (PACS) and stored for later viewing. A web-based front end is used as an interface to query for images and show the results with the retrieved images and report text. Using a comprehensive radiological lexicon for the underlying terminology, the search algorithm also finds results for synonyms, abbreviations and related topics. Results: The test set was 108 manually annotated reports analysed by different system configurations. Best results were achieved using full syntactic and semantic analysis with a precision of 0.929 and recall of 0.952. Operating successfully since October 2010, 258,824 reports have been indexed and a total of 405,146 preview images are stored in the database. Conclusions: Data-mining and NLP techniques provide quick access to a vast repository of images and radiology reports with both high precision and recall values. Consequently, the system has become a valuable tool in daily clinical routine, education and research. Key Points: • Radiology reports can now be analysed using sophisticated natural language-processing techniques. • Semantic text analysis is backed by terminology of a radiological lexicon. • The search engine includes results for synonyms, abbreviations and compositions. • Key images are automatically extracted from radiology reports and fetched from PACS. • Such systems help to find diagnoses, improve report quality and save time. © European Society of Radiology 2012.","Data mining; Image retrieval; Natural language processing; Radiology reports; Search engine","accuracy; algorithm; article; data mining; human; image analysis; image processing; image retrieval; medical information system; natural language processing; nomenclature; picture archiving and communication system; priority journal; recall; semantics; Algorithms; Data Mining; Humans; Information Storage and Retrieval; Natural Language Processing; Radiology Information Systems; Search Engine; Semantics; Software; User-Computer Interface",Article,Scopus
"Lee Y.H., Song H.-T., Suh J.-S.","Quantitative computed tomography (QCT) as a radiology reporting tool by using optical character recognition (OCR) and macro program",2012,"Journal of Digital Imaging",5,"10.1007/s10278-012-9464-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870052962&doi=10.1007%2fs10278-012-9464-8&partnerID=40&md5=89e22f254e6200cbde56bc09db6a6c10","The objectives are (1) to introduce a new concept of making a quantitative computed tomography (QCT) reporting system by using optical character recognition (OCR) and macro program and (2) to illustrate the practical usages of the QCT reporting system in radiology reading environment. This reporting system was created as a development tool by using an open-source OCR software and an open-source macro program. The main module was designed for OCR to report QCT images in radiology reading process. The principal processes are as follows: (1) to save a QCT report as a graphic file, (2) to recognize the characters from an image as a text, (3) to extract the T scores from the text, (4) to perform error correction, (5) to reformat the values into QCT radiology reporting template, and (6) to paste the reports into the electronic medical record (EMR) or picture archiving and communicating system (PACS). The accuracy test of OCR was performed on randomly selected QCTs. QCT as a radiology reporting tool successfully acted as OCR of QCT. The diagnosis of normal, osteopenia, or osteoporosis is also determined. Error correction of OCR is done with AutoHotkey-coded module. The results of T scores of femoral neck and lumbar vertebrae had an accuracy of 100 and 95.4 %, respectively. A convenient QCT reporting system could be established by utilizing open-source OCR software and open-source macro program. This method can be easily adapted for other QCT applications and PACS/EMR. © Society for Imaging Informatics in Medicine 2012.","Computer in medicine; OCR; PACS; QCT; Reading room","Accuracy test; Development tools; Electronic medical record; Femoral necks; Graphic files; Lumbar vertebra; Macro program; Main module; OCR software; Open-source; Osteopenia; PACS; Picture archiving; QCT; Quantitative computed tomographies; Radiology reporting; Reading room; Reporting systems; Computerized tomography; Diagnosis; Error correction; Medical computing; Optical character recognition; Radiology; Radiation; article; automated pattern recognition; computer assisted tomography; computer program; femur neck; hospital information system; human; lumbar vertebra; metabolic bone disease; methodology; osteoporosis; radiography; Bone Diseases, Metabolic; Femur Neck; Humans; Lumbar Vertebrae; Osteoporosis; Pattern Recognition, Automated; Radiology Information Systems; Software; Tomography, X-Ray Computed",Article,Scopus
"Lakhani P., Kim W., Langlotz C.P.","Automated extraction of critical test values and communications from unstructured radiology reports: An analysis of 9.3 million reports from 1990 to 2011",2012,"Radiology",14,"10.1148/radiol.12112438","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870040429&doi=10.1148%2fradiol.12112438&partnerID=40&md5=50e49c1252aa09831cd13aa78aa3e5f3","Purpose: To determine the frequency of critical radiology results in 9.3 million radiology reports from our health system, to identify those containing documentation of communication by using automated text-classification algorithms, and to assess the impact of a policy requiring documentation of critical results communication. Materials and Methods: This HIPAA-compliant retrospective study received institutional review board approval. Text-mining algorithms that were previously validated to have mean accuracies of more than 90% for identifying certain critical results and documentation of communications were applied to a database of 9.3 million radiology reports. The frequency of critical results and documentation of communication were then determined from 1990 to 2011. Results: There was an increase in documentation of communication for all critical results from 1990 to 2011. In 1990, 19.0% of reports with critical values had evidence of documentation of communication compared with 72.4% of reports in 2010. The linear trend for increasing documentation of communications began in 1997 and continued until 2011 (P < .001). From 1990 to 2011, documentation of communication was highest in acute scrotal torsion (70.6%) and ectopic pregnancy (65.4%) and lowest in unexplained free-intraperitoneal air (29.5%) and malpositioned tubes (30.4%). In 2010-2011, radiologists were least likely to document communication of results for malpositioned endotracheal and enteric tubes (2010, 58.56%; 2011, 57.50%) and unexplained free-intraperitoneal air (2010, 59.57%; 2011, 75.51%). They were most likely to document communication of results for ectopic pregnancy (2010, 94.12%; 2011, 93.48%) and acute appendicitis (2010, 86.87%; 2011, 84.31%). Conclusion: There was an increase in documentation of communication of critical results, which demonstrated a rising linear trend that began in 1997 and continued until 2011. The increasing trend began well before policy implementation, indicating that other factors such as heightened awareness among radiologists likely had a role. © RSNA, 2012.",,"acute appendicitis; acute scrotal torsion; algorithm; article; automation; data mining; data processing; digestive tube; ectopic pregnancy; endotracheal tube; interpersonal communication; medical documentation; peritoneal disease; priority journal; radiology; retrospective study; scrotum disorder; trend study; unexplained free intraperitoneal air; Algorithms; Automation; Chi-Square Distribution; Communication; Data Mining; Decision Making, Computer-Assisted; Documentation; Humans; Organizational Policy; Radiology Department, Hospital; Radiology Information Systems; Retrospective Studies",Article,Scopus
"Krestin G.P., Grenier P.A., Hricak H., Jackson V.P., Khong P.L., Miller J.C., Muellner A., Schwaiger M., Thrall J.H.","Integrated diagnostics: Proceedings from the 9th biennial symposium of the International Society for Strategic Studies in Radiology",2012,"European Radiology",10,"10.1007/s00330-012-2510-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870315067&doi=10.1007%2fs00330-012-2510-6&partnerID=40&md5=abe35667a58c55ee660aa82032dea1d9","The International Society for Strategic Studies in Radiology held its 9th biennial meeting in August 2011. The focus of the programme was integrated diagnostics and massive computing. Participants discussed the opportunities, challenges, and consequences for the discipline of radiology that will likely arise from the integration of diagnostic technologies. Diagnostic technologies are increasing in scope, including advanced imaging techniques, new molecular imaging agents, and sophisticated point-of-use devices. Advanced information technology (IT), which is increasingly influencing the practice of medicine, will aid clinical communication and the development of ""population images"" that represent the phenotype of particular diseases, which will aid the development of diagnostic algorithms. Integrated diagnostics offer increased operational efficiency and benefits to patients through quicker and more accurate diagnoses. As physicians with the most expertise in IT, radiologists are well placed to take the lead in introducing IT solutions and cloud computing to promote integrated diagnostics. To achieve this, radiologists must adapt to include quantitative data on biomarkers in their reports. Radiologists must also increase their role as participating physicians, collaborating with other medical specialties, not only to avoid being sidelined by other specialties but also to better prepare as leaders in the selection and sequence of diagnostic procedures. Key Points • New diagnostic technologies are yielding unprecedented amounts of diagnostic information. • Advanced IT/cloud computing will aid integration and analysis of diagnostic data. • Better diagnostic algorithms will lead to faster diagnosis and more rapid treatment. © European Society of Radiology 2012.","Algorithms; Diagnostic techniques and procedures; Efficiency; Informatics; Organizational; Radiology","magnetic nanoparticle; pyruvic acid; acoustic radiation force impulse imaging; algorithm; article; bioinformatics; carbon nuclear magnetic resonance; cloud computing; computer security; decision support system; diagnosis; diagnostic accuracy; digital imaging; evidence based medicine; health care cost; health care delivery; health care quality; human; information processing; information retrieval; information storage; information technology; integrated diagnostics; interdisciplinary communication; Internet; lab on a chip; laboratory test; medical informatics; medical information; medical specialist; medical technology; medical terminology; molecular imaging; nonhuman; patient referral; point of care testing; population research; primary medical care; priority journal; privacy; proton nuclear magnetic resonance; radiologist; specialization; staff training; standardization; Algorithms; Biological Markers; Computer Systems; Decision Support Systems, Clinical; Diagnostic Imaging; Europe; Humans; International Cooperation; Medical Informatics; Molecular Imaging; Nanoparticles; Radiology; Societies, Medical",Article,Scopus
"Maghsoodi A., Sevenster M., Scholtes J., Nalbantov G.","Sentence-based classification of free-text breast cancer radiology reports",2012,"Proceedings - IEEE Symposium on Computer-Based Medical Systems",5,"10.1109/CBMS.2012.6266374","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867319459&doi=10.1109%2fCBMS.2012.6266374&partnerID=40&md5=8f20be40da0b5c49a0377e64f56fed07","Radiology reports generally consist of narrative text. It has been envisioned that structured medical content can be leveraged to clinical applications. Text-mining techniques can be utilized to realize this vision. We created a pipeline for automatic sentence classification of narrative breast cancer radiology reports. A corpus of 353 reports and 8166 sentences was annotated with seven sentence classes related to laterality, modality and recommendation. © 2012 IEEE.",,"Breast Cancer; Clinical application; Radiology reports; Text-mining; Diseases; Radiation; Radiology; Text processing",Conference Paper,Scopus
"March S., Cernile G., West K., Borhani D., Fritz A., Brueckner P.","Application of automated pathology reporting concepts to radiology reports.",2012,"Journal of registry management",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893110972&partnerID=40&md5=36dbbf42824f45f1e2f63f8eb8b328e6","This study was designed to extend the concept of automated pathology reporting to radiology reports to find central nervous system (CNS) neoplasms that may currently go undetected. Existing E-Path software was modified to account for the structure and language of radiology reports. Logic was added to allow registries to configure whether they want only new reports or if they also want history, metastatic, and/or previously known reports. Five hospital registries and 3 central registries participated. Three quality-control (QC) studies were conducted with fine-tuning taking place between the studies. The first QC study included random samples of 1,500 reports from 3 data sources. The second and third QC studies each included 1 random sample from 2 different data sources. The software was able to extract reportable CNS neoplasms with a high degree of specificity and sensitivity at 99% and 100% respectively, using the original set of coding rules. This rule set was favored by our hospital registries. Participating population-based registries preferred to receive only positive-new cases. The specificity and sensitivity for this category was 96% and 94% respectively. One hospital registry compared the cases found by the software to their registry database and found 13 additional CNS neoplasm cases in a 10-month period which represented an increase of 18%. Automated radiology reporting is a promising method of mining a previously untapped data source to find cases of CNS neoplasms that may be missed by conventional techniques.",,"article; central nervous system tumor; computer program; hospital information system; human; information system; laboratory diagnosis; organization and management; pathology; quality control; radiology; register; statistics; Central Nervous System Neoplasms; information system; organization and management; pathology; radiology; register; statistics and numerical data; Central Nervous System Neoplasms; False Negative Reactions; False Positive Reactions; Humans; Information Systems; Pathology; Quality Control; Radiology; Radiology Information Systems; Registries; Software; Central Nervous System Neoplasms; False Negative Reactions; False Positive Reactions; Humans; Information Systems; Pathology; Quality Control; Radiology; Radiology Information Systems; Registries; Software",Article,Scopus
"Xu Y., Tsujii J., Chang E.I.-C.","Named entity recognition of follow-up and time information in 20 000 radiology reports",2012,"Journal of the American Medical Informatics Association",27,"10.1136/amiajnl-2012-000812","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872259831&doi=10.1136%2famiajnl-2012-000812&partnerID=40&md5=3623fb39ec84edeb3162bf9726b24c29","Objective To develop a system to extract follow-up information from radiology reports. The method may be used as a component in a system which automatically generates follow-up information in a timely fashion. Methods A novel method of combining an LSP (labeled sequential pattern) classifier with a CRF (conditional random field) recognizer was devised. The LSP classifier filters out irrelevant sentences, while the CRF recognizer extracts follow-up and time phrases from candidate sentences presented by the LSP classifier. Measurements The standard performance metrics of precision (P), recall (R), and F measure (F) in the exact and inexact matching settings were used for evaluation. Results Four experiments conducted using 20 000 radiology reports showed that the CRF recognizer achieved high performance without time-consuming feature engineering and that the LSP classifier further improved the performance of the CRF recognizer. The performance of the current system is P=0.90, R=0.86, F=0.88 in the exact matching setting and P=0.98, R=0.93, F=0.95 in the inexact matching setting. Conclusion The experiments demonstrate that the system performs far better than a baseline rule-based system and is worth considering for deployment trials in an alert generation system. The LSP classifier successfully compensated for the inherent weakness of CRF, that is, its inability to use global information.",,"article; effect size; follow up; human; machine learning; medical information; medical record; radiology; artificial intelligence; classification; data mining; electronic medical record; feasibility study; hospital information system; methodology; natural language processing; Artificial Intelligence; Data Mining; Electronic Health Records; Feasibility Studies; Humans; Natural Language Processing; Radiology Information Systems",Article,Scopus
"Hawkins C.M., Hall S., Hardin J., Salisbury S., Towbin A.J.","Prepopulated radiology report templates: A prospective analysis of error rate and turnaround time",2012,"Journal of Digital Imaging",33,"10.1007/s10278-012-9455-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865355659&doi=10.1007%2fs10278-012-9455-9&partnerID=40&md5=57d8157cde662549b70cd255c8fdebf0","Current speech recognition software allows exam-specific standard reports to be prepopulated into the dictation field based on the radiology information system procedure code. While it is thought that prepopulating reports can decrease the time required to dictate a study and the overall number of errors in the final report, this hypothesis has not been studied in a clinical setting. A prospective study was performed. During the first week, radiologists dictated all studies using prepopulated standard reports. During the second week, all studies were dictated after prepopulated reports had been disabled. Final radiology reports were evaluated for 11 different types of errors. Each error within a report was classified individually. The median time required to dictate an exam was compared between the 2 weeks. There were 12,387 reports dictated during the study, of which, 1,173 randomly distributed reports were analyzed for errors. There was no difference in the number of errors per report between the 2 weeks; however, radiologists overwhelmingly preferred using a standard report both weeks. Grammatical errors were by far the most common error type, followed by missense errors and errors of omission. There was no significant difference in the median dictation time when comparing studies performed each week. The use of prepopulated reports does not alone affect the error rate or dictation time of radiology reports. While it is a useful feature for radiologists, it must be coupled with other strategies in order to decrease errors. © 2011 Society for Imaging Informatics in Medicine.","Prepopulated reports; Speech recognition; Standardized report; Structured report; Turnaround time","Clinical settings; Error rate; Error types; Grammatical errors; Prepopulated reports; Prospective analysis; Prospective study; Radiology information system; Radiology reports; Randomly distributed; Speech recognition softwares; Standardized report; Structured reports; Radiation; Radiology; Speech recognition; Turnaround time; Errors; article; automatic speech recognition; electronic medical record; hospital information system; human; medical record; prospective study; reproducibility; standard; Humans; Medical Records; Medical Records Systems, Computerized; Prospective Studies; Radiology Information Systems; Reproducibility of Results; Speech Recognition Software",Article,Scopus
"Pathak S.D., Kim W., Munasinghe I., Criminisi A., White S., Siddiqui K.","Linking DICOM pixel data with radiology reports using automatic semantic annotation",2012,"Proceedings of SPIE - The International Society for Optical Engineering",3,"10.1117/12.912391","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861879075&doi=10.1117%2f12.912391&partnerID=40&md5=71ea79a784a4edaec865b6957ff0607d","Improved access to DICOM studies to both physicians and patients is changing the ways medical imaging studies are visualized and interpreted beyond the confines of radiologists' PACS workstations. While radiologists are trained for viewing and image interpretation, a non-radiologist physician relies on the radiologists' reports. Consequently, patients historically have been typically informed about their imaging findings via oral communication with their physicians, even though clinical studies have shown that patients respond to physician's advice significantly better when the individual patients are shown their own actual data. Our previous work on automated semantic annotation of DICOM Computed Tomography (CT) images allows us to further link radiology report with the corresponding images, enabling us to bridge the gap between image data with the human interpreted textual description of the corresponding imaging studies. The mapping of radiology text is facilitated by natural language processing (NLP) based search application. When combined with our automated semantic annotation of images, it enables navigation in large DICOM studies by clicking hyperlinked text in the radiology reports. An added advantage of using semantic annotation is the ability to render the organs to their default window level setting thus eliminating another barrier to image sharing and distribution. We believe such approaches would potentially enable the consumer to have access to their imaging data and navigate them in an informed manner. © 2012 SPIE.","Classification; DICOM; Machine learning; Natural language processing; Regression; Semantic association","Clinical study; Computed Tomography; DICOM; Hyperlinked texts; Image data; Image interpretation; Image sharing; Imaging data; NAtural language processing; Oral communication; Radiology reports; Regression; Search application; Semantic annotations; Semantic associations; Textual description; Window level; Classification (of information); Communication; Computational linguistics; Computerized tomography; Learning algorithms; Learning systems; Medical applications; Medical imaging; Natural language processing systems; Photonic crystals; Radiation; Radiology; Semantics; Computer aided diagnosis",Conference Paper,Scopus
"Bosmans J.M.L., Peremans L., Menni M., de Schepper A.M., Duyck P.O., Parizel P.M.","Structured reporting: If, why, when, how-and at what expense? Results of a focus group meeting of radiology professionals from eight countries",2012,"Insights into Imaging",54,"10.1007/s13244-012-0148-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870311549&doi=10.1007%2fs13244-012-0148-1&partnerID=40&md5=77ebd483e20a5ef654752866b9f92d42","Purpose: To determine why, despite growing evidence that radiologists and referring physicians prefer structured reporting (SR) to free text (FT) reporting, SR has not been widely adopted in most radiology departments. Methods: A focus group was formed consisting of 11 radiology professionals from eight countries. Eight topics were submitted for discussion. The meeting was videotaped, transcribed, and analyzed according to the principles of qualitative healthcare research. Results: Perceived advantages of SR were facilitation of research, easy comparison, discouragement of ambiguous reports, embedded links to images, highlighting important findings, not having to dictate text nobody will read, and automatic translation of teleradiology reports. Being compelled to report within a rigid frame was judged unacceptable. Personal convictions appeared to have high emotional value. It was felt that other healthcare stakeholders would impose SR without regard to what radiologists thought of it. If the industry were to provide ready-made templates for selected examinations, most radiologists would use them. Conclusion: If radiologists can be convinced of the advantages of SR and the risks associated with failing to participate actively in its implementation, they will take a positive stand. The industry should propose technology allowing SR without compromising accuracy, completeness, workflows, and cost-benefit balance. Main Messages: • Structured reporting offers radiologists opportunities to improve their service to other stakeholders.• If radiologists can be convinced of the advantages of structured reporting, they may become early adopters.• The healthcare industry should propose technology allowing structured reporting.• Structured reporting will fail if it compromises accuracy, completeness, workflows or cost-benefit balance. © 2012 European Society of Radiology.","Advantages; Obstacles; Qualitative healthcare research; Radiology; Structured reporting",,Article,Scopus
"Sevenster M., Van Ommering R., Qian Y.","Automatically correlating clinical findings and body locations in radiology reports using MedLEE",2012,"Journal of Digital Imaging",31,"10.1007/s10278-011-9411-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861639366&doi=10.1007%2fs10278-011-9411-0&partnerID=40&md5=300b477c45ec9cad26651c6ac556b415","In this paper, we describe and evaluate a system that extracts clinical findings and body locations from radiology reports and correlates them. The system uses Medical Language Extraction and Encoding System (MedLEE) to map the reports' free text to structured semantic representations of their content. A lightweight reasoning engine extracts the clinical findings and body locations from MedLEE's semantic representation and correlates them. Our study is illustrative for research in which existing natural language processing software is embedded in a larger system. We manually created a standard reference based on a corpus of neuro and breast radiology reports. The standard reference was used to evaluate the precision and recall of the proposed system and its modules. Our results indicate that the precision of our system is considerably better than its recall (82.32-91.37% vs. 35.67-45.91%). We conducted an error analysis and discuss here the practical usability of the system given its recall and precision performance. © Society for Imaging Informatics in Medicine 2011.","BI-RADS; Data extraction; Knowledge base; Natural language processing","BI-RADS; Breast radiology; Data extraction; Free texts; Knowledge base; NAtural language processing; Precision and recall; Radiology reports; Reasoning engine; Recall and precision; Semantic representation; System use; Computational linguistics; Error analysis; Knowledge based systems; Radiation; Radiology; Semantics; Natural language processing systems; article; brain disease; breast disease; computer program; data mining; hospital information system; human; natural language processing; radiography; radiology; Brain Diseases; Breast Diseases; Data Mining; Humans; Natural Language Processing; Radiology; Radiology Information Systems; Software",Article,Scopus
"Emerman C.L., Gallagher M.A., Diaz P.J.","Incidental radiology findings: Effectiveness of a radiology-electronic medical records interface system for improving communication",2012,"Journal of Clinical Outcomes Management",2,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84858168148&partnerID=40&md5=4d26f91429e8375bbf2628da998acdad","• Objective: To report on a quality assurance program to improve communication with regard to radiologic findings. • Methods: Quality improvement report. • Results: Incidental findings requiring follow-up are common occurrences, particularly for thoracoabdominal CT scans. We found that many of these findings do not have a follow-up plan documented in the medical record. We significantly improved the rate of documented communication using technology that recognizes text strings in the radiology report. • Conclusion: An automated system of recognizing incidental findings notations in the radiology reports through an electronic medical records system that generated reports to clinicians and letters to patients improves patient safety.",,"article; automation; communication protocol; computer network; electronic medical record; hospital information system; human; incidental finding; major clinical study; medical documentation; medical information; patient safety; quality control; radiodiagnosis",Article,Scopus
"Lakhani P., Kim W., Langlotz C.P.","Automated detection of critical results in radiology reports",2012,"Journal of Digital Imaging",40,"10.1007/s10278-011-9426-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861326925&doi=10.1007%2fs10278-011-9426-6&partnerID=40&md5=6b089155f8add9d21e094776187299d2","The goal of this study was to develop and validate text-mining algorithms to automatically identify radiology reports containing critical results including tension or increasing/new large pneumothorax, acute pulmonary embolism, acute cholecystitis, acute appendicitis, ectopic pregnancy, scrotal torsion, unexplained free intraperitoneal air, new or increasing intracranial hemorrhage, and malpositioned tubes and lines. The algorithms were developed using rule-based approaches and designed to search for common words and phrases in radiology reports that indicate critical results. Certain text-mining features were utilized such as wildcards, stemming, negation detection, proximity matching, and expanded searches with applicable synonyms. To further improve accuracy, the algorithms utilized modality and examspecific queries, searched under the ""Impression"" field of the radiology report, and excluded reports with a low level of diagnostic certainty. Algorithm accuracy was determined using precision, recall, and F-measure using human review as the reference standard. The overall accuracy (F-measure) of the algorithms ranged from 81% to 100%, with a mean precision and recall of 96% and 91%, respectively. These algorithms can be applied to radiology report databases for quality assurance and accreditation, integrated with existing dashboards for display and monitoring, and ported to other institutions for their own use. © Society for Imaging Informatics in Medicine 2011.","Algorithms; Communication; Critical Results Reporting; Data Mining; Natural Language Processing; Quality Assurance; Quality Control","Acute appendicitis; Automated detection; Ectopic pregnancies; F-measure; Intracranial hemorrhages; Intraperitoneal; Low level; Mean precision; NAtural language processing; Proximity matching; Pulmonary embolism; Radiology reports; Reference standard; Results reporting; Rule-based approach; Text-mining; Accreditation; Communication; Computational linguistics; Data mining; Natural language processing systems; Quality assurance; Quality control; Radiation; Radiology; Algorithms; algorithm; article; automated pattern recognition; clinical pathway; data mining; factual database; hospital information system; human; information retrieval; methodology; radiology; research; validation study; Algorithms; Critical Pathways; Data Mining; Databases, Factual; Humans; Information Storage and Retrieval; Pattern Recognition, Automated; Radiology; Radiology Information Systems; Research Report",Article,Scopus
"Zopf J.J., Langer J.M., Boonn W.W., Kim W., Zafar H.M.","Development of automated detection of radiology reports citing adrenal findings",2012,"Journal of Digital Imaging",10,"10.1007/s10278-011-9425-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861312758&doi=10.1007%2fs10278-011-9425-7&partnerID=40&md5=afc6ea67f90dcee849e5da8818d50815","The aim of this study was to determine the feasibility of automated detection of adrenal nodules, a common finding on CT, using a newly developed search engine that mines dictated radiology reports. To ensure Health Insurance Portability and Accountability Act compliance, we utilized a preexisting de-identified database of 32,974 CT reports from February 1, 2009 to February 28, 2010. Common adrenal descriptors from 29 staff radiologists were used to develop an automated rule-based algorithm targeting adrenal findings. Each sentence within the free text of reports was searched with an adapted NegEx negation algorithm. The algorithm was refined using a 2- week test period of reports and subsequently validated using a 6-week period. Manual review of the 3,693 CT reports in the validation period identified 222 positive reports while the algorithm detected 238 positive reports. The algorithm identified one true positive report missed on manual review for a total of 223 true positive reports. This resulted in a precision of 91% (217 of 238) and a recall of 97% (217 of 223). The sensitivity of the query was 97.3% (95% confidence interval (CI), 93.9-98.9%), and the specificity was 99.3% (95% CI, 99.1-99.6%). The positive predictive value of the algorithm was 91.0% (95% CI, 86.6-94.3%), and the negative predictive value was 99.8% (95% CI, 99.6-99.9%). The prevalence of true positive adrenal findings identified by the query (7.1%) was nearly identical to the true prevalence (7.2%). Automated detection of language describing common findings in imaging reports, such as adrenal nodules on CT, is feasible. © Society for Imaging Informatics in Medicine 2011.","Adrenal nodules; Computed tomography; Data mining; Natural language; Negation algorithm; Processing; Radiology information systems (RIS); Radiology reporting; Unstructured radiology reports","Adrenal nodules; Computed Tomography; Natural languages; Radiology information system; Radiology reporting; Radiology reports; Computerized tomography; Data mining; Health insurance; Processing; Radiation; Radiology; Search engines; Algorithms; adrenal gland; algorithm; article; automated pattern recognition; comparative study; computer assisted tomography; confidence interval; decision support system; factual database; feasibility study; health insurance; hospital information system; human; laboratory diagnosis; methodology; pathology; radiography; reproducibility; United States; Adrenal Glands; Algorithms; Confidence Intervals; Databases, Factual; Decision Making, Computer-Assisted; False Negative Reactions; False Positive Reactions; Feasibility Studies; Health Insurance Portability and Accountability Act; Humans; Pattern Recognition, Automated; Radiology Information Systems; Reproducibility of Results; Tomography, X-Ray Computed; United States",Article,Scopus
"Apostolova E., Tomuro N., Mongkolwat P., Demner-Fushman D.","Domain adaptation of coreference resolution for radiology reports",2012,"BioNLP@HLT-NAACL 2012 - Workshop on Biomedical Natural Language Processing, Proceedings",6,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084281242&partnerID=40&md5=a616f76e867f7e96239bac0ecb83b8b2","In this paper we explore the applicability of existing coreference resolution systems to a biomedical genre: radiology reports. Analysis revealed that, due to the idiosyncrasies of the domain, both the formulation of the problem of coreference resolution and its solution need significant domain adaptation work. We reformulated the task and developed an unsupervised algorithm based on heuristics for coreference resolution in radiology reports. The algorithm is shown to perform well on a test dataset of 150 manually annotated radiology reports. © 2012 Association for Computational Linguistics.",,"Natural language processing systems; Radiation; Radiology; Coreference resolution; Domain adaptation; Radiology reports; Resolution systems; Unsupervised algorithms; Statistical tests",Conference Paper,Scopus
"Prevedello L.M., Farkas C., Ip I.K., Cohen A.B., Mukundan S., Sodickson A.D., Khorasani R.","Large-scale automated assessment of radiologist adherence to the physician quality reporting system for stroke",2012,"Journal of the American College of Radiology",14,"10.1016/j.jacr.2012.01.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926231956&doi=10.1016%2fj.jacr.2012.01.014&partnerID=40&md5=661ca2b6e8462ee375d77c523903892a","Purpose: Physician Quality Reporting System (PQRS) measure 10 assesses the percentage of radiology reports for possible stroke that document the presence or absence of hemorrhage, mass, and acute infarction. Although it is an important report quality metric, determining adherence to this measure is often laborious, limiting its practical use. The aim of this study was to assess adherence to PQRS measure 10 using an automated approach to facilitate continuous measurement. A secondary goal was to identify explanatory variables that may affect adherence. Methods: To determine measure adherence, a computerized algorithm was built, validated, and executed on 4,045 reports from CT and MRI examinations performed between January 2008 and October 2010 in patients with suspected stroke. Radiologist adherence was measured, accounting for differences in imaging modality, the presence of abnormalities, and trainee participation in report creation. Results: Of 4,045 reports, 58.1% met the PQRS requirement, documenting all 3 components. Although the presence of infarct increased the chance of PQRS adherence (P <.001), the existence of hemorrhage had the opposite effect (P <.001). Reports that had trainee participation were more likely to be in accordance with PQRS standards (62% vs 47%, P <.001). After controlling for pertinent variables, more than 2-fold variation in individual PQRS adherence (27%-68%) remained (P <.001). Conclusions: A considerable portion of eligible radiology reports do not include all components proposed by PQRS measure 10. An important contributor to performance gaps resides in individual physician variability. By automating measurement and monitoring of radiologist PQRS performance, informatics tools may enable targeted interventions to improve report quality. © 2012 American College of Radiology.","imaging; NLP; PQRS; quality improvement reporting; stroke","accuracy; algorithm; article; brain hemorrhage; brain infarction; clinical assessment; computer program; female; human; male; medical documentation; medical student; physician attitude; Physician Quality Reporting System; practice guideline; radiologist; stroke; total quality management",Article,Scopus
"Lacson R., Prevedello L.M., Andriole K.P., Gill R., Lenoci-Edwards J., Roy C., Gandhi T.K., Khorasani R.","Factors associated with radiologists' adherence to fleischner society guidelines for management of pulmonary nodules",2012,"Journal of the American College of Radiology",69,"10.1016/j.jacr.2012.03.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926231337&doi=10.1016%2fj.jacr.2012.03.009&partnerID=40&md5=c838132a6088b257b4dfdb1d248640c9","Purpose: In 2005, the Fleischner Society guidelines (FSG) for managing pulmonary nodules detected on CT scans were published. The aim of this study was to evaluate adherence to the FSG, adjusting for demographic and clinical variables that may contribute to adherence. Methods: Radiology reports were randomly obtained for 1,100 chest and abdominal CT scans performed between January and June 2010 in a tertiary hospital's emergency department and outpatient clinics. An automated document retrieval system using natural language processing was used to identify patients with pulmonary nodules from the data set. Features relevant to evaluating variation in adherence to the FSG, including age, sex, race, nodule size, and scan site (eg, the emergency department) and type, were extracted by manual review from reports retrieved using natural language processing. All variables were entered into a logistic regression model. Results: Three hundred fifteen reports were identified to have pulmonary nodules, 75 of which were for patients with concurrent malignancies or aged < 35 years. Of the remaining 240 reports, 34% of recommendations for pulmonary nodules were adherent to the FSG. Nodule size demonstrated an association with guideline adherence, with adherence highest in the >4-mm to 6-mm nodule group (P =.04) and progressively diminishing for smaller and bigger nodules. Conclusions: Pulmonary nodules are prevalent findings on chest and abdominal CT scans. Although most radiologists recommend follow-up imaging for these findings, recommendations for pulmonary nodules were consistent with the FSG in 34% of radiology reports. Nodule size demonstrated an association with guideline adherence, after adjusting for key variables. © 2012 American College of Radiology.","Clinical practice; Guidelines; Pulmonary nodules","adult; computer assisted tomography; female; Fleischner Society guideline; human; lung nodule; major clinical study; male; practice guideline; radiologist; review",Article,Scopus
"Wagholikar A., Zuccon G., Nguyen A., Chu K., Martin S., Lai K., Greenslade J.","Clinician-driven automated classification of limb fractures from free-text radiology reports",2012,"CEUR Workshop Proceedings",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892631229&partnerID=40&md5=1e37809e4d2e658ab84d3e9420fe55c1","The aim of this research is to report initial experimental results and evaluation of a clinician-driven automated method that can address the issue of misdiagnosis from unstructured radiology reports. Timely diagnosis and reporting of patient symptoms in hospital emergency departments (ED) is a critical component of health services delivery. However, due to disperse information resources and vast amounts of manual processing of unstructured information, a point-of-care accurate diagnosis is often difficult. A rule-based method that considers the occurrence of clinician specified keywords related to radiological findings was developed to identify limb abnormalities, such as fractures. A dataset containing 99 narrative reports of radiological findings was sourced from a tertiary hospital. The rule-based method achieved an F-measure of 0.80 and an accuracy of 0.80. While our method achieves promising performance, a number of avenues for improvement were identified using advanced natural language processing (NLP) techniques.","Classification; Emergency department; Limb fractures; Machine learning; Radiology reports; Rule-based method","Artificial intelligence; Classification (of information); Emergency rooms; Fracture; Learning algorithms; Learning systems; Natural language processing systems; Radiation; Text processing; Automated classification; Emergency departments; Health services deliveries; Hospital emergency departments; NAtural language processing; Radiology reports; Rule-based method; Unstructured radiology reports; Radiology",Conference Paper,Scopus
"Roberts K., Rink B., Harabagiu S.M., Scheuermann R.H., Toomay S., Browning T., Bosler T., Peshock R.","A machine learning approach for identifying anatomical locations of actionable findings in radiology reports.",2012,"AMIA ... Annual Symposium proceedings / AMIA Symposium. AMIA Symposium",18,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880840399&partnerID=40&md5=490f0dae867107d1ebf5a201b8e04e98","Recognizing the anatomical location of actionable findings in radiology reports is an important part of the communication of critical test results between caregivers. One of the difficulties of identifying anatomical locations of actionable findings stems from the fact that anatomical locations are not always stated in a simple, easy to identify manner. Natural language processing techniques are capable of recognizing the relevant anatomical location by processing a diverse set of lexical and syntactic contexts that correspond to the various ways that radiologists represent spatial relations. We report a precision of 86.2%, recall of 85.9%, and F(1)-measure of 86.0 for extracting the anatomical site of an actionable finding. Additionally, we report a precision of 73.8%, recall of 69.8%, and F(1)-measure of 71.8 for extracting an additional anatomical site that grounds underspecified locations. This demonstrates promising results for identifying locations, while error analysis reveals challenges under certain contexts. Future work will focus on incorporating new forms of medical language processing to improve performance and transitioning our method to new types of clinical data.",,"anatomy; appendicitis; article; artificial intelligence; hospital information system; human; methodology; natural language processing; pathology; radiography; Unified Medical Language System; Anatomy; Appendicitis; Artificial Intelligence; Humans; Natural Language Processing; Radiology Information Systems; Unified Medical Language System",Article,Scopus
"Stewart M.J., Georgiou A., Hordern A., Dimigen M., Westbrook J.I.","What do radiology incident reports reveal about in-hospital communication processes and the use of health information technology?",2012,"Studies in Health Technology and Informatics",11,"10.3233/978-1-61499-078-9-213","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84868283727&doi=10.3233%2f978-1-61499-078-9-213&partnerID=40&md5=cac77f868c003619cabbab07798b62d6","Background: There has been recent rapid growth in the use of medical imaging leading to concerns about an increase in unnecessary investigations, patient exposure to radiation, and incorrect diagnoses. Incident reporting systems provide a portal for staff to catalogue adverse events which occur within a hospital or department. Analysing incident reports can reveal trends and provide guidance for quality improvement efforts. Methods: Classification of medical imaging related-incidents from a major teaching hospital in Sydney, Australia using WHO International Classification for Patient Safety (ICPS) taxonomy. All incidents with radiology identified as incident location (n=219) were extracted. Incidents were from January 2005 to October 2011. Two researchers independently cleaned the data set. One researcher then applied the ICPS to free text incident reports. Results: 216 unique incidents were extracted. 15 incidents were unable to be classified using the ICPS. 8 incidents were classified twice, resulting in 209 coded incidents. Communication breakdown was a contributing factor in 49% (103/209) of incidents reported. 147 of the 209 incidents were associated with activities associated with data collection, storage or retrieval of electronic information. Health information technology (HIT) systems were mentioned explicitly in 10% of incidents, indicating some contribution to the error. Conclusions: Communication breakdown and HIT systems are contributors to error, and should be addressed. HIT systems need to be monitored and flaws addressed to ensure quality care. © 2012 The authors and IOS Press. All rights reserved.","Classification; Diagnostic imaging; Hospital incident reporting; Medical errors; Medical informatics","Classification (of information); Diagnosis; Digital storage; Errors; Hospitals; Hybrid integrated circuits; Public health; Radiation; Radiology; Communication breakdowns; Diagnostic imaging; Electronic information; Health information technologies; Health information technologies (HIT); Incident reporting systems; Medical errors; Medical informatics; Medical imaging; article; Australia; diagnostic imaging; hospital management; human; medical error; medical informatics; radiology department; risk management; standard; teaching hospital; Diagnostic Imaging; Hospital Communication Systems; Hospitals, Teaching; Humans; Medical Errors; Medical Informatics; New South Wales; Radiology Department, Hospital; Risk Management",Conference Paper,Scopus
"Stramare R., Scattolin G., Beltrame V., Gerardi M., Sommavilla M., Gatto C., Mosca P., Rubaltelli L., Rossi C.R., Saccavini C.","Structured reporting using a shared indexed multilingual radiology lexicon",2012,"International Journal of Computer Assisted Radiology and Surgery",6,"10.1007/s11548-011-0663-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865784634&doi=10.1007%2fs11548-011-0663-4&partnerID=40&md5=a09247985da76ea72d9b2bef5e0d23e7","Purpose: A system for creating structured reports (SRs) using a standardized radiology lexicon was developed and tested to facilitate automated translation of content and multidisciplinary international communications. Methods: A database of radiology terms, RadLex developed by the Radiological Society of North America, was used to create a shared indexed multilingual radiology lexicon. A diagnostic workstation for generating structured reports (OpenEye) was implemented with a ""RadLex manager"" function for adding new words to the lexicon in both English and Italian. Sample reports of examinations included in the Medical Imaging Resource Center (MIRC) radiology imaging database of clinical cases were prepared using this system. The system was evaluated for teaching purposes and scientific dissemination. Results: The OpenEye system was able to manage the glossary to create new SRs and manually translate existing reports containing freely worded descriptions. The OpenEye system provides instant translation from Italian into English and enables clinical cases to be published in the MIRC, while making them accessible for consultation on an international scale. Conclusion: The SR is advantageous compared with a freely worded report in terms of clarity and completeness of the content. Creating SRs for each clinical case enables rapid and focused analysis at multidisciplinary meetings. All our cases have been included in the MIRC database as part of a broader-based European Project for research on soft tissues sarcomas (CONTICANET). © CARS 2011.","CONTICANET; MIRC; RadLex; Structured report","article; autoanalyzer; automation; book; clinical assessment tool; clinical research; computer program; consultation; data base; english language; human; imaging and display; information dissemination; interpersonal communication; Italian; language; multilingual radiology lexicon; priority journal; radiology; structured reporting; teaching",Article,Scopus
"Danforth K.N., Early M.I., Ngan S., Kosco A.E., Zheng C., Gould M.K.","Automated identification of patients with pulmonary nodules in an integrated health system using administrative health plan data, radiology reports, and natural language processing",2012,"Journal of Thoracic Oncology",53,"10.1097/JTO.0b013e31825bd9f5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863849846&doi=10.1097%2fJTO.0b013e31825bd9f5&partnerID=40&md5=2a5f53059a10cf9d3b39add5ba4c89dc","INTRODUCTION:: Lung nodules are commonly encountered in clinical practice, yet little is known about their management in community settings. An automated method for identifying patients with lung nodules would greatly facilitate research in this area. METHODS:: Using members of a large, community-based health plan from 2006 to 2010, we developed a method to identify patients with lung nodules, by combining five diagnostic codes, four procedural codes, and a natural language processing algorithm that performed free text searches of radiology transcripts. An experienced pulmonologist reviewed a random sample of 116 radiology transcripts, providing a reference standard for the natural language processing algorithm. RESULTS:: With the use of an automated method, we identified 7112 unique members as having one or more incident lung nodules. The mean age of the patients was 65 years (standard deviation 14 years). There were slightly more women (54%) than men, and Hispanics and non-whites comprised 45% of the lung nodule cohort. Thirty-six percent were never smokers whereas 11% were current smokers. Fourteen percent of the patients were subsequently diagnosed with lung cancer. The sensitivity and specificity of the natural language processing algorithm for identifying the presence of lung nodules were 96% and 86%, respectively, compared with clinician review. Among the true positive transcripts in the validation sample, only 35% were solitary and unaccompanied by one or more associated findings, and 56% measured 8 to 30 mm in diameter. CONCLUSIONS:: A combination of diagnostic codes, procedural codes, and a natural language processing algorithm for free text searching of radiology reports can accurately and efficiently identify patients with incident lung nodules, many of whom are subsequently diagnosed with lung cancer. Copyright © 2012 by the International Association for the Study of Lung Cancer.","lung cancer; lung nodules; natural language processing (NLP); pulmonary coin lesion; validation study","accuracy; aged; algorithm; article; automation; cohort analysis; computed tomographic angiography; computer assisted tomography; data analysis; female; health care system; Hispanic; human; lung cancer; lung nodule; male; natural language processing; patient identification; priority journal; sensitivity and specificity; smoking; validation process",Article,Scopus
"He J., De Rijke M., Sevenster M., Van Ommering R., Qian Y.","Generating links to background knowledge: A case study using narrative radiology reports",2011,"International Conference on Information and Knowledge Management, Proceedings",24,"10.1145/2063576.2063845","https://www.scopus.com/inward/record.uri?eid=2-s2.0-83055161588&doi=10.1145%2f2063576.2063845&partnerID=40&md5=7b309e9721bf7cf9fa312f2699376ed0","Automatically annotating texts with background information has recently received much attention. We conduct a case study in automatically generating links from narrative radiology reports to Wikipedia. Such links help users understand the medical terminology and thereby increase the value of the reports. Direct applications of existing automatic link generation systems trained on Wikipedia to our radiology data do not yield satisfactory results. Our analysis reveals that medical phrases are often syntactically regular but semantically complicated, e.g., containing multiple concepts or concepts with multiple modifiers. The latter property is the main reason for the failure of existing systems. Based on this observation, we propose an automatic link generation approach that takes into account these properties. We use a sequential labeling approach with syntactic features for anchor text identification in order to exploit syntactic regularities in medical terminology. We combine this with a sub-anchor based approach to target finding, which is aimed at coping with the complex semantic structure of medical phrases. Empirical results show that the proposed system effectively improves the performance over existing systems. © 2011 ACM.","automatic link generation; radiology reports; wikipedia","Automatic link generation; Background information; Background knowledge; Complex semantic structures; Empirical results; Existing systems; Medical terminologies; radiology reports; Syntactic features; Target finding; Text identification; Wikipedia; Knowledge management; Radiology; Semantics; Syntactics; Terminology; Radiation",Conference Paper,Scopus
"Hadimli K., Turhan Yöndem M.","Information retrieval from Turkish radiology reports without medical knowledge",2011,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"10.1007/978-3-642-24764-4_19","https://www.scopus.com/inward/record.uri?eid=2-s2.0-81855213214&doi=10.1007%2f978-3-642-24764-4_19&partnerID=40&md5=136d62b641db56f708e7d063bcd51d4e","It is observed that a person with no medical knowledge can still partially understand contents of Turkish radiology reports. Based on this observation, one rule based method and one data driven method for information retrieval from Turkish radiology reports are proposed. Both methods lack use of medical ontologies and medical lexicons in order to test the limits of the observation in isolation of other factors. © 2011 Springer-Verlag.",,"Data-driven methods; Medical knowledge; Medical ontology; One-rule; Radiology reports; Turkishs; Information retrieval; Ontology; Radiation; Radiology; Search engines",Conference Paper,Scopus
"Patton R.M., Rojas C.C., Beckerman B.G., Potok T.E.","A computational framework for search, discovery, and trending of patient health in radiology reports",2011,"Proceedings - 2011 1st IEEE International Conference on Healthcare Informatics, Imaging and Systems Biology, HISB 2011",,"10.1109/HISB.2011.4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-81355163940&doi=10.1109%2fHISB.2011.4&partnerID=40&md5=dca45c9707265643578456ddee9f9700","The healthcare industry as a whole lags far behind other industries in terms of knowledge discovery capabilities. There are many piece-wise approaches to analysis of patient records. Unfortunately, there are few approaches that enable a completely automated approach that supports not just search, but also discovery and prediction of patient health. The work presented here describes a computational framework that provides near complete automation of the discovery and trending of patient characteristics. This approach has been successfully applied to the domain of mammography, but could be applied to other domains of radiology with minimal effort. © 2011 IEEE.","genetic algorithm; information retrieval; radiology; wavelets","Automated approach; Computational framework; Healthcare industry; Patient health; Patient record; Piece-wise; Radiology reports; wavelets; Genetic algorithms; Health care; Information retrieval; Radiation; Radiology; Information science",Conference Paper,Scopus
"Friedlin J., Mahoui M., Jones J., Jamieson P.","Knowledge discovery and data mining of free text radiology reports",2011,"Proceedings - 2011 1st IEEE International Conference on Healthcare Informatics, Imaging and Systems Biology, HISB 2011",14,"10.1109/HISB.2011.31","https://www.scopus.com/inward/record.uri?eid=2-s2.0-81355136264&doi=10.1109%2fHISB.2011.31&partnerID=40&md5=31aa6f9b141264ea2a325115f471c9b1","Medical Knowledge Discovery and Data Mining (KDD) over text is a promising yet difficult technology for unlocking meaning and uncovering associations in vast clinical text repositories. We report our experience in developing a new text analytic system called MEDAT or Medical Exploratory Data Analysis over Text, which overcomes several problems in text mining. The MEDAT system employs an annotated semantic index with a large number of assertions (propositions). The semantic index is able to capture complex assertions which encapsulate conceptual relationships including their modifiers at a granular level. The index represents semantically equivalent sentences with the same symbols, a necessary component for KDD semantic queries, including semantic Boolean and correlation queries. The graphical user interface enables users to perform complex semantic analysis of the Roentgen corpus, consisting of 594,000 de-identified radiology reports with 4.3 million sentences, without having to learn a programming language. The MEDAT architecture offers a novel framework for text mining in other medical domains. © 2011 IEEE.","Corpus Linguistics; Data Mining; Knowledge Discovery; Natural Language Processing; Semantic Annotation; Semantic Search; Text Analytics; Text Mining","Corpus linguistics; NAtural language processing; Semantic Annotation; Semantic Search; Text Analytics; Text mining; Computational linguistics; Data mining; Graphical user interfaces; Health care; Information science; Medical education; Medical imaging; Medical problems; Natural language processing systems; Radiation; Radiology; Semantics; Medical computing",Conference Paper,Scopus
"Martins V.F., De Assis Moura Jr. L.","An evaluation methodology for automatic transcription system of radiology reports",2011,"Communications in Computer and Information Science",3,"10.1007/978-3-642-24352-3_21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80054054154&doi=10.1007%2f978-3-642-24352-3_21&partnerID=40&md5=630a8a539b878c558fea067e4d0e92ee","This research combines knowledge from Computer Science and Health Science in order to propose an evaluation methodology for Automatic Transcription System of Radiology Reports. This methodology was designed based on Voice User interface requirements and specific requirements of automatic transcription systems of Radiology report. The same methodology was previously validated through some inspections and usability tests outside the hospital environment and, afterwards, it was used in two hospitals in São Paulo city. This approach aims to reduce costs of testing and available time by radiologists interviewed. Thus, the final product in this work consists of a set of criteria for evaluation of usability, comprising the name of the metric, evaluating method, steps to be followed and material to be used. By the use of this set, the evaluators can process the results of each requirement from the software. © 2011 Springer-Verlag.","Automatic Transcription System of Radiology Reports; Dictation System; Usability Evaluation; Voice User Interface","Automatic transcription; Dictation System; Evaluating method; Evaluation methodologies; Health science; Hospital environment; Radiology reports; Usability evaluation; Usability tests; Voice User Interface; Hospitals; Information systems; Radiation; Radiology; Transcription; User interfaces",Conference Paper,Scopus
"Ten J.I., Fernandez J.M., Vaño E.","Automatic management system for dose parameters in interventional radiology and cardiology",2011,"Radiation Protection Dosimetry",19,"10.1093/rpd/ncr350","https://www.scopus.com/inward/record.uri?eid=2-s2.0-81255179264&doi=10.1093%2frpd%2fncr350&partnerID=40&md5=ba46e37c5447eac696f6b9a7a05083b2","The purpose of this work was to develop an automatic management system to archive and analyse the major study parameters and patient doses for fluoroscopy guided procedures performed in cardiology and interventional radiology systems. The X-ray systems used for this trial have the capability to export at the end of the procedure and via e-mail the technical parameters of the study and the patient dose values. An application was developed to query and retrieve from a mail server, all study reports sent by the imaging modality and store them on a Microsoft SQL Server data base. The results from 3538 interventional study reports generated by 7 interventional systems were processed. In the case of some technical parameters and patient doses, alarms were added to receive malfunction alerts so as to immediately take appropriate corrective actions. © The Author 2011. Published by Oxford University Press. All rights reserved.",,"article; automation; cardiology; fluoroscopy; hospital information system; human; instrumentation; interventional radiology; methodology; radiation dose; radiation monitoring; radiation protection; Automation; Cardiology; Fluoroscopy; Humans; Radiation Dosage; Radiation Monitoring; Radiation Protection; Radiology Information Systems; Radiology, Interventional",Article,Scopus
"Charnock P., Jones R., Fazakerley J., Wilde R., Dunn A.F.","A preliminary study into performing routine tube output and automatic exposure control quality assurance using radiology information system data",2011,"Radiation Protection Dosimetry",,"10.1093/rpd/ncr303","https://www.scopus.com/inward/record.uri?eid=2-s2.0-81255173057&doi=10.1093%2frpd%2fncr303&partnerID=40&md5=3e8ed5209be47d786ff55aa3d1146938","Data are currently being collected from hospital radiology information systems in the North West of the UK for the purposes of both clinical audit and patient dose audit. Could these data also be used to satisfy quality assurance (QA) requirements according to UK guidance? From 2008 to 2009, 731 653 records were submitted from 8 hospitals from the North West England. For automatic exposure control QA, the protocol from Institute of Physics and Engineering in Medicine (IPEM) report 91 recommends that milliamperes per second can be monitored for repeatability and reproducibility using a suitable phantom, at 70-81 kV. Abdomen AP and chest PA examinations were analysed to find the most common kilovoltage used with these records then used to plot average monthly milliamperes per second with time. IPEM report 91 also recommends that a range of commonly used clinical settings is used to check output reproducibility and repeatability. For each tube, the dose area product values were plotted over time for two most common exposure factor sets. Results show that it is possible to do performance checks of AEC systems; however more work is required to be able to monitor tube output performance. Procedurally, the management system requires work and the benefits to the workflow would need to be demonstrated. © The Author 2011. Published by Oxford University Press. All rights reserved.",,"article; automation; body burden; health care quality; hospital information system; human; image processing; image quality; practice guideline; radiation dose; Automation; Body Burden; Humans; Image Processing, Computer-Assisted; Phantoms, Imaging; Practice Guidelines as Topic; Quality Assurance, Health Care; Radiation Dosage; Radiology Information Systems",Article,Scopus
"Chang C.A., Strahan R., Jolley D.","Non-clinical errors using voice recognition dictation software for radiology reports: A retrospective audit",2011,"Journal of Digital Imaging",29,"10.1007/s10278-010-9344-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80053917639&doi=10.1007%2fs10278-010-9344-z&partnerID=40&md5=20c4a491b33b828a9d89d05e49bb48de","The purpose of this study is to ascertain the error rates of using a voice recognition (VR) dictation system. We compared our results with several other articles and discussed the pros and cons of using such a system. The study was performed at the Southern Health Department of Diagnostic Imaging, Melbourne, Victoria using the GE RIS with Powerscribe 3.5 VR system. Fifty random finalized reports from 19 radiologists obtained between June 2008 and November 2008 were scrutinized for errors in six categories namely, wrong word substitution, deletion, punctuation, other, and nonsense phrase. Reports were also divided into two categories: computer radiography (CR= plain film) and non-CR (ultrasound, computed tomography, magnetic resonance imaging, nuclear medicine, and angiographic examinations). Errors were divided into two categories, significant but not likely to alter patient management and very significant with the meaning of the report affected, thus potentially affecting patient management (nonsense phrase). Three hundred seventy-nine finalized CR reports and 631 non-CR finalized reports were examined. Eleven percent of the reports in the CR group had errors. Two percent of these reports contained nonsense phrases. Thirty-six percent of the reports in the non-CR group had errors and out of these, 5% contained nonsense phrases. VR dictation system is like a double-edged sword. Whilst there are many benefits, there are also many pitfalls. We hope that raising the awareness of the error rates will help in our efforts to reduce error rates and strike a balance between quality and speed of reports generated. © Society for Imaging Informatics in Medicine 2010.","Productivity; Radiology reporting; Reporting; Speech recognition; Voice recognition; Workflow","Computed Tomography; Diagnostic imaging; Error rate; Melbourne; Patient management; Radiology reporting; Radiology reports; Reporting; VR systems; Workflow; Computerized tomography; Magnetic resonance imaging; Management; Nuclear medicine; Productivity; Radiation; Radiology; Random errors; Tomography; Speech recognition; article; Australia; automatic speech recognition; documentation; electronic medical record; hospital information system; human; methodology; reproducibility; retrospective study; sensitivity and specificity; standard; Documentation; Humans; Medical Records Systems, Computerized; Radiology Information Systems; Reproducibility of Results; Retrospective Studies; Sensitivity and Specificity; Speech Recognition Software; Victoria",Article,Scopus
"Iv M., Patel M.R., Santos A., Kang Y.S.","Informatics in radiology: Use of a macro scripting editor to facilitate transfer of dual-energy x-ray absorptiometry reports into an existing departmental voice recognition dictation system",2011,"Radiographics",9,"10.1148/rg.314105741","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79960528603&doi=10.1148%2frg.314105741&partnerID=40&md5=5eb684b08e0e1a6e4efbf6febb95fafb","The process of verbally reporting or manually retyping numeric data generated at dual-energy x-ray absorptiometry (DXA) involves numerous pitfalls. With use of a macro scripting editor, a customized macro was created to automate the transfer of data generated by a DXA scanner into a structured voice recognition dictation system without requiring radiologists to type in a medical record number or accession number to identify the study. A preliminary report is generated with use of software for a DXA unit and a customized template that includes numeric and qualitative assessments of osteoporosis as well as data from prior studies if available. A customized macro is then invoked by the macro scripting editor, which selectively transfers the report from the draft document into the voice recognition dictation system, thereby producing a final structured diagnostic report. All of the radiologists surveyed to evaluate this automated method reported ease of software use and greater efficiency in report production. In addition, a random audit of the 800 DXA scans that have been reported with this technique demonstrated no reports generated under an incorrect accession number and no incorrect transfer of data. Automated DXA reporting is now the preferred method of dictation at the authors' institution and represents an inexpensive, accurate, and customizable means of DXA reporting. © RSNA, 2011.",,"article; automatic speech recognition; automation; computer interface; computer program; hospital information system; medical informatics; methodology; organization and management; photon absorptiometry; radiology; United States; Absorptiometry, Photon; Medical Informatics; Radiology; Radiology Information Systems; Software; Software Design; Speech Recognition Software; United States; User-Computer Interface; Word Processing",Article,Scopus
"Zopf J., Langer J., Boonn W., Kim W., Zafar H.","Development of automated detection of radiology reports citing adrenal findings",2011,"Progress in Biomedical Optics and Imaging - Proceedings of SPIE",,"10.1117/12.881252","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79957938817&doi=10.1117%2f12.881252&partnerID=40&md5=5c4bf7c1377264d420d527b10cc5a810","Indeterminate incidental findings pose a challenge to both the radiologist and the ordering physician as their imaging appearance is potentially harmful but their clinical significance and optimal management is unknown. We seek to determine if it is possible to automate detection of adrenal nodules, an indeterminate incidental finding, on imaging examinations at our institution. Using PRESTO (Pathology-Radiology Enterprise Search tool), a newly developed search engine at our institution that mines dictated radiology reports, we searched for phrases used by attendings to describe incidental adrenal findings. Using these phrases as a guide, we designed a query that can be used with the PRESTO index. The results were refined using a modified version of NegEx to eliminate query terms that have been negated within the report text. In order to validate these findings we used an online random date generator to select two random weeks. We queried our RIS database for all reports created on those dates and manually reviewed each report to check for adrenal incidental findings. This survey produced a ground- truth dataset of reports citing adrenal incidental findings against which to compare query performance. We further reviewed the false positives and negatives identified by our validation study, in an attempt to improve the performance query. This algorithm is an important step towards automating the detection of incidental adrenal nodules on cross sectional imaging at our institution. Subsequently, this query can be combined with electronic medical record data searches to determine the clinical significance of these findings through resultant follow-up. © 2011 Copyright Society of Photo-Optical Instrumentation Engineers (SPIE).","adrenal incidental findings; automated detection","Automated detection; Cross-sectional imaging; Data searches; Data sets; Electronic medical record; Enterprise searches; False positive; Incidental findings; Optimal management; Query performance; Query terms; Radiology reports; Validation study; Information science; Medical computing; Radiation; Radiology; Search engines; Medical imaging",Conference Paper,Scopus
"Horii S.C., Kim W., Boonn W., Iyoob C., Maston K., Coleman B.G.","Utility of rapid database searching for quality assurance: 'Detective work' in uncovering radiology coding and billing errors",2011,"Progress in Biomedical Optics and Imaging - Proceedings of SPIE",,"10.1117/12.878816","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79957937665&doi=10.1117%2f12.878816&partnerID=40&md5=27be8ed4c15d52d99026a8e2e4300ca4","When the first quarter of 2010 Department of Radiology statistics were provided to the Section Chiefs, the authors (SH, BC) were alarmed to discover that Ultrasound showed a decrease of 2.5 percent in billed examinations. This seemed to be in direct contradistinction to the experience of the ultrasound faculty members and sonographers. Their experience was that they were far busier than during the same quarter of 2009. The one exception that all acknowledged was the month of February, 2010 when several major winter storms resulted in a much decreased Hospital admission and Emergency Department visit rate. Since these statistics in part help establish priorities for capital budget items, professional and technical staffing levels, and levels of incentive salary, they are taken very seriously. The availability of a desktop, Web-based RIS database search tool developed by two of the authors (WK, WB) and built-in database functions of the ultrasound miniPACS, made it possible for us very rapidly to develop and test hypotheses for why the number of billable examinations was declining in the face of what experience told the authors was an increasing number of examinations being performed. Within a short time, we identified the major cause as errors on the part of the company retained to verify billable Current Procedural Terminology (CPT) codes against ultrasound reports. This information is being used going forward to recover unbilled examinations and take measures to reduce or eliminate the types of coding errors that resulted in the problem. © 2011 Copyright Society of Photo-Optical Instrumentation Engineers (SPIE).","data mining; databases; economics; quality assurance; search","Capital budgets; Database searches; Database searching; databases; Emergency departments; Faculty members; First quarter; Hospital admissions; Mini-PACS; search; Sonographers; Staffing level; Winter storms; Database systems; Hospitals; Information retrieval; Information science; Medical applications; Medical computing; Medical imaging; Quality assurance; Quality control; Radiation; Radiology; Search engines; Storms; Ultrasonics; User interfaces; Wages; Coding errors",Conference Paper,Scopus
"Petrick N., Kim H.J.G., Clunie D., Borradaile K., Ford R., Zeng R., Gavrielides M.A., McNitt-Gray M.F., Fenimore C., Lu Z.Q.J., Zhao B., Buckler A.J.","Evaluation of 1D, 2D and 3D nodule size estimation by radiologists for spherical and non-spherical nodules through CT thoracic phantom imaging",2011,"Progress in Biomedical Optics and Imaging - Proceedings of SPIE",7,"10.1117/12.878265","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79955773619&doi=10.1117%2f12.878265&partnerID=40&md5=a9003c167ab36142b3a2e1b108d34418","The purpose of this work was to estimate bias in measuring the size of spherical and non-spherical lesions by radiologists using three sizing techniques under a variety of simulated lesion and reconstruction slice thickness conditions. We designed a reader study in which six radiologists estimated the size of 10 synthetic nodules of various sizes, shapes and densities embedded within a realistic anthropomorphic thorax phantom from CT scan data. In this manuscript we report preliminary results for the first four readers (Reader 1-4). Two repeat CT scans of the phantom containing each nodule were acquired using a Philips 16-slice scanner at a 0.8 and 5 mm slice thickness. The readers measured the sizes of all nodules for each of the 40 resulting scans (10 nodules x 2 slice thickness x 2 repeat scans) using three sizing techniques (1D longest in-slice dimension; 2D area from longest in-slice dimension and corresponding longest perpendicular dimension; 3D semi-automated volume) in each of 2 reading sessions. The normalized size was estimated for each sizing method and an inter-comparison of bias among methods was performed. The overall relative biases (standard deviation) of the 1D, 2D and 3D methods for the four readers subset (Readers 1-4) were -13.4 (20.3), -15.3 (28.4) and 4.8 (21.2) percentage points, respectively. The relative biases for the 3D volume sizing method was statistically lower than either the 1D or 2D method (p<0.001 for 1D vs. 3D and 2D vs. 3D). © 2011 SPIE.","CT Imaging; Lung Nodules; Phantom Study; Reader Study; Reader Variability; Size Estimation","CT imaging; Lung Nodules; Phantom Study; Reader Study; Reader Variability; Size Estimation; Computer aided diagnosis; Computerized tomography; Estimation; Medical imaging; Spheres; Three dimensional",Conference Paper,Scopus
"Zimmerman S.L., Kim W., Boonn W.W.","Informatics in radiology automated structured reporting of imaging findings using the AIM standard and XML",2011,"Radiographics",36,"10.1148/rg.313105195","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79958025221&doi=10.1148%2frg.313105195&partnerID=40&md5=321f581a5de6a01ca4bc6c3f5ab76f2a","Quantitative and descriptive imaging data are a vital component of the radiology report and are frequently of paramount importance to the ordering physician. Unfortunately, current methods of recording these data in the report are both inefficient and error prone. In addition, the free-text, unstructured format of a radiology report makes aggregate analysis of data from multiple reports difficult or even impossible without manual intervention. A structured reporting work flow has been developed that allows quantitative data created at an advanced imaging workstation to be seamlessly integrated into the radiology report with minimal radiologist intervention. As an intermediary step between the workstation and the reporting software, quantitative and descriptive data are converted into an extensible markup language (XML) file in a standardized format specified by the Annotation and Image Markup (AIM) project of the National Institutes of Health Cancer Biomedical Informatics Grid. The AIM standard was created to allow image annotation data to be stored in a uniform machine-readable format. These XML files containing imaging data can also be stored on a local database for data mining and analysis. This structured work flow solution has the potential to improve radiologist efficiency, reduce errors, and facilitate storage of quantitative and descriptive imaging data for research. © RSNA, 2011.",,"article; computer interface; computer language; computer program; diagnostic imaging; hospital information system; human; medical informatics; organization and management; standard; system analysis; three dimensional imaging; United States; Diagnostic Imaging; Efficiency, Organizational; Humans; Imaging, Three-Dimensional; Medical Informatics Applications; Programming Languages; Radiology Information Systems; Software; Systems Integration; United States; User-Computer Interface",Article,Scopus
"Akhtar W., Ali A., Mirza K.","Impact of a voice recognition system on radiology report turnaround time: Experience from a non-english-speaking South Asian country",2011,"American Journal of Roentgenology",10,"10.2214/AJR.10.5426","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79957814031&doi=10.2214%2fAJR.10.5426&partnerID=40&md5=feb6656f7f4a1f8b58fac4852e710b29",[No abstract available],,"automatic speech recognition; computer assisted tomography; fluoroscopy; interventional radiology; language ability; letter; nuclear magnetic resonance imaging; nuclear medicine; priority journal; South Asia; turnaround time; work experience; workflow; comparative study; hospital information system; human; note; organization and management; Pakistan; radiology department; retrospective study; time; university hospital; Academic Medical Centers; Efficiency, Organizational; Humans; Pakistan; Radiology Department, Hospital; Radiology Information Systems; Retrospective Studies; Speech Recognition Software; Time Factors",Letter,Scopus
"Ip I.K., Mortele K.J., Prevedello L.M., Khorasani R.","Focal cystic pancreatic lesions: Assessing variation in radiologists' management recommendations",2011,"Radiology",67,"10.1148/radiol.10100970","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952994772&doi=10.1148%2fradiol.10100970&partnerID=40&md5=0a41c0ef8a7426a2002b62a102ba6102","Purpose: To estimate the prevalence of focal cystic pancreatic lesions (FCPLs) among patients undergoing computed tomographic (CT) or magnetic resonance (MR) imaging at one institution and to examine any variation in radiologists' recommendation practice pattern with regards to FCPLs. Materials and Methods: Institutional review board approval was obtained for this retrospective HIPPA-compliant study. The requirement to obtain informed consent was waived. A cohort of patients with FCPLs was identified from radiology reports by using natural language processing. Patient-specific (ie, age, sex, symptoms, history of pancreatitis), radiologist-specific (ie, years of experience, area of expertise), and FCPL-specific (ie, size, location, septation, calcification, mural nodularity, pancreatic duct involvement, and presence of multiple cysts) variables were obtained. The outcome measure was whether a follow-up study was recommended. A logistic regression model was used to identify relative recommendation rates after controlling for key explanatory variables. Results: Between January 1 and December 31, 2009, a total of 1067 FCPLs were identified in 765 patients. Prevalence rates ranged from 2.2% at CT to 15.9% at MR imaging. Radiologists recommended a follow-up imaging study in 23.7% of cases of a FCPL. A 2.8-fold difference in the rate of recommendation of further imaging existed across radiologists after controlling for explanatory variables such as lesion-, radiologist-, and patient-specific characteristics. A history of pancreatitis was associated with a nearly twofold decrease in recommending further imaging. Conclusion: FCPLs are common, and nearly one-quarter of radiology reports recommend at least one follow-up imaging study. Significant variation exists in the rate of recommendation for further imaging studies by radiologists, even after controlling for key explanatory variables. © RSNA, 2011.",,"aged; anamnesis; article; computer assisted tomography; controlled study; diagnostic accuracy; false negative result; false positive result; female; focal cystic pancreatic lesion; follow up; human; major clinical study; male; nuclear magnetic resonance imaging; pancreas disease; pancreatitis; prevalence; priority journal; radiologist; retrospective study; sensitivity and specificity; statistical model; Female; Humans; Magnetic Resonance Imaging; Male; Massachusetts; Middle Aged; Observer Variation; Pancreatic Cyst; Physician's Practice Patterns; Prevalence; Referral and Consultation; Reproducibility of Results; Risk Assessment; Risk Factors; Sensitivity and Specificity; Tomography, X-Ray Computed",Article,Scopus
"Lacson R., Khorasani R.","Practical examples of natural language processing in radiology",2011,"Journal of the American College of Radiology",11,"10.1016/j.jacr.2011.09.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928096721&doi=10.1016%2fj.jacr.2011.09.010&partnerID=40&md5=eef0351cbe23f311069da8d1afcc5af4",[No abstract available],,"accuracy; computer assisted tomography; data extraction; follow up; human; information retrieval; lung nodule; natural language processing; nuclear magnetic resonance imaging; radiology; review; total quality management; word recognition",Article,Scopus
"Lacson R., Khorasani R.","Natural language processing for radiology (Part 2)",2011,"Journal of the American College of Radiology",8,"10.1016/j.jacr.2011.04.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928096665&doi=10.1016%2fj.jacr.2011.04.019&partnerID=40&md5=744393e0d5ab1e82b6d8ecc38de286ef",[No abstract available],,"clinical research; decision support system; electronic medical record; health care quality; information retrieval; medical information system; natural language processing; radiology; short survey; workflow",Article,Scopus
"Yetisgen-Yildiz M., Gunn M.L., Xia F., Payne T.H.","Automatic identification of critical follow-up recommendation sentences in radiology reports.",2011,"AMIA ... Annual Symposium proceedings / AMIA Symposium. AMIA Symposium",30,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84874216941&partnerID=40&md5=7da0fd420922eae398bc2d97d43c6ffd","Communication of follow-up recommendations when abnormalities are identified on imaging studies is prone to error. When recommendations are not systematically identified and promptly communicated to referrers, poor patient outcomes can result. Using information technology can improve communication and improve patient safety. In this paper, we describe a text processing approach that uses natural language processing (NLP) and supervised text classification methods to automatically identify critical recommendation sentences in radiology reports. To increase the classification performance we enhanced the simple unigram token representation approach with lexical, semantic, knowledge-base, and structural features. We tested different combinations of those features with the Maximum Entropy (MaxEnt) classification algorithm. Classifiers were trained and tested with a gold standard corpus annotated by a domain expert. We applied 5-fold cross validation and our best performing classifier achieved 95.60% precision, 79.82% recall, 87.0% F-score, and 99.59% classification accuracy in identifying the critical recommendation sentences in radiology reports.",,"algorithm; article; classification; electronic medical record; hospital information system; human; information retrieval; knowledge base; methodology; natural language processing; radiology; semantics; Unified Medical Language System; validation study; Algorithms; Electronic Health Records; Humans; Information Storage and Retrieval; Knowledge Bases; Natural Language Processing; Radiology; Radiology Information Systems; Semantics; Unified Medical Language System",Article,Scopus
"Warden G.I., Lacson R., Khorasani R.","Leveraging terminologies for retrieval of radiology reports with critical imaging findings.",2011,"AMIA ... Annual Symposium proceedings / AMIA Symposium. AMIA Symposium",10,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865393337&partnerID=40&md5=5ffe60de1a4fe5607518c7fd8727ce53","Communication of critical imaging findings is an important component of medical quality and safety. A fundamental challenge includes retrieval of radiology reports that contain these findings. This study describes the expressiveness and coverage of existing medical terminologies for critical imaging findings and evaluates radiology report retrieval using each terminology. Four terminologies were evaluated: National Cancer Institute Thesaurus (NCIT), Radiology Lexicon (RadLex), Systemized Nomenclature of Medicine (SNOMED-CT), and International Classification of Diseases (ICD-9-CM). Concepts in each terminology were identified for 10 critical imaging findings. Three findings were subsequently selected to evaluate document retrieval. SNOMED-CT consistently demonstrated the highest number of overall terms (mean=22) for each of ten critical findings. However, retrieval rate and precision varied between terminologies for the three findings evaluated. No single terminology is optimal for retrieving radiology reports with critical findings. The expressiveness of a terminology does not consistently correlate with radiology report retrieval.",,"article; classification; hospital information system; human; International Classification of Diseases; linguistics; radiography; Systematized Nomenclature of Medicine; Humans; International Classification of Diseases; Radiography; Radiology Information Systems; Systematized Nomenclature of Medicine; Vocabulary, Controlled",Article,Scopus
"Gershanik E.F., Lacson R., Khorasani R.","Critical finding capture in the impression section of radiology reports.",2011,"AMIA ... Annual Symposium proceedings / AMIA Symposium. AMIA Symposium",30,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863321126&partnerID=40&md5=f14582d6eaceebd8906ad31d80902b3b","Radiology reports communicate imaging findings to ordering physicians. The substantial information in these reports often causes physicians to focus on the summarized ""impression"" section. This study evaluated how often a critical finding is documented in the report's ""impression"" section and describes how an automated application can improve documentation. A retrospective review of all chest CT scan reports finalized between October, 2009 and September, 2010 at an academic institution was performed. A natural language processing application was utilized to evaluate the frequency of reporting a pulmonary nodule in the ""impression"" section, versus the ""findings"" section of a report. Results showed 3,401 reports with documented pulmonary nodules in the ""findings"" section, compared to 2,162 in the ""impression"" section - a 36.4% difference. The study revealed significant discrepant documentation in the ""findings"" versus ""impression"" sections. Automated systems could improve such critical findings documentation and communication between ordering physicians and radiologists.",,"article; computer assisted tomography; hospital information system; human; lung; lung nodule; multiple pulmonary nodules; natural language processing; nomenclature; radiography; retrospective study; Humans; Lung; Multiple Pulmonary Nodules; Natural Language Processing; Radiology Information Systems; Retrospective Studies; Solitary Pulmonary Nodule; Terminology as Topic; Tomography, X-Ray Computed",Article,Scopus
"Bonciarelli G., Batacchi S., Biffi R., Buononato M., Damascelli B., Ghibaudo F., Orsi F., Pittiruti M., Scoppettuolo G., Verzè A., Borasi G., de Cicco M., Dosio R., Gazzo P., Maso R., Roman A., Ticha V., Venier G., Blackburn P., Goossens G.A., Santolucito J.B., Stas M., van Boxtel T., Vesely T.M., de Lutio E.","GAVeCeLT consensus statement on the correct use of totally implantable venous access devices for diagnostic radiology procedures",2011,"Journal of Vascular Access",16,"10.5301/JVA.2011.7736","https://www.scopus.com/inward/record.uri?eid=2-s2.0-83455257802&doi=10.5301%2fJVA.2011.7736&partnerID=40&md5=478a3e5497dc0b79535ec3abf86cd3da","The use of totally implantable venous access devices in radiology may be associated with complications such as occlusion of the system (because of the high density of some contrast), infection (if the port is not handled in aseptic conditions, using proper barrier protections), and mechanical complications due to the high-pressure administration of contrast by automatic injectors (so-called power injector), including extravasation of contrast media into the soft tissues, subintimal venous or myocardial injection, or serious damage to the device itself (breakage of the external connections, dislocation of the noncoring needle, or breakage of the catheter). The last problem - i.e., the damage of the device from a power injection - is not an unjustified fear, but a reality. A warning by the US Food and Drug Administration of July 2004 reports around 250 complications of this kind, referring to both port and central venous catheters and peripherally inserted central catheter systems, which occurred over a period of several years; in all cases, the damage occurred during the injection of contrast material by means of power injectors for computed tomography or magnetic resonance imaging procedures. Though the risk associated with the use of ports in radiodiagnostics is thus clear, it has been suggested that administration of the contrast material via the port may have some advantage in terms of image quality, increased comfort for the patient, and maybe more accurate reproducibility of the patient's own follow-up exams. This contention needs to be supported by evidence. Also, since many cancer patients who need frequent computed tomography studies already have totally implantable systems, it would seem reasonable to try to define how and when such systems may safely be used. The purpose of this consensus statement is to define recommendations based on the best available evidence, for the safe use of implantable ports in radiodiagnostics. © 2011 Wichtig Editore.","Contrast media; Extravasation; High pressure; Implantable ports; Power injection","contrast medium; heparin; contrast medium; diagnostic agent; adrenal gland; article; asepsis; body weight; cannula; catheter infection; catheter occlusion; central venous catheter; clinical practice; computer assisted tomography; consensus; contrast medium extravasation; cost effectiveness analysis; diabetes mellitus; flow rate; food and drug administration; gravity; groups by age; hand washing; human; indwelling catheter; infusion; injection site; kidney; lipid solubility; liver; medical education; osmolarity; pancreas; patient safety; practice guideline; pressure; radiodiagnosis; resistance blood vessel; syringe; unconsciousness; vascular access; vascular access device; vascularization; viscosity; central venous catheterization; equipment; equipment design; indwelling catheter; injection; instrumentation; interventional magnetic resonance imaging; interventional radiology; predictive value; risk assessment; risk factor; standard; Catheterization, Central Venous; Catheters, Indwelling; Contrast Media; Equipment Design; Equipment Failure; Humans; Injections; Magnetic Resonance Imaging, Interventional; Patient Safety; Predictive Value of Tests; Pressure; Radiography, Interventional; Risk Assessment; Risk Factors",Article,Scopus
"Heresbach D., Djabbari M., Riou F., Marcus C., Le Sidaner A., Pierredon-Foulogne M.A., Ponchon T., Boudiaf M., Seyrig J.A., Laumonier H., Luet D., Giraud-Cohen M., Pelletier A.L., Charachon A., Ramaholimihaso F., Bouillet P., Veyrac M., Ficarelli S., Vahedi K., Keruhel J., Lamouliatte H., Ridereau-Zins C., Bouhnik Y., Tissier M., Diris B., Zagdanski A.M., Josselin J.M., Hamonic S., Gandon Y.","Accuracy of computed tomographic colonography in a nationwide multicentre trial, and its relation to radiologist expertise",2011,"Gut",48,"10.1136/gut.2010.225623","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79953744512&doi=10.1136%2fgut.2010.225623&partnerID=40&md5=f16cf3a65e52c8c7239e3808cb02a7b9","Objective: Reports on the accuracy of computed tomographic colonography (CTC) mainly involve series from expert institutions. The aims of this study were to assess CTC accuracy in a nationwide population and to relate it to radiologist performance in their initial training. Design: Nationwide multicentre trial. Setting: Twenty-eight radiologists, working in 26 mostly academic clinical units, were involved in the study after having attended a formal specialised 2-day training session on CTC. They worked through a training set of 52 cases with automatic feedback after an attempt at each case. Patients: The study enrolled 845 patients with average and high risk of colorectal cancer, 737 of whom had both complete CTC and videocolonoscopy data, which constituted the dataset. Interventions: Patients underwent same-day CTC followed by videocolonoscopy with segmental unblinding of CTC results. Main outcome measures: Sensitivity, specificity and positive and negative predictive values for detection of polyps ≥6 mm in per-patient and per-lesion analyses of CTC without computer-aided detection. Results: Sensitivity, specificity and positive and negative predictive values for patients with polyps ≥6 mm were 69% (95% CI 61% to 77%), 91% (95% CI 89% to 94%), 67% (95% CI 59% to 74%) and 92% (95% CI 90% to 94%), respectively. Univariate analysis showed that the detection rate for polyps ≥6 mm was linked to neither radiologist case volume nor number of polyps, but was related to sensitivity achieved in the training set. Pooled sensitivity was 72% (95% CI 63% to 80%) versus 51% (95% CI 40% to 60%) for radiologists achieving above and below median sensitivity in the training set (61%), respectively. Multivariate analysis showed that sensitivity for polyps ≥6 mm in the training set was the only remaining significant predictive factor for subsequent performance. Conclusions: Radiologist sensitivity CTC for detection of polyps ≥6 mm in training was the sole independent predictor for subsequent sensitivity in detection of such polyps.",,"adult; aged; article; cancer risk; colon polyp; colonoscopy; colorectal cancer; computed tomographic colonography; continuing education; diagnostic accuracy; diagnostic value; female; human; major clinical study; male; multicenter study; occult blood; predictive value; priority journal; radiologist; rectum polyp; sensitivity and specificity; tumor volume; video colonoscopy; videoendoscopy",Article,Scopus
"Lakhani P., Langlotz C.P.","Automated detection of radiology reports that document non-routine communication of critical or significant results",2010,"Journal of Digital Imaging",19,"10.1007/s10278-009-9237-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650597124&doi=10.1007%2fs10278-009-9237-1&partnerID=40&md5=b9e74bdd1bf0fab5ac3ac4bd241cbb76","The purpose of this investigation is to develop an automated method to accurately detect radiology reports that indicate non-routine communication of critical or significant results. Such a classification system would be valuable for performance monitoring and accreditation. Using a database of 2.3 million free-text radiology reports, a rule-based query algorithm was developed after analyzing hundreds of radiology reports that indicated communication of critical or significant results to a healthcare provider. This algorithm consisted of words and phrases used by radiologists to indicate such communications combined with specific handcrafted rules. This algorithm was iteratively refined and retested on hundreds of reports until the precision and recall did not significantly change between iterations. The algorithm was then validated on the entire database of 2.3 million reports, excluding those reports used during the testing and refinement process. Human review was used as the reference standard. The accuracy of this algorithm was determined using precision, recall, and F measure. Confidence intervals were calculated using the adjusted Wald method. The developed algorithm for detecting critical result communication has a precision of 97.0% (95% CI, 93.5-98.8%), recall 98.2% (95% CI, 93.4-100%), and F measure of 97.6% (∈=∈1). Our query algorithm is accurate for identifying radiology reports that contain non-routine communication of critical or significant results. This algorithm can be applied to a radiology reports database for quality control purposes and help satisfy accreditation requirements. © 2009 Society for Imaging Informatics in Medicine.","Critical results reporting; data mining; Joint Commission on Accreditation of Healthcare Organizations (JCAHO); natural language processing; online analytical processing (OLAP); quality assurance; quality control; radiology reporting","Joint Commission on Accreditation of Healthcare Organizations (JCAHO); NAtural language processing; On-line analytical processing; radiology reporting; Results reporting; Accreditation; Algorithms; Civil aviation; Communication; Computational linguistics; Data mining; Database systems; Natural language processing systems; Quality assurance; Radiation; Radiology; Quality control; algorithm; article; automation; decision support system; doctor patient relation; hospital information system; human; information dissemination; neoplasm; practice guideline; radiography; Algorithms; Automation; Decision Making, Computer-Assisted; Humans; Information Dissemination; Neoplasms; Physician-Patient Relations; Practice Guidelines as Topic; Radiology Information Systems",Article,Scopus
"do B.H., Wu A., Biswal S., Kamaya A., Rubin D.L.","Informatics in Radiology RADTF: A Semantic Search-enabled, Natural Language Processor-generated radiology teaching file",2010,"Radiographics",33,"10.1148/rg.307105083","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78349272715&doi=10.1148%2frg.307105083&partnerID=40&md5=fc7313032d7e5a0a74bf47ba23b58590","Storing and retrieving radiology cases is an important activity for education and clinical research, but this process can be time-consuming. In the process of structuring reports and images into organized teaching files, incidental pathologic conditions not pertinent to the primary teaching point can be omitted, as when a user saves images of an aortic dissection case but disregards the incidental osteoid osteoma. An alternate strategy for identifying teaching cases is text search of reports in radiology information systems (RIS), but retrieved reports are unstructured, teaching-related content is not highlighted, and patient identifying information is not removed. Furthermore, searching unstructured reports requires sophisticated retrieval methods to achieve useful results. An open-source, RadLex®-compatible teaching file solution called RADTF, which uses natural language processing (NLP) methods to process radiology reports, was developed to create a searchable teaching resource from the RIS and the picture archiving and communication system (PACS). The NLP system extracts and de-identifies teaching-relevant statements from full reports to generate a stand-alone database, thus converting existing RIS archives into an on-demand source of teaching material. Using RADTF, the authors generated a semantic search-enabled, Web-based radiology archive containing over 700,000 cases with millions of images. RADTF combines a compact representation of the teaching-relevant content in radiology reports and a versatile search engine with the scale of the entire RIS-PACS collection of case material. ©RSNA, 2010.",,"article; computer interface; data mining; education; electronic medical record; hospital information system; medical informatics; methodology; natural language processing; radiology; semantics; teaching; Computer-Assisted Instruction; Data Mining; Medical Informatics Applications; Medical Records Systems, Computerized; Natural Language Processing; Radiology; Radiology Information Systems; Semantics; User-Computer Interface",Article,Scopus
"Patton R.M., Beckerman B.G., Potok T.E., Treadwell J.N.","Genetic algorithm for analysis of abdominal aortic aneurysms in radiology reports",2010,"Proceedings of the 12th Annual Genetic and Evolutionary Computation Conference, GECCO '10 - Companion Publication",,"10.1145/1830761.1830828","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955948742&doi=10.1145%2f1830761.1830828&partnerID=40&md5=33dd8a3c5240e113376848f6e6106eda","An abdominal aortic aneurysm is a problem in which the wall of the artery that supplies blood to the abdomen and lower extremities expands under pressure or balloons outward. Patients must undergo surgery to repair such an aneurysm, and there is currently no known indicator of long-term success or failure from this surgery. Our work uses a genetic algorithm to analyze radiology reports from these patients to look for common patterns in the language used as well as common features of both successful and unsuccessful surgeries. The results of the genetic algorithm show that patients with complications or unusual characteristics can be identified from a set of radiology reports without the use of search keywords, clustering, categorization, or ontology. This allows medical researchers to search and identify interesting patient records without the need for explicitly defining what ""interesting"" patient records are. © 2010 ACM.","Abdominal aortic aneurysm; Genetic algorithm; Medical knowledge discovery; Natural language processing","Abdominal aortic aneurysms; Common features; Lower extremity; Medical knowledge discovery; Medical researchers; NAtural language processing; Patient record; Radiology reports; Search keyword; Blood vessels; Computational linguistics; Genetic algorithms; Medical education; Natural language processing systems; Ontology; Radiation; Radiology; Surgery; Clustering algorithms",Conference Paper,Scopus
"Flynn R.W.V., Macdonald T.M., Schembri N., Murray G.D., Doney A.S.F.","Automated data capture from free-text radiology reports to enhance accuracy of hospital inpatient stroke codes",2010,"Pharmacoepidemiology and Drug Safety",23,"10.1002/pds.1981","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77956641332&doi=10.1002%2fpds.1981&partnerID=40&md5=ec5fbc319b797c4dfd3dfbe0af339d63","Purpose: Much potentially useful clinical information for pharmacoepidemiological research is contained in unstructured free-text documents and is not readily available for analysis. Routine health data such as Scottish Morbidity Records (SMR01) frequently use generic 'stroke' codes. Free-text Computerised Radiology Information System (CRIS) reports have potential to provide this missing detail. We aimed to increase the number of stroke-type-specific diagnoses by augmenting SMR01 with data derived from CRIS reports and to assess the accuracy of this methodology. Methods: SMR01 codes describing first-ever-stroke admissions in Tayside, Scotland from 1994 to 2005 were linked to CRIS CT-brain scan reports occurring with 14 days of admission. Software was developed to parse the text and elicit details of stroke type using keyword matching. An algorithm was iteratively developed to differentiate intracerebral haemorrhage (ICH) from ischaemic stroke (IS) against a training set of reports with pathophysiologically precise SMR01 codes. This algorithm was then applied to CRIS reports associated with generic SMR01 codes. To establish the accuracy of the algorithm a sample of 150 ICH and 150 IS reports were independently classified by a stroke physician. Results: There were 8419 SMR01 coded first-ever strokes. The proportion of patients with pathophysiologically clear diagnoses doubled from 2745 (32.6%) to 5614 (66.7%). The positive predictive value was 94.7% (95%CI 89.8-97.3) for IS and 76.7% (95%CI 69.3-82.7) for haemorrhagic stroke. Conclusions: A free-text processing approach was acceptably accurate at identifying IS, but not ICH. This approach could be adapted to other studies where radiology reports may be informative. Copyright © 2010 John Wiley & Sons, Ltd.","Brain infarction; Cerebral haemorrhage; Medical records; Natural language processing; Radiology information systems; Stroke","algorithm; article; automation; brain hemorrhage; brain ischemia; computer assisted tomography; computer program; hospital admission; hospital patient; human; medical record; pharmacoepidemiology; priority journal; stroke; United Kingdom; Algorithms; Cerebral Hemorrhage; Electronic Health Records; Female; Hospitals; Humans; Inpatients; Male; Radiology; Radiology Information Systems; Stroke; Tomography, X-Ray Computed",Article,Scopus
"Krishnaraj A., Lee J.K.T., Laws S.A., Crawford T.J.","Voice recognition software: Effect on radiology report turnaround time at an academic medical center",2010,"American Journal of Roentgenology",48,"10.2214/AJR.09.3169","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954738306&doi=10.2214%2fAJR.09.3169&partnerID=40&md5=784f351c24f7c115ca6319ddb8930e8d","OBJECTIVE. Previous studies have documented reductions in turnaround time after implementation of voice recognition software in the generation of radiology reports. Our preliminary observations suggested that improvement in report turnaround time varies among users. The purpose of this study was to analyze the effect of work habits and caseload on such variations. SUBJECTS AND METHODS. Data were collected for 9 months before and after the implementation of voice recognition after a 6-month training period. Thirty faculty members were ranked according to their report turnaround time before and after implementation of voice recognition and according to their percentage reduction in report turnaround time. The report turnaround times before and after implementation of voice recognition for faculty were compared with the number of verified reports and work habit type. RESULTS. The average report turnaround time for the department before implementation of voice recognition was 28 hours. After implementation of voice recognition, the average turnaround time was 12.7 hours, and the volume of verified reports increased 5% between the two study periods. The improvement in report turnaround time for individual faculty members ranged from -33% to +93%, and the rank order did not change significantly (Spearman coefficient, 0.58; p < 0.05). Faculty members' ranks in report turnaround time did not correlate significantly with volume rank before and after implementation of voice recognition (Spearman coefficients, 0.341 and 0.346; p > 0.05). Faculty members who had type 1 work habits, that is, reviewed, revised, and finalized reports at the time of image review, benefited the most from use of voice recognition. CONCLUSION. Use of voice recognition software decreased report turnaround time for the department and for 28 of 30 individual faculty members. Improvement in report turn-around time does not correlate with workload but does correlate with work habits, suggesting human behavior may play a role in determining the outcome of adopting a productivity-enhancing technology. © American Roentgen Ray Society.","Human behavior; Informatics; Report turnaround time; Voice recognition","article; automatic speech recognition; behavior; human; information processing; normal human; priority journal; radiology; turnaround time; university hospital; workload; Academic Medical Centers; Analysis of Variance; Efficiency, Organizational; Humans; Radiology Department, Hospital; Radiology Information Systems; Speech Recognition Software; Time Factors",Article,Scopus
"Cook T.S., Itri J.N., Boonn W.W., Kim W.","Analyzing how radiologists recommend follow-up: Toward development of an automated tracking and feedback system for clinical, laboratory, and radiologic studies",2010,"Progress in Biomedical Optics and Imaging - Proceedings of SPIE",,"10.1117/12.845971","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77953472780&doi=10.1117%2f12.845971&partnerID=40&md5=f4577acacdf36d9d93cc30a9c1a2d17f","Radiologists often recommend further imaging, laboratory or clinical follow-up as part of a study interpretation, but rarely receive feedback as to the results of these additional tests. In most cases, the radiologist has to actively pursue this information by searching through the multiple electronic medical records at our institution. In this work, we seek to determine if it would be possible to automate the feedback process by analyzing how radiologists phrase recommendations for clinical, laboratory or radiologic follow-up. We surveyed a dozen attending radiologists to create a set of phrases conventionally used to indicate the need for follow-up. Next, we mined dictated reports over a 1-year period to quantify the appearance of each of these phrases. We are able to isolate 5 phrases that appear in over 21,000 studies performed during the 1-year period, and classify them by modality. We also validated the query by evaluating one day's worth of reports for follow-up recommendations and assessing the comparative performance of the follow-up query. By automatically mining imaging reports for these key phrases and tracking these patients' electronic medical records for additional imaging or pathology, we can begin to provide radiologists with automated feedback regarding studies they have interpreted. Furthermore, we can analyze how often these recommendations lead to a definitive diagnosis and enable radiologists to adjust their practice and decision-making accordingly and ultimately improve patient care. © 2010 Copyright SPIE - The International Society for Optical Engineering.","automated feedback; Follow-up recommendations; radiology utilization","automated feedback; Automated tracking; Electronic medical record; Feedback process; Feedback systems; Key-phrase; Patient care; Automation; Decision making; Information science; Medical applications; Medical computing; Radiation; Radiology; Medical imaging",Conference Paper,Scopus
"Kim W., Boonn W.","Evaluation of an open source tool for indexing and searching enterprise radiology and pathology reports",2010,"Progress in Biomedical Optics and Imaging - Proceedings of SPIE",1,"10.1117/12.846772","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77953451835&doi=10.1117%2f12.846772&partnerID=40&md5=a1a26a68377a4dce2763202982ea6a46","Data mining of existing radiology and pathology reports within an enterprise health system can be used for clinical decision support, research, education, as well as operational analyses. In our health system, the database of radiology and pathology reports exceeds 13 million entries combined. We are building a web-based tool to allow search and data analysis of these combined databases using freely available and open source tools. This presentation will compare performance of an open source full-text indexing tool to MySQL's full-text indexing and searching and describe implementation procedures to incorporate these capabilities into a radiology-pathology search engine. © 2010 Copyright SPIE - The International Society for Optical Engineering.","data mining; open source; pathology; radiology; search engine","Clinical decision support; Data analysis; Health systems; open source; Open source tools; Open sources; Operational analysis; Text-indexing; Web-based tools; Data mining; Data reduction; Decision support systems; Indexing (of information); Information retrieval; Information science; Pathology; Radiation; Radiology; Search engines; World Wide Web; Medical imaging",Conference Paper,Scopus
"Welte F.J., Kim S.C., Doshi D.J., O'Connor S.C., Coughlin B.F.","Incorporation of a formalized emergency radiology curriculum to facilitate population of a MIRC-based digital teaching file",2010,"Journal of Digital Imaging",5,"10.1007/s10278-009-9178-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77952239116&doi=10.1007%2fs10278-009-9178-8&partnerID=40&md5=c8d0359fdca4caf1b7a3519d0d14855c","Teaching files are integral to radiological training. Digital Imaging and Communication in Medicine compatible digital radiological data and technological advances have made digital teaching files a desirable way to preserve and share representative and/or unusual cases for training purposes. The Medical Imaging Resource Community (MIRC) system developed by the Radiological Society of North America (RSNA) is a robust multi-platform digital teaching file implementation that is freely available. An emergency radiology training curriculum developed by the American Society of Emergency Radiology (ASER) was incorporated to determine if such an approach might facilitate the entry, maintenance, and cataloguing of interesting cases. The RSNA MIRC software was obtained from the main MIRC website and installed. A coding system was developed based on the outline form of the ASER curriculum. Weekly reports were generated tallying the number of cases in each category of the curriculum. Resident participation in the entry and maintenance of cases markedly increased after incorporation of the ASER curriculum. The coding schema facilitated progress assessment. Ultimately, 454 total cases were entered into the MIRC database, representing at least 42% of the subcategories within the ASER curriculum (161 out of 376). The incorporation of the ASER emergency radiology curriculum greatly facilitated the location, cataloguing, tracking, and maintenance of representative cases and served as an effective means by which to unify the efforts of the department to develop a comprehensive teaching resource within this subspecialty. This approach and format will be extended to other educational curricula in other radiological subspecialties. © 2009 Society for Imaging Informatics in Medicine.","Computer communication networks; Computers in medicine; Data mining; Database management systems; Electronic teaching file; Emergency radiology; Experiential; Extensible Markup Language (XML); Medical Imaging Resource Center (MIRC); Web technology","Computer communication networks; Data-base management systems; Electronic teaching file; Emergency radiology; Extensible markup language; Medical imaging resource centers; Web technologies; Computer networks; Computer resource management; Curricula; Data mining; Hypertext systems; Libraries; Linguistics; Maintenance; Management; Management information systems; Markup languages; Medical computing; Medical imaging; Query languages; Radiation; Radiology; XML; Medical education; article; clinical competence; computer program; curriculum; education; emergency treatment; female; hospital information system; human; image quality; information processing; information retrieval; instrumentation; medical education; medical informatics; methodology; radiology; teaching; Automatic Data Processing; Clinical Competence; Computer-Assisted Instruction; Curriculum; Education, Medical, Graduate; Educational Measurement; Emergency Treatment; Female; Humans; Information Storage and Retrieval; Internship and Residency; Medical Informatics; Radiographic Image Enhancement; Radiology; Radiology Information Systems; Software",Article,Scopus
"Reiner B.","Uncovering and improving upon the inherent deficiencies of radiology reporting through data mining",2010,"Journal of Digital Imaging",46,"10.1007/s10278-010-9279-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77952238485&doi=10.1007%2fs10278-010-9279-4&partnerID=40&md5=5538e15d8d762981761d8e8a26786ba0","Uncertainty has been the perceived Achilles heel of the radiology report since the inception of the free-text report. As a measure of diagnostic confidence (or lack thereof), uncertainty in reporting has the potential to lead to diagnostic errors, delayed clinical decision making, increased cost of healthcare delivery, and adverse outcomes. Recent developments in data mining technologies, such as natural language processing (NLP), have provided the medical informatics community with an opportunity to quantify report concepts, such as uncertainty. The challenge ahead lies in taking the next step from quantification to understanding, which requires combining standardized report content, data mining, and artificial intelligence; thereby creating Knowledge Discovery Databases (KDD). The development of this database technology will expand our ability to record, track, and analyze report data, along with the potential to create data-driven and automated decision support technologies at the point of care. For the radiologist community, this could improve report content through an objective and thorough understanding of uncertainty, identifying its causative factors, and providing data-driven analysis for enhanced diagnosis and clinical outcomes. © 2010 Society for Imaging Informatics in Medicine.","Data mining; Reporting; Uncertainty","Achilles heel; Adverse outcomes; Clinical decision making; Clinical outcome; Data mining technology; Data-driven; Data-driven analysis; Database technology; Decision supports; Healthcare delivery; Knowledge discovery database; Medical informatics; Natural language processing; Point of care; Radiology reporting; Radiology reports; Artificial intelligence; Computational linguistics; Data mining; Decision making; Decision support systems; Diagnosis; Information science; Natural language processing systems; Radiation; Radiology; Uncertainty analysis; Medical computing; clinical competence; clinical practice; computer assisted diagnosis; data base; forecasting; hospital information system; human; information dissemination; medical record; public relations; radiology; review; sensitivity and specificity; standard; total quality management; Clinical Competence; Database Management Systems; Forecasting; Humans; Image Interpretation, Computer-Assisted; Information Dissemination; Interprofessional Relations; Medical Records Systems, Computerized; Physician's Practice Patterns; Radiology; Radiology Information Systems; Sensitivity and Specificity; Total Quality Management",Article,Scopus
"Savova G.K., Fan J., Ye Z., Murphy S.P., Zheng J., Chute C.G., Kullo I.J.","Discovering peripheral arterial disease cases from radiology notes using natural language processing",2010,"AMIA ... Annual Symposium proceedings / AMIA Symposium. AMIA Symposium",60,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964959775&partnerID=40&md5=6c1991b58f3621b3c8c81416a647f415","As part of the Electronic Medical Records and Genomics Network, we applied, extended and evaluated an open source clinical Natural Language Processing system, Mayo's Clinical Text Analysis and Knowledge Extraction System, for the discovery of peripheral arterial disease cases from radiology reports. The manually created gold standard consisted of 223 positive, 19 negative, 63 probable and 150 unknown cases. Overall accuracy agreement between the system and the gold standard was 0.93 as compared to a named entity recognition baseline of 0.46. Sensitivity for the positive, probable and unknown cases was 0.93-0.96, and for the negative cases was 0.72. Specificity and negative predictive value for all categories were in the 90's. The positive predictive value for the positive and unknown categories was in the high 90's, for the negative category was 0.84, and for the probable category was 0.63. We outline the main sources of errors and suggest improvements.",,"algorithm; electronic medical record; human; natural language processing; peripheral occlusive artery disease; sensitivity and specificity; Algorithms; Electronic Health Records; Humans; Natural Language Processing; Peripheral Arterial Disease; Sensitivity and Specificity",Article,Scopus
"Womack J.A., Scotch M., Gibert C., Chapman W., Yin M., Justice A.C., Brandt C.","A comparison of two approaches to text processing: facilitating chart reviews of radiology reports in electronic medical records.",2010,"Perspectives in health information management / AHIMA, American Health Information Management Association",10,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952794925&partnerID=40&md5=793fe40ebb5869f9321959e7155641d3","Chart review is central to health services research. Text processing, which analyzes free-text fields through automated methods, can facilitate this process. We compared precision and accuracy of NegEx and SQLServer 2008 Free-Text Search in identifying acute fractures in radiology reports.The term ""fracture"" was included in 23,595 radiology reports from the Veterans Aging Cohort Study. Four hundred reports were randomly selected and manually reviewed for acute fractures to establish a gold standard. Reports were then processed by SQLServer and NegEx. Results were compared to the gold standard to determine accuracy, precision, recall, and F-statistic.NegEx and the gold standard identified acute fractures in 13 reports. SQLServer identified 2 in a report-based analysis (precision: 1.00; accuracy: 0.97; recall: 0.15; F-statistic: 0.26), and 12 in a sentence-by-sentence analysis (precision: 1.00; recall: 0.92; accuracy: 0.92; F-statistic: 0.96).Text-processing tools utilizing basic database or programming skills are comparable, precise, and accurate in identifying reports for review.",,"algorithm; article; cohort analysis; comparative study; electronic medical record; fracture; health services research; human; information retrieval; laboratory diagnosis; medical audit; methodology; natural language processing; radiography; radiology department; sensitivity and specificity; standard; United States; Algorithms; Cohort Studies; Electronic Health Records; False Negative Reactions; Fractures, Bone; Health Services Research; Humans; Information Storage and Retrieval; Medical Audit; Natural Language Processing; Radiology Department, Hospital; Sensitivity and Specificity; United States",Article,Scopus
"Salvador V.F.M., De Assis Moura Jr. L.","Evaluation methodology for automatic radiology reporting transcription systems",2010,"Studies in Health Technology and Informatics",2,"10.3233/978-1-60750-588-4-1246","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649518589&doi=10.3233%2f978-1-60750-588-4-1246&partnerID=40&md5=0a3be61b409516b3bf2f3cf82a416e24","This article describes a usability evaluation methodology for automatic transcription system used for radiology reporting. In order to assess this class of system's limitations and strengths, a review of the concepts involved in this kind of system is done in a critical way. Specific requirements, for this category of application, that are forgotten when a product is launched in the market, are listed and a methodology for their evaluation is presented. © 2010 IMIA and SAHIA. All rights reserved.","Automatic transcription system for reports; Usability evaluation; Voice user interface","Radiation; Radiology; Transcription; Automatic transcription; Evaluation methodologies; Radiology reporting; Usability evaluation; Voice user interface; User interfaces",Conference Paper,Scopus
"Alumäe T., Meister E.","Estonian large vocabulary speech recognition system for radiology",2010,"Frontiers in Artificial Intelligence and Applications",6,"10.3233/978-1-60750-641-6-33","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78049281524&doi=10.3233%2f978-1-60750-641-6-33&partnerID=40&md5=fc905ecff3a28d68aec6ac8b8dbf4126","This paper describes implementation and evaluation of an Estonian large vocabulary continuous speech recognition system prototype for the radiology domain. We used a 44 million word corpus of radiology reports to build a word trigram language model. We recorded a test set of dictated radiology reports using ten radiologists. Using speaker independent speech recognition, we achieved a 9.8% word error rate. Recognition worked in around 0.5 real-time. One of the prominent sources of errors were mistakes in writing compound words. © 2010 The authors and IOS Press. All rights reserved.","applications; radiology; speech recognition","Applications; Computational linguistics; Continuous speech recognition; Radiation; Radiology; Vocabulary control; Compound words; Language model; Large vocabulary continuous speech recognition; Large vocabulary speech recognition; Radiology reports; Speaker-independent speech recognition; Tri grams; Word error rate; Speech recognition",Conference Paper,Scopus
"Solti I., Cooke C.R., Xia F., Wurfel M.M.","Automated classification of radiology reports for acute lung injury: Comparison of keyword and machine learning based natural language processing approaches",2009,"Proceedings - 2009 IEEE International Conference on Bioinformatics and Biomedicine Workshops, BIBMW 2009",30,"10.1109/BIBMW.2009.5332081","https://www.scopus.com/inward/record.uri?eid=2-s2.0-72849149323&doi=10.1109%2fBIBMW.2009.5332081&partnerID=40&md5=33c3e2881f999d0b3a78a6cdfba4785b","This paper compares the performance of keyword and machine learning-based chest x-ray report classification for Acute Lung Injury (ALI). ALI mortality is approximately 30 percent. High mortality is, in part, a consequence of delayed manual chest x-ray classification. An automated system could reduce the time to recognize ALI and lead to reductions in mortality. For our study, 96 and 857 chest x-ray reports in two corpora were labeled by domain experts for ALI. We developed a keyword and a Maximum Entropy-based classification system. Word unigram and character n-grams provided the features for the machine learning system. The Maximum Entropy algorithm with character 6-gram achieved the highest performance (Recall=0.91, Precision=0.90 and F-measure=0.91) on the 857-report corpus. This study has shown that for the classification of ALI chest x-ray reports, the machine learning approach is superior to the keyword based system and achieves comparable results to highest performing physician annotators. ©2009 IEEE.",,"Acute lung injury; Automated classification; Automated systems; Classification system; Domain experts; F-measure; Machine learning systems; Machine-learning; Maximum entropy; N-grams; NAtural language processing; Radiology reports; Biological organs; Computational linguistics; Education; Natural language processing systems; Robot learning; Software agents; Technical presentations; Bioinformatics",Conference Paper,Scopus
"Chen J.Y., Lakhani P., Safdar N.M., Nagy P.G.","Letter to the editor Re: Voice recognition dictation: Radiologist as transcriptionist and improvement of report workflow and productivity using speech recognition-a follow-up study",2009,"Journal of Digital Imaging",1,"10.1007/s10278-009-9197-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-72349087786&doi=10.1007%2fs10278-009-9197-5&partnerID=40&md5=022941e26b6bf5fc6bbcfa35a21a272e",[No abstract available],,"automatic speech recognition; cost benefit analysis; follow up; imaging; letter; outpatient department; priority journal; productivity; radiologist; speech discrimination; Efficiency; Humans; Medical Records Systems, Computerized; Physician's Practice Patterns; Radiology; Radiology Information Systems; Speech Recognition Software; Work Simplification; Workflow",Letter,Scopus
"Dang P.A., Kalra M.K., Blake M.A., Schultz T.J., Stout M., Halpern E.F., Dreyer K.J.","Use of radcube for extraction of finding trends in a large radiology practice",2009,"Journal of Digital Imaging",9,"10.1007/s10278-008-9128-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-72349085536&doi=10.1007%2fs10278-008-9128-x&partnerID=40&md5=3651c86cfe6d353cac7549885c81403f","The purpose of our study was to demonstrate the use of Natural Language Processing (Leximer), along with Online Analytic Processing, (NLP-OLAP), for extraction of finding trends in a large radiology practice. Prior studies have validated the Natural Language Processing (NLP) program, Leximer for classifying unstructured radiology reports based on the presence of positive radiology findings (F POS) and negative radiology findings (F NEG). The F POS included new relevant radiology findings and any change in status from prior imaging. Electronic radiology reports from 1995-2002 and data from analysis of these reports with NLP-Leximer were saved in a data warehouse and exported to a multidimensional structure called the Radcube. Various relational queries on the data in the Radcube were performed using OLAP technique. Thus, NLP-OLAP was applied to determine trends of F POS in different radiology exams for different patient and examination attributes. Pivot tables were exported from NLP-OLAP interface to Microsoft Excel for statistical analysis. Radcube allowed rapid and comprehensive analysis of F POS and F NEG trends in a large radiology report database. Trends of F POS were extracted for different patient attributes such as age groups, gender, clinical indications, diseases with ICD codes, patient types (inpatient, ambulatory), imaging characteristics such as imaging modalities, referring physicians, radiology subspecialties, and body regions. Data analysis showed substantial differences between F POS rates for different imaging modalities ranging from 23.1% (mammography, 49,163/212,906) to 85.8% (nuclear medicine, 93,852/109,374; p &lt; 0.0001). In conclusion, NLP-OLAP can help in analysis of yield of different radiology exams from a large radiology report database. © 2008 Society for Imaging Informatics in Medicine.","Data mining; Natural language processing; Online Analytical Processing (OLAP)","Age groups; Comprehensive analysis; Data analysis; Imaging characteristics; Imaging modality; Microsoft excel; Multi-dimensional structure; NAtural language processing; On-line analytic processing; On-line analytical processing; Online Analytical Processing (OLAP); Pivot-tables; Radiology reports; Relational queries; Statistical analysis; Civil aviation; Computational linguistics; Data handling; Data warehouses; Fluorine containing polymers; Getters; Natural language processing systems; Nuclear medicine; Radiology; Spreadsheets; Radiation; article; computer interface; computer program; data base; extraction; imaging and display; information processing; mammography; medical practice; nuclear medicine; online system; priority journal; radcube; radiodiagnosis; radiology; Automatic Data Processing; Databases, Factual; Diagnostic Imaging; Female; Humans; Information Storage and Retrieval; Logistic Models; Male; Medical Records Systems, Computerized; Natural Language Processing; Practice Management, Medical; Probability; Radiographic Image Enhancement; Radiology Information Systems; Sensitivity and Specificity",Article,Scopus
"Sistrom C.L., Dreyer K.J., Dang P.P., Weilburg J.B., Boland G.W., Rosenthal D.I., Thrall J.H.","Recommendations for additional imaging in radiology reports: Multifactorial analysis of 5.9 million examinations",2009,"Radiology",110,"10.1148/radiol.2532090200","https://www.scopus.com/inward/record.uri?eid=2-s2.0-73449092699&doi=10.1148%2fradiol.2532090200&partnerID=40&md5=50991a4c418a71e5146f2eb12a0e51ab","Purpose: To quantify the rates of recommendation for additional imaging (RAI) in a large number of radiology reports of different modalities and to estimate the effects of 11 clinically relevant factors. Materials and Methods: This HIPAA compliant research was approved by the institutional review board under an expedited protocol for analyzing anonymous aggregated radiology data. All diagnostic imaging examinations (n = 5 948 342) interpreted by radiologists between 1995 and 2008 were studied. A natural language processing technique specifically designed to extract information about any recommendations from radiology report texts was used. The analytic data set included three quantitative variables: the interpreting radiologist's experience, the year of study, and patient age. Categoric variables described patient location (inpatient, outpatient, emergency department), whether a resident dictated the case, patient sex, modality, body area studied, ordering service, radiologist's specialty division, and whether the examination result was positive. A multivariable logistic regression model was used to determine the effect of each of these factors on likelihood of RAI while holding all others equal. Results: Recommendations increased during the 13 years of study, with the unadjusted rate rising from roughly 6% to 12%. After accounting for all other factors, the odds of any one examination resulting in an RAI increased by 2.16 times (95% confidence interval: 2.12, 2.21) from 1995 to 2008. As radiologist experience increased, the odds of an RAI decreased by about 15% per decade. Studies that had positive findings were more likely (odds ratio = 5.03; 95% confidence interval: 4.98, 5.07) to have an RAI. The remaining factors also had significant effects on the tendency for an RAI. Conclusion: The likelihood of RAI increased by 15% for each decade of radiologist experience and roughly doubled over 13 years of study. © RSNA, 2009.",,"article; diagnostic imaging; emergency ward; female; hospital patient; human; image analysis; major clinical study; male; medical information; medical practice; medical research; medical specialist; natural language processing; outpatient; practice guideline; priority journal; quantitative analysis; radiologist; radiology; residency education; Diagnostic Imaging; Female; Humans; Male; Medicine; Middle Aged; Multivariate Analysis; Radiology; Referral and Consultation",Article,Scopus
"Dang P.A., Kalra M.K., Schultz T.J., Graham S.A., Dreyer K.J.","Render: An online searchable radiology study repository",2009,"Radiographics",33,"10.1148/rg.295085036","https://www.scopus.com/inward/record.uri?eid=2-s2.0-70349930165&doi=10.1148%2frg.295085036&partnerID=40&md5=733980dbcce22bf3f3815a29f0a9064a","Radiology departments are a rich source of information in the form of digital radiology reports and images obtained in patients with a wide spectrum of clinical conditions. A free text radiology report and image search application known as Render was created to allow users to find pertinent cases for a variety of purposes. Render is a radiology report and image repository that pools researchable information derived from multiple systems in near real time with use of (a) Health Level 7 links for radiology information system data, (b) periodic file transfers from the picture archiving and communication system, and (c) the results of natural language processing (NLP) analysis. Users can perform more structured and detailed searches with this application by combining different imaging and patient characteristics such as examination number; patient age, gender, and medical record number; and imaging modality. Use of NLP analysis allows a more effective search for reports with positive findings, resulting in the retrieval of more cases and terms having greater relevance. From the retrieved results, users can save images, bookmark examinations, and navigate to an external search engine such as Google. Render has applications in the fields of radiology education, research, and clinical decision support. © RSNA, 2009.",,"article; factual database; hospital information system; Internet; medical informatics; medical record; methodology; online system; radiology; United States; Databases, Factual; Internet; Medical Informatics; Medical Records Systems, Computerized; Online Systems; Radiology; Radiology Information Systems; United States",Article,Scopus
"Perakis K., Haritou M., Kordatzakis A., Androulidakis A., Zografos G., Koutsouris D.","Clinical evaluation of a telemedicine platform for digital watermarking of radiology images",2009,"Journal on Information Technology in Healthcare",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-68749112761&partnerID=40&md5=2f8de490fce3e3f9ab598079bd896cf0","Objective: Data such as images transmitted as part of telemedicine consultations should ensure maximum patient confidentiality. One way to enhance this is through the use of a digital watermark. This can hold information which is not visible to users viewing the image unless they have a key to unlock the digital watermark. The information held in a digital watermark can also be used for other purposes such as indexation. The purpose of this pilot study is to evaluate the feasibility and user views on a telemedicine platform for digital watermarking of radiology images. Methods: Mammograms taken in a health centre in Athens were scanned and digitally watermarked with a variety of information including patient details, their identity number and details of the centre where the mammograms had been taken. The digitally watermarked mammograms were transmitted to a Breast Unit in Athens for clinical assessment. At the Breast Unit the watermarks were unlocked by a clinician with a digital key, and after evaluation the images with additional text such as a diagnosis or a report incorporated in the digital watermark were transmitted back to the health centre. A questionnaire was given to the 10 medical personnel who participated in the pilot study to evaluate their views on the system and the digital watermarking tool. Results: A total of 39 mammograms were successfully transmitted with a digital watermark over a 4 week period. Users found the digital watermarking tool easy to use. The majority of the personnel felt that the additional information embedded with the watermark was comprehensive and useful. In addition they felt that the security precautions of the application guaranteed both the integrity of the images as well as the privacy of medical data. Conclusion: Digital watermarking can easily be incorporated into a telemedicine platform. It enhances security and confidentiality of patient data and provides other benefits such as data integrity, efficient image archiving and retrieval. © The Journal on Information Technology in Healthcare.",,"access to information; article; clinical assessment; clinical evaluation; confidentiality; digital mammography; feasibility study; Greece; information retrieval; information technology; patient information; pilot study; radiology image digital watermarking; teleconsultation; telemedicine; teleradiology",Article,Scopus
"Erinjeri J.P., Picus D., Prior F.W., Rubin D.A., Koppel P.","Development of a google-based search engine for data mining radiology reports",2009,"Journal of Digital Imaging",15,"10.1007/s10278-008-9110-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-68049126218&doi=10.1007%2fs10278-008-9110-7&partnerID=40&md5=23388f130d925a850cb3cd28b3b7e2a0","The aim of this study is to develop a secure, Google-based data-mining tool for radiology reports using free and open source technologies and to explore its use within an academic radiology department. A Health Insurance Portability and Accountability Act (HIPAA)-compliant data repository, search engine and user interface were created to facilitate treatment, operations, and reviews preparatory to research. The Institutional Review Board waived review of the project, and informed consent was not required. Comprising 7.9 GB of disk space, 2.9 million text reports were downloaded from our radiology information system to a fileserver. Extensible markup language (XML) representations of the reports were indexed using Google Desktop Enterprise search engine software. A hypertext markup language (HTML) form allowed users to submit queries to Google Desktop, and Google's XML response was interpreted by a practical extraction and report language (PERL) script, presenting ranked results in a web browser window. The query, reason for search, results, and documents visited were logged to maintain HIPAA compliance. Indexing averaged approximately 25,000 reports per hour. Keyword search of a common term like ""pneumothorax"" yielded the first ten most relevant results of 705,550 total results in 1.36 s. Keyword search of a rare term like ""hemangioendothelioma"" yielded the first ten most relevant results of 167 total results in 0.23 s; retrieval of all 167 results took 0.26 s. Data mining tools for radiology reports will improve the productivity of academic radiologists in clinical, educational, research, and administrative tasks. By leveraging existing knowledge of Google's interface, radiologists can quickly perform useful searches. © 2008 Society for Imaging Informatics in Medicine.","Data mining; Google; HIPAA; Reports; Search engine","Administrative tasks; Data repositories; Data-mining tools; Disk space; Extensible markup language; Google; Google desktop; Health insurance portability and accountability acts; HIPAA; Hypertext Markup Language; Keyword search; Open-source technology; Practical extraction and report languages; Radiology information system; Radiology reports; Reports; Engines; Health insurance; Hypertext systems; Knowledge management; Linguistics; Mining; Online searching; Query languages; Radiation; Radiology; Search engines; User interfaces; Web browsers; Windows; World Wide Web; XML; Markup languages; article; data extraction; data mining; hemangioendothelioma; information retrieval; markup language; medical literature; pneumothorax; priority journal; radiology department; Humans; Information Storage and Retrieval; Radiology; Radiology Information Systems; United States; User-Computer Interface",Article,Scopus
"Schonnemann U., Wiil U.K.","Using a classification scheme to facilitate outsourcing of radiology services",2009,"HEALTHINF 2009 - Proceedings of the 2nd International Conference on Health Informatics",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954660724&partnerID=40&md5=46b7401453c93bb06bfc06e04d9c679c","This paper deals with the issues involved in outsourcing radiology services. Based upon a field study of the work practices at the radiology department at Svendborg Hospital in Denmark, a novel solution (including a prototype of a computer supported reporting tool) that enables outsourcing of radiology services is introduced. The solution is based upon development of a classification scheme of possible radiology findings. Using predefined clinical findings for the radiology reports assure a high quality and enable automatic translation of radiology reports.","Articulation work; Classification scheme; Common information space; Design and development of methodologies for Healthcare IT; Knowledge management; Support for clinical decision-making","Articulation work; Automatic translation; Classification scheme; Common information space; Denmark; Design and development of methodologies for Healthcare IT; Field studies; High quality; Novel solutions; Radiology reports; Reporting tools; Svendborg; Work practices; Classification (of information); Health care; Information technology; Knowledge management; Outsourcing; Radiation; Radiology; Systems analysis; Decision making",Conference Paper,Scopus
"Bashyam V., Hsu W., Watt E., Bui A.A.T., Kangarloo H., Taira R.K.","Informatics in radiology: Problem-centric organization and visualization of patient imaging and clinical data",2009,"Radiographics",26,"10.1148/rg.292085098","https://www.scopus.com/inward/record.uri?eid=2-s2.0-66149124538&doi=10.1148%2frg.292085098&partnerID=40&md5=5fb4e606e4202ae2e377138f50092078","A patient's electronic medical record contains a large amount of unstructured textual information. As patient records become increasingly dense owing to an aging population and increased occurrence of chronic diseases, a tool is needed to help organize and navigate patient data in a way that facilitates a clinician's ability to understand this information and that improves efficiency. A system has been developed for physicians that summarizes clinical information from a patient record. This system provides a gestalt view of the patient's record by organizing information about each disease along four dimensions (axes): time (eg, disease progression over time), space (eg, tumor in left frontal lobe), existence (eg, certainty of existence of a finding), and causality (eg, response to treatment). A display is generated from information provided by radiology reports and discharge summaries. Natural language processing is used to identify clinical abnormalities (problems, symptoms, findings) from these reports as well as associated properties and relationships. This information is presented in an integrated format that organizes extracted findings into a problem list, depicts the information on a timeline grid, and provides direct access to relevant reports and images. The goal of this system is to improve the structure of clinical information and its presentation to the physician, thereby simplifying the information retrieval and knowledge discovery necessary to bridge the gap between acquiring raw data and making an informed diagnosis. © RSNA, 2009.",,"algorithm; article; computer assisted diagnosis; computer graphics; computer interface; computer program; data base; hospital information system; image enhancement; information retrieval; methodology; organization and management; reproducibility; sensitivity and specificity; United States; Algorithms; Computer Graphics; Database Management Systems; Image Enhancement; Image Interpretation, Computer-Assisted; Information Storage and Retrieval; Radiology Information Systems; Reproducibility of Results; Sensitivity and Specificity; Software; United States; User-Computer Interface",Article,Scopus
"Paulett J.M., Langlotz C.P.","Improving language models for radiology speech recognition",2009,"Journal of Biomedical Informatics",17,"10.1016/j.jbi.2008.08.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-60049096136&doi=10.1016%2fj.jbi.2008.08.001&partnerID=40&md5=a325f70b4a4bf22c6ee72d0c4d8e68b4","Speech recognition systems have become increasingly popular as a means to produce radiology reports, for reasons both of efficiency and of cost. However, the suboptimal recognition accuracy of these systems can affect the productivity of the radiologists creating the text reports. We analyzed a database of over two million de-identified radiology reports to determine the strongest determinants of word frequency. Our results showed that body site and imaging modality had a similar influence on the frequency of words and of three-word phrases as did the identity of the speaker. These findings suggest that the accuracy of speech recognition systems could be significantly enhanced by further tailoring their language models to body site and imaging modality, which are readily available at the time of report creation. © 2008 Elsevier Inc. All rights reserved.","n-Gram; Radiology; Radiology reports; Speech recognition; Trigram model; Word frequency","Imaging modalities; Language models; n-Gram; Radiology reports; Recognition accuracies; Speech recognition systems; Trigram model; Word frequency; Computational linguistics; Linguistics; Radiation; Radiology; Speech analysis; Speech recognition; article; controlled study; diagnostic accuracy; human; imaging system; language ability; major clinical study; priority journal; radiodiagnosis; speech analysis; speech discrimination; word recognition; Analysis of Variance; Artificial Intelligence; Diagnostic Imaging; Humans; Medical Records Systems, Computerized; Radiology; Radiology Information Systems; Speech Recognition Software",Article,Scopus
"Patton R.M., Potok T.E., Beckerman B.G., Treadwell J.N.","A genetic algorithm for learning significant phrase patterns in radiology reports",2009,"Proceedings of the 11th Annual Genetic and Evolutionary Computation Conference, GECCO-2009",8,"10.1145/1570256.1570380","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650963123&doi=10.1145%2f1570256.1570380&partnerID=40&md5=c567480bee938e9edbaec44ab280d5f2","Radiologists disagree with each other over the characteristics and features of what constitutes a normal mammogram and the terminology to use in the associated radiology report. Recently, the focus has been on classifying abnormal or suspicious reports, but even this process needs further layers of clustering and gradation, so that individual lesions can be more effectively classified. Using a genetic algorithm, the approach described here successfully learns phrase patterns for two distinct classes of radiology reports (normal and abnormal). These patterns can then be used as a basis for automatically analyzing, categorizing, clustering, or retrieving relevant radiology reports for the user. © 2009 ACM.","genetic algorithm; information retrieval; learning agents; mammography reports; maximum variation sampling; multi-agent system","Genetic algorithms; Learning algorithms; Radiation; Radiology; Search engines; Classifieds; Clusterings; Learn+; Learning agents; Mammography report; Maximum variation sampling; Maximum variations; Process needs; Radiology reports; Multi agent systems",Conference Paper,Scopus
"Branstetter IV B.F., Shrestha R.B.","Re: ""Frequency and Spectrum of Errors in Final Radiology Reports Generated With Automatic Speech Recognition Technology""",2009,"Journal of the American College of Radiology",1,"10.1016/j.jacr.2009.04.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-67649804367&doi=10.1016%2fj.jacr.2009.04.015&partnerID=40&md5=7d6c266d729a403a3bd8810a2a86364e",[No abstract available],,"analytical error; automatic speech recognition; computer program; frequency analysis; letter; medical practice; radiologist",Letter,Scopus
"Janower M.L.","Re: ""Frequency and Spectrum of Errors in Final Radiology Reports Generated With Automatic Speech Recognition Technology""",2009,"Journal of the American College of Radiology",1,"10.1016/j.jacr.2009.05.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-67649784293&doi=10.1016%2fj.jacr.2009.05.004&partnerID=40&md5=f1bccf48fb883a984b4ea3a4f3ddecb4",[No abstract available],,"analytical error; automatic speech recognition; error; frequency analysis; letter; radiologist",Letter,Scopus
"Marcovici P.A.","Re: ""Frequency and Spectrum of Errors in Final Radiology Reports Generated With Automatic Speech Recognition Technology""",2009,"Journal of the American College of Radiology",4,"10.1016/j.jacr.2009.01.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-63149179312&doi=10.1016%2fj.jacr.2009.01.002&partnerID=40&md5=2278b8f7edbb8dcdee43370722b78ff0",[No abstract available],,"accuracy; automatic speech recognition; clinical practice; computer program; health survey; letter; medical error; patient care; patient safety; radiology; resident; satisfaction",Letter,Scopus
"Nishimoto N., Terae S., Uesugi M., Ogasawara K., Sakurai T.","Development of a medical-text parsing algorithm based on character adjacent probability distribution for Japanese radiology reports",2008,"Methods of Information in Medicine",9,"10.3414/ME9127","https://www.scopus.com/inward/record.uri?eid=2-s2.0-57749177048&doi=10.3414%2fME9127&partnerID=40&md5=beb247f9499a0023366f4af209d42ca0","Objectives: The objectives of this study were to investigate the transitional probability distribution of medical term boundaries between characters and to develop a parsing algorithm specifically for medical texts. Methods: Medical terms in Japanese computed tomography (CT) reports were identified using the ChaSen morphological analysis system. MeSH-based-medical terms (51,385 entries), obtained from the metathesaurus in the Unified Medical Language System (UMLS, 2005AA), were added as a medical dictionary for ChaSen. A radiographer corrected the set of results containing 300 parsed CT reports. In addition, two radiologists checked the medical term parsing of 200 CT sentences. Results: We obtained modified inter-annotator agreement scores for the text corrected by the radiologists. We retrieved the transitional probability as the conditional probability of a uni-gram, bi-gram, and tri-gram. The highest transitional probability P(Ci Ci - 2*Ci - 1) was 1.00. For an example of anatomical location, the term ""pulmonary hilum"" was parsed as a tri-gram. Conclusions: Retrieval of transitional probability will improve the accuracy of parsing compound medical terms. © 2008 Schattauer GmbH.","Compound terms; Natural language processing; Prediction by partial matching; Transitional probability; Unified Medical Languge System","accuracy; article; book; computer assisted tomography; controlled study; language; learning algorithm; mathematical analysis; mathematical model; medical information system; natural language processing; nomenclature; priority journal; probability; process design; radiology; Access to Information; Algorithms; Humans; Japan; Markov Chains; Medical Informatics; Models, Statistical; Models, Theoretical; Natural Language Processing; Probability; Radiology; Terminology as Topic; Tomography, X-Ray Computed; Unified Medical Language System",Article,Scopus
"Gong T., Tan C.L., Yun L.T., Lee C.K., Pang B.C., Lim C.C.T., Tian Q., Tang S., Zhang Z.","Text mining in radiology reports",2008,"Proceedings - IEEE International Conference on Data Mining, ICDM",18,"10.1109/ICDM.2008.150","https://www.scopus.com/inward/record.uri?eid=2-s2.0-67049114677&doi=10.1109%2fICDM.2008.150&partnerID=40&md5=962e54d291ce3fb37072eaa9f79d06f6","Medical text mining has gained increasing interest in recent years. Radiology reports contain rich information describing radiologist's observations on the patient's medical conditions in the associated medical images. However, as most reports are in free text format, the valuable information contained in those reports cannot be easily accessed and used, unless proper text mining has been applied. In this paper, we propose a text mining system to extract and use the information in radiology reports. The system consists of three main modules: a medical finding extractor, a report and image retriever, and a text-assisted image feature extractor. In evaluation, the overall precision and recall for medical finding extraction are 95.5% and 87.9% respectively, and for all modifiers of the medical findings 88.2% and 82.8% respectively. The overall result of report and image retrieval module and text-assisted image feature extraction module is satisfactory to radiologists. ©2008 IEEE.",,"Free texts; Image feature extractions; Image features; Main module; Medical conditions; Medical images; Precision and recall; Radiology reports; Text mining; Data mining; Feature extraction; Image retrieval; Information management; Radiation; Radiology; Mining",Conference Paper,Scopus
"Rubin D.L.","Creating and curating a terminology for radiology: Ontology modeling and analysis",2008,"Journal of Digital Imaging",115,"10.1007/s10278-007-9073-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-55649125289&doi=10.1007%2fs10278-007-9073-0&partnerID=40&md5=eb472576946a27ee79f42638e18d8bde","The radiology community has recognized the need to create a standard terminology to improve the clarity of reports, to reduce radiologist variation, to enable access to imaging information, and to improve the quality of practice. This need has recently led to the development of RadLex, a controlled terminology for radiology. The creation of RadLex has proved challenging in several respects: It has been difficult for users to peruse the large RadLex taxonomies and for curators to navigate the complex terminology structure to check it for errors and omissions. In this work, we demonstrate that the RadLex terminology can be translated into an ontology, a representation of terminologies that is both human-browsable and machine-processable. We also show that creating this ontology permits computational analysis of RadLex and enables its use in a variety of computer applications. We believe that adopting an ontology representation of RadLex will permit more widespread use of the terminology and make it easier to collect feedback from the community that will ultimately lead to improving RadLex. © 2007 Society for Imaging Informatics in Medicine.","Ontologies; RadLex; Software tools; Terminologies; Vocabularies","Computational analyses; Errors and omissions; Imaging informations; Modeling and analysis; Ontology representations; Processable; RadLex; Software tools; Vocabularies; Widespread uses; Computational methods; Computer applications; Radiation; Radiology; Taxonomies; Terminology; Ontology; article; computer analysis; computer program; human computer interaction; Internet; linguistics; medical information; nomenclature; priority journal; radiology; Computer Systems; Database Management Systems; Information Storage and Retrieval; Models, Theoretical; Radiology; Radiology Information Systems; Software; Software Design; Systems Integration; Terminology as Topic; User-Computer Interface; Vocabulary, Controlled",Article,Scopus
"Pezzullo J.A., Tung G.A., Rogg J.M., Davis L.M., Brody J.M., Mayo-Smith W.W.","Voice recognition dictation: Radiologist as transcriptionist",2008,"Journal of Digital Imaging",72,"10.1007/s10278-007-9039-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-55649118880&doi=10.1007%2fs10278-007-9039-2&partnerID=40&md5=545dd63290da43a80afcddd6b87b8b78","Continuous voice recognition dictation systems for radiology reporting provide a viable alternative to conventional transcription services with the promise of shorter report turnaround times and increased cost savings. While these benefits may be realized in academic institutions, it is unclear how voice recognition dictation impacts the private practice radiologist who is now faced with the additional task of transcription. In this article, we compare conventional transcription services with a commercially available voice recognition system with the following results: 1) Reports dictated with voice recognition took 50% longer to dictate despite being 24% shorter than those conventionally transcribed, 2) There were 5.1 errors per case, and 90% of all voice recognition dictations contained errors prior to report signoff while 10% of transcribed reports contained errors. 3). After signoff, 35% of VR reports still had errors. Additionally, cost savings using voice recognition systems in non-academic settings may not be realized. Based on average radiologist and transcription salaries, the additional time spent dictating with voice recognition costs an additional $6.10 per case or $76,250.00 yearly. The opportunity costs may be higher. Informally surveyed, all radiologists expressed dissatisfaction with voice recognition with feelings of frustration, and increased fatigue. In summary, in non-academic settings, utilizing radiologists as transcriptionists results in more error ridden radiology reports and increased costs compared with conventional transcription services. © 2007 Society for Imaging Informatics in Medicine.","Radiologist; Transcriptionist; Voice recognition dictation","Academic institutions; Cost savings; Dictation systems; Opportunity costs; Radiologist; Radiology reporting; Radiology reports; Transcriptionist; Voice recognition dictation; Voice recognitions; Compensation (personnel); Costs; Errors; Military operations; Radiation; Radiology; Transcription; Turnaround time; Wages; Speech recognition; analytical error; article; automatic speech recognition; career; comparative study; computer assisted tomography; cost benefit analysis; medical information system; nuclear magnetic resonance imaging; priority journal; radiologist; transcriptionist; Adult; Aged; Aged, 80 and over; Cost-Benefit Analysis; Humans; Job Satisfaction; Medical Records; Middle Aged; Physician's Practice Patterns; Private Practice; Radiology; Radiology Information Systems; Speech Recognition Software; Time; User-Computer Interface; Work Simplification; Young Adult",Article,Scopus
"DeFlorio R., Coughlin B., Coughlin R., Li H., Santoro J., Akey B., Favreau M.","Process modification and emergency department radiology service",2008,"Emergency Radiology",22,"10.1007/s10140-008-0735-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-53549116434&doi=10.1007%2fs10140-008-0735-0&partnerID=40&md5=6e10daeb0d19c1f6fe4ab0b64d9466c2","Our purpose was to demonstrate the impact of changes in technology, staffing, and departmental processes on service levels in emergency department (ED) radiology. We also attempted to determine if report turnaround time affects ED patient throughput. Radiology performance was evaluated before and after the modifications of processes integral to the interpretation of ED imaging. Picture archiving and communication system, voice recognition (VR), staffing, physical site, work flow, and administrative modifications were undertaken over ∼2 years. The average time interval from the exam completion to report signature was 5,184 min (standard deviation (SD) of 1,858 min before the implementation of VR and other modifications of ED radiology processes). In post initial modifications, it was 150 min (SD, 169 min) and 157 min (SD, 215 min) in post additional modifications. The percentage of the signed written reports available in less than or equal to 60 min was 0%, 27%, and 40%, respectively. Ongoing improvements are needed to increase the service levels for ED radiology. Further improvement will require collaboration and adjustment with the ongoing assessment of metrics. © 2008 Am Soc Emergency Radiol.","Modifications; Performance; Report turnaround; Service; Voice recognition","article; automatic speech recognition; clinical practice; emergency ward; health care; health service; human; priority journal; radiodiagnosis; Diagnostic Errors; Emergency Service, Hospital; Humans; Radiology Information Systems; Task Performance and Analysis; Time Factors",Article,Scopus
"Bhan S.N., Coblentz C.L., Norman G.R., Ali S.H.","Effect of voice recognition on radiologist reporting time",2008,"Canadian Association of Radiologists Journal",29,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-55949125654&partnerID=40&md5=cb42ca1186fd761fbaf905be53d0e29b","Objective: To study the effect that voice recognition (VR) has on radiologist reporting efficiency in a clinical setting and to identify variables associated with faster reporting time. Methods: Five radiologists were observed during the routine reporting of 402 plain radiograph studies using either VR (n = 217) or conventional dictation (CD) (n = 185). Two radiologists were observed reporting 66 computed tomography (CT) studies using either VR (n = 39) or CD (n = 27). The time spent per reporting cycle, defined as the radiologist's time spent on a study from report finalization to the subsequent report finalization, was compared. As well, characteristics about the radiologist and their reporting style were collected and correlated against reporting time. Results: For plain radiographs, radiologists took 13.4% (P = 0.048) more time to produce reports using VR, but there was significant variability between radiologists. Significant association with faster reporting times using VR included: English as a first language (r = -0.24), use of a template (r = -0.34), use of a headset microphone (r = -0.46), and increased experience with VR (r = -0.43). Experience as a staff radiologist and having a previous study for comparison did not correlate with reporting time. For CT, there was no significant difference in reporting time identified between VR and CD (P = 0.61). Conclusions: Overall, VR slightly decreases the reporting efficiency of radiologists. However, efficiency may be improved if English is a first language, a headset microphone, and macros and templates are used.","Productivity; Radiology; Speech recognition; Voice recognition","article; automatic speech recognition; computer assisted tomography; controlled study; experience; human; language; medical documentation; microphone; physician attitude; radiography; radiologist; Efficiency, Organizational; Humans; Medical Records Systems, Computerized; Ontario; Radiology; Radiology Department, Hospital; Radiology Information Systems; Speech Recognition Software; Time; Time and Motion Studies; Tomography, X-Ray Computed",Article,Scopus
"Mcgurk S., Brauer K., Macfarlane T.V., Duncan K.A.","The effect of voice recognition software on comparative error rates in radiology reports",2008,"British Journal of Radiology",56,"10.1259/bjr/20698753","https://www.scopus.com/inward/record.uri?eid=2-s2.0-53749100848&doi=10.1259%2fbjr%2f20698753&partnerID=40&md5=ec67e3eb7c21277be14552d2c3b1fe7a","This study sought to confirm whether reports generated in a department of radiology contain more errors if generated using voice recognition (VR) software than if traditional dictation-transcription (DT) is used. All radiology reports generated over a 1-week period in a British teaching hospital were assessed. The presence of errors and their impact on the report were assessed. Data collected included the type of report, site of dictation, the experience of the operator, and whether English was the first language of the operator. 1887 reports were reviewed. 1160 (61.5%) were dictated using VR and 727 reports (38.5%) were generated by DT. 71 errors (3.8% of all reports) were identified. 56 errors were made using VR (4.8% of VR reports), whereas 15 errors were identified in DT reports (2.1% of transcribed reports). The difference in report errors between these two dictation methods was statistically significant (p=0.002). Of the 71 reports containing errors, 37 (52.1%) had errors that affecting understanding. Other factors were also identified that significantly increased the likelihood of errors in a VR-generated report, such as working in a busy inpatient environment (p<0.001) and having a language other than English as a first language (p=0.034). Operator grade was not significantly associated with increased errors. In conclusion, using VR significantly increases the number of reports containing errors. Errors using VR are significantly more likely to occur in noisy areas with a high workload and are more likely to be made by radiologists for whom English is not their first language. © 2008 The British Institute of Radiology.",,"analytical error; article; automatic speech recognition; comprehension; data collection method; English as a second language; experience; intermethod comparison; language; medical record; operator; radiology department; teaching hospital; work environment; Clinical Competence; Humans; Language; Medical Records Systems, Computerized; Noise, Occupational; Programming Languages; Radiology Department, Hospital; Radiology Information Systems; Speech Recognition Software",Article,Scopus
"Bertaud V., Lasbleiz J., Mougin F., Burgun A., Duvauferrier R.","A unified representation of findings in clinical radiology using the UMLS and DICOM",2008,"International Journal of Medical Informatics",13,"10.1016/j.ijmedinf.2007.11.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-46149110490&doi=10.1016%2fj.ijmedinf.2007.11.003&partnerID=40&md5=4ae2672c68cd3d3e04effa3b7eafa8ec","Purpose: Collecting and analyzing findings constitute the basis of medical activity. Computer assisted medical activity raises the problem of modelling findings. We propose a unified representation of findings integrating the representations of findings in the GAMUTS in Radiology [M.M. Reeder, B. Felson, GAMUTS in radiology Comprehensive lists of roentgen differential diagnosis, fourth ed., 2003], the Unified Medical Language System (UMLS®), and the Digital Imaging and Communication in Medicine Structured Report (DICOM-SR). Materials and Methods: Starting from a corpus of findings in bone and joint radiology [M.M. Reeder, B. Felson, GAMUTS in Radiology comprehensive lists of roentgen differential diagnosis, fourth ed., 2003] (3481 words), an automated mapping to the UMLS was performed with the Metamap Program. The resulting UMLS terms and Semantic Types were analyzed in order to find a generic template in accordance with DICOM-SR structure. Results: UMLS Concepts were missing for 45% of the GAMUTS findings. Three kinds of regularities were observed in the way the Semantic Types were combined: ""pathological findings"", ""physiological findings"" and ""anatomical findings"". A generic and original DICOM-SR template modelling finding was proposed. It was evaluated for representing GAMUTS jaws findings. 21% missing terms had to be picked up from Radlex (5%) or created (16%). Discussion-Conclusion: This article shows that it is possible to represent findings using the UMLS and the DICOM SR formalism with a semi-automated method. The Metamap program helped to find a model to represent the semantic structure of free texts with standardized terms (UMLS Concepts). Nevertheless, the coverage of the UMLS is not comprehensive. This study shows that the UMLS should include more technical concepts and more concepts regarding findings, signs and symptoms to be suitable for radiology representation. The semi-automated translation of the whole GAMUTS using the UMLS concepts and the DICOM SR relations could help to create or supplement the DCMR Templates and Context Groups pertaining to the description of imaging findings. © 2007 Elsevier Ireland Ltd. All rights reserved.","Diagnosis [subheading]; Medical informatics; Radiology; Unified medical language system","Clinical radiology; Computer assisted; differential diagnosis; Unified Medical Language System (UMLS); Diagnosis; Health; Radiation; Radiology; article; automation; bone radiography; computer program; differential diagnosis; digital imaging and communications in medicine; human; joint radiography; medical informatics; medical information system; natural language processing; priority journal; radiology; semantics; standardization; systematized nomenclature of medicine; Humans; Medical Informatics; Radiographic Image Enhancement; Radiology Department, Hospital; Semantics; Unified Medical Language System",Article,Scopus
"Dang P.A., Kalra M.K., Blake M.A., Schultz T.J., Halpern E.F., Dreyer K.J.","Extraction of recommendation features in radiology with natural language processing: Exploratory study",2008,"American Journal of Roentgenology",25,"10.2214/AJR.07.3508","https://www.scopus.com/inward/record.uri?eid=2-s2.0-49149101134&doi=10.2214%2fAJR.07.3508&partnerID=40&md5=d4b7ac8d72281ec367cf7c89a3c5e96f","OBJECTIVE. The purposes of this study were to validate a natural language processing program for extraction of recommendation features, such as recommended time frames and imaging technique, from electronic radiology reports and to assess patterns of recommendation features in a large database of radiology reports. MATERIALS AND METHODS. This study was performed on a radiology reports database covering the years 1995-2004. From this database, 120 reports with and without recommendations were selected and randomized. Two radiologists independently classified these reports according to presence of recommendations, time frame, and imaging technique suggested for follow-up or repeated examinations. The natural language processing program then was used to classify the reports according to the same criteria used by the radiologists. The accuracy of classification of recommendation features was determined. The program then was used to determine the patterns of recommendation features for different patients and imaging features in the entire database of 4,211,503 reports. RESULTS. The natural language processing program had an accuracy of 93.2% (82/88) for identifying the imaging technique recommended by the radiologists for further evaluation. Categorization of recommended time frames in the reports with the 88 recommendations obtained with the program resulted in 83 (94.3%) accurate classifications and five (5.7%) inaccurate classifications. Recommendations of CT were most common (27.9%, 105,076 of 376,918 reports) followed by those for MRI (17.8%). In most (85.4%, 322,074/376,918) of the reports with imaging recommendations, however, radiologists did not specify the time frame. CONCLUSION. Accurate determination of recommended imaging techniques and time frames in a large database of radiology reports is possible with a natural language processing program. Most imaging recommendations are for high-cost but more accurate radiologic studies. © American Roentgen Ray Society.","Radiology practice; Recommendations; Recommended imaging techniques","article; computer assisted tomography; cost benefit analysis; data base; diagnostic accuracy; fluoroscopy; follow up; imaging; language processing; mammography; nuclear magnetic resonance imaging; nuclear medicine; priority journal; radiologist; radiology; Algorithms; Chi-Square Distribution; Decision Making, Computer-Assisted; Humans; Logistic Models; Natural Language Processing; Quality Control; Radiology; Radiology Information Systems; Retrospective Studies; Sensitivity and Specificity",Article,Scopus
"Boland G.W.L., Guimaraes A.S., Mueller P.R.","Radiology report turnaround: Expectations and solutions",2008,"European Radiology",44,"10.1007/s00330-008-0905-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-45849134819&doi=10.1007%2fs00330-008-0905-1&partnerID=40&md5=6b35950b5c9dd3cda9ea754928a72002","The ultimate work product of a radiology department is a finalized radiology report. Radiology stakeholders are now demanding faster report turnaround times (RTAT) and anything that delays delivery of the finalized report will undermine the value of a radiology department. Traditional reporting methods are inherently inefficient and the desire to deliver fast RTAT will always be challenged. It is only through the adoption of an integrated radiology information system (RIS)/picture archiving and communication system (PACS) and voice recognition (VR) system that RTAT can consistently meet stakeholder expectations. VR systems also offer the opportunity to create standardized, higher quality reports. © European Society of Radiology 2008.","PACS; Report turnaround; RIS; Voice recognition","article; automatic speech recognition; computer assisted tomography; diagnostic imaging; hospital information system; medical record; nuclear magnetic resonance imaging; picture archiving and communication system; priority journal; radiology department; reimbursement; standardization; turnaround time; Diagnostic Imaging; Documentation; Humans; Radiology Information Systems; Speech Recognition Software; Time and Motion Studies; Workload",Article,Scopus
"Nayak N.R., Meghea C., Bhargavan M., Forman H.P., Sunshine J.H.","Prevalence of productivity-enhancing technologies in radiology",2008,"American Journal of Roentgenology",1,"10.2214/AJR.07.3501","https://www.scopus.com/inward/record.uri?eid=2-s2.0-44849140102&doi=10.2214%2fAJR.07.3501&partnerID=40&md5=d16b9cba2f565764237e7c526ea243e3","OBJECTIVE. The objective of our study was to describe the prevalence of different operational technologies in radiology practices and to identify which characteristics of radiology practices are plausibly causal factors in a practice's use of a technology. MATERIALS AND METHODS. We analyzed data from the American College of Radiology's 2003 Survey of Radiologists, a stratified random-sample survey that guaranteed respondents' confidentiality and achieved a 63% response rate with a total of 1,924 responses. Responses were weighted to make them representative of all radiologists and radiology practices in the United States. We used univariate analysis and multiple logistic regression. RESULTS. In 2003, PACS, wet-reading telephone lines, film-hanging staff, and templates (standard report language) were each used in practices that encompassed approximately half of U.S. radiologists. In contrast, only 42% of radiologists were in practices that used nurse practitioners or physician assistants for tasks beyond what technologists may do, and only 18% were in practices that used speech recognition software (SRS). Twenty-one percent of radiologists were in practices reported to have neither film-hanging staff nor PACS. The percentage of practices (as opposed to radiologists) that used various technologies ranged from 13% for SRS to 49% for templates. Multiple logistic regression showed that, other factors equal, academic practices were particularly likely to use some of the technologies and solo practices and other small practices were particularly likely not to have some of the technologies. CONCLUSION. Most operational technologies are fairly widely diffused, but a surprising number of radiologists work without some basic supports. © American Roentgen Ray Society.","Digital images; Practice of radiology; Speech recognition software; Teleradiology; Wet-reading telephone lines","article; automatic speech recognition; confidentiality; data analysis; health care personnel; health care practice; medical school; multivariate logistic regression analysis; nurse practitioner; physician assistant; priority journal; productivity; radiologist; radiology; random sample; telephone; United States; univariate analysis; X ray film; Biotechnology; Data Collection; Diagnostic Imaging; Efficiency; Radiology; United States",Article,Scopus
"Nishimoto N., Terae S., Uesugi M., Tanikawa T., Endou A., Ogasawara K., Sakurai T.","Parsing error correction of medical phrases for semantic annotation of clinical radiology reports.",2008,"AMIA ... Annual Symposium proceedings / AMIA Symposium. AMIA Symposium",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-73949126599&partnerID=40&md5=a8ecd90b311fa33b618b4e4085f602d6","The purpose of this study is to develop a module for correcting errors in the product of a natural language parser. When tested with 300 CT reports, a total of 604 patterns were generated. The recall and precision was improved to 90.7% and 74.1% after processed by the module from initial 80.5% and 42.8% respectively. This rule-based module will help health care personnel reduce the cost of manual tagging correction for corpus building.",,"algorithm; article; artificial intelligence; automated pattern recognition; hospital information system; information retrieval; Japan; medical record; methodology; natural language processing; nomenclature; semantics; statistics; Algorithms; Artificial Intelligence; Information Storage and Retrieval; Japan; Medical Records Systems, Computerized; Natural Language Processing; Pattern Recognition, Automated; Radiology Information Systems; Semantics; Terminology as Topic",Article,Scopus
"Quint L.E., Quint D.J., Myles J.D.","Frequency and Spectrum of Errors in Final Radiology Reports Generated With Automatic Speech Recognition Technology",2008,"Journal of the American College of Radiology",48,"10.1016/j.jacr.2008.07.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-56249122297&doi=10.1016%2fj.jacr.2008.07.005&partnerID=40&md5=6059aaf664f379de26d58df659327c50","Purpose: Automatic speech recognition technology has a high frequency of transcription errors, necessitating careful proofreading and report editing. The purpose of this study was to determine the frequency and spectrum of significant dictation errors in finalized radiology reports generated with speech recognition technology. Methods: All 265 radiology reports that were reviewed in preparation for 12 consecutive weekly multidisciplinary thoracic oncology group conferences were examined for significant dictation errors; reports were compared with the corresponding imaging studies. In addition, departmental radiologists were surveyed regarding their estimates of overall and individual report error rates. Results: Two hundred six of 265 (78%) reports contained no significant errors, and 59 (22%) contained errors. Report error rates by individual radiologists ranged from 0% to 100%. There were no significant differences in error rates between native and nonnative English speakers (P > .8) or between reports dictated by faculty members alone and those dictated by trainees and signed by faculty members (P > .3). The most frequent types of errors were wrong-word substitution, nonsense phrases, and missing words. Fifty-five of 88 radiologists (63%) believed that overall error rates did not exceed 10%, and 67 of 88 radiologists (76%) believed that their own individual error rates did not exceed 10%. Conclusions: More than 20% of our reports contained potentially confusing errors, and most radiologists believed that report error rates were much lower than they actually were. Knowledge of the frequency and spectrum of errors should raise awareness of this issue and facilitate methods for report improvement. © 2008 American College of Radiology.","Automatic speech recognition; error rate; radiology report","article; automatic speech recognition; language; medical error; medical school; medical student; radiologist",Article,Scopus
"Dang P.A., Kalra M.K., Blake M.A., Schultz T.J., Stout M., Lemay P.R., Freshman D.J., Halpern E.F., Dreyer K.J.","Natural Language Processing Using Online Analytic Processing for Assessing Recommendations in Radiology Reports",2008,"Journal of the American College of Radiology",23,"10.1016/j.jacr.2007.09.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-39749176483&doi=10.1016%2fj.jacr.2007.09.003&partnerID=40&md5=ce7169a96043cb1ae362f1dce6c999b1","Purpose: The study purpose was to describe the use of natural language processing (NLP) and online analytic processing (OLAP) for assessing patterns in recommendations in unstructured radiology reports on the basis of patient and imaging characteristics, such as age, gender, referring physicians, radiology subspecialty, modality, indications, diseases, and patient status (inpatient vs outpatient). Materials and Methods: A database of 4,279,179 radiology reports from a single tertiary health care center during a 10-year period (1995-2004) was created. The database includes reports of computed tomography, magnetic resonance imaging, fluoroscopy, nuclear medicine, ultrasound, radiography, mammography, angiography, special procedures, and unclassified imaging tests with patient demographics. A clinical data mining and analysis NLP program (Leximer, Nuance Inc, Burlington, Massachusetts) in conjunction with OLAP was used for classifying reports into those with recommendations (IREC) and without recommendations (NREC) for imaging and determining IREC rates for different patient age groups, gender, imaging modalities, indications, diseases, subspecialties, and referring physicians. In addition, temporal trends for IREC were also determined. Results: There was a significant difference in the IREC rates in different age groups, varying between 4.8% (10-19 years) and 9.5% (&gt;70 years) (P &lt;.0001). Significant variations in IREC rates were observed for different imaging modalities, with the highest rates for computed tomography (17.3%, 100,493/581,032). The IREC rates varied significantly for different subspecialties and among radiologists within a subspecialty (P &lt; .0001). For most modalities, outpatients had a higher rate of recommendations when compared with inpatients. Conclusion: The radiology reports database analyzed with NLP in conjunction with OLAP revealed considerable differences between recommendation trends for different imaging modalities and other patient and imaging characteristics. © 2008 American College of Radiology.","Natural Language Processing; radiology practice; radiology reports; recommendations","adolescent; adult; aged; angiography; article; child; clinical study; computer assisted tomography; data base; demography; disease classification; fluoroscopy; gender; groups by age; health care; hospital patient; human; imaging system; major clinical study; mammography; natural language processing; nuclear magnetic resonance imaging; nuclear medicine; online analytical processing; outpatient; physician; radiodiagnosis; radiography; radiology; statistical significance; ultrasound",Article,Scopus
"Rubin D.L., Noy N.F., Musen M.A.","Protégé: A tool for managing and using terminology in radiology applications",2007,"Journal of Digital Imaging",70,"10.1007/s10278-007-9065-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-35448966196&doi=10.1007%2fs10278-007-9065-0&partnerID=40&md5=7e0183902604059038e291a6d5884121","The development of standard terminologies such as RadLex is becoming important in radiology applications, such as structured reporting, teaching file authoring, report indexing, and text mining. The development and maintenance of these terminologies are challenging, however, because there are few specialized tools to help developers to browse, visualize, and edit large taxonomies. Protégé ( http://protege.stanford.edu ) is an open-source tool that allows developers to create and to manage terminologies and ontologies. It is more than a terminology-editing tool, as it also provides a platform for developers to use the terminologies in end-user applications. There are more than 70,000 registered users of Protégé who are using the system to manage terminologies and ontologies in many different domains. The RadLex project has recently adopted Protégé for managing its radiology terminology. Protégé provides several features particularly useful to managing radiology terminologies: an intuitive graphical user interface for navigating large taxonomies, visualization components for viewing complex term relationships, and a programming interface so developers can create terminology-driven radiology applications. In addition, Protégé has an extensible plug-in architecture, and its large user community has contributed a rich library of components and extensions that provide much additional useful functionalities. In this report, we describe Protégé's features and its particular advantages in the radiology domain in the creation, maintenance, and use of radiology terminology. © 2007 Society for Imaging Informatics in Medicine.","Ontologies; RadLex; Software tools; Terminologies; Vocabulaires","Text mining; Data mining; Graphical user interfaces; Ontology; Radiology; Terminology; Visualization; Computer aided software engineering; article; computer program; linguistics; medical technology; nomenclature; priority journal; radiology department; Computer Graphics; Computer Systems; Database Management Systems; Feedback; Humans; Information Storage and Retrieval; Knowledge Bases; Radiology Information Systems; Software; Software Design; Systems Integration; Terminology as Topic; User-Computer Interface",Article,Scopus
"Desjardins B., Hamilton R.C.","A Practical Approach for Inexpensive Searches of Radiology Report Databases",2007,"Academic Radiology",5,"10.1016/j.acra.2007.02.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34250342220&doi=10.1016%2fj.acra.2007.02.008&partnerID=40&md5=fd67690ef8e201d3418a97faa515f12e","Rationale and Objectives: We present a method to perform full text searches of radiology reports for the large number of departments that do not have this ability as part of their radiology or hospital information system. Materials and Methods: A tool written in Microsoft Access (front-end) has been designed to search a server (back-end) containing the indexed backup weekly copy of the full relational database extracted from a radiology information system (RIS). This front end-/back-end approach has been implemented in a large academic radiology department, and is used for teaching, research and administrative purposes. Results: The weekly second backup of the 80 GB, 4 million record RIS database takes 2 hours. Further indexing of the exported radiology reports takes 6 hours. Individual searches of the indexed database typically take less than 1 minute on the indexed database and 30-60 minutes on the nonindexed database. Guidelines to properly address privacy and institutional review board issues are closely followed by all users. Conclusions: This method has potential to improve teaching, research, and administrative programs within radiology departments that cannot afford more expensive technology. © 2007 AUR.","Computers; information system; radiology reports","article; computer language; computer program; data base; hospital information system; institutional review; medical literature; medical research; practice guideline; priority journal; privacy; radiology department; search engine; teaching; Abstracting and Indexing; Academic Medical Centers; Computer Systems; Databases, Factual; Humans; Information Storage and Retrieval; Medical Records; Radiology Department, Hospital; Radiology Information Systems; Software Design; User-Computer Interface",Article,Scopus
"Huang Y., Lowe H.J.","A Novel Hybrid Approach to Automated Negation Detection in Clinical Radiology Reports",2007,"Journal of the American Medical Informatics Association",119,"10.1197/jamia.M2284","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34247380744&doi=10.1197%2fjamia.M2284&partnerID=40&md5=86d4916ee5c9db0ca2148d3c5e9fe933","Objective: Negation is common in clinical documents and is an important source of poor precision in automated indexing systems. Previous research has shown that negated terms may be difficult to identify if the words implying negations (negation signals) are more than a few words away from them. We describe a novel hybrid approach, combining regular expression matching with grammatical parsing, to address the above limitation in automatically detecting negations in clinical radiology reports. Design: Negations are classified based upon the syntactical categories of negation signals, and negation patterns, using regular expression matching. Negated terms are then located in parse trees using corresponding negation grammar. Measurements: A classification of negations and their corresponding syntactical and lexical patterns were developed through manual inspection of 30 radiology reports and validated on a set of 470 radiology reports. Another 120 radiology reports were randomly selected as the test set on which a modified Delphi design was used by four physicians to construct the gold standard. Results: In the test set of 120 reports, there were a total of 2,976 noun phrases, of which 287 were correctly identified as negated (true positives), along with 23 undetected true negations (false negatives) and 4 mistaken negations (false positives). The hybrid approach identified negated phrases with sensitivity of 92.6% (95% CI 90.9-93.4%), positive predictive value of 98.6% (95% CI 96.9-99.4%), and specificity of 99.87% (95% CI 99.7-99.9%). Conclusion: This novel hybrid approach can accurately locate negated concepts in clinical radiology reports not only when in close proximity to, but also at a distance from, negation signals. © 2007 J Am Med Inform Assoc.",,"article; automation; confidence interval; Delphi study; electronic medical record; gold standard; grammar; information processing; information system; predictive validity; radiological procedures; radiology department; sensitivity and specificity; Abstracting and Indexing; Automatic Data Processing; Delphi Technique; Humans; Medical Records; Natural Language Processing; Radiology",Article,Scopus
"Pyrros A., Nikolaidis P., Yaghmai V., Zivin S., Tracy J.I., Flanders A.","A Bayesian Approach for the Categorization of Radiology Reports",2007,"Academic Radiology",3,"10.1016/j.acra.2007.01.028","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33947149110&doi=10.1016%2fj.acra.2007.01.028&partnerID=40&md5=3cc05d8c2d97eb740a27f752c73e49dc","Rationale and Objective: We sought to develop a Bayesian-filter that could distinguish positive radiology computed tomography (CT) reports of appendicitis from negative reports with no appendicitis. Materials and Methods: Standard unstructured electronic text radiology reports containing the key word appendicitis were obtained using a Java-based text search engine from a hospital General Electric PACS system. A total of 500 randomly selected reports from multiple radiologists were then manually categorized and merged into two separate text files: 250 positive reports and 250 negative findings of appendicitis. The two text files were then processed by the freely available UNIX-based software dbacl 1.9, a digramic Bayesian classifier for text recognition, on a Linux based Pentium 4 system. The software was then trained on the two separate merged text files categories of positive and negative appendicitis. The ability of the Bayesian filter to discriminate between reports of negative and positive appendicitis images was then tested on 100 randomly selected reports of appendicitis: 50 positive cases and 50 negative cases. Results: The training time for the Bayesian filter was approximately 2 seconds. The Bayesian filter subsequently was able to categorize 50 of 50 positive reports of appendicitis and 50 of 50 reports of negative appendicitis, in less than 10 seconds. Conclusion: A Bayesian-filter system can be used to quickly categorize radiology report findings and automatically determine after training, with a high degree of accuracy, whether the reports have text findings of a specific diagnosis. The Bayesian filter can potentially be applied to any type of radiologic report finding and any relevant category. © 2007 AUR.","automatic text processing; Bayesian filter; PACS reports","accuracy; appendicitis; article; autoanalysis; Bayes theorem; computer assisted tomography; computer program; discriminant analysis; priority journal; radiologist; radiology; Algorithms; Appendicitis; Bayes Theorem; Decision Making, Computer-Assisted; Diagnosis, Differential; False Negative Reactions; False Positive Reactions; Humans; Natural Language Processing; Radiology Information Systems; Tomography, X-Ray Computed",Article,Scopus
"Lee S.I., Saokar A., Dreyer K.J., Weilburg J.B., Thrall J.H., Hahn P.F.","Does radiologist recommendation for follow-up with the same imaging modality contribute substantially to high-cost imaging volume?",2007,"Radiology",49,"10.1148/radiol.2423051754","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33847242197&doi=10.1148%2fradiol.2423051754&partnerID=40&md5=68407c1b10ac7a56929b4e606d14c75f","Purpose: To retrospectively measure repeat rates for high-cost imaging studies, determining their causes and trends, and the impact of radiologist recommendations for a repeat examination on imaging volume. Materials and Methods: This HIPAA-compliant study had institutional review board approval, with waiver of informed consent. Repeat examination was defined as a same-modality examination performed in the same patient within 0 days to 7 months of a first examination. From a database of all radiology examinations (>2.9 million) at one institution from May 1996 to June 2003, a computerized search identified head, spine, chest, and abdominal computed tomographic (CT), brain and spine magnetic resonance (MR) imaging, pelvic ultrasonography (US), and nuclear cardiology examinations with a prior examination of the same type within 7 months. Examination pairs were subdivided into studies repeated at less than 2 weeks, between 2 weeks and 2 months, or between 2 and 7 months. Automated classification of radiology reports revealed whether a repeat examination from June 2002 to June 2003 had been preceded by a radiologist recommendation on the prior report. Trends over time were analyzed with linear regression, and 95% confidence intervals were calculated. Results: Between July 2002 and June 2003, 31 111 of 100 335 examinations (31%) were repeat examinations. Body CT (9057 of 20 177 [45%] chest and 8319 of 22 438 [37%] abdomen) and brain imaging (6823 of 18 378 [37%] CT and 3427 of 11 455 [30%] MR imaging) represented the highest repeat categories. Among five high-cost, high-volume imaging examinations, 6426 of 85 014 (8%) followed a report with a radiologist recommendation. Most common indications for examination repetition were neurologic surveillance within 2 weeks and cancer follow-up at 2-7 months. From 1997 to mid-2003, MR imaging and CT repeat rates increased (0.71% per year [P < .01] and 1.87% per year [P < .01], respectively). Conclusion: Repeat examinations account for nearly one-third of high-cost radiology examinations and represent an increasing proportion of such examinations. Most repeat examinations are initiated clinically without a recommendation by a radiologist. © RSNA, 2007.",,"abdomen; article; brain; cancer diagnosis; cardiovascular system; computer assisted tomography; diagnostic imaging; echography; follow up; head; health care cost; human; imaging system; nuclear magnetic resonance imaging; pelvis; periodic medical examination; priority journal; radiologist; repeat procedure; spine; thorax; Diagnostic Imaging; Health Care Costs; Radiology Department, Hospital; Referral and Consultation; United States",Article,Scopus
"Castilla A.C., Furuie S.S., Mendonça E.A.","Multilingual information retrieval in thoracic radiology: Feasibility study",2007,"Studies in Health Technology and Informatics",1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875571907&partnerID=40&md5=3bed02e7dc2a302bed3c6d0f50870520","Most essential information contained in the electronic medical record is stored as text, and this imposes several difficulties on automated data extraction and retrieval. Natural language processing is an approach that can unlock clinical information from free texts. The proposed methodology uses the specialized natural language processor MEDLEE developed for the English language. To use this processor on Portuguese medical texts, chest X-ray reports were machine translated (MT) into English. The result of serial coupling of MT and NLP is tagged text that needs further investigation for extracting clinical findings. This experiment's objective was to investigate normal reports and reports with device description on a set of 165 chest X-ray reports. We obtained sensitivity and specificity of 1 and 0.71 for the first condition, and 0.97 and 0.97 for the second. The reference was formed by the opinions of two radiologists. The results of this experiment indicate the viability of extracting clinical findings from chest X-ray reports through coupling MT and NLP. © 2007 The authors. All rights reserved.","information storage and retrieval; machine translation; natural language processing; thoracic radiography","Computational linguistics; Couplings; Digital storage; Medical computing; Translation (languages); X ray radiography; X rays; Clinical information; Electronic medical record; Information storage and retrieval; Machine translations; Multi-lingual information retrieval; Sensitivity and specificity; Thoracic radiography; Thoracic radiologies; Natural language processing systems",Conference Paper,Scopus
"Carrell D., Miglioretti D., Smith-Bindman R.","Coding free text radiology reports using the Cancer Text Information Extraction System (caTIES).",2007,"AMIA ... Annual Symposium proceedings / AMIA Symposium. AMIA Symposium",15,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-56149111869&partnerID=40&md5=04a74060d6b6a5165d6d204fa81b41db","We coded 700 radiology reports from 373 women using an unmodified deployment of the Cancer Text Information Extraction System (caTIES), a publicly-available tool using natural language processing techniques. We were moderately successfully using caTIES for case ascertainment, successfully identifying 9/11 of a random sample of cancer case (sensitivity 82%) and 5/100 controls (specificity 95%) We are currently developing a classification scheme to assess clinical risk of ovarian cancer and identifying required extensions to caTIES algorithms.",,"algorithm; article; classification; documentation; female; hospital information system; human; linguistics; medical record; methodology; natural language processing; neoplasm; ovary tumor; radiography; Abstracting and Indexing as Topic; Algorithms; Female; Forms and Records Control; Humans; Natural Language Processing; Neoplasms; Ovarian Neoplasms; Radiology Information Systems; Vocabulary, Controlled",Article,Scopus
"Goldstein I., Arzrumtsyan A., Uzuner O.","Three approaches to automatic assignment of ICD-9-CM codes to radiology reports.",2007,"AMIA ... Annual Symposium proceedings / AMIA Symposium. AMIA Symposium",60,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-46949090420&partnerID=40&md5=7360b630c228fae489242689564208c4","We describe and evaluate three systems for automatically predicting the ICD-9-CM codes of radiology reports from short excerpts of text. The first system benefits from an open source search engine, Lucene, and takes advantage of the relevance of reports to one another based on individual words. The second uses BoosTexter, a boosting algorithm based on n-grams (sequences of consecutive words) and s-grams (sequences of non-consecutive words) extracted from the reports. The third employs a set of hand-crafted rules that capture lexical elements (short, meaningful, strings of words) derived from BoosTexter's n-grams, and that are enhanced by shallow semantic information in the form of negation, synonymy, and uncertainty. Our evaluation shows that semantic information significantly contributes to ICD-9-CM coding with lexical elements. Also, a simple hand-crafted rule-based system with lexical elements and semantic information can outperform algorithmically more complex systems, such as Lucene and BoosTexter, when these systems base their ICD-9-CM predictions only upon individual words, n-grams, or s grams.",,"algorithm; article; artificial intelligence; classification; evaluation; hospital information system; human; international classification of diseases; medical record; methodology; radiology; semantics; Algorithms; Artificial Intelligence; Forms and Records Control; Humans; International Classification of Diseases; Medical Records Systems, Computerized; Radiology; Radiology Information Systems; Semantics",Article,Scopus
"Castilla A.C., Furuie S.S., Mendonça E.A.","Multilingual information retrieval in thoracic radiology: feasibility study.",2007,"Medinfo. MEDINFO",2,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-38449121902&partnerID=40&md5=1676d3c41e90c1759de11cd917b2868e","Most essential information contained in the electronic medical record is stored as text, and this imposes several difficulties on automated data extraction and retrieval. Natural language processing is an approach that can unlock clinical information from free texts. The proposed methodology uses the specialized natural language processor MEDLEE developed for the English language. To use this processor on Portuguese medical texts, chest X-ray reports were machine translated (MT) into English. The result of serial coupling of MT and NLP is tagged text that needs further investigation for extracting clinical findings. This experiment's objective was to investigate normal reports and reports with device description on a set of 165 chest X-ray reports. We obtained sensitivity and specificity of 1 and 0.71 for the first condition, and 0.97 and 0.97 for the second. The reference was formed by the opinions of two radiologists. The results of this experiment indicate the viability of extracting clinical findings from chest X-ray reports through coupling MT and NLP.",,"article; feasibility study; human; information retrieval; language; methodology; natural language processing; thorax radiography; Feasibility Studies; Humans; Information Storage and Retrieval; Multilingualism; Natural Language Processing; Radiography, Thoracic",Article,Scopus
"Reinus W.R.","Economics of Radiology Report Editing Using Voice Recognition Technology",2007,"Journal of the American College of Radiology",12,"10.1016/j.jacr.2007.07.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-36349013667&doi=10.1016%2fj.jacr.2007.07.011&partnerID=40&md5=110467e793522a6fb1ba483f7bbe6525","As voice recognition technology takes hold in radiology practices, independent and hospital-based practices are faced with a decision of who should be responsible for the report-editing process, radiologists or transcriptionists. Although a radiologist's time is expensive compared with a transcriptionist's, if certain other conditions prevail, it may be possible to eliminate transcriptionists from the report generation process. Among these conditions are political, budgeting, psychosocial, and economic constraints. The author presents an econometric model that examines the economic issues involved in such a decision. Practices, both academic and private, can use this model to help determine which course of action makes the most economic sense. This is not always obvious. © 2007 American College of Radiology.","dictation; economics; model; transcription; Voice recognition","article; automatic speech recognition; budget; cost control; cost effectiveness analysis; health care cost; health economics; human; politics; radiologist; radiology; social psychology",Article,Scopus
"Forman H.P.","Re: ""Economics of Radiology Report Editing Using Voice Recognition Technology""",2007,"Journal of the American College of Radiology",2,"10.1016/j.jacr.2007.08.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-36348954935&doi=10.1016%2fj.jacr.2007.08.003&partnerID=40&md5=c494f07c7566ac702bd35228dc131211",[No abstract available],,"analytic method; article; automatic speech recognition; automation; consumer; cost benefit analysis; cost effectiveness analysis; evidence based practice; feedback system; health care; health economics; radiologist; radiology; reimbursement; scientific literature; telephone",Note,Scopus
"Reiner B.I., Knight N., Siegel E.L.","Radiology Reporting, Past, Present, and Future: The Radiologist's Perspective",2007,"Journal of the American College of Radiology",133,"10.1016/j.jacr.2007.01.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34247386754&doi=10.1016%2fj.jacr.2007.01.015&partnerID=40&md5=ff59eb0602c5c8184cec63454d1bc3bf","Although imaging technologies have undergone dramatic evolution over the past century, radiology reporting has remained largely static, in both content and structure. Existing free-text (prose) reports have been criticized for a number of inherent deficiencies, including inconsistencies in content, structure, organization, and nomenclature. A number of new initiatives and technologies now present the radiology community with the unique opportunity to fundamentally change the radiology report from free to structured text. These new developments include a standardized nomenclature (RadLex), automated information technologies (picture archiving and communications systems and electronic medical records), and automated data tracking and analysis software (natural-language processing). Despite the increasing availability of these tools and technologies for revolutionizing reporting, clinical, psychologic, legal, and economic challenges have collectively limited structured reporting to mammography. These challenges are most evident in the current environment of heightened expectations for improved quality, timeliness, and communication, along with increasing stress, fatigue, and malpractice concerns. In conclusion, the authors present an alternative to traditional reporting that attempts to address some of these diverse challenges while incorporating the aforementioned initiatives and technologic developments. This approach uses a graphical symbol language that is directly mapped to a standardized lexicon (RadLex) and is automatically converted into a structured hierarchical text report, which can then be much more easily searched and analyzed. © 2007 American College of Radiology.","pay for performance; quality assurance; Radiology reporting; structured reporting","analytic method; article; economic aspect; fatigue; history of medicine; imaging; legal aspect; malpractice; mammography; medical literature; psychological aspect; quality control; radiologist; stress; total quality management",Article,Scopus
"Siegel E.L., Reiner B.I., Knight N.","Reengineering workflow: The radiologist's perspective",2006,"PACS: A Guide to the Digital Revolution: Second Edition",2,"10.1007/0-387-31070-3_6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-57549106297&doi=10.1007%2f0-387-31070-3_6&partnerID=40&md5=a418e7b75bd47a10e40fe874036cce26","Ask almost any observer what has changed most about the practice of radiology in the last half century and the immediate answer will be the technology. New modalities, interventional techniques, and the digitalization of almost every aspect of image acquisition, retrieval, processing, reporting, and archiving have profoundly altered the look of the imaging department. Ask a radiologist the same question, however, and he or she will respond that the most fundamental and challenging change in actual practice has been in the pace of work demanded of the individual who interprets the images. Gone are the days of a few studies in the morning, home for lunch, and a few more in the afternoon, as Colonel Thompson outlined in his diary at Walter Reed in 1956. Almost gone are the days of single- or two-view studies, interpreted on film and returned with dictated and manually transcribed reports to the referring physician. Instead, an extraordinarily rapid and exponential growth in the number of images that constitute a single study, as well as the performance of numerous studies per patient, has multiplied the daily total of images presented to many radiologists by factors of not tens or hundreds but thousands. Tenacity and creativity have joined sensitivity and specificity as necessary metrics of radiologic success, as once-daunting 8-channel computed tomography (CT) datasets are replaced by those generated from 64-channel studies, and modalities from magnetic resonance (MR) to ultrasound (US) to fusion techniques in nuclear imaging yield increasingly large and complex groups of images. As Horii and others have pointed out, the size of these datasets has actually accomplished what logic and documented successes sometimes failed to do. These images form the ""first group of examinations that cannot practically be printed to film for interpretation."" A 1000-image CT examination-now commonplace in many institutions-would require a minimum of 67 film sheets to print (using a 4 4 matrix on film) and would take up 17 panels of a 4-light-box mechanical film changer for each window/level combination. The image explosion has made the transition to filmless imaging mandatory for many who once considered it an interesting future option. The result over the past 5 years has been an increasing focus on workflow issues relating to the essence of radiologic practice: the process that occurs at the interface between the interpreter and the image. The literature documenting radiologist workflow issues is growing. Of course, the tasks of the radiologist at the workstations are part of a larger workflow and depend on a number of factors, including effective picture archiving and communication systems (PACS) integration with the radiology and hospital information systems (RIS and HIS, respectively), worklist management, workstation design, and innovations in the interpretation process, reporting, and interactions with clinicians and the larger medical enterprise. Less studied but equally important are the effects of room design and ergonomics on radiologist workflow and productivity as well as the need for reliable metrics and tools by which such productivity can be assessed and compared. Because PACS serve increasingly as the nexus and conduit for the work of the radiologist, a number of other chapters in this book cover in greater detail the technical elements that make up routine workflow. Our goal in this chapter is to provide background, overview, and resources on current challenges and benefits associated with various elements of radiologist workflow. © 2006 Springer Science+Business Media, Inc.",,,Book Chapter,Scopus
"Noumeir R.","Radiology interpretation process modeling",2006,"Journal of Biomedical Informatics",27,"10.1016/j.jbi.2005.07.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33644940354&doi=10.1016%2fj.jbi.2005.07.001&partnerID=40&md5=9441e6c2c4df91ef9f2c614277072fdc","Information and communication technology in healthcare promises optimized patient care while ensuring efficiency and cost-effectiveness. However, the promised results are not yet achieved; the healthcare process requires analysis and radical redesign to achieve improvements in care quality and productivity. Healthcare process reengineering is thus necessary and involves modeling its workflow. Even though the healthcare process is very large and not very well modeled yet, its sub-processes can be modeled individually, providing fundamental pieces of the whole model. In this paper, we are interested in modeling the radiology interpretation process that results in generating a diagnostic radiology report. This radiology report is an important clinical element of the patient healthcare record and assists in healthcare decisions. We present the radiology interpretation process by identifying its boundaries and by positioning it on the large healthcare process map. Moreover, we discuss an information data model and identify roles, tasks and several information flows. Furthermore, we describe standard frameworks to enable radiology interpretation workflow implementations between heterogeneous systems. © 2005 Elsevier Inc. All rights reserved.","Business process redesign; Diagnostic report; Digital imaging and communications in medicine; Integrating the healthcare enterprise; Interpretation; Process modeling; Process reengineering; Radiology; Workflow management systems; Workflow modeling","Communication; Cost effectiveness; Health care; Information technology; Logic design; Business process redesign; Diagnostic report; Digital imaging and communications in medicine; Integrating the healthcare enterprise; Interpretation; Process modeling; Process reengineering; Workflow management systems; Workflow modeling; Radiology; article; communication software; cost effectiveness analysis; digital imaging; health care management; health care organization; health service; image processing; information technology; medical information; patient care; priority journal; process model; radiodiagnosis; radiology; Canada; Decision Support Systems, Clinical; Decision Support Techniques; Information Dissemination; Information Storage and Retrieval; Process Assessment (Health Care); Radiographic Image Interpretation, Computer-Assisted; Radiology Information Systems",Article,Scopus
"Miguel-Dasit A., Martí-Bonmatí L., Sanfeliu P., Aleixandre R.","Scientific papers presented at the European Congress of Radiology 2000: Publication rates and characteristics during the period 2000-2004",2006,"European Radiology",44,"10.1007/s00330-005-2861-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-31444453445&doi=10.1007%2fs00330-005-2861-3&partnerID=40&md5=36517794822a147c62aea984b205b471","To determine the rate at which abstracts orally presented at the ECR 2000 were published between 2000-2004, and to identify predictive factors of publication and differences between abstracts and subsequently published papers. Specific search profiles were devised to retrieve items from the Medline database. From 1020 abstracts originating from 39 countries, 479 articles (publication rate 47%) were subsequently published in 139 Medline-indexed journals, most frequently in European Radiology (14%). Country of origin statistically (P <0.0001) influences the subsequent publication of the abstract, Germany having the highest number of presentations (n=343) and derived articles (publication rate 54%). Abstracts presented by authors from the USA (n=21) had the highest publication rate (76%). Most papers were published within the first 3 years after the meeting, as original articles and in English-language journals. Both the study sample size and the first author frequently changed. Chest and cardiac studies had the highest publication rates (56%, both). In summary, abstracts presented at the ECR 2000 had a high publication rate in Medline-indexed journals. Country of origin and subspecialty of presentation appeared to influence subsequent full publication. More articles were published in European Radiology than in other journal. © Springer-Verlag 2005.","ECR 2000; Publication; Radiology and radiologists, research; Radiology and radiologists, socioeconomic issues; Scientific congress","abstract report; article; controlled study; data base; European Union; Germany; health care organization; information retrieval; language; medical research; MEDLINE; priority journal; publication; publishing; radiocardiography; radiology; sample size; scientific literature; statistical analysis; symposium; thorax radiography; United States; Abstracting and Indexing; Congresses; Education, Medical, Continuing; Humans; Likelihood Functions; Manuscripts, Medical; MEDLINE; Publishing; Radiology; Socioeconomic Factors",Article,Scopus
"Matykiewicz P., Pestian J., Duch W., Johnson N.","Unambiguous concept mapping in radiology reports: graphs of consistent concepts.",2006,"AMIA ... Annual Symposium proceedings / AMIA Symposium. AMIA Symposium",1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-34748824900&partnerID=40&md5=e2ee396424b50f9af33cb3f104768972",[No abstract available],,"article; classification; human; kidney; medical information system; medical record; natural language processing; radiography; radiology; Humans; Kidney; Medical Records; Natural Language Processing; Radiography; Radiology; Unified Medical Language System",Article,Scopus
"Friedlin J., McDonald C.J.","A natural language processing system to extract and code concepts relating to congestive heart failure from chest radiology reports.",2006,"AMIA ... Annual Symposium proceedings / AMIA Symposium. AMIA Symposium",34,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-34748821126&partnerID=40&md5=45ef622248399efcf509bef1d1cb4be0","We have developed a natural language processing system for extracting and coding clinical data from free text reports. The system is designed to be easily modified and adapted to a variety of free text clinical reports such as admission notes, radiology and pathology reports, and discharge summaries. This report presents the results of this system to extract and code clinical concepts related to congestive heart failure from 39,000 chest radiology reports. The system detects the presence or absence of six concepts: congestive heart failure, Kerley B lines, cardiomegaly, prominent pulmonary vasculature, pulmonary edema, and pleural effusion. We compared it's output to a gold standard which consisted of specially trained human coders as well as an experienced physician. Results indicate that the system had high specificity, recall and precision for each of the concepts it is designed to detect.",,"article; classification; comparative study; congestive heart failure; human; medical record; natural language processing; prediction and forecasting; radiography; sensitivity and specificity; thorax radiography; validation study; Forms and Records Control; Heart Failure, Congestive; Humans; Natural Language Processing; Predictive Value of Tests; Radiography, Thoracic; Sensitivity and Specificity",Article,Scopus
"Lakhani P., Menschik E.D., Goldszal A.F., Murray J.P., Weiner M.G., Langlotz C.P.","Development and validation of queries using structured query language (SQL) to determine the utilization of comparison imaging in radiology reports stored on PACS",2006,"Journal of Digital Imaging",9,"10.1007/s10278-005-7667-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33644918594&doi=10.1007%2fs10278-005-7667-y&partnerID=40&md5=35b703a3141bb912b5f9dc6290222b2a","The purpose of this research was to develop queries that quantify the utilization of comparison imaging in free-text radiology reports. The queries searched for common phrases that indicate whether comparison imaging was utilized, not available, or not mentioned. The queries were iteratively refined and tested on random samples of 100 reports with human review as a reference standard until the precision and recall of the queries did not improve significantly between iterations. Then, query accuracy was assessed on a new random sample of 200 reports. Overall accuracy of the queries was 95.6%. The queries were then applied to a database of 1.8 million reports. Comparisons were made to prior images in 38.69% of the reports (693,955/1,793,754), were unavailable in 18.79% (337,028/1,793,754), and were not mentioned in 42.52% (762,771/1,793,754). The results show that queries of text reports can achieve greater than 95% accuracy in determining the utilization of prior images. Copyright © 2005 by SCAR (Society for Computer Applications in Radiology).","Databases; Query; Structured query language (SQL)","Iterative methods; Medical imaging; Radiology; Query accuracy; Random samples; Structured query language (SQL); Query languages; article; comparative study; data base; diagnostic accuracy; digital imaging; image analysis; image processing; imaging system; priority journal; radiology; sampling; standard; structured query language; utilization review; validation process; Database Management Systems; Humans; Image Processing, Computer-Assisted; Information Storage and Retrieval; Natural Language Processing; Radiology Information Systems; Reproducibility of Results; Software",Article,Scopus
"Kwak M., Jung S., Choi J.","Information extraction from radiology reports mingled two languages",2005,"Proceedings of the 7th International Workshop on Enterprise Networking and Computing in Healthcare Industry, HEALTHCOM 2005",,"10.1109/HEALTH.2005.1500443","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745270048&doi=10.1109%2fHEALTH.2005.1500443&partnerID=40&md5=9a5c1978bee1984b4f082c831f6d9f3f","This study presents overall of information Extraction (IE) for SNVH (Seoul National University Hospital) radiology reports coexisted Korean and English using Concept Node (CN) definition which is a case frame as extraction rule. The following steps are performed: design conceptual model by terminology exploration, create a CN definition based on syntactic relationship between two major semantic entities analyzed with sentences by a domain expert and implement automatic IE system using CN definition. Main purposes is to investigate whether syntactic and semantic analysis technique using extraction rule (CN) is effective for typical Korean medical text in mixed two different languages. © 2005 IEEE.",,"Concept Node (CN); Information extraction; Semantic analysis; Seoul National University Hospital (SNVH); Data acquisition; Data mining; Linguistics; Radiology; Semantics; Information technology",Conference Paper,Scopus
"Mendonça E.A., Haas J., Shagina L., Larson E., Friedman C.","Extracting information on pneumonia in infants using natural language processing of radiology reports",2005,"Journal of Biomedical Informatics",76,"10.1016/j.jbi.2005.02.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-23244449654&doi=10.1016%2fj.jbi.2005.02.003&partnerID=40&md5=669257a8b3480a512f68e37211dfe885","Natural language processing (NLP) is critical for improvement of the healthcare process because it can encode clinical data in patient documents. Many clinical applications such as decision support require coded data to function appropriately. However, in order to be applicable for healthcare, performance must be adequate. A valuable automated application is the detection of infectious diseases, such as surveillance of pneumonia in newborns (e.g., neonates) because the disease produces significant rates of morbidity and mortality, and manual surveillance is challenging. Studies have demonstrated that automated surveillance using NLP is a useful adjunct to manual surveillance and an effective tool for infection control practitioners. This paper presents a study evaluating the feasibility of an NLP-based monitoring system to screen for healthcare-associated pneumonia in neonates. We estimated sensitivity, specificity, and positive predictive value by comparing results with clinicians' judgments. Sensitivity was 71% and specificity was 99%. Our results demonstrated that the automated method was feasible. © 2005 Elsevier Inc. All rights reserved.","Infants; Infectious diseases; Natural language processing; Surveillance","Decision support systems; Diseases; Health care; Information retrieval; Medical imaging; Natural language processing systems; Morbidity; Mortality; NLP-based monitoring systems; Pneumonia; Biomedical engineering; accuracy; article; artificial intelligence; automation; decision support system; health care; health survey; human; infant; infant disease; infection; medical documentation; medical information; medical record; morbidity; mortality; newborn; patient monitoring; pneumonia; priority journal; Database Management Systems; Diagnosis, Computer-Assisted; Expert Systems; Feasibility Studies; Humans; Infant, Newborn; Information Storage and Retrieval; Mass Screening; Medical Records Systems, Computerized; Natural Language Processing; Pneumonia; Radiology Information Systems; Reproducibility of Results; Sensitivity and Specificity; United States",Article,Scopus
"Marwede D., Fielding M.","The epistemological-ontological divide in clinical radiology",2005,"Studies in Health Technology and Informatics",2,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84886931183&partnerID=40&md5=f41a0439103d9f1fd05f78faf983b1bd","Medical ontologies like GALEN, the FMA or SNOMED represent a kind of ""100% certain"" medical knowledge which is not inherent to all medical sub-domains. Clinical radiology uses computerized imaging techniques to make the human body visible and interprets the imaging findings in a clinical context delivering a textual report. For clinical radiology few standardized vocabularies are available. We examined the definitions given in the glossary of terms for thoracic radiology published by the Fleischner Society. We further classified these terms with regard to their definitions in terms of (a) describing visible structures on the image itself, (b) referring to ontological entities of the body (anatomical or pathological), and (c) terms imposing knowledge on structures visible on the image, epistemologically representing ontological entities of the body. Each ontological/epistemological definition was rated on a scale of vague/weak-sound/strong and put in context with the evaluation comments for the use of the terms given in the glossary itself. The result of this distinction shows that clinical radiology uses many terms referring to ontological entities valid for representation in a medical ontology. However, many epistemological terms exist in the terminology which impose epistemological knowledge on ontological entities. The analysis of the evaluation comments reveals that terms classified as sound (ontologically) and strong (epistemologically) are evaluated higher than terms bearing vague or weak definitions. On the basis of this, we argue that the distinction between ontological and epistemological definitions is necessary in order to construct epistemologically-sensitive application ontologies for medical sub-domains, like clinical radiology, where knowledge is fragmented in terms of description, inferred from a description, concluded on the basis of imaging, or other additional information with varying degrees of certainty.","Clinical radiology; Conceptual modelling; Controlled vocabularies; Medical ontology","Glossaries; Ontology; Radiation; Radiology; Thesauri; Clinical radiology; Computerized imaging; Conceptual modelling; Human bodies; Medical knowledge; Medical ontology; Sensitive application; Thoracic radiologies; Medical imaging; controlled vocabulary; human; information processing; knowledge; nomenclature; Systematized Nomenclature of Medicine; Automatic Data Processing; Humans; Knowledge; Systematized Nomenclature of Medicine; Terminology as Topic; Vocabulary, Controlled",Conference Paper,Scopus
"Bashyam V., Taira R.K.","Indexing anatomical phrases in neuro-radiology reports to the UMLS 2005AA.",2005,"AMIA ... Annual Symposium proceedings / AMIA Symposium. AMIA Symposium",10,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-39049191566&partnerID=40&md5=9675de55e769e0ef42afff68f3f86241","This work describes a methodology to index anatomical phrases to the 2005AA release of the Unified Medical Language System (UMLS). A phrase chunking tool based on Natural Language Processing (NLP) was developed to identify semantically coherent phrases within medical reports. Using this phrase chunker, a set of 2,551 unique anatomical phrases was extracted from brain radiology reports. These phrases were mapped to the 2005AA release of the UMLS using a vector space model. Precision for the task of indexing unique phrases was 0.87.",,"algorithm; anatomy; article; brain; classification; documentation; histology; human; medical information system; medical record; methodology; natural language processing; radiography; Abstracting and Indexing; Algorithms; Anatomy; Brain; Humans; Medical Records; Natural Language Processing; Unified Medical Language System",Article,Scopus
"Vreeman D.J., McDonald C.J.","Automated mapping of local radiology terms to LOINC.",2005,"AMIA ... Annual Symposium proceedings / AMIA Symposium. AMIA Symposium",26,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-39049187173&partnerID=40&md5=30973c7f366611580747145cb93aad33","We developed an automated tool, called the Intelligent Mapper (IM), to improve the efficiency and consistency of mapping local terms to LOINC. We evaluated IM's performance in mapping diagnostic radiology report terms from two hospitals to LOINC by comparing IM's term rankings to a manually established gold standard. Using a CPT-based restriction, for terms with a LOINC code match, IM ranked the correct LOINC code first in 90% of our development set terms, and in 87% of our test set terms. The CPT-based restriction significantly improved IM's ability to identify correct LOINC codes. We have made IM freely available, with the aim of reducing the effort required to integrate disparate systems and helping move us towards the goal of interoperable health information exchange.",,"article; artificial intelligence; classification; computer program; evaluation; human; linguistics; Logical Observation Identifiers Names and Codes; radiology; Artificial Intelligence; Humans; Logical Observation Identifiers Names and Codes; Radiology; Software; Vocabulary, Controlled",Article,Scopus
"Kwak M., Han S., Choi J.","Information extraction from Korean radiology reports mingled two language.",2005,"AMIA ... Annual Symposium proceedings / AMIA Symposium. AMIA Symposium",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-39049179339&partnerID=40&md5=9af033a0a7c71622ad69dbaf377b1298","This study presents overall of Information Extraction (IE) for SNUH (Seoul National University Hospital) radiology reports coexisted Korean and English using Concept Node (CN) which is a case frame as extraction rule. The following steps are performed: design conceptual model by terminology exploration based on lexical analysis, create a CN definition based on syntactic relationship pattern and implement automatic IE system using CN. Main purposes is to investigate whether syntactic and semantic analysis technique using extraction rule (CN) is effective for typical Korean medical text in mixed two different languages.",,"article; human; information retrieval; language; linguistics; medical record; radiology; Humans; Information Storage and Retrieval; Linguistics; Medical Records Systems, Computerized; Multilingualism; Radiology",Article,Scopus
"Bashyam V., Taira R.K.","A study of lexical behaviour of sentences in chest radiology reports.",2005,"AMIA ... Annual Symposium proceedings / AMIA Symposium. AMIA Symposium",4,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-34547125498&partnerID=40&md5=a063bed53d0517cb07aab7b522aef010","Statistical natural language processors have been the focus of much research during the past decade. The UCLA Medical Imaging Informatics Group (MII) has developed a statistical NLP for the domain of radiology. We report a study of syntactic and semantic behaviour of sentences in the domain of chest radiology.",,"article; human; linguistics; natural language processing; thorax radiography; Humans; Linguistics; Natural Language Processing; Radiography, Thoracic",Article,Scopus
"Huang Y., Lowe H.J.","A grammar-based classification of negations in clinical radiology reports.",2005,"AMIA ... Annual Symposium proceedings / AMIA Symposium. AMIA Symposium",8,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-33947183613&partnerID=40&md5=1c759fc225786899d2f1e1e521c5bb09","We describe the development of a classification scheme of negations based on syntactical categories of negative words, and patterns of negation. Each category contains a negative word or phrase and a pattern to locate negated terms. The classification was derived through literature study and manual inspection of 500 radiology reports of six common imaging modalities.",,"article; classification; documentation; linguistics; medical information system; medical record; natural language processing; radiology; Abstracting and Indexing; Linguistics; Medical Records; Natural Language Processing; Radiology; Unified Medical Language System",Article,Scopus
"Huang Y., Lowe H.J., Klein D., Cucina R.J.","Improved identification of noun phrases in clinical radiology reports using a high-performance statistical natural language parser augmented with the UMLS Specialist Lexicon",2005,"Journal of the American Medical Informatics Association",56,"10.1197/jamia.M1695","https://www.scopus.com/inward/record.uri?eid=2-s2.0-18044384608&doi=10.1197%2fjamia.M1695&partnerID=40&md5=40cf1c8a2fbc8c558ad14495f271967f","Objective: The aim of this study was to develop and evaluate a method of extracting noun phrases with full phrase structures from a set of clinical radiology reports using natural language processing (NLP) and to investigate the effects of using the UMLS® Specialist Lexicon to improve noun phrase identification within clinical radiology documents. Design: The noun phrase identification (NPI) module is composed of a sentence boundary detector, a statistical natural language parser trained on a nonmedical domain, and a noun phrase (NP) tagger. The NPI module processed a set of 100 XML-represented clinical radiology reports in Health Level 7 (HL7)® Clinical Document Architecture (CDA)-compatible format. Computed output was compared with manual markups made by four physicians and one author for maximal (longest) NP and those made by one author for base (simple) NP, respectively. An extended lexicon of biomedical terms was created from the UMLS Specialist Lexicon and used to improve NPI performance. Results: The test set was 50 randomly selected reports. The sentence boundary detector achieved 99.0% precision and 98.6% recall. The overall maximal NPI precision and recall were 78.9% and 81.5% before using the UMLS Specialist Lexicon and 82.1% and 84.6% after. The overall base NPI precision and recall were 88.2% and 86.8% before using the UMLS Specialist Lexicon and 93.1% and 92.6% after, reducing false-positives by 31.1% and false-negatives by 34.3%. Conclusion: The sentence boundary detector performs excellently. After the adaptation using the UMLS Specialist Lexicon, the statistical parser's NPI performance on radiology reports increased to levels comparable to the parser's native performance in its newswire training domain and to that reported by other researchers in the general nonmedical domain.",,"accuracy; article; data base; language; medical informatics; nomenclature; radiology; statistical analysis",Article,Scopus
"Thomas B.J., Ouellette H., Halpern E.F., Rosenthal D.I.","Automated computer-assisted categorization of radiology reports",2005,"American Journal of Roentgenology",35,"10.2214/ajr.184.2.01840687","https://www.scopus.com/inward/record.uri?eid=2-s2.0-15944400709&doi=10.2214%2fajr.184.2.01840687&partnerID=40&md5=f79f231ee09924a91f5c5b8a6e64ed0f","OBJECTIVE. The objective of our study was to create and validate an automated computerized method for the categorization of narrative text radiograph reports. MATERIALS AND METHODS. Using commercially available software with embedded Boolean logic, we created a text search algorithm to categorize reports of radiography examinations into ""fracture,"" ""normal,"" and ""neither normal nor fracture."" The algorithm was refined and optimized through repeated testing on 512 consecutive ankle radiography reports from a single clinical imaging center. The final algorithm was applied on a different set of 750 consecutive radiography reports of the spine and extremities produced at three different clinical imaging sites and interpreted by 44 different radiologists. Expert reviewers assessed the accuracy of the final classification. The chi-square test or Fisher's exact test was performed to determine the reproducibility of results across different clinical imaging sites. RESULTS. The computerized classification was highly accurate for the classification of radiography reports into ""normal"" (specificity, 91.6%; sensitivity, 91.3%), ""neither normal nor fracture"" (sensitivity, 87.8%; specificity, 94.9%), and ""fracture"" (sensitivity, 94.1%; specificity, 98.1%) categories. This performance showed no significant difference across the three sites (p > 0.05). CONCLUSION. Computerized categorization of narrative-text radiography reports is highly sensitive and specific and can be used to classify reports from different imaging sites generated by different radiologists. This method can be an extremely powerful tool in future cost-effectiveness studies, health care policy studies, operations assessments, and quality control. © American Roentgen Ray Society.",,"ankle radiography; article; clinical assessment; computer program; controlled study; fracture; human; human experiment; imaging system; priority journal; radiologist; spine radiography; X ray film; algorithm; chi square distribution; decision support system; hospital information system; laboratory diagnosis; reproducibility; sensitivity and specificity; Algorithms; Chi-Square Distribution; Decision Making, Computer-Assisted; False Negative Reactions; False Positive Reactions; Humans; Radiology Information Systems; Reproducibility of Results; Sensitivity and Specificity; Software",Article,Scopus
"Yam C.-S., Rofsky N., Kruskal J., Sitek A.","Development of a radiology report monitoring system for case tracking",2005,"American Journal of Roentgenology",1,"10.2214/ajr.184.1.01840343","https://www.scopus.com/inward/record.uri?eid=2-s2.0-11144292798&doi=10.2214%2fajr.184.1.01840343&partnerID=40&md5=109c614cef9910847eadde645c59caac","OBJECTIVE. The objective was to develop an automated system to monitor and collect radiology reports for case-tracking purposes. CONCLUSION. The system we developed allows users to automate the case-tracking process for either clinical follow-up or teaching purposes. With this system, radiologists can initiate the tracking of a case by dictating a keyword into the report. Any existing and future reports associated with the same patient will be collected automatically. The schematic that we developed is based on the Health Level Seven (HL7) standard, which is platform-independent. In our implementation, we used an IBM-compatible computer and commercially available software. Users can monitor the case-tracking progress from Web browsers.",,"article; automation; computer program; computer system; data analysis; hospital information system; Internet; medical information system; patient monitoring; priority journal; radiology",Article,Scopus
"Eng J., Eisner J.M.","Radiology report entry with automatic phrase completion driven by language modeling",2004,"Radiographics",11,"10.1148/rg.245035197","https://www.scopus.com/inward/record.uri?eid=2-s2.0-4944260413&doi=10.1148%2frg.245035197&partnerID=40&md5=09209ce62e2801cb01d0e5f3bc62df49","Keyboard entry or correction of radiology reports by radiologists and transcriptionists remains necessary in many settings despite advances in computerized speech recognition. A report entry system that implements an automated phrase completion feature based on language modeling was developed and tested. The special text editor uses context to predict the full word or phrase being typed, updating the displayed prediction after each keystroke. At any point, pressing the tab key inserts the predicted phrase without having to type the remaining characters of the phrase. Successive words of the phrase are predicted by a trigram language model. Phrase lengths are chosen to minimize the expected number of keystrokes as predicted by the language model. Operation is highly and automatically customized to each user. The language model was trained on 36,843 general radiography reports, which were consecutively generated and contained 1.48 million words. Performance was tested on 200 randomly selected reports outside of the training set. The phrase completion technique reduced the average number of keystrokes per report from 194 to 58; the average reduction factor was 3.3 (geometric mean) (95% confidence interval, 3.2-3.5). The algorithm significantly reduced the number of keystrokes required to generate a radiography report (P < .00005). © RSNA, 2004.","Computers; Information management; Information management, systems; Radiology reporting systems","algorithm; article; automation; computer system; confidence interval; geometry; language; medical informatics; model; performance; prediction; radiography; radiologist; randomization; speech discrimination; computer program; hospital information system; human; information processing; language; man machine interaction; medical record; radiography; time; workload; Algorithms; Data Display; Humans; Language; Man-Machine Systems; Medical Records Systems, Computerized; Radiography; Radiology Information Systems; Software; Time Factors; Workload",Article,Scopus
"Mamlin B.W., Heinze D.T., McDonald C.J.","Automated extraction and normalization of findings from cancer-related free-text radiology reports.",2003,"AMIA ... Annual Symposium proceedings / AMIA Symposium. AMIA Symposium",41,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-16544361890&partnerID=40&md5=b3aac2f8381985d643b369693bfeb6c8","We describe the performance of a particular natural language processing system that uses knowledge vectors to extract findings from radiology reports. LifeCode (A-Life Medical, Inc.) has been successfully coding reports for billing purposes for several years. In this study, we describe the use of LifeCode to code all findings within a set of 500 cancer-related radiology reports against a test set in which all findings were manually tagged. The system was trained with 1400 reports prior to running the test set. RESULTS: LifeCode had a recall of 84.5% and precision of 95.7% in the coding of cancer-related radiology report findings. CONCLUSION: Despite the use of a modest sized training set and minimal training iterations, when applied to cancer-related reports the system achieved recall and precision measures comparable to other reputable natural language processors in this domain.",,"article; classification; comparative study; computer program; evaluation; expert system; hospital information system; human; information retrieval; international classification of diseases; linguistics; medical record; methodology; natural language processing; neoplasm; radiography; thorax radiography; Expert Systems; Forms and Records Control; Humans; Information Storage and Retrieval; International Classification of Diseases; Natural Language Processing; Neoplasms; Radiography, Thoracic; Radiology Information Systems; Software; Vocabulary, Controlled",Article,Scopus
"Huang Y., Lowe H.J., Hersh W.R.","A Pilot Study of Contextual UMLS Indexing to Improve the Precision of Concept-based Representation in XML-structured Clinical Radiology Reports",2003,"Journal of the American Medical Informatics Association",35,"10.1197/jamia.M1369","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0242495825&doi=10.1197%2fjamia.M1369&partnerID=40&md5=cc53b9914512e8766e1cc09b4cc3a095","Objective: Despite the advantages of structured data entry, much of the patient record is still stored as unstructured or semistructured narrative text. The issue of representing clinical document content remains problematic. The authors' prior work using an automated UMLS document indexing system has been encouraging but has been affected by the generally low indexing precision of such systems. In an effort to improve precision, the authors have developed a context-sensitive document indexing model to calculate the optimal subset of UMLS source vocabularies used to index each document section. This pilot study was performed to evaluate the utility of this indexing approach on a set of clinical radiology reports. Design: A set of clinical radiology reports that had been indexed manually using UMLS concept descriptors was indexed automatically by the SAPHIRE indexing engine. Using the data generated by this process the authors developed a system that simulated indexing, at the document section level, of the same document set using many permutations of a subset of the UMLS constituent vocabularies. Measurements: The precision and recall scores generated by simulated indexing for each permutation of two or three UMLS constituent vocabularies were determined. Results: While there was considerable variation in precision and recall values across the different subtypes of radiology reports, the overall effect of this indexing strategy using the best combination of two or three UMLS constituent vocabularies was an improvement in precision without significant impact of recall. Conclusion: In this pilot study a contextual indexing strategy improved overall precision in a set of clinical radiology reports.",,"accuracy; article; automation; bone scintiscanning; computer assisted tomography; computer language; information processing; medical documentation; medical record; pilot study; radiology; recall; simulation; X ray analysis",Article,Scopus
"Chapman W.W., Cooper G.F., Hanbury P., Chapman B.E., Harrison L.H., Wagner M.M.","Creating a text classifier to detect radiology reports describing mediastinal findings associated with inhalational anthrax and other disorders",2003,"Journal of the American Medical Informatics Association",37,"10.1197/jamia.M1330","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0042334852&doi=10.1197%2fjamia.M1330&partnerID=40&md5=f8a54db5b3fa39acda1869ed6e7a2dcf","Objective: The aim of this study was to create a classifier for automatic detection of chest radiograph reports consistent with the mediastinal findings of inhalational anthrax. Design: The authors used the Identify Patient Sets (IPS) system to create a key word classifier for detecting reports describing mediastinal findings consistent with anthrax and compared their performances on a test set of 79,032 chest radiograph reports. Measurements: Area under the ROC curve was the main outcome measure of the IPS classifier. Sensitivity and specificity of an initial IPS model were calculated based on an existing key word search and were compared against a Boolean version of the IPS classifier. Results: The IPS classifier received an area under the ROC curve of 0.677 (90% CI = 0.628 to 0.772) with a specificity of 0.99 and maximum sensitivity of 0.35. The initial IPS model attained a specificity of 1.0 and a sensitivity of 0.04. Conclusion: The IPS system is a useful tool for helping domain experts create a statistical key word classifier for textual reports that is a potentially useful component in surveillance of radiographic findings suspicious for anthrax.",,"anthrax; article; automation; Bacillus anthracis; diagnostic accuracy; diagnostic imaging; health survey; mediastinum; medical informatics; performance; thorax radiography; validation process",Article,Scopus
"Ralston M.D., Coleman R.M., Beaulieu D.M.","Progress toward paperless radiology in the digital environment: Planning, implementation, and benefits",2003,"Journal of Digital Imaging",1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0041845350&partnerID=40&md5=54c35e3ff8befab5c4814288fd32324c","The effort involved in going paperless has proved worthwhile at MMC, resulting in faster throughput by technologists, radiologists, and transcriptionists, as well as quicker report availability for clinicians. Since the radiologists is freed from the distractions of finding and handling paper documents, they are allowed to concentrate more fully on the clinical images and information and thereby may potentially render better interpretations. Likewise, because transcription is freed from paperwork, report turnaround time has improved remarkably.",,"Computer workstations; Electronic document identification systems; Health care; Image communication systems; Image retrieval; Radiology; Servers; World Wide Web; Computed radiography; Digital dictation system; Picture archiving and communication systems; Radiology information system; Webserver system; Digital image storage",Article,Scopus
"Langlotz C.P., Caldwell S.A.","The completeness of existing lexicons for representing radiology report information.",2002,"Journal of digital imaging : the official journal of the Society for Computer Applications in Radiology",37,"10.1007/s10278-002-5046-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-19044392066&doi=10.1007%2fs10278-002-5046-5&partnerID=40&md5=b43aef017efb30c12ef45607dfa9cb0e","Although most medical lexicons contain up to 80% of clinical terms used in an ambulatory patient medical records archive, preliminary research suggests that they may be far less complete for radiology terms. We therefore compared the likelihood that several existing medical lexicons would contain terms found in a radiology report to the likelihood they would contain terms found in an ambulatory care medical record. We used three samples of imaging terms to assess the completeness of existing lexicons for medical imaging: (1) a random sample of imaging terms from the Unified Medical Language System Large Scale Vocabulary Test (UMLS-LSVT; n = 218), (2) terms actually used in the first 80 clinical knee magnetic resonance imaging reports generated by the routine clinical use of a structured reporting system (eDictation, Marlton, NJ; n = 76), and (3) terms listed in a glossary of thoracic imaging prepared by the Fleischner Society (n = 173). Using the UMLS Web-based Knowledge Source Server (http://umlsks.nlm.nih. gov/), we measured the rate at which terms in each of the above three sources were found in the UMLS and two of its major constituent terminologies: ICD-9-CM and SNOMED International. ICD-9-CM contained matches for 3%, 8%, and 11% of terms from the Fleischner Society Glossary, eDictation, and NLM-LSVT, respectively. SNOMED International contained matches for 32%, 46%, and 36% of terms from the Fleischner Society Glossary, eDictation, and NLM-LSVT, respectively. The UMLS contained matches for 36%, 50%, and 45% of terms from the Fleischner Society Glossary, eDictation, and NLM-LSVT, respectively. The assessed vocabularies were least likely to contain a term from the Fleischner Society Glossary and most likely to contain a term from the eDictation lexicon. The UMLS was the most complete, and ICD-9 was the least complete of the three systems evaluated. No lexicon achieved greater than 50% completeness for any test set of imaging terms. Our results show that no single lexicon is sufficiently complete to allow comprehensive indexing, search, and retrieval of radiology report information. These results confirm the few results available from the medical literature indicating that existing controlled vocabularies are insufficiently complete to represent the contents of radiology reports. A subjective analysis of these results may identify particular imaging sub-areas for which new terms should be developed.",,"article; human; medical information system; medical record; nomenclature; radiology; standard; Humans; Medical Records; Radiology; Terminology; Unified Medical Language System",Article,Scopus
"Hersh W., Mailhot M., Arnott-Smith C., Lowe H.","Selective automated indexing of findings and diagnoses in radiology reports",2001,"Journal of Biomedical Informatics",41,"10.1006/jbin.2001.1025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0035564683&doi=10.1006%2fjbin.2001.1025&partnerID=40&md5=e3c1cc1ad7b449afeabab94c25763040","The recent improvements in capabilities of desktop computers and communications networks give impetus for the development of clinical image repositories that can be used for patient care and medical education. A challenge in the use of these systems is the accurate indexing of images for retrieval performance acceptable to users. This paper describes a series of experiments aiming to adapt the SAPHIRE system, which matches text to concepts in the UMLS Metathesaurus, for the automated indexing of image reports. A series of enhancements to the baseline system resulted in a recall of 63% but a precision of only 30% in detecting concepts. At this level of performance, such a system might be problematic for users in a purely automated indexing environment. However, if the ability to retrieve images in repositories based on content in their reports is desired by clinical users, and no other current systems offer this functionality, then follow-up research questions include whether these imperfect results would be useful in a completely or partially automated indexing environment and/or whether other approaches can improve upon them. © 2001 Elsevier Science (USA).","Automated indexing; Evaluation; Metathesaurus; Natural language processing; SAPHIRE; Unified medical language system (UMLS)","accuracy; article; automation; computer system; evaluation; image enhancement; image processing; information processing; information retrieval; language; medical informatics; performance; priority journal; radiodiagnosis; radiology",Article,Scopus
"Taira R.K., Soderland S.G., Jakobovits R.M.","Automatic structuring of radiology free-text reports",2001,"Radiographics",89,"10.1148/radiographics.21.1.g01ja18237","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0035220275&doi=10.1148%2fradiographics.21.1.g01ja18237&partnerID=40&md5=f39d5469d7dfc39b08e1a4d815c5229e","A natural language processor was developed that automatically structures the important medical information (eg, the existence, properties, location, and diagnostic interpretation of findings) contained in a radiology free-text document as a formal information model that can be interpreted by a computer program. The input to the system is a free-text report from a radiologic study. The system requires no reporting style changes on the part of the radiologist. Statistical and machine learning methods are used extensively throughout the system. A graphical user interface has been developed that allows the creation of hand-tagged training examples. Various aspects of the difficult problem of implementing an automated structured reporting system have been addressed, and the relevant technology is progressing well. Extensible Markup Language is emerging as the preferred syntactic standard for representing and distributing these structured reports within a clinical environment. Early successes hold out hope that similar statistically based models of language will allow deep understanding of textual reports. The success of these statistical methods will depend on the availability of large numbers of high-quality training examples for each radiologic subdomain. The acceptability of automated structured reporting systems will ultimately depend on the results of comprehensive evaluations.","Computers; Computers, diagnostic aid; Radiology and radiologists, design of radiological facilities; Radiology reporting systems","article; computer interface; hospital information system; human; Humans; Radiology Information Systems; User-Computer Interface",Article,Scopus
"Lui C.Y., Tam K.F., Lam H.S., Chan L.K.","Continuous speech recognition system in a non-native English speaking radiology department",2001,"Asian Oceanian Journal of Radiology",2,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0035056736&partnerID=40&md5=65ed8bbc8b849fc332746599732b7a01","Introduction: Continuous speech recognition system has been implemented in many radiology departments worldwide aiming at facilitating radiology reporting. Most of the earlier reports are on English speaking departments. We describe our experience in using the system in a radiology department in Hong Kong, a city using English as a second language. The benefits and difficulties we encountered in using the system are highlighted and the technique on the best use of speech recognition system is listed. The impacts of using the system for radiology reporting at the department as well as the hospital level are discussed. Methods: The initial learning time of the system was measured and the accuracy in transcribing sample reports was assessed. The same sets of reports were then transcribed again and the ability of the system to show improvement in accuracy was measured. New sample reports are then used for reassessment of transcription accuracy. Finally, the accuracy of the system in transcription of digital file of sample reports was measured. Results: Average system accuracy was as high as 95.7% after training the same reports for 4 times. However, transcribing a new report only had accuracy ranging from 84.5% to 86.7%. Average transcription accuracy via a digital file was 82.5%, which was below our expectation. Discussion: Although continuous speech recognition technology is still evolving, our experience showed that it had high accuracy after short initial learning time. This was comparable to other reports with native English speaking radiologists. The system allows continuous flow of speech without the need to speak discrete words. It has a wide vocabulary that is capable of extension by learning through artificial intelligence. Multiple users, each with an individual speech file, are allowed. However, background noise is a big problem that lowers recognition accuracy and the time for transcription of a report by the system is slower than a well-trained typist. Its readily available feature is a distinct advantage over a typist in a busy department especially at odd hours.","Radiology; Reporting; Speech recognition","accuracy; article; artificial intelligence; computer program; Hong Kong; information processing; information system; language; learning; linguistics; radiologist; radiology department; speech discrimination; technology",Article,Scopus
"Kuzmak P.M., Dayhoff R.E.","Integrating non-radiology DICOM images into the electronic medical record at the Department of Veterans Affairs",2001,"Proceedings of SPIE - The International Society for Optical Engineering",2,"10.1117/12.435479","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0034779077&doi=10.1117%2f12.435479&partnerID=40&md5=d85839294560b96633a72a9f2475d177","The US Department of Veterans Affairs VistA hospital information system (HIS) provides a complete infrastructure to support multimedia objects as part of its electronic medical record. Acquisition, exportation, storage, long-term archiving, retrieval, display, and clinical database integration capabilities are provided for DICOM objects. We have extended HIS support of DICOM to include endoscopy and ophthalmology. Both radiology and non-radiology studies have the same need for patient and study information to properly identify images, and can use the same DICOM services, but there are some major differences. Workflow is quite different for the non-radiology specialties. The specialist who performs the procedure typically does the interpretation. Stored images are often not needed for the interpretation, but are used to document the findings of the procedure. There is no radiology information system equivalent for endoscopy or ophthalmology on our HIS. Images for those specialties need to be associated with different parts of the medical record than does radiology. For example, endoscopy images are associated with the endoscopy report, while ophthalmology images are associated with a progress note. We made significant modifications to the DICOM Modality Worklist and Storage service provider code to handle these new modalities, and we are now beginning field testing.",,"Database systems; Digital image storage; Multimedia systems; Radiology; Electronic medical record; Hospital information system; Medical computing",Conference Paper,Scopus
"Sinha U., Dai B., Johnson D.B., Taira R., Dionisio J., Tashima G., Golamco M., Kangarloo H.","Computers in radiology: Interactive software for generation and visualization of structured findings in radiology reports",2000,"American Journal of Roentgenology",12,"10.2214/ajr.175.3.1750609","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0033850921&doi=10.2214%2fajr.175.3.1750609&partnerID=40&md5=d2c61aa042ef8bf5cf4ad17a4f8f5bfb","OBJECTIVE. Our objectives were to develop a user-friendly graphic interface for a module that integrates traditional radiology reporting, natural language processing, and editing capabilities; to facilitate the structuring of radiology reports as part of routine clinical practice; to use a commercial speech recognition module for online transcription; and to implement the module in a hardware-independent environment. CONCLUSION. After implementation, the module was tested with 150 chest radiology reports by two radiologists and assessed for ease of use and accuracy. Overall, accuracy was close to 90% and user satisfaction was high. When radiology reports are structured as a part of routine clinical practice, it is possible to accomplish intelligent indexing and retrieval to facilitate teaching and research.",,"accuracy; article; computer graphics; computer program; information retrieval; medical documentation; priority journal; radiology; thorax radiography; hospital information system; medical record; Medical Records Systems, Computerized; Radiology Information Systems; Software",Article,Scopus
"Kanal K.M., Hangiandreou N.J., Sykes A.-M.G., Eklund H.E., Araoz P.A., Leon J.A., Erickson B.J.","Evaluation of the accuracy of a continuous speech recognition software system in radiology",2000,"Journal of Digital Imaging",7,"10.1007/bf03167667","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0033625328&doi=10.1007%2fbf03167667&partnerID=40&md5=db2ed50d998aa3f1f49e11b76cab7ceb","The accuracy of a continuous speech recognition software for radiology was measured. The impact on accuracy of the gender of the speaker and the status of the speaker as a native or non-native English speaker was examined. The potential for routine clinical use of the system for radiology report transcription was evaluated.",,"Computer aided analysis; Computer software; Image analysis; Speech recognition; Continuous speech recognition; Diagnostic radiography; adult; article; computer program; female; hospital information system; human; male; medical record; natural language processing; speech; Adult; Female; Hospital Records; Humans; Male; Medical Records Systems, Computerized; Natural Language Processing; Radiology Information Systems; Software; Speech",Article,Scopus
"Lemme Patti J., Morin Richard L.","Implementation of speech recognition in an electronic radiology practice",2000,"Journal of Digital Imaging",24,"10.1007/bf03167649","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0033625306&doi=10.1007%2fbf03167649&partnerID=40&md5=6dc91258d356f52c9530949a35e8f49d","For both efficiency and economic reasons, our practice (200,000 examinations) has converted all remote dictation to speech recognition transcription (PowerScribe, L & H, Burlington, MA). The design criteria included complete automation to the existing radiology information system (RIS), with full RIS capabilities immediately available following dictation. All dictations for computed tomography, magnetic resonance imaging, ultrasound, and nuclear medicine were converted from remote transcription to speech recognition over a 2-week period (following a 4-week installation phase and 8 days of training). The average turnaround time for these reports decreased from approximately 2 hours to less than 1 minute. Reports are then sent to the institutional Electronic Medical Record and are available throughout all facilities in a nominal 2 minutes. Speech recognition rates were suprisingly high, although certain phrases caused consistent difficulties and certain staff required retraining. This presents our analysis of both successful and problematic areas during our design and implementation, as well as statistical performance analyses.",,"Automation; Computerized tomography; Magnetic resonance imaging; Nuclear medicine; Radiology; Speech recognition; Statistical methods; Ultrasonic imaging; Electronic medical record (EMR); Radiology information system (RIS); Medical imaging; article; hospital information system; human; medical record; natural language processing; productivity; speech; task performance; United States; Efficiency; Florida; Humans; Medical Records Systems, Computerized; Natural Language Processing; Radiology Information Systems; Speech; Time and Motion Studies",Article,Scopus
"Mack S., Holstein J., Kleber K., Grönemeyer D.H.W.","New aspects of image distribution and workflow in radiology",2000,"Journal of Digital Imaging",10,"10.1007/bf03167617","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0033625268&doi=10.1007%2fbf03167617&partnerID=40&md5=e1a90e8f67b86d40cfcc8b8faf1f8242","The progressive use of digital image-generating devices and digital communication technology in clinical and practice environments implies changes in radiological workflow and asks for adequate quality assurance in the whole process of radiology report preparation. This improvement potential has to be rigorously reinvestigated with regard to up-to-date procedures and the full exploitation of supporting technologies like linguistic analysis, help desk and trouble ticket systems, competitive allocation algorithms, time-and-event monitoring, and intelligent agents. These approaches are to be evaluated in combination with business process analysis and shall help to reduce turnaround times for radiology reports while maintaining or even increasing quality-assurance levels.",,"Algorithms; Artificial intelligence; Computational linguistics; Digital communication systems; Hospital data processing; Information retrieval systems; Medical imaging; Radiology; Digital imaging and communications in medicine (DICOM) image viewers; Image communication systems; article; Germany; health care quality; hospital information system; human; Internet; radiology department; task performance; workload; Germany; Humans; Internet; Quality Assurance, Health Care; Radiology Department, Hospital; Radiology Information Systems; Task Performance and Analysis; Workload",Article,Scopus
"Chew F.S.","Evaluation of clinical experience in a radiology residency program with quantitative profiling: Rationale, methods, and application",1999,"Academic Radiology",6,"10.1016/S1076-6332(99)80489-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0033277532&doi=10.1016%2fS1076-6332%2899%2980489-9&partnerID=40&md5=da699f47b0df258ba5d1f3a29778aa7c","Rationale and Objectives. The author developed a technique for residency program evaluation, called ""quantitative profiling"", that is based on computer retrieval of radiologic reports. The hypothesis was that it would provide insights into the contributions of residents to clinical service, measures of resident experience and productivity for program evaluation, and benchmarks for comparison. Materials and Methods. The radiology residency program of a major teaching hospital was studied retrospectively from 1989 to 1997. The number of radiologic reports signed by individual residents and faculty members was retrieved. The clinical experience of the 1993-1997 cohort of residents was described according to subspecialty area and modality. Results. Residents signed 46.5% of all reports, with a mean total of 14,445 reports ± 1,292 per resident during the entire residency. The distribution of examinations was as follows: thoracic, 42.1%; musculoskeletal, 26.1%; abdominal, 13.4%; sonography, 8.7%; neuroradiology, 4.3%; nuclear, 2.4%; breast, 1.6%; and vascular, 1.4%. The most frequently reported results were for one-view chest radiography. Conclusion. Quantitative profiling can help track the range and progress of resident experience, help determine the deployment of residents, and provide empirical data upon which decisions to modify residency programs may be based.","Education; Radiology and radiologists, departmental management; Radiology reporting systems","conference paper; continuing education; evaluation; priority journal; radiologist; residency education; teaching hospital; thorax radiography; article; education; health care quality; hospital information system; human; medical education; radiology; retrospective study; Human; Internship and Residency; Program Evaluation; Radiology; Radiology Information Systems; Retrospective Studies",Conference Paper,Scopus
"Hayes J.C.","'Natural language' adds structure to radiology reports.",1999,"Diagnostic imaging",2,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0033210555&partnerID=40&md5=6e3fc101c219002856e81e565186268b",[No abstract available],,"algorithm; article; computer assisted diagnosis; computer interface; computer program; hospital information system; human; information retrieval; methodology; nomenclature; radiology; sensitivity and specificity; United States; Algorithms; California; Humans; Image Interpretation, Computer-Assisted; Information Storage and Retrieval; Radiology; Radiology Information Systems; Sensitivity and Specificity; Software; Terminology; User-Computer Interface",Article,Scopus
"Hripcsak G., Kuperman G.J., Friedman C., Heitjan D.F.","A reliability study for evaluating information extraction from radiology reports",1999,"Journal of the American Medical Informatics Association",37,"10.1136/jamia.1999.0060143","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0033036039&doi=10.1136%2fjamia.1999.0060143&partnerID=40&md5=37f326f299a816293af1f39d40b8e880","Goal: To assess the reliability of a reference standard for an information extraction task. Setting: Twenty-four physician raters from two sites and two specialties judged whether clinical conditions were present based on reading chest radiograph reports. Methods: Variance components, generalizability (reliability) coefficients, and the number of expert raters needed to generate a reliable reference standard were estimated. Results: Per-rater reliability averaged across conditions was 0.80 (95% CI, 0.79- 0.81). Reliability for the nine individual conditions varied from 0.67 to 0.97, with central line presence and pneumothorax the most reliable, and pleural effusion (excluding CHF) and pneumonia the least reliable. One to two raters were needed to achieve a reliability of 0.70, and six raters, on average, were required to achieve a reliability of 0.95. This was far more reliable than a previously published per-rater reliability of 0.19 for a more complex task. Differences between sites were attributable to changes to the condition definitions. Conclusion: In these evaluations, physician raters were able to judge very reliably the presence of clinical conditions based on text reports. Once the reliability of a specific rater is confirmed, it would be possible for that rater to create a reference standard reliable enough to assess aggregate measures on a system. Six raters would be needed to create a reference standard sufficient to assess a system on a case-by-case basis. These results should help evaluators design future information extraction studies for natural language processors and other knowledge-based systems.",,"article; computer aided design; extraction; information processing; language ability; physician attitude; pleura effusion; pneumonia; pneumothorax; reliability; standard",Article,Scopus
"Aronow D.B., Fangfang F., Croft W.B.","Ad hoc classification of radiology reports",1999,"Journal of the American Medical Informatics Association",59,"10.1136/jamia.1999.0060393","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032886481&doi=10.1136%2fjamia.1999.0060393&partnerID=40&md5=a4a17fd5ed73124a11569a37a6e2e249","Objective: The task of ad hoc classification is to automatically place a large number of text documents into nonstandard categories that are determined by a user. The authors examine the use of statistical information retrieval techniques for ad hoc classification of dictated mammography reports. Design: The authors' approach is the automated generation of a classification algorithm based on positive and negative evidence that is extracted from relevance-judged documents. Test documents are sorted into three conceptual bins: membership in a user-defined class, exclusion from the user-defined class, and uncertain. Documentation of absent findings through the use of negation and conjunction, a hallmark of interpretive test results, is managed by expansion and tokenization of these phrases. Measurements: Classifier performance is evaluated using a single measure, the F measure, which provides a weighted combination of recall and precision of document sorting into true positive and true negative bins. Results: Single terms are the most effective text feature in the classification profile, with some improvement provided by the addition of pairs of unordered terms to the profile. Excessive iterations of automated classifier enhancement degrade performance because of overtraining. Performance is best when the proportions of relevant and irrelevant documents in the training collection are close to equal. Special handling of negation phrases improves performance when the number of terms in the classification profile is limited. Conclusions: The ad hoc classifier system is a promising approach for the classification of large collections of medical documents. NegExpander can distinguish positive evidence from negative evidence when the negative evidence plays an important role in the classification.",,"algorithm; article; classification; mammography; performance; radiology",Article,Scopus
"Honeyman Janice C.","Information systems integration in radiology",1999,"Journal of Digital Imaging",21,"10.1007/bf03168810","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032588478&doi=10.1007%2fbf03168810&partnerID=40&md5=ae6f549f11aa24e471a40b3f04b5414e","Advances in information systems and technology in conjunction with outside forces requiring improved reporting are driving sweeping changes in the practice of radiology. In most academic radiology departments, there can be at least five separate information systems in daily use, a clinical picture archiving and communication system (PACS), a hospital information system (HIS), a radiology information system (RIS), a voice-recognition dictation system, and an electronic teaching/research file system. A PACS will have incomplete, incorrect, and inconsistent data if manual data entry is used. Correct routing of studies for diagnostic reporting and clinical review requires accurate information about the study type and the referring physician or service, often not easily entered manually. An HIS is a hospital-wide information system used to access patient information, reports from various services, and billing information. The RIS is typically a system specifically designed to place radiology orders, to receive interpretations, and to prepare bills for patients. Voice-recognition systems automatically transcribe the radiologist's dictation, eliminating transcription delays. Another system that is needed in a teaching hospital holds images and data for research and education. Integration of diverse systems must be performed to provide the functionality required by an electronic radiology department and the services it supports. Health Level 7 (HL7) and Digital Imaging and Communications in Medicine (DICOM) have enabled sharing of data among systems and can be used as the building blocks for truly integrated systems, but the user community and manufacturers need to specify the types of functionality needed to build clinically useful systems. Although technology development has produced the tools for interoperability for clinical and research/educational use, more work needs to be done to define the types of interaction that needs to be performed to realize the potential of these systems.",,"Computer aided instruction; Computer systems programming; Data recording; Hospital data processing; Image communication systems; Management information systems; Pattern recognition systems; Speech recognition; Teaching; Digital imaging and communication in medicine (DICOM); Hospital information systems (HIS); Picture archiving and communication systems (PACS); Radiology information systems (RIS); Diagnostic radiography; article; automated pattern recognition; computer network; data base; diagnostic imaging; education; hospital information system; human; medical record; organization and management; radiology; radiology department; system analysis; teaching; teaching hospital; voice; Computer Communication Networks; Computer-Assisted Instruction; Databases; Diagnostic Imaging; Hospital Information Systems; Hospitals, Teaching; Humans; Medical Records Systems, Computerized; Pattern Recognition, Automated; Radiology; Radiology Department, Hospital; Radiology Information Systems; Systems Integration; Voice",Article,Scopus
"Rubin R.K., Henri C.J., Cox R.D.","Bridging the gap: Linking a legacy hospital information system with a filmless radiology picture archiving and communications system within a nonhomogeneous environment",1999,"Journal of Digital Imaging",2,"10.1007/bf03168768","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032588431&doi=10.1007%2fbf03168768&partnerID=40&md5=29f398d29a81c1c52ecdfb6f3c0b5d5e","A health level 7 (HL7)-conformant data link to exchange information between the mainframe hospital information system (HIS) of our hospital and our home-grown picture archiving and communications system (PACS) is a result of a collaborative effort between the HIS department and the PACS development team. Based of the ability to link examination requisitions and image studies, applications have been generated to optimize workflow and to improve the reliability and distribution of radiology information. Now, images can be routed to individual radiologists and clinicians; worklists facilitate radiology reporting; applications exist to create, edit, and view reports and images via the internet; and automated quality control now limits the incidence of `lost' cases and errors in image routing. By following the HL7 standard to develop the gateway to the legacy system, the development of a radiology information system for booking, reading, reporting, and billing remains universal and does not preclude the option to integrate off-the-shelf commercial products.",,"Codes (standards); Data communication systems; Hospital data processing; Image compression; Image quality; Information management; Internet; Optimization; Telecommunication links; Hospital information systems (HIS); Picture archiving and communication systems (PACS); Diagnostic radiography; article; computer network; data base; diagnostic imaging; hospital information system; human; information retrieval; instrumentation; Internet; organization and management; quality control; system analysis; teleradiology; workload; Computer Communication Networks; Database Management Systems; Diagnostic Imaging; Hospital Information Systems; Humans; Information Storage and Retrieval; Internet; Quality Control; Radiology Information Systems; Systems Integration; Teleradiology; Workload",Article,Scopus
"Garland H.T., Cavanaugh B.J., Cecil R., Hayes B.L., Lavoie S., Leontiev A., Veprauskas J.","Interfacing the radiology information system to the modality: An integrated approach",1999,"Journal of Digital Imaging",7,"10.1007/bf03168766","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032588430&doi=10.1007%2fbf03168766&partnerID=40&md5=21d6813978b6c4f8a8c5fa5f49930cb3","The radiology information system (RIS) provides patient and examination information that is used in setting up and performing a radiologic procedure. In a digital imaging environment, information from the RIS can also be used to populate fields in the Digital Imaging and Communications in Medicine (DICOM) image header. Ideally, information from the RIS should be available at the modality at the time of the examination, and automatically be attached to the image in the appropriate DICOM fields before storage in the picture archiving and communications system (PACS). We have designed a highly integrated RIS interface for a digital radiography (DR) system. This interface employs browser technology to make RIS information conveniently available at the modality, and DICOM modality performed procedure step (MPPS) for RIS/DR information exchange. A novel feature of our approach is that a single display screen at the modality is used to alternatively display either the modality control window or the RIS window. Full access to RIS capabilities is available at the modality, including worklists and prior reports.",,"Data structures; Image compression; Information management; Interfaces (computer); Picture archiving and communications system (PACS); Radiology information systems (RIS); Diagnostic radiography; article; computer interface; computer program; computer system; diagnostic imaging; hospital information system; human; image quality; information processing; information retrieval; medical record; system analysis; Computer Systems; Data Display; Diagnostic Imaging; Humans; Information Storage and Retrieval; Medical Records Systems, Computerized; Radiographic Image Enhancement; Radiology Information Systems; Software; Systems Integration; User-Computer Interface",Article,Scopus
"Galimberti E., Belluschi F., Bosaglia M., Bianchessi S.","Radiology examinations in non infectious complications of CAPD",1998,"EDTNA-ERCA Journal",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032422412&partnerID=40&md5=f2665fc52ade1b988445ccee614ac4d5","Continuous Ambulatory Peritoneal Dialysis (CAPD) patients may have non infectious abdominal complications that affect the survival of their dialysis treatment. It is important to document the origin of leakages and hernias, causes of catheter malfunction or haemoperitoneum. Therapeutic options will depend on investigations and include catheter removal or replacement, surgical intervention or eventual transfer to automated peritoneal dialysis (APD). In this paper we report our experience of the technical implementation of Peritoneography and Peritoneum Computed Tomography.","Computed Tomography; Continuous Ambulatory Peritoneal Dialysis (CAPD); Iopamidol; Peritoneography","abdominal wall hernia; article; automation; computer assisted tomography; continuous ambulatory peritoneal dialysis; edema; female; human; major clinical study; male; peritoneal dialysis; Drainage; Equipment Failure; Female; Hemoperitoneum; Hernia, Ventral; Humans; Kidney Failure, Chronic; Male; Peritoneal Dialysis, Continuous Ambulatory; Risk Factors; Tomography, X-Ray Computed",Article,Scopus
"Van Den Berg L., Aarts J.C.N.M., Beentjes L.B., Van Dalen A., Elsakkers P., Julius H.W., Kicken P.J.H., Van Der Meer F., Teeuwisse W., Thijssen M.A.O., Zoetelief J.","Guidelines for quality control of equipment used in diagnostic radiology in The Netherlands",1998,"Radiation Protection Dosimetry",6,"10.1093/oxfordjournals.rpd.a032552","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032426155&doi=10.1093%2foxfordjournals.rpd.a032552&partnerID=40&md5=b2b38be12a54ad432adc75fa7d0aea75","The Dutch working group on 'Quality Criteria for Equipment Used in Diagnostic Radiology' has formulated guidelines providing technical criteria for equipment used in conventional diagnostic radiology. These guidelines are applicable to the technical parameters having a major impact on image quality and patient dose and include methods for testing. The following parameters are included: tube voltage, automatic exposure control, film processing, film-screen combination, light tightness and illumination of the dark room, half-value layer and filtration, light field, grid, focal spot size, viewing boxes and geometrical indicators. Each guideline consists of the following chapters: (1) Scope and field of application, (2) Background information, (3) Test procedure, (4) Test frequency, (5) Registration of observations, (6) Evaluation and intepretation, (7) Test report. Chapter 3 includes both the principles of the test method and a step by step description of the procedures. The principles of the test procedure provide a basis for adaptation to local circumstances. The step by step test procedure allows a quality control measurement to be performed with limited physical knowledge of the equipment. Chapter 6 includes limiting values. Draft guidelines were evaluated in practice in 20 hospitals. The final document has been accepted by the professional societies in the Netherlands and the Dutch Minister of Health as a reference set of tools to perform Quality Control of equipment used for conventional diagnostic radiology.",,"conference paper; human; illumination; image quality; light; Netherlands; practice guideline; quality control; radiation dose; radiation protection; radiodiagnosis; technique",Conference Paper,Scopus
"Mehta Amit, Dreyer Keith J., Schweitzer Alan, Couris John, Rosenthal Daniel","Voice recognition - an emerging necessity within radiology: Experiences of the Massachusetts General Hospital",1998,"Journal of Digital Imaging",27,"10.1007/bf03168173","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032194832&doi=10.1007%2fbf03168173&partnerID=40&md5=08fcfb81d080095fb4deb1acc80f9c96","Voice recognition represents a technology that is finally ready for prime time use. As radiology services continue to acquire a larger percentage of the shrinking health-care dollar, decreasing operating costs and improved services will become a necessity. The benefits of voice recognition implementation are significant, as are the challenges. This report will discuss the technology, experiences of a major health-care institution with implementation, and potential benefits for the radiology practice.",,"Computer software; Health care; Natural language processing systems; Pattern recognition systems; Speech analysis; Speech recognition; Speech synthesis; Natural language understanding (NLU); Diagnostic radiography; article; computer interface; hospital information system; human; voice; Humans; Radiology Information Systems; User-Computer Interface; Voice",Article,Scopus
"Erickson Bradley J., Ryan William J., Gehring Dale G., Beebe Calvin","Clinician usage patterns of a desktop radiology information display application",1998,"Journal of Digital Imaging",9,"10.1007/bf03168285","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032129248&doi=10.1007%2fbf03168285&partnerID=40&md5=336609c1d391070e85485f2f5a8fe894","We developed a system for delivering radiologic images and reports to desktop computers used for the electronic medical record (EMR). This system was used by both primary care physicians and specialists primarily in the out-patient setting. The system records all physician interactions with the application to a database. This usage information was then studied in order to understand the value and requirements of an application that could display radiology information (reports and images) on EMR workstations. In this report we describe some of the differences and similarities in usage patterns for the two physician groups. A very high percentage of physicians indicated that having image display capabilities on the workstations was very valuable.",,"Computer aided diagnosis; Computer workstations; Information retrieval; Medical imaging; Personal computers; Radiology; Computerized patient record; Electronic medical record; Picture archival and communication systems (PACS); Image communication systems; article; computer interface; computer network; hospital information system; human; information processing; medical record; pilot study; questionnaire; Computer Communication Networks; Data Display; Humans; Medical Records Systems, Computerized; Pilot Projects; Questionnaires; Radiology Information Systems; User-Computer Interface",Article,Scopus
"Dayhoff Ruth E., Kuzmak Peter M.","Providing complete multimedia patient data to consulting radiologists, other specialists, and the referring clinician",1998,"Journal of Digital Imaging",7,"10.1007/bf03168284","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032129240&doi=10.1007%2fbf03168284&partnerID=40&md5=353cda526099079effdd22e78fa21d92","The Integrated Imaging System has been developed to provide complete patient data in an integrated manner that facilitates the clinician's decision making. Images and associated text data are available any time throughout the hospital on Windows-based workstations that are interfaced to the main hospital system in a client-server architecture. The system handles high quality image data from cardiology, pulmonary and gastrointestinal medicine, pathology, radiology, hematology, and nuclear medicine, as well as textual reports from the hospital information system, scanned documents and electrocardiograms. The system improves the quality of patient care, enhances clinician's communication, and is used at conferences, morning report and during ward rounds.",,"Client server computer systems; Computer aided diagnosis; Computer workstations; Image communication systems; Imaging systems; Information retrieval systems; Local area networks; Medical imaging; Multimedia systems; Patient monitoring; User interfaces; Integrated imaging systems; Digital image storage; hospital information system; human; medical record; multimedia; organization and management; review; teleconsultation; teleradiology; Humans; Medical Records Systems, Computerized; Multimedia; Radiology Information Systems; Remote Consultation; Teleradiology",Article,Scopus
"Johnson D.B., Taira R.K., Zhou W., Goldin J.G., Aberle D.R.","Hyperad: Augmenting and Visualizing Free Text Radiology Reports",1998,"Radiographics",5,"10.1148/radiographics.18.2.9536493","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032015093&doi=10.1148%2fradiographics.18.2.9536493&partnerID=40&md5=03b603d9da8dabd05a38e86996da62f7","Hyperad is an automated computer system designed to extract key concepts from thoracic radiology reports and give physicians access to a large database containing the reports and key concepts. The concepts are extracted from textual documents with natural language processing techniques, then stored with the original documents in the database, which can be queried in terms of findings or associated attributes from an intuitive and easily accessible interface. The extracted concepts are represented both textually in a coded hypertext format and graphically on a coronal cross-sectional anatomy atlas, an idealized graphical model of human anatomy. To facilitate implementation, the communication protocols and standards of the World Wide Web (Web) were adopted. The reports and associated forms are encoded in standard hypertext markup language, which makes it possible to use hypermedia links to navigate the Hyperad database with any graphical Web browser. In the future, Hyperad may prove useful for other applications.","Computers; Diagnostic radiology; Radiology and radiologists","article; computer interface; computer system; data base; human; hypermedia; medical record; radiology; Computer Systems; Databases; Humans; Hypermedia; Medical Records; Radiology; User-Computer Interface",Article,Scopus
"Johnson D.B., Taira R.K., Cardenas A.F., Aberle D.R.","Extracting information from free text radiology reports",1997,"International Journal on Digital Libraries",15,"10.1007/s007990050024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-12344284370&doi=10.1007%2fs007990050024&partnerID=40&md5=59c936f9ecd6d889a7840b1ae626a194","Medical reports are often electronically archived as unstructured free text. In radiology original images and other associated data are stored and linked to these free text reports. Unfortunately, once stored, these images and reports are difficult and time consuming to retrieve and use. Current technology for automatic image processing and extraction cannot yet support the direct extraction and indexing of findings from medical images that is needed. More advanced techniques must be explored to provide easier access to medical image databases. We describe a system designed to extract and structure the information contained in free text radiology reports. The system uses natural language processing techniques to transform free text descriptions into structured information units that can be used to index and provide access to image databases. To provide access to the results of the system we developed a unique user interface for reporting and accessing radiology reports. We present a general system architecture for information extraction. Although the prototype focuses on thoracic radiology, this system can be extended into other areas of medicine. We discuss the system's knowledge sources and structures, and explain how natural language processing techniques are used to extract information from reports. The results of clinical testing of the prototype are presented and evaluated. © Springer-Verlag 1997.","Free text analysis; Information extraction; Information extraction from text; Natural language indexing; Radiology reports",,Article,Scopus
"Cook J.F., Hansen M., Breitweser J.","Optimizing radiology in the new picture archiving and communication system environment",1997,"Journal of Digital Imaging",5,"10.1007/bf03168687","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031195533&doi=10.1007%2fbf03168687&partnerID=40&md5=a3f26744d5e996a78f220a02cc8dfc2f","Picture archiving and communications systems (PACS) have inescapably altered the face of radiology. Images are available to radiologists and clinicians alike, nearly instantaneously. For patient care management, service has improved, but without inclusion of input from radiologists. Effecting timely report availability requires reorganization of radiology. In a hospital-wide PACS environment, we undertook to render a preliminary report on all nonprocedural computed radiography examinations within 30 minutes in a teaching environment. Two periods of time in the same month were analyzed, one before reorganization and one after. Of 686 reports, 117 were examined with a statistical significance of α = .05 (95% confidence) and a power of 90%. Average times for examination acquisition to preliminary report availability on the PACS decreased from 5 hours to 31 minutes. Standard deviation in report generation times decreased from 8 hours to 30 minutes. This preliminary study suggests that business process reengineering can effect improvement in information flow within a teaching facility resulting in radiologists rejoining the patient care management team. Successes, pitfalls, and future requirements are discussed. Copyright © 1997 by W.B. Saunders Company.","Department management; Diagnostic radiology; Picture archiving and communications system (PACS); Radiology reports","Diagnostic radiography; Hospital data processing; Image communication systems; Imaging systems; Information retrieval systems; Management information systems; Radiology; Statistical methods; Business process reengineering; Diagnostic radiology; Nonprocedural computed radiography examination; Picture archiving and communication systems (PACS); Medical imaging; article; hospital information system; human; organization and management; public hospital; radiology department; United States; Efficiency, Organizational; Hospitals, Military; Humans; Radiology Department, Hospital; Radiology Information Systems; United States",Article,Scopus
"Haug P.J., Farrell M., Frear J., Blatter D., Frederick P.R.","Developing a radiology data base for quality assurance",1997,"Journal of Digital Imaging",7,"10.1007/bf03168670","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031195519&doi=10.1007%2fbf03168670&partnerID=40&md5=3cbba4d55c0197ad9df63624e98979ca","Radiology Information Systems (RIS) are designed to capture and manage the data associated with ordering, executing, reporting, and billing x-ray procedures. The HELP Hospital Information System contains a radiology subsystem that supports these functions. In an effort to enhance quality assurance initiatives, we have created a supplemental data base. This data base contains not only the data traditionally generated by RISs but also data from the hospital system that is relevant to quality assurance. One of the goals associated with this data base is to use techniques from the discipline of Continuous Quality Improvement (CQI) in the radiology department. A focus of our initial efforts has been the time necessary to provide x-ray reports to ordering physicians once the imaging examination has been performed. Efforts to manage the portion of this time interval caused by transcription have resulted in a substantial decrease in the time required for this function. A second goal of this project is to evaluate the quality of x-ray ordering. This objective requires a computerized record of the outcome of the x-ray procedure. Initial analysis of data derived from this data base indicates significant differences in the ordering behavior for computed tomography (CT) examinations among a test group of physicians. A third goal is to do quality assurance on x-ray reports. Experience with pilot systems has shown promising results using a mathematical model of report quality. We hope to leverage these techniques and this quality assurance data base to define a CQI process for medical reports in general and for x-ray reports in particular. Copyright © 1997 by W.B. Saunders Company.",,"article; computer assisted tomography; data base; factual database; health care quality; hospital information system; human; standard; total quality management; Database Management Systems; Databases, Factual; Hospital Information Systems; Humans; Quality Assurance, Health Care; Radiology Information Systems; Tomography, X-Ray Computed; Total Quality Management; Computerized tomography; Data acquisition; Data reduction; Hospital data processing; Information retrieval systems; Mathematical models; Medical computing; Quality assurance; Radiology; Continuously quality improvement (CQI); Hospital information systems (HIS); Radiology information systems (RIS); Database systems",Article,Scopus
"Ramaswamy M.R., Patterson D.S., Yin L., Goodacre B.W.","MoSearch: A Radiologist-friendly Tool for Finding-based Diagnostic Report and Image Retrieval",1996,"Radiographics",6,"10.1148/radiographics.16.4.8835980","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0030184371&doi=10.1148%2fradiographics.16.4.8835980&partnerID=40&md5=b2757ee156e11cdb28cc3dcc802e4375","The diagnostic reports generated in a radiology department contain a wealth of information. Although radiology information systems can greatly facilitate patient-based access to this information, they typically provide only limited finding-based access. A user-friendly personal computer-based software package that allows radiologists to conduct sophisticated real-time searches of diagnostic reports on the basis of patient characteristics, modality used, anatomy examined, and imaging findings and to easily review, refine, and output the results was designed and implemented in a large academic hospital. A notable feature of this system is the use of synonym-matching and syntactic cues, which allow it to identify findings within the text of a diagnostic report much more accurately than a simple keyword search can. This type of system is easily and inexpensively implemented and is a valuable tool in the support of various research and teaching applications in a radiology department.","Computers, educational aid; Radiology reporting systems","article; computer interface; hospital information system; Radiology Information Systems; User-Computer Interface",Article,Scopus
"Kahn Jr. C.E., Wang K., Bell D.S.","Structured Entry of Radiology Reports Using World Wide Web Technology",1996,"Radiographics",28,"10.1148/radiographics.16.3.8897632","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0030133537&doi=10.1148%2fradiographics.16.3.8897632&partnerID=40&md5=5d485a5faff2404038e06c268d3f8901","Structured data entry - in which information is entered by using predetermined data elements and formats - has the potential to improve the radiology reporting process. The dependence on particular computer hardware and software platforms has posed a barrier to wider use of this approach. The World Wide Web (WWW), a client-server protocol for delivery of multimedia data via the Internet, was used to achieve platform-independent structured entry of radiology reports. A developmental system for structured entry of radiology reports, called SPIDER, incorporates a knowledge base of hierarchically organized concepts, a WWW server, and two specialized programs. The WebForm program transforms the system's knowledge into graphical WWW data-entry forms; the WebReport program converts data entered on these forms into outline-format reports. SPIDER received favorable evaluations from sonographers and physicians who used the system to record the results of several test cases. WWW technology can be used to achieve platform-independent entry of the results of radiologic procedures.","Computers; Internet; Radiology and radiologists","article; artificial intelligence; computer network; information processing; multimedia; radiology; Artificial Intelligence; Computer Communication Networks; Data Display; Multimedia; Radiology",Article,Scopus
"Taira R.K., Johnson D.B., Bhushan V., Rivera M., Wong C., Huang L., Aberle D.R., Greaves M., Goldin J.G.","A concept-based retrieval system for thoracic radiology",1996,"Journal of Digital Imaging",8,"10.1007/BF03168565","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0030072256&doi=10.1007%2fBF03168565&partnerID=40&md5=acc0e5e829604517925518be2f22b9cc","Current digital information systems in radiology are insufficient to accommodate the retrieval needs of academicians. Significant efforts are required in retrieving clinical cases for teaching and research. We describe a prototype system that supports intelligent case retrieval based on a combined specification of patient demographics, radiologic findings, and pathologic diagnoses. The documents for these cases can be distributed among multiple heterogeneous data bases. The system features automatic indexing of radiology and pathology reports, a comprehensive lexicon for thoracic radiology, an interface to a hospital information system, radiology information system, and picture archiving and communication systems, and a graphical user interface for query formulation and results visualization. The prototype system was developed within the domain of thoracic radiology involving patients with lung cancer. copyright © 1996 by W.B. Saunders Company.","Free-text analysis; Information retrieval systems; Query interfaces","article; comparative study; computer interface; documentation; hospital information system; human; information retrieval; local area network; lung tumor; radiography; system analysis; thorax radiography; Abstracting and Indexing; Hospital Information Systems; Humans; Information Storage and Retrieval; Local Area Networks; Lung Neoplasms; Radiography, Thoracic; Radiology Information Systems; Systems Integration; User-Computer Interface; Data communication systems; Database systems; Diagnosis; Graphical user interfaces; Indexing (of information); Management information systems; Medical computing; Query languages; Radiology; Concept-based retrieval system; Free text analysis; Query interfaces; Thoracic radiology; Information retrieval systems",Article,Scopus
"Weltin G., Swett H.","A computer utility for automated retrieval of radiology reports",1996,"American Journal of Roentgenology",1,"10.2214/ajr.166.5.8615236","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029938054&doi=10.2214%2fajr.166.5.8615236&partnerID=40&md5=ea478257b0b97305f66571bf3efa4a2a","OBJECTIVE. Many radiology information systems (RISs) installed during the 1980s have a user interface that is crude by today's standards. We explored improving this user interface by using the local processing power of the personal computer. In this article we describe a computer program that significantly enhances the ease of report retrieval by automating much of the interaction with our RIS, which is IDXrad. MATERIALS AND METHODS. The program, named DERVISH, runs under DOS on International Business Machines- compatible personal computers having an 80286 or faster processor, an enhanced graphics adapter or video gate array display, two serial ports, a mouse, and a bar code wand. It is written in the C++ programming language. Input may be by keyboard, mouse, or bar code wand, and reports may be displayed singly or multiply and printed to a local printer or an RIS printer or copied to a disk file. DERVISH not only performs many of the routine tasks of an RIS session such as logging on and off but also provides a menu-driven environment for report display, including optional restriction of the report list to related prior reports. Keyboard use is minimized in favor of a mouse and a bar code wand. DERVISH also emulates a standard RIS terminal for functions other than report retrieval. RESULTS. Originally intended to help retrieve the prior radiology reports on a patient at hand, DERVISH has found use in our quality management effort as well, simplifying comparison of reports from related radiologic techniques. An early version suffered poor acceptance because of its nonstandard interface and frequent malfunctions. The current version is presently in use in our emergency radiology department. CONCLUSION. DERVISH serves not only as a useful utility in itself but also as a demonstration of the ability of the local processing power of a desktop computer to improve the user interface of an aging RIS and to extend its functional life.",,"article; computer program; health care organization; information retrieval; information system; priority journal; radiology",Article,Scopus
"Hruby W., Pärtan G., Mosser H., Krampla W., Malcher J.","The digital hospital information technology in radiology",1996,"RBM - Revue Europeenne de Technologie Biomedicale",3,"10.1016/0222-0776(96)82710-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029905753&doi=10.1016%2f0222-0776%2896%2982710-6&partnerID=40&md5=5a526db8e0264d0494c405aa22d6c249","The experiences that were made in the radiology department at the Danubehospital/Vienna concerning the digital archive and digital communication via the LAN showed: - the diagnostic qualities of digital projection radiography regarding spatial resolution are adequate or just about sufficient, the excellent contrast resolution is an advantage of great value; - monitor-reporting is feasible in clinical routine with no draw-backs; - the HIS-RIS-PACS integration is not yet sufficient; a consistent user-interface is necessary and the requested automatic and intelligent perfecting-algorithms are needed (both are high-priority topics; implementation and clinical evaluation are expected soon). Autorouting of reported examinations to the peripheral wards is another top priority topic; a feasible technical solution will be beneficial for the radiologists and clinicians; - digital communication can accelerate data-exchange and contribute to the reduction of the length of stay in hospital; - digital archives are highly cost-effective; - digital archives shouldn't cause any legal problems as durability, and availability of images and reports is better than in the conventional system; - not yet sufficiently solved are questions concerning archive access and electronic signatures.",,"computer analysis; conference paper; digital radiography; human; imaging; medical information; medical technology; radiology",Conference Paper,Scopus
"Kurdziel K.A., Hopper K.D., Zaidel M., Zukoski M.J.","'Robo-Rad': An inexpensive user-friendly multimedia report system for radiology",1996,"Telemedicine Journal",8,"10.1089/tmj.1.1996.2.123","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029758397&doi=10.1089%2ftmj.1.1996.2.123&partnerID=40&md5=a117e89e1692896dfbe0be910ec01ff4","Background and Purpose. The complex information obtained by CT, MR, and ultrasound examinations is often difficult to convey with a written report. Today's multimedia computer technology provides a medium within which the audio and the visual components of a radiologic consultation can be made available simultaneously, with the projected capability of remote access from any personal computer. A system was developed to run on low-end computer systems with image quality adequate for reporting purposes and prudent memory management (each report occupies < 4 MB). With this system-'Robo-Rad'-the image and radiologist are recorded simultaneously while he or she describes and points out (with a mouse) areas of interest. This dynamic report, along with patient data, can be retrieved and viewed by the consulting physician at his/her convenience using a low-end PC or Macintosh computer. Materials and Methods. To assess the clinical utility of Robo-Rad, survey responses were solicited from clinical physicians at the Penn State University Hospital (41.5% faculty/fellows, 31.7% residents, 11.8% medical students, 2% clinical nursing; n = 101) during a hands-on demonstration using studies of 35 consecutive inpatients whose CT scans had been dictated into the system. Results. In an average week, the surveyed professionals ordered 3.2 ± 3.0 CT studies, reviewed 3.8 ± 3.0 CTs, spent 1.5 ± 2.0 hours locating CT studies, and discussed 2.3 ± 1.9 CT cases with a radiologist. The average time spent discussing a single CT case with a radiologist was reported as 9.4 ± 5.9 minutes. On a five-point rating scale (1 = not at all to 5 = very much so), respondents indicated that the Robo-Rad report was helpful (4.3 ± 0.7) and provided clinically important information that would be difficult to convey with current dictation systems (4.2 ± 0.8). Desire to discuss the case with a radiologist in addition to viewing the Robo-Rad report scored 3.2 ± 1.0. If such a system were readily available, 91.8% of the respondents indicated that they would use it in addition to the currently available written report and audio dictation system, and 96.6% would use it instead of the current system. Local area network and modems were the modalities of highest interest for remote access (69.3% and 44.6%, respectively). Conclusions. Judging by these data, the Robo-Rad system would be of benefit to clinicians. It provides a user-friendly, low-cost multimedia radiology report utilizing readily available technology to improve radiologist-clinician communication.",,"article; audiovisual equipment; computer assisted tomography; computer system; diagnostic imaging; human; image quality; information retrieval; medical information; microcomputer; patient information; priority journal; questionnaire; radiologist; radiology; telecommunication",Article,Scopus
"Getty David J.","Assisting the radiologist to greater accuracy",1996,"Proceedings of SPIE - The International Society for Optical Engineering",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029714697&partnerID=40&md5=b27481e9c0e9c36c7853f668a44fc450","We have developed a method for improving the accuracy of image-based diagnosis by providing the radiologist with image-reading and decision-making aids. The image-reading aid is a checklist of visual features to guide the radiologist through a systematic assessment of the features of a detected abnormality. The decision aid is a computer-based statistical decision rule that accepts the feature assessments made by the radiologist, and returns an advisory estimate of the probability that disease is present. I discuss the steps involved in developing and testing these aids, and present illustrative examples of their successful application in mammography. I describe other possible benefits of a feature-based diagnostic system in improving report standardization, training of radiologists, quality assurance, and automated report-writing. Finally, I discuss potentially greater improvements in diagnostic accuracy that may be realized through the future development of hybrid systems in which a radiologist and computer interact, and systems combining features from multiple tests or sources.",,"Image based diagnosis; Image reading aids; Mammography; Radiologists; Computer applications; Decision making; Diagnosis; Oncology; Radiography; Standardization; Statistical methods; Medical imaging",Conference Paper,Scopus
"Honeyman Janice C., Frost Meryll M., Staab Edward V.","Use of film digitizers to assist radiology image management",1996,"Proceedings of SPIE - The International Society for Optical Engineering",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029707031&partnerID=40&md5=494e4221020564b4ea81821d04c6b2ca","The purpose of this development effort was to evaluate the possibility of using digital technologies to solve image management problems in the Department of Radiology at the University of Florida. The three problem areas investigated were local interpretation of images produced in remote locations, distribution of images to areas outside of radiology, and film handling. In all cases the use of a laser film digitizer interfaced to an existing Picture Archiving and Communication System (PACS) was investigated as a solution to the problem. In each case the volume of studies involved were evaluated to estimate the impact of the solution on the network, archive, and workstations. The results of our analysis and the decisions that were made based on the analysis are described below. In the cases where systems were installed, a description of the system and its integration into the PACS system is included. For all three problem areas, although we could move images via a digitizer to the archive and a workstation, there was no way to inform the radiologist that a study needed attention. In the case of outside films, the patient did not always have a medical record number that matched one in our Radiology Information Systems (RIS). In order to incorporate all studies for a patient, we needed common locations for orders, reports, and images. RIS orders were generated for each outside study to be interpreted and a medical record number assigned if none existed. All digitized outside films were archived in the PACS archive for later review or comparison use. The request generated by the RIS requesting a diagnostic interpretation was placed at the PACS workstation to alert the radiologists that unread images had arrived and a box was added to the workstation user interface that could be checked by the radiologist to indicate that a report had been dictated. The digitizer system solved several problems, unavailable films in the emergency room, teleradiology, and archiving of outside studies that had been read by University of Florida radiologists. As changes in health care drive management changes, existing tools can be used in new ways to help make the transition easier. In this case, adding digitizers to an existing PACS network helped solve several image management problems.",,"Image transmission; Laser film digitizers; Picture archiving and communication systems (PACS); Analog to digital conversion; Communication systems; Digital image storage; Information retrieval systems; Laser applications; Radiology; Medical imaging",Conference Paper,Scopus
"Harrison R.M., Faulkner K., Davies M.L., Chapple C.L., Robson K.J., Broadhead D.A.","Patient dosimetry in diagnostic radiology-some practical considerations in an NHS region",1995,"Journal of Radiological Protection",5,"10.1088/0952-4746/15/3/004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029150704&doi=10.1088%2f0952-4746%2f15%2f3%2f004&partnerID=40&md5=8a1c3345ba03a61b1c44c4c4c05d432a","The requirement to monitor the doses received by patients undergoing diagnostic X-ray examinations is discussed and reviewed in the context of the implementation and coordination of patient dosimetry services within an NHS Region by a regionally managed medical physics department. Four aspects of the dosimetry programme are described. Following installation of dose-area-product (DAP) meters, a region-wide data collection programme and associated database has been established, together with regular dosimetry reports. Thermoluminescence techniques are also widely employed and a complementary automated dosimetry system has been developed. Agreement between calculated and measured doses is generally within 15%. A survey of doses from or scanners in the region has resulted, in some cases, in changes in technique, in order to reduce doses. In mammography, regular assessment of 18 X-ray units has shown that mean glandular doses are consistently less than 2 mGy. An important consideration arising from the entire programme is the need to use the collected dose data to implement changes in technique if dose reduction is indicated or if NRPB reference levels are exceeded. The regionally managed programme ensures that a large database of relevant information, covering a comprehensive range of techniques and equipment, is available to a wide audience of physicists, radiographers and radiologists.",,"article; autoanalysis; data base; dosimetry; human; information processing; mammography; national health service; patient monitoring; priority journal; radiodiagnosis; scintiscanning; technique; thermoluminescence dosimetry",Article,Scopus
"Wong A.W.K., Huang H.K., Arenson R.L., Yin L.","Automated prefetch mechanism: Design and implementation for a radiology PACS",1994,"Proceedings of SPIE - The International Society for Optical Engineering",7,"10.1117/12.174293","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0343325489&doi=10.1117%2f12.174293&partnerID=40&md5=83257cbc20cf4fc69e1eea236291d60d","A clinicalpicture archiving and communication system (PACS) requires immediate access to both patients' previous and current images as well as the corresponding radiology reports. We have developed a prefetch mechanismfor the PACS system in the UCSF Department of Radiology that automatically retrieves historical images and reportsfor reviewing at remote display stations. The prefetch mechanism is initiated as soon as the PACS archive subsystem detects the arrival of a patient via the PACS/RIS interface. Selected historical images, patient demographics, examination descriptions, and radiology reports are retrieved from the optical disk library and PACS database, and are distributed to the designated display station(s) prior to completion of the patient's current examination. The prefetch mechanism utilizes several parameters, including patient origin, referring physician, location of display station, number of patient's archived images, and age of these individual archived images. In addition, we have designed a 4-dimensionalprefetch look-up table composed of examination type, disease category, section radiologist, and referring physician. This table determines what historical images and relevant information should be retrieved. This table can easily be updated periodically by the radiologists and physicians according to their needs. The prefetch mechanism implemented in our PACS provides radiologists and physicians with immediate access to their desired images and relevant information, which consequently accelerates acceptance of the PACS for use in clinical review. © 1994 SPIE. All rights reserved.",,"Medical imaging; Radiation; Radiology; Table lookup; Archiving and communication systems; Current image; Design and implementations; Look up table; Optical disks; PACS archive; Prefetch mechanism; Radiology reports; Medical applications",Conference Paper,Scopus
"Crabbe J.P., Frank C.L., Nye W.W.","Improving report turnaround time: An integrated method using data from a radiology information system",1994,"American Journal of Roentgenology",33,"10.2214/ajr.163.6.7992756","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028588672&doi=10.2214%2fajr.163.6.7992756&partnerID=40&md5=10faa9b738c87fdf6d6cc83e8c018133","OBJECTIVE. In the face of a changing health care system and increased competition, radiology departments need to become more efficient. One measurement of efficiency is promptness in producing a final report. Many large radiology centers have radiology information systems (RIS) that track work flow, collecting tremendous amounts of data. Most, however, lack an appropriate analytic mechanism. We have developed an integrated system that allows continual monitoring of radiology work flow and thus of opportunities to apply interventions. This system can form an important component of the quality management process in the radiology department. MATERIALS AND METHODS. In developing the system, we identified seven key steps in the work- flow process. When left to chance, these steps occur out of sequence and large delays occur. A scheme was devised to improve the sequencing of the work flow by using the data collected from the RIS, sorted by radiology division and patient type. Biweekly, the appropriate data file is transferred to each division for analysis, via the department's computer network. A one- step process follows, using desktop Macintosh computers and a custom program written in Microsoft Excel. Extracted data are quickly converted into a tailored division summary, and a report is automatically generated. RESULTS. The result summary format is uniform throughout the department, allowing ease of review at divisional and departmental meetings. Problems can be immediately localized to a specific step in the work-flow process. Automation of much of the system allows continual, near-real-time review of work flow. Using this approach, we have seen a sustained reduction of average report turnaround time. CONCLUSION. This system allows continual monitoring of work flow. It is largely automated and lends itself well to inclusion in the quality management program of any radiology department.",,"article; data analysis; health care quality; health care system; information processing; information system; integration; medical information; priority journal; radiology; turnover time",Article,Scopus
"Friedman C., Cimino J.J., Johnson S.B.","A schema for representing medical language applied to clinical radiology",1994,"Journal of the American Medical Informatics Association",35,"10.1136/jamia.1994.95236155","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028440534&doi=10.1136%2fjamia.1994.95236155&partnerID=40&md5=14c40ffb355fad9539a3111d3f398014","Objective: Develop a representational schema for clinical concepts and apply it to the task of encoding radiology reports of the chest. Design: The schema was developed following a manual analysis of sample reports from the domain. The schema has two main components: the Medical Entities Dictionary (MED), which specifies the formal representation of the concepts in the domain and of their structures, and the natural-language processor, which specifies the linguistic expressions of the concepts. The schema was evaluated by applying it to a test set of 7,500 reports. Two-hundred reports from the test set were manually analyzed by a medical expert to determine the accuracy and success rate of the system. Results: 82% of the 7,500 reports that contained relevant clinical information were successfully structured automatically. For the smaller set of 200 reports, 80% were structured successfully with an accuracy rate of 97%. Conclusions: The schema is a formal representation for clinical concepts in radiology reports, and provides domain coverage that is particularly well-suited for natural-language processing of radiology for use in a decision support system.",,"article; artificial intelligence; decision support system; documentation; radiology; Decision Support Systems, Management; Evaluation Studies; Natural Language Processing; Radiology; Subject Headings; Support, Non-U.S. Gov't; Support, U.S. Gov't, P.H.S.; Terminology",Article,Scopus
"Friedman C., Alderson P.O., Austin J.H.M., Cimino J.J., Johnson S.B.","A general natural-language text processor for clinical radiology",1994,"Journal of the American Medical Informatics Association",513,"10.1136/jamia.1994.95236146","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028403632&doi=10.1136%2fjamia.1994.95236146&partnerID=40&md5=1c8c3c777c4df99c883efb774109d933","Objective: Development of a general natural-language processor that identifies clinical information in narrative reports and maps that information into a structured representation containing clinical terms. Design: The natural-language processor provides three phases of processing, all of which are driven by different knowledge sources. The first phase performs the parsing. It identifies the structure of the text through use of a grammar that defines semantic patterns and a target form. The second phase regularization, standardizes the terms in the initial target structure via a compositional mapping of multi-word phrases. The third phase, encoding, maps the terms to a controlled vocabulary. Radiology is the test domain for the processor and the target structure is a formal model for representing clinical information in that domain. Measurements: The impression sections of 230 radiology reports were encoded by the processor. Results of an automated query of the resultant database for the occurrences of four diseases were compared with the analysis of a panel of three physicians to determine recall and precision. Results-Without training specific to the four diseases, recall and precision of the system (combined effect of the processor and query generator) were 70% and 87%. Training of the query component increased recall to 85% without changing precision.",,"article; artificial intelligence; computer assisted diagnosis; hospital information system; human; medical record; semantics; Diagnosis, Computer-Assisted; Human; Medical Records; Natural Language Processing; Radiology Information Systems; Semantics; Support, Non-U.S. Gov't; Support, U.S. Gov't, P.H.S.",Article,Scopus
"Wiltgen M., Gell G., Graif E., Stubler S., Kainz A., Pitzler R.","An integrated picture archiving and communications system-radiology information system in a radiological department",1993,"Journal of Digital Imaging",9,"10.1007/BF03168413","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027551287&doi=10.1007%2fBF03168413&partnerID=40&md5=780a59350e1be6e17d6a81599b95caeb","In this report we present an integrated picture archiving and communication system (PACS)-radiology information system (RIS) which runs as part of the daily routine in the Department of Radiology at the University of Graz. Although the PACS and the RIS have been developed independently, the two systems are interfaced to ensure a unified and consistent long-term archive. The configuration connects four computer tomography scanners (one of them situated at a distance of 1 km), a magnetic resonance imaging scanner, a digital subtraction angiography unit, an evaluation console, a diagnostic console, an image display console, an archive with two optical disk drives, and several RIS terminals. The configuration allows the routine archiving of all examinations on optical disks independent of reporting. The management of the optical disks is performed by the RIS. Images can be selected for retrieval via the RIS by using patient identification or medical criteria. A special software process (PACS-MONITOR) enables the user to survey and manage image communication, archiving, and retrieval as well as to get information about the status of the system at any time and handle the different procedures in the PACS. The system is active 24 hours a day. To make the PACS operation as independent as possible from the permanent presence of a system manager (electronic data processing expert), a rule-based expert system (OPERAS; OPERating ASsistant) is in use to localize and eliminate malfunctions that occur during routine work. The PACS-RIS reduces labor and speeds access to images within radiology and clinical departments. © 1993 Society for Imaging Informatics in Medicine.","picture archiving and communication systems (PACS); radiological information systems (RIS)","article; Austria; computer network; computer program; hospital information system; human; organization and management; radiology department; Austria; Computer Communication Networks; Human; Radiology Department, Hospital; Radiology Information Systems; Software; Support, Non-U.S. Gov't",Article,Scopus
"Friedman C., Cimino J.J., Johnson S.B.","A conceptual model for clinical radiology reports.",1993,"Proceedings / the ... Annual Symposium on Computer Application [sic] in Medical Care. Symposium on Computer Applications in Medical Care",17,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027719379&partnerID=40&md5=1616d5ef3a5ad6fdca56021bb35bb4ac","The structural and informational content of clinical radiology reports was examined to develop a comprehensive representational schema of the concepts in the domain. The model involves several different conceptual levels, ranging from the high level description of the report to the lower level description of the clinical concepts contained in the reports and the specification of the terms used to express the concepts. The design of an adequate structured representation for the domain has important implications for the design of the electronic patient record, for the unification of different controlled vocabularies by enabling them to be mapped to one common representation, and for the facilitation of natural language processing of clinical reports so that coded data may be obtained.",,"article; documentation; hospital information system; human; medical record; natural language processing; nomenclature; theoretical model; Humans; Medical Records; Models, Theoretical; Natural Language Processing; Radiology Information Systems; Subject Headings; Terminology",Article,Scopus
"Bluemke D.A., Eng J.","An automated radiology reporting system that uses HyperCard",1993,"American Journal of Roentgenology",11,"10.2214/ajr.160.1.8416622","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027472007&doi=10.2214%2fajr.160.1.8416622&partnerID=40&md5=ab73149f0e7dd60b34f282ec0aad6e17","SCRIBE is an automated radiology reporting system that uses the HyperCard environment on Macintosh computers. Radiologic findings and anatomic terms are presented in graphic form, and the appropriate terms are selected by using a trackball or touch-sensitive video screen. Additional lists of more specific terms and differential diagnoses can be requested by the user for abnormal findings. The system is suited to the reporting of plain films and is being used in the emergency room of a large academic radiology department. Advantages of the system include low cost, operational familiarity to Macintosh users, and elimination of transcription costs. Finished reports are immediately available in both printed and electronic forms.",,"article; clinical practice; coding; computer system; cost effectiveness analysis; differential diagnosis; emergency ward; medical assessment; medical documentation; medical school; priority journal; radiodiagnosis; reliability",Article,Scopus
"Gillespy 3rd. T.","Advanced applications of personal computers in the radiologist's office.",1993,"Radiographics : a review publication of the Radiological Society of North America, Inc",2,"10.1148/radiographics.13.1.8426918","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027357832&doi=10.1148%2fradiographics.13.1.8426918&partnerID=40&md5=12bdfee4d8049b1cce6925e06a50941a","The author's department has found various advanced applications for the computer to be useful in daily practice. They use a data-base program to track interesting cases for later retrieval. The program automatically generates an American College of Radiology code based on the body part and diagnosis. The program is also used to track radiographic film quality. A barcode scanner attached to a computer at the film alternator is used to enter the accession number generated by the radiology information system. If any deficiencies are present, they are entered from a preprinted bar-code sheet. The bar-code scanner allows rapid entry of all examinations during the read-out session. Reports generated from the data base have been helpful in identifying and quantifying radiographic examination deficiencies. Department computers are also connected to the campus Ethernet network. This network allows radiologists to electronically verify radiology reports and to conduct electronic literature searches on the computers in their offices.",,"article; data base; medical record; microcomputer; radiology; Database Management Systems; Medical Records Systems, Computerized; Microcomputers; Radiology; MLCS; MLOWN",Article,Scopus
"Pilgram P.B.","Using a team approach to implement automatic printing of pathology/radiology reports.",1993,"Journal for healthcare quality : official publication of the National Association for Healthcare Quality",1,"10.1111/j.1945-1474.1993.tb00075.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027357405&doi=10.1111%2fj.1945-1474.1993.tb00075.x&partnerID=40&md5=c88d0f0185070c9813ac1e8e05015566","In a quality environment, improvement starts with a commitment from top management and flows down to all levels in the organization. One of the many ways in which an organization can demonstrate this commitment is by first listening to customers and then taking actions to improve services based on the identified needs of those the organization serves. This article describes a quality process in action and demonstrates how teamwork and commitment can produce the desired outcome: customer satisfaction.",,"article; consumer; hospital bed capacity; hospital department; management; medical record; methodology; organization and management; personnel management; public relations; radiology department; standard; task performance; United States; Consumer Satisfaction; Hospital Bed Capacity, 500 and over; Interdepartmental Relations; Management Audit; Management Quality Circles; Medical Records; Pathology Department, Hospital; Planning Techniques; Radiology Department, Hospital; Research Design; Task Performance and Analysis; Tennessee",Article,Scopus
"McDermott V.G.M., Chapman M.E., Gillespie I.","Sedation and patient monitoring in vascular and interventional radiology",1993,"British Journal of Radiology",30,"10.1259/0007-1285-66-788-667","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027320099&doi=10.1259%2f0007-1285-66-788-667&partnerID=40&md5=687eeb558decc8f5b0f788d92c7ecd79","A postal survey of British and Irish interventional radiologists was carried out in 1991 in order to assess current practice with respect to sedation and monitoring of patients during angiography and interventional procedures. The response rate was 65%. 49% of patients are fasted prior to angiography and 68% prior to interventional procedures. Radiologists participate in obtaining consent in 60% of cases. Patients are often (50%) sedated for angiography and usually (62-94% depending on the procedure) sedated for interventional procedures. Nurses are present for most procedures, but are given the task of monitoring the patient's vital signs in only 49% of cases. Anaesthetists are present for less than 10% of interventional procedures. Pulse oximetry is used routinely in 20% of departments, and automatic blood pressure monitors in 16%. 28% of radiologists never administer oxygen to patients under sedation, whereas 4% always do. 43% of departments have a staffed recovery area. Most vascular/interventional suites are stocked with emergency drugs and 80% with a defibrillator. 28% of departments report at least one death during or shortly after a procedure during the last 10 years. 18% of interventional radiologists have taken a refresher course in cardiopulmonary resuscitation in the past year. These findings indicate a wide variation in practice and a need to standardize practice at a uniform high level.",,"atropine; diamorphine; diazepam; fentanyl; flumazenil; midazolam; morphine; nalbuphine; naloxone; pentazocine; pethidine; temazepam; anesthesia; angiography; article; blood pressure monitoring; cardiovascular system; defibrillator; diet restriction; heart rate; human; interventional radiology; monitor; normal human; nurse; patient monitoring; priority journal; pulse oximetry; pulse rate; radiologist; resuscitation; sedation",Article,Scopus
"De Valois J.C., Overtoom Th. T.C., Holtkamp M.","Interventional radiology with the Integris C2000",1992,"MedicaMundi",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027058779&partnerID=40&md5=71cb23079ce42b184cc9048fa0f5cd67","The St. Antonius Hospital is a major referral centre for heart and vascular disease, as well as lung conditions. The Integris C2000 system, installed in the hospital in May 1990, has provided excellent results in an extensive range of vascular and non-vascular interventional procedures, as well as virtually every type of vascular diagnostic examination. The system has subsequently been upgraded, and now provides even better facilities. The system and its applications are described, and examples are given of the results obtained.",,"adult; angiocardiography; arteriovenous fistula; article; cardiology; case report; diagnostic imaging; false aneurysm; female; heart disease; human; information retrieval; interventional radiology; lung disease; male; transluminal coronary angioplasty; vascular disease",Article,Scopus
"Maloney Kris, Ovitt Theron W.M.D., Parra Miguel V.","Intelligent interface to model the radiologist's requirements for primary image interpretation",1992,"Proceedings of SPIE - The International Society for Optical Engineering",1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026989985&partnerID=40&md5=34211e53dc0d098ec2586d69392f2ae5","Many functional, technical, and perceptual considerations must be met before a workstation will be adequate for primary diagnosis. The focus of this paper is the functional aspect of the workstation. Specifically, we are concerned with determining how images and data must be presented to the radiologist, for the purpose of primary diagnosis, under the constraints imposed by the digital workstation. We have developed aninterface that is being used to acquire detailed information about the current diagnostic process. The purpose of this interface is twofold. First, this interface enables us to monitor the image and information access patterns of the radiologists in the process of interpreting films. This information is used to automate the presentation of images and information to the radiologist in future cases. Second, this interface provides a continuously evolving tool to capture the physical attributes, or navigational cues, necessary for the radiologist to develop a mental model of the operation of the diagnostic workstation. This report describes the current operation and future goals of this interface.",,"Computer workstations; Data acquisition; Diagnostic radiography; Digital image storage; Expert systems; Image analysis; Knowledge based systems; Nonbibliographic retrieval systems; Pattern recognition; User interfaces; Clinical image presentation; Diagnostic workstations; Digital workstations; Intelligent interfaces; Primary diagnosis; Primary image interpretation; Radiologist requirements; Medical imaging",Conference Paper,Scopus
"Reed R.A.","Voice recognition for the radiology market.",1992,"Topics in health record management",6,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026829544&partnerID=40&md5=087c344b45c3b4cce3372d895b229a85","Voice recognition is an exciting technology that is only starting to catch on in radiology. By reducing training time from days to several minutes, today's voice recognition systems are more practical than their predecessors. Voice recognition systems will improve the productivity of radiologists, allowing them to spend less time dictating their findings and more time concentrating on their specialty. Ultimately, the major benefit is increased patient care. As more and more hospitals become automated, voice recognition systems are a natural fit in this process. Radiology departments will be able to have integrated systems that will allow everything from initial patient entry, procedure status and tracking, and report dictation with voice recognition, to electronic report signature, report archiving, and patient billing.",,"article; computer interface; hospital information system; information processing; organization and management; productivity; radiology department; task performance; United States; voice; Automatic Data Processing; Efficiency; Radiology Department, Hospital; Radiology Information Systems; United States; User-Computer Interface; Voice; Work Simplification",Article,Scopus
"Frank M.S., Green D.W., Sasewich J.A., Johnson J.A.","Integration of a personal computer workstation and radiology information system for obstetric sonography",1992,"American Journal of Roentgenology",5,"10.2214/ajr.159.6.1442410","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026490459&doi=10.2214%2fajr.159.6.1442410&partnerID=40&md5=d54439d4e76080aa7e9d8f7ecf084b48","A personal computer workstation has been developed for storage and analysis of obstetric sonographic examinations. The workstation also serves as an interactive data terminal for our radiology information system. A data- base management program locally stores quantitative and descriptive sonographic results. Algorithms are used to analyze growth parameters over serial examinations, plot growth curves, generate a radiologic report, and provide instantaneous diagnostic assistance and suggestions. A bibliographic data-base system containing more than 3000 references (with abstracts) in the obstetric sonographic literature is integrated with the software's analytical functions. A telecommunications software module performs dialogues, such as immediate automatic transcription of the sonographic report, with the radiology information system. An examination summary form, growth curves, and the radiologist's report can be printed or digitally faxed by the workstation after authorization by the radiologist. The workstation has improved the organization of sonographic data, facilitated serial quantitative analysis, supplemented educational resources for our staff radiologists and residents, reduced transcription errors and transcription delays, and shortened to minutes the time necessary to deliver precise examination results to clinicians. This model is suitable for use in many areas in a radiology department.",,"article; computer system; echography; information processing; information retrieval; information system; obstetrics; priority journal; radiology",Article,Scopus
"Race Kevin","Radiologists speak to their computers",1990,"Physicians & computers",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025398380&partnerID=40&md5=8e98cbe7550764db5d6dc9dcaf8e55aa","A new development in voice technology is expected to save radiologists significant amounts of time in the process of dictating their reports and sending them back to the referring physician. With Lanier Voice Products' RADstation, a radiologist can see the report as it is dictated, ensuring its accuracy. Radiologists at Johns Hopkins Medical Center in Baltimore are among the first in the nation to use the speech-activated computer system. RADstation, which has a 30,000 word vocabulary, is designed to allow automatic transcription of documents as they are verbally reported by the radiologist. Now, radiologists 'see' medical reports and recommendations appear on a computer screen as they speak. Documents can be instantly forwarded to other physicians via facsimile and hard copies are produced for hospital records. With RADstation, reports can be completed and printed in as little as two minutes.",,"Computer Operating Systems--Report Generators; Signal Processing--Digital Techniques; Speech--Recognition; Automatic Verbal Report Transcription; Radiology Report Generators; Speech-Activated Computer Systems; Voice Recognition Systems; Radiography",Article,Scopus
"Mezrich Reuben S., Grossberg David, Fairman Randall","ImageNet: A HyperCard driven radiology workstation and image database",1989,"Proceedings - Annual Symposium on Computer Applications in Medical Care",1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024890778&partnerID=40&md5=77b741e8d6a8b78b138b12b4ea2177af","A description is given of a radiology workstation that combines the features of the Macintosh II computer, HyperCard software, and an Ethernet network to provide an inexpensive and flexible means for the acquisition, display, analysis, and storage of medical images. Images are acquired in seconds and displayed at the same resolution and gray scale as seen at the original medical imaging system. The images become an integral part of a database that combines clinical and demographic information with the pictorial detail, which is useful for general information retrieval as well as for clinical consultation, study comparison, and teaching files. The images can be formatted for slide presentation or printed on plain paper for inclusion in a report to a referring physician and can be analyzed for quantification of image detail.",,"Database Systems; Image Storage, Digital; Radiography--Diagnostic Applications; HyperCard Driven Radiology Workstation; Image Database; IMAGENET Radiology Workstation; Information Retrieval Systems",Conference Paper,Scopus
"Gavant M.L.","Development and implementation of the Veterans Administration's multihospital radiology information system",1989,"Journal of Digital Imaging",,"10.1007/BF03168038","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024718856&doi=10.1007%2fBF03168038&partnerID=40&md5=120abd1acdc255877cb2bd05a058a1b1","Unknown to most radiology professionals, the Veterans Administration (VA) is implementing an automated radiology information system as an integrated component of its Decentralized Hospital Computer Program. The basic design has been evaluated and refined over the past 5 years. It is now becoming available in all 172 VA medical facilities. Radiology services are provided in a complex management and fiscal environment. The primary purpose of the information system is to improve the efficient processing, performance, and reporting of requests for radiologic consultations and procedures. The automatic capturing of demographic and medical statistics will provide local and national managers more complete data with which to plan future financial, equipment, and personnel requirements. The VA radiology module has the potential to influence the shape of all future systems, commercial and public. This report describes the development of this radiology information system, its current status, and its potential impact on the largest health care system in the country. The module serves as an example of what can or should be expected from the radiology portion of a comprehensive medical information management system. © 1989 W.B. Saunders Company.",,"article; computer; computer program; computer system; forecasting; government; hospital information system; human; information retrieval; online system; public hospital; United States; Computer Systems; Computers; Forecasting; Hospitals, Veterans; Human; Information Storage and Retrieval; Online Systems; Radiology Information Systems; Software; United States; United States Department of Veterans Affairs",Article,Scopus
"Ranum David L.","Knowledge based understanding of radiology text",1988,"Proceedings - Annual Symposium on Computer Applications in Medical Care",11,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024111523&partnerID=40&md5=1a51b28ef492f085ad8d5577d489ac17","A data-acquisition tool which will extract pertinent diagnostic information from radiology reports has been designed and implemented. Pertinent diagnostic information is defined as that clinical data which is used by the HELP medical expert system. The program uses a memory-based semantic parsing technique to understand the text. Moreover, the memory structures and lexicon necessary to perform this action are automatically generated from the diagnostic knowledge base by a special-purpose compiler. The result is a system where data extraction from free text is directed by an expert system whose goal is diagnosis.",,"Artificial Intelligence--Expert Systems; Radiography--Diagnostic Applications; HELP Expert System; Knowledge Based Systems; Medical Expert Systems; Semantic Parsing; Biomedical Engineering",Conference Paper,Scopus
"Arenson Ronald, Viale Richard, van der Voorde Frans","ADVANCED MICROCOSTING SYSTEM FOR FORECASTING AND MANAGING RADIOLOGY EXPENSES.",1985,"Proceedings - Annual Symposium on Computer Applications in Medical Care",1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022305860&partnerID=40&md5=422ace59d0cecbc11d570c06692de84d","The new prospective payment system encourages hospital cost containment and necessitates understanding actual costs for radiology procedures. The automated microcosting system described here, utilizing data from the Radiology Information Management System, hospital expense reports, and payroll management reports, calculates an accurate unit cost for each procedure type. This data is very useful for cost control, enhancement of department efficiency, and planning.",,"DATA PROCESSING - Hospital Applications; AUTOMATED MICROCOSTING SYSTEM; COST CONTROL; RADIOLOGY PROCEDURES; HOSPITALS",Conference Paper,Scopus
"Mun S.K., Choyke P., Duerinckx A., Wang P., Benson H., Wang C., Elliott L.P.","Development of pacs at georgetown university radiology department",1985,"Proceedings of SPIE - The International Society for Optical Engineering",4,"10.1117/12.947366","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022269499&doi=10.1117%2f12.947366&partnerID=40&md5=41a6f2e91be0af9545f2295bd36230a2","Computer based information is becoming more common in the practice of modern radiology. Patient information, radiological reports and many radiological images are already in electronic digital format. There is also an increased application of computer technologies throughout the hospital. Use of hospital information system (HIS) and radiological information system (RIS)is receiving wider acceptance in the medical community, in an attempt to provide timely and efficient patient care. As more computer technologies and computer based management tools are utilized in the operation of the Radiology Department, full realization of integrated digital picture archiving and communication system (PACS) encompassing all the subsystems such as digital imaging devices, report generating system, archiving system, picture viewing system, information distribution system and administrative management component is becoming within the reach of currently available technologies (1,2). Only when all the patient data, radiological reports, images and administrative data can be simultaneously managed, will the full benefit of computer technology be realized in the practice of radiology. © 1985 SPIE.",,"DATA PROCESSING - Hospital Applications; DATABASE SYSTEMS; IMAGE PROCESSING; RADIOGRAPHY - Medical Applications; DATABASE MANAGEMENT; HOSPITAL INFORMATION SYSTEM; PICTURE ARCHIVING AND COMMUNICATION SYSTEM (PACS); REPORT GENERATION; WORKSTATION CONFIGURATION; INFORMATION RETRIEVAL SYSTEMS",Conference Paper,Scopus
"Richardson M.L.","Applications of an inexpensive microcomputer for the general radiologist",1983,"Computerized Radiology",1,"10.1016/0730-4862(83)90171-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0020535333&doi=10.1016%2f0730-4862%2883%2990171-3&partnerID=40&md5=041e510bf0431288148ca54931f55acf","Computer programs of interest to the general radiologist have been written by the author and others for an inexpensive microcomputer. Most of these programs are in the public domain and include: computer-assisted diagnosis; computer-assisted medical education; Bayesian analysis, general statistical analysis; word processing; and radiographic image analysis. Previously, computerized functions such as these have been limited to those with access to a large institutional computer. Due to the general availability of inexpensive microcomputers, the average radiologist or group can now afford the many benefits a computer can add to the practice of radiology. © 1982.","Artificial intelligence; Bayesian analysis; Computer assisted instruction; Computer diagnosis; Decision analysis; Information storage and retrieval; Microcomputer; Radiographic image analysis; Word-processing, radiographic report generation","BIOMEDICAL ENGINEERING - Computer Aided Diagnosis; DATA PROCESSING - Word Processing; IMAGE PROCESSING - Image Analysis; STATISTICAL METHODS - Computer Applications; MICROCOMPUTERS; RADIOGRAPHY; computer; computer analysis; diagnosis; image analysis; information retrieval; methodology; microcomputer; nonhuman; radiologist; Computer-Assisted Instruction; Computers; Cost-Benefit Analysis; Diagnosis, Computer-Assisted; Human; Information Systems; Microcomputers; Probability; Radiology; Statistics",Article,Scopus
"Quintin J.A., Simborg D.W.","University of California San Francisco automated radiology department system’ without picture archival and communication system (PACS)",1982,"Proceedings of SPIE - The International Society for Optical Engineering",,"10.1117/12.967672","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0020311096&doi=10.1117%2f12.967672&partnerID=40&md5=246cb21b6ab6fb21ee78511c3438617a","A Fully Automated And Comprehensive Radiology Department System Was Implemented In The Fall Of 1980, Which Highly Integrates The Multiple Functions Of A Large Radiology Department In A Major Medical Center. The Major Components Include Patient Registration, Film Track’Ing, Management Statistics, Patient Flow Control, Radiologist Reporting, Pathology Coding And Billing. The Highly Integrated Design Allows Sharing Of Critical Files To Reduce Redun’Dancy And Errors In Communication And Allows Rapid Dissemination Of Information Throughout The Department. As One Node Of An Integrated Distributed Hospital System, Information From Central Hospital Functions Such As Patient Identification Are Incorporated Into The System And Reports And Other Information Are Available To Other Hospital Systems. The System Is Implemented On A Data General Eclipse S/250 Using The Miis Operating System. The Management Of A Radiology Department Has Become Sufficiently Complex That The Application Of Computer Techniques To The Smooth Operation Of The Department Has Become Almost A Necessity. This System Provides Statistics On Room Utilization, Technologist Productivity, And Radiologist Activity. Room Utilization Graphs Are A Valuable Aid For Staffing And Schedul’Ing Of Technologists, As Well As Analyzing Appropriateness Of Radiologic Equipment In A Department. Daily Reports Summarize By Radiology Section Exams Not Dictated. File Room Reports Indicate Which Film Borrowers Are Delinquent In Returning Films For 24 Hours, 48 Hours And One Week. Letters To The Offenders Are Automatically Generated On The High Speed Line Printer. Although All Radiology Departments Have Similar Needs, Customization Is Likely To Be Required To Meet Specific Priorities And Needs At Any Individual Department. It Is Impor’Tant In Choosing A System Vendor That Such Flexibility Be Available. If Appropriately Designed, A System Will Provide Considerable Improvements In Efficiency And Effectiveness. © 1982 SPIE.",,"AUTOMATION; PATIENT REGISTRATION; PICTURE ARCHIVAL AND COMMUNICATION; RADIOLOGY; SAN FRANCISCO; UNIV. OF CALIF.; BIOMEDICAL ENGINEERING",Conference Paper,Scopus
"Fisher A.A.","Reactions to glutaraldehyde with particular reference to radiologists and X-ray technicians",1981,"Cutis",17,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0019828911&partnerID=40&md5=05432d9817d1ce682e760b357526f48d","Radiologists and x-ray technicians are exposed to glutaraldehyde in x-ray solutions. It has been established that glutaraldehyde is one of a number of chemicals which is present in x-ray solutions used for automatic processing. In fact, most 'rapid process' x-ray films contain glutaraldehyde in the emulsion. This is the first report of allergic contact dermatitis due to glutaraldehyde in a radiologist and x-ray technician from handling x-ray containing glutaraldehyde. All persons with hand dermatitis who handle x-ray films should have a patch test with 1 percent aqueous solution of glutaraldehyde.",,"glutaraldehyde; contact allergy; diagnosis; editorial; hand eczema; occupational eczema; radiological technologist; radiologist; Aldehydes; Dermatitis, Occupational; Glutaral; Hand Dermatoses; Human; Lung Diseases, Obstructive; Radiology; Technology, Radiologic; X-Ray Film",Article,Scopus
"Kolodny G.M.","A cost-effective radiology reporting system",1981,"Applied Radiology",5,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0019796258&partnerID=40&md5=b7fbbbe52bffae1a95e29b6147c83ba1","A system that provides referring physicians rapid access to dictated radiology reports via telephone has been in service in several institutions, including Massachusetts General Hospital, for periods up to five years. In a controlled study, it was shown to reduce significantly the delay between radiologist dictation and referring-physician access to reports. A referring physician phoning into the system hears the actual dictation. A recently introduced model of this system (Rapid Telephone Access System or RTAS, Sudbury Systems Inc, Sudbury, Mass) includes patient registration, automatic report printing, and remote typing. Another feature, digital speech compression and storage, makes the system substantially more cost effective than standard business dictation systems.",,"computer analysis; cost benefit analysis; diagnosis; economic aspect; information processing; methodology; radiography; radiotherapy; short survey; therapy; Computers; Cost-Benefit Analysis; Hospital Departments; Information Systems; Microcomputers; Modems; Radiology Department, Hospital; Telephone",Article,Scopus
"Burnett L.L.","A simple hospital radiology information system",1980,"Radiology",,"10.1148/radiology.136.2.7403508","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0018938156&doi=10.1148%2fradiology.136.2.7403508&partnerID=40&md5=b51d4a9a4287f6d7b7668e79ec6ef43c","The film jackets of hospitalized patients are filed in a consultation room according to hospital room and bed number. A single file clerk handles inpatient activity, which includes the expedited preparation of radiographs for reporting, as well as the filing and delivery of the reports to other departments of the 321-bed hospital. Clinicians have easy, immediate access to the radiographs, the consultation of a radiologist, and the report. This results in the meaningful transfer of information. The system requires minimal space and no investment in automated viewers or additional clerical personnel. Acceptance by the clinicians, the staff, and the radiologists has been enthusiastic.",,"classification; diagnosis; image storage; information retrieval; methodology; radiography",Article,Scopus
"Horn B.A., Brown W.J., Randall M.G.","Computerized data management system for diagnostic radiology-equipment performance and service",1979,"Proceedings of SPIE - The International Society for Optical Engineering",,"10.1117/12.957139","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957505852&doi=10.1117%2f12.957139&partnerID=40&md5=385e6929d208aedb0b8cc24865a5a30a","A data management system, implemented on a minicomputer, has been developed to provide rapid and convenient access to parts, service, performance, and radiation safety records for diagnostic x-ray equipment. The system is designed to provide on-line information retrieval and reporting for the regional medical physics/x-ray service organization for our seven medical centers and their associated clinics. The on-line data base contains: Complete information describing each x-ray system; parts inventories at each medical center and at regional service headquarters; and detailed summaries of all service, preventive maintenance, performance, and radiation safety reports for the previous two years and the current year-to-date. Data includes, in part, labor times, system downtime, problem areas and types, parts used, tube potential and current calibration, half-value layers, and radiation safety noncompliances to be corrected. In addition to retrieval of information for display on a CRT terminal, printed reports can be obtained on demand which summarize the financial transactions on a monthly and year-to’date basis. Additional reports describing parts inventories, x-ray system histories, and statistical summaries of service problems may also be printed on demand. The specific contents of the data base, correlative capabilities of the system, and examples of available reports will be discussed. © 1979 SPIE.",,"Diagnostic radiography; Hospitals; Medical information systems; Preventive maintenance; Radiation shielding; Search engines; X ray apparatus; X rays; Complete information; Data management system; Diagnostic radiology; Diagnostic X-ray equipment; Equipment performance; Financial transactions; Service organizations; Statistical summary; Information management",Conference Paper,Scopus
"Oestreich A.E., Hakimi B.R.","The computer as an aid in the daily practice of pediatric radiology",1978,"Pediatric Radiology",,"10.1007/BF00975680","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0017816284&doi=10.1007%2fBF00975680&partnerID=40&md5=ca1c889b81c47eb538c8cc63af4f3551","The use of a relatively small computer limited to a Department of Radiology has considerable benefit in report generation and information retrieval. In addition, the arithmetical tasks of pediatric radiological reporting procedures such as bone age and scanograms have been automated, and other helpful features have arisen. © 1978 Springer-Verlag.","Bone age; Computers in radiology","bone; bone age; computer; computer analysis; diagnosis; infant; methodology; newborn; preschool child; radiography; school child; Child; Child, Preschool; Computers; Hospital Departments; Human; Pediatrics; Radiography; Radiology Department, Hospital",Article,Scopus
"Simborg D.W., Krajci E.J., Wheeler P.S., Gitlin J.N., Goldstein K.S.","Computer-assisted radiology reporting: quality of reports",1977,"Radiology",5,"10.1148/125.3.587","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0017745035&doi=10.1148%2f125.3.587&partnerID=40&md5=62bdb9bbfdbe336a590caa7e95d4ee04","Automated medical communication systems for patient care usually enhance timeliness and retrievability. The effect of automated systems on communication quality has not been sufficiently measured. The radiology reports produced with the automated radiology reporting system at the Johns Hopkins Hospital were evaluated for quality and compared to reports produced by dictation. No differences in quality between computer-generated and dictated reports were detected by three consultant radiologists using a specially designed quality rating system.",,"computer; computer analysis; diagnosis; methodology; radiography",Article,Scopus
"Katz A., Budkin A., Shupler R.","An automated radiology information system",1977,"Radiology",6,"10.1148/124.3.699","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0017704428&doi=10.1148%2f124.3.699&partnerID=40&md5=836b244635eaa70bff55d9ba5a12b2b7","An automated radiology department information system, serving the diagnostic radiology and nuclear medicine divisions, has been developed. Radiology applications are part of a centralized data processing operation which incorporates clinical, administrative, research, and teaching subsets. The radiology subset includes remote on line ordering/reporting, automated examination census and statistics, an on line adult trail/workload control program, and financial reports. The software is linked to other hospital applications. This system improved report turn around times, decreased clerical loads, and provided better financial management.",,"radioisotope; computer; computer analysis; diagnosis; information system; nuclear medicine; radiography",Article,Scopus
"Wheeler P.S., Simborg D.W., Gitlin J.N.","The Johns Hopkins radiology reporting system",1976,"RADIOLOGY",23,"10.1148/119.2.315","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0017284453&doi=10.1148%2f119.2.315&partnerID=40&md5=a4e055907f7e18870e917cdf38c0e1fb","Radiologists can comprehensively report diagnostic radiographs by computer with a speed approaching that of dictation. This is the main mode of radiographic reporting used at the Johns Hopkins Hospital. Support functions include information storage, retrieval, statistics, and billing. Costs are comparable to stenography. The system can be run from a large time sharing computer or dedicated minicomputer. A commercial stand alone version will soon be available.",,"computer; computer analysis; diagnosis; methodology; radiography",Article,Scopus
"Mani R.L.","RAPORT radiology system: Results of clinical trials",1976,"American Journal of Roentgenology",11,"10.2214/ajr.127.5.811","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0017185851&doi=10.2214%2fajr.127.5.811&partnerID=40&md5=1323485a62b18633a59f488c45392b09","RAPORT(TM), (TM), an automated radiology management and reporting system, is currently operational in more than 25 hospital departments of varying sizes and types. Data have been gathered from 19 installations in operation for 6 months or longer and four systems which failed. Findings were as follows: Mark sense forms were used in 71% of cases (29% dictation) and for an average of 70% of all pathologic material. Report turnaround time ranged from 0.1 to 6 hr (average 2.5 hr) depending on departmental priorities and organization. Rejection of the system was based upon inadequate documentation of needs prior to installation, poor preparation of staff members, and underestimation of the impact of computer systems on existing organizations. System downtime averaged 2.5 hr per month. The ratio of pathologic to normal reports did not vary significantly among university, government, and private hospitals. RAPORT can no longer be considered an experimental system. Properly managed, it is an effective administrative tool which can significantly improve departmental service.",,"classification; diagnosis; methodology; radiology; therapy",Article,Scopus
"Weintraub H.D., Worcester J., Resnic A., Kolodny G.M.","Clinical evaluation of the rapid telephone access system for radiology reporting",1976,"Radiology",1,"10.1148/121.2.349","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0017089129&doi=10.1148%2f121.2.349&partnerID=40&md5=96529b8f490a8e69ae878787e4d52786","The Rapid Telephone Access System (RTAS) for radiology reporting was evaluated clinically among patients undergoing fluoroscopy, excretory urography, orcholecystography at a community based teaching hospital. After the radiologist has dictated his report in the customary manner, it can be heard by the referring physician using any telephone. Reports can be reduced to hard copy by a typist, or an automatic typewriter can be programmed to print normal or standard reports. Time between dictation and access of the report was significantly reduced after installation of the RTAS (p<0.001). There was also a trend toward reduced hospital stay (p<0.05) for patients in the study group. The system has been readily accepted by radiologists and referring physicians.",,"computer analysis; diagnosis; radiography; telephone",Article,Scopus
"Barnhard H.J., Jacobson H.G., Nance J.W.","Diagnostic radiology information system (DRIS)",1974,"Radiologe",4,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0016169247&partnerID=40&md5=96567123700e4c1a07eecd5b538a8af0","The Diagnostic Radiology Information System (DRIS) is a batch operating computer system which accepts the dictation of radiologists for computer analysis. The dictation is text analyzed for auto indexed computer files that facilitate rapid and inexpensive retrospective searches based upon anatomical and pathological terms as normally used by the radiologist in natural language. Management information statistics are readily available to administrative personnel to facilitate departmental organization and management and the improved delivery of health care. DRIS is written in ANS FORTRAN for medium to large computers and is readily transferred from one computer to another. The method of capturing the data for input to the system is optional and may vary from a simple typewriter magnetic tape device to an extremely sophisticated report generation system requiring a great amount of radiologist interaction. It is anticipated that the majority of DRIS users will continue with the time tested techniques of radiology dictation and secretarial transcription.",,"computer; computer analysis; computer program; diagnosis; information processing; methodology; radiodiagnosis; thesaurosis; X ray picture; Diagnosis, Computer-Assisted; Human; Information Systems; Medical Records; Radiology; Subject Headings; United States",Article,Scopus
"Abrams H.L.","Clinical problems in radiology",1974,"Contemporary Surgery",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0016366407&partnerID=40&md5=91bd0dd3e6c1704fa1077cd437595bfd","The roentgenographic 'metastatic bone survey' has traditionally represented the major modality for detecting tumor spread to bone in the asymptomatic patient. Its usefulness has been seriously questioned since the appearance of reports indicating that a significant percentage of osseous metastases were not visible on radiographic studies. This reflects the large volume of bone that must be destroyed before metastases become visible. In recent years it has become clear that bone scintigraphy is capable of visualizing metastatic bone disease when radiographic studies have failed to do so. The method has, therefore, been applied increasingly to this problem, with fruitful results. The authors summarize the state of the art and placed the method in perspective. They emphasize that this valuable technique complements rather than replaces the radiograph, and that optimal data retrieval depends on the strategic and parallel use of both techniques. Once the bone scan detects the abnormal area, the roentgenogram may provide critical and more specific information as to its character.",,"radioisotope; technetium polyphosphate tc 99m; unclassified drug; bone metastasis; bone scintiscanning; cancer; diagnosis; major clinical study; methodology; orthopedics; review; scintillation camera; scintiscanning; skeleton; skeleton radiography",Article,Scopus
"Simon M., Leeming B.W., Bleich H.L., Reiffen B., Byrd J., Blair D., Shimm D.","Computerized radiology reporting using coded language",1974,"Radiology",15,"10.1148/113.2.343","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0016274018&doi=10.1148%2f113.2.343&partnerID=40&md5=529b21676235168e271fe51c7ade84dd","A logical and comprehensive classification code has been built into a computerized system to permit the direct generation of radiologic reports. The report appears instantly on the television screen and, upon approval, is typed out both in the patient's area and radiology department, bypassing the traditional transcription and delivery process. No secretary or mail clerk is needed. Since precoded input is used, data retrieval will be highly efficient and accurate. Computer operating costs will be competitive with conventional manual reporting. The CLIP (Coded Language Information Processing) system is presently undergoing clinical trial.",,"computer; computer analysis; computer program; diagnosis; medical record; methodology; radiology; therapy",Article,Scopus
"Kolodny G.M.","Access of radiology reports",1974,"Radiology",,"10.1148/111.3.597","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0016156230&doi=10.1148%2f111.3.597&partnerID=40&md5=5435396532a438a4d8f307eade2879d2","The delay between the radiological diagnosis and its availability to the referring physician is a serious problem in the delivery of health care, accounting for as much as $1,500,000 per yr in health care costs at a large city hospital. Components of an ideal system which would provide rapid access to radiology reports are discussed, and various alternative systems are analyzed. It is suggested that telephone access to the radiologist's oral report would meet many of these requirements. However, there are major limitations to available commercial equipment now used for related purposes.",,"article; classification; diagnosis; information processing; information retrieval; methodology; radiodiagnosis",Article,Scopus
